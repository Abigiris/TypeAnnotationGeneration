{
    "literate-lamp-master/literate_lamp/args.py": {
        "list_models": {
            "name": "list_models",
            "location": 12,
            "return": [
                "None"
            ],
            "arguments": {
                "models": [
                    "List[str]"
                ]
            }
        },
        "get_args": {
            "name": "get_args",
            "location": 19,
            "return": [
                "DotDict"
            ],
            "arguments": {
                "arguments": [
                    "Optional[List[str]]"
                ]
            }
        },
        "get_args.preprocessed_name": {
            "name": "preprocessed_name",
            "location": 138,
            "return": [
                "str"
            ],
            "arguments": {
                "split_type": [
                    "str"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/common.py": {
        "set_args": {
            "name": "set_args",
            "location": 30,
            "return": [
                "None"
            ],
            "arguments": {
                "args": [
                    "args.DotDict"
                ]
            }
        },
        "get_seq2seq": {
            "name": "get_seq2seq",
            "location": 35,
            "return": [
                "Callable[([int, int, int, bool, float], Seq2SeqEncoder)]"
            ],
            "arguments": {
                "encoder_type": [
                    "Optional[str]"
                ]
            }
        },
        "get_encoder": {
            "name": "get_encoder",
            "location": 48,
            "return": [
                "Callable[([int, int, int, bool, float], Seq2VecEncoder)]"
            ],
            "arguments": {
                "encoder_type": [
                    "Optional[str]"
                ]
            }
        },
        "get_word_embeddings": {
            "name": "get_word_embeddings",
            "location": 64,
            "return": [
                "TextFieldEmbedder"
            ],
            "arguments": {
                "vocabulary": [
                    "Vocabulary"
                ]
            }
        },
        "build_dmn": {
            "name": "build_dmn",
            "location": 81,
            "return": [
                "Model"
            ],
            "arguments": {
                "vocabulary": [
                    "Vocabulary"
                ]
            }
        },
        "build_relational_xl": {
            "name": "build_relational_xl",
            "location": 115,
            "return": [
                "Model"
            ],
            "arguments": {
                "vocabulary": [
                    "Vocabulary"
                ]
            }
        },
        "build_advanced_xlnet": {
            "name": "build_advanced_xlnet",
            "location": 167,
            "return": [
                "Model"
            ],
            "arguments": {
                "vocab": [
                    "Vocabulary"
                ]
            }
        },
        "build_simple_xlnet": {
            "name": "build_simple_xlnet",
            "location": 210,
            "return": [
                "Model"
            ],
            "arguments": {
                "vocabulary": [
                    "Vocabulary"
                ]
            }
        },
        "build_dcmn": {
            "name": "build_dcmn",
            "location": 219,
            "return": [
                "Model"
            ],
            "arguments": {
                "vocabulary": [
                    "Vocabulary"
                ]
            }
        },
        "build_rel_han": {
            "name": "build_rel_han",
            "location": 242,
            "return": [
                "Model"
            ],
            "arguments": {
                "vocab": [
                    "Vocabulary"
                ]
            }
        },
        "build_relational_transformer": {
            "name": "build_relational_transformer",
            "location": 341,
            "return": [
                "Model"
            ],
            "arguments": {
                "vocab": [
                    "Vocabulary"
                ]
            }
        },
        "build_hierarchical_attn_net": {
            "name": "build_hierarchical_attn_net",
            "location": 427,
            "return": [
                "Model"
            ],
            "arguments": {
                "vocab": [
                    "Vocabulary"
                ]
            }
        },
        "build_advanced_attn_bert": {
            "name": "build_advanced_attn_bert",
            "location": 499,
            "return": [
                "Model"
            ],
            "arguments": {
                "vocab": [
                    "Vocabulary"
                ]
            }
        },
        "build_hierarchical_bert": {
            "name": "build_hierarchical_bert",
            "location": 554,
            "return": [
                "Model"
            ],
            "arguments": {
                "vocab": [
                    "Vocabulary"
                ]
            }
        },
        "build_zero_trian": {
            "name": "build_zero_trian",
            "location": 605,
            "return": [
                "Model"
            ],
            "arguments": {
                "vocab": [
                    "Vocabulary"
                ]
            }
        },
        "build_simple_trian": {
            "name": "build_simple_trian",
            "location": 694,
            "return": [
                "Model"
            ],
            "arguments": {
                "vocab": [
                    "Vocabulary"
                ]
            }
        },
        "build_advanced_bert": {
            "name": "build_advanced_bert",
            "location": 785,
            "return": [
                "Model"
            ],
            "arguments": {
                "vocab": [
                    "Vocabulary"
                ]
            }
        },
        "build_simple_bert": {
            "name": "build_simple_bert",
            "location": 830,
            "return": [
                "Model"
            ],
            "arguments": {
                "vocab": [
                    "Vocabulary"
                ]
            }
        },
        "build_baseline": {
            "name": "build_baseline",
            "location": 846,
            "return": [
                "Model"
            ],
            "arguments": {
                "vocab": [
                    "Vocabulary"
                ]
            }
        },
        "build_attentive_reader": {
            "name": "build_attentive_reader",
            "location": 869,
            "return": [
                "Model"
            ],
            "arguments": {
                "vocab": [
                    "Vocabulary"
                ]
            }
        },
        "build_trian": {
            "name": "build_trian",
            "location": 898,
            "return": [
                "Model"
            ],
            "arguments": {
                "vocab": [
                    "Vocabulary"
                ]
            }
        },
        "create_reader": {
            "name": "create_reader",
            "location": 998,
            "return": [
                "readers.BaseReader"
            ],
            "arguments": {
                "reader_type": [
                    "str"
                ]
            }
        },
        "get_modelfn_reader": {
            "name": "get_modelfn_reader",
            "location": 1063,
            "return": [
                "Tuple[(Callable[([Vocabulary], Model)], str)]"
            ],
            "arguments": {}
        },
        "split_list": {
            "name": "split_list",
            "location": 1071,
            "return": [
                "Dict[(str, List[Instance])]"
            ],
            "arguments": {
                "data": [
                    "List[Instance]"
                ]
            }
        },
        "evaluate": {
            "name": "evaluate",
            "location": 1081,
            "return": [
                "None"
            ],
            "arguments": {
                "model": [
                    "Model"
                ],
                "reader": [
                    "readers.BaseReader"
                ],
                "test_data": [
                    "List[Instance]"
                ]
            }
        },
        "print_dmn_instance": {
            "name": "print_dmn_instance",
            "location": 1111,
            "return": [
                "None"
            ],
            "arguments": {
                "instance": [
                    "Instance"
                ],
                "prediction": [
                    "torch.Tensor"
                ]
            }
        },
        "print_base_instance": {
            "name": "print_base_instance",
            "location": 1124,
            "return": [
                "None"
            ],
            "arguments": {
                "instance": [
                    "Instance"
                ],
                "prediction": [
                    "torch.Tensor"
                ]
            }
        },
        "process_dmn_list": {
            "name": "process_dmn_list",
            "location": 1137,
            "return": [
                "str"
            ],
            "arguments": {
                "fields": [
                    "ListField"
                ]
            }
        },
        "print_xlnet_instance": {
            "name": "print_xlnet_instance",
            "location": 1143,
            "return": [
                "None"
            ],
            "arguments": {
                "instance": [
                    "Instance"
                ],
                "probability": [
                    "torch.Tensor"
                ]
            }
        },
        "process_bert_list": {
            "name": "process_bert_list",
            "location": 1168,
            "return": [
                "Tuple[(str, str, str)]"
            ],
            "arguments": {
                "fields": [
                    "ListField"
                ]
            }
        },
        "print_bert_instance": {
            "name": "print_bert_instance",
            "location": 1181,
            "return": [
                "None"
            ],
            "arguments": {
                "instance": [
                    "Instance"
                ],
                "prediction": [
                    "torch.Tensor"
                ]
            }
        },
        "error_analysis": {
            "name": "error_analysis",
            "location": 1195,
            "return": [
                "None"
            ],
            "arguments": {
                "model": [
                    "Model"
                ],
                "test_data": [
                    "List[Instance]"
                ],
                "sample_size": [
                    "int"
                ]
            }
        },
        "print_instance": {
            "name": "print_instance",
            "location": 1231,
            "return": [
                "None"
            ],
            "arguments": {
                "passage_id": [
                    "str"
                ],
                "question_id": [
                    "str"
                ],
                "question_type": [
                    "str"
                ],
                "passage": [
                    "str"
                ],
                "question": [
                    "str"
                ],
                "answer1": [
                    "str"
                ],
                "answer2": [
                    "str"
                ],
                "probability": [
                    "torch.Tensor"
                ],
                "label": [
                    "int"
                ]
            }
        },
        "print_xlnet_instance.clean": {
            "name": "clean",
            "location": 1146,
            "return": [
                "str"
            ],
            "arguments": {
                "string": [
                    "str"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/conceptnet.py": {
        "triple_as_sentence": {
            "name": "triple_as_sentence",
            "location": 95,
            "return": [
                "str"
            ],
            "arguments": {
                "triple": [
                    "Tuple[(str, str, str)]"
                ]
            }
        },
        "ConceptNet.__init__": {
            "name": "__init__",
            "location": 19,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "conceptnet_path": [
                    "Optional[Path]"
                ]
            }
        },
        "ConceptNet.get_relation": {
            "name": "get_relation",
            "location": 35,
            "return": [
                "str"
            ],
            "arguments": {
                "self": [],
                "word1": [
                    "str"
                ],
                "word2": [
                    "str"
                ]
            }
        },
        "ConceptNet.get_all_text_query_triples": {
            "name": "get_all_text_query_triples",
            "location": 50,
            "return": [
                "Set[Tuple[(str, str, str)]]"
            ],
            "arguments": {
                "self": [],
                "text": [
                    "Sequence[str]"
                ],
                "query": [
                    "Sequence[str]"
                ]
            }
        },
        "ConceptNet.get_text_query_relations": {
            "name": "get_text_query_relations",
            "location": 73,
            "return": [
                "List[str]"
            ],
            "arguments": {
                "self": [],
                "text": [
                    "Sequence[str]"
                ],
                "query": [
                    "Sequence[str]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/graph.py": {
        "main": {
            "name": "main",
            "location": 5,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "literate-lamp-master/literate_lamp/layers.py": {
        "learned_embeddings": {
            "name": "learned_embeddings",
            "location": 243,
            "return": [
                "BasicTextFieldEmbedder"
            ],
            "arguments": {
                "vocab": [
                    "Vocabulary"
                ],
                "dimension": [
                    "int"
                ],
                "namespace": [
                    "str"
                ]
            }
        },
        "bert_embeddings": {
            "name": "bert_embeddings",
            "location": 253,
            "return": [
                "BasicTextFieldEmbedder"
            ],
            "arguments": {
                "pretrained_model": [
                    "Path"
                ],
                "training": [
                    "bool"
                ],
                "top_layer_only": [
                    "bool"
                ]
            }
        },
        "xlnet_embeddings": {
            "name": "xlnet_embeddings",
            "location": 269,
            "return": [
                "BasicTextFieldEmbedder"
            ],
            "arguments": {
                "config_path": [
                    "Path"
                ],
                "model_path": [
                    "Path"
                ],
                "window_size": [
                    "Optional[int]"
                ],
                "training": [
                    "bool"
                ],
                "top_layer_only": [
                    "bool"
                ]
            }
        },
        "glove_embeddings": {
            "name": "glove_embeddings",
            "location": 289,
            "return": [
                "BasicTextFieldEmbedder"
            ],
            "arguments": {
                "vocab": [
                    "Vocabulary"
                ],
                "file_path": [
                    "Path"
                ],
                "dimension": [
                    "int"
                ],
                "training": [
                    "bool"
                ],
                "namespace": [
                    "str"
                ]
            }
        },
        "lstm_seq2seq": {
            "name": "lstm_seq2seq",
            "location": 303,
            "return": [
                "Seq2SeqEncoder"
            ],
            "arguments": {
                "input_dim": [
                    "int"
                ],
                "output_dim": [
                    "int"
                ],
                "num_layers": [
                    "int"
                ],
                "bidirectional": [
                    "bool"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "gru_seq2seq": {
            "name": "gru_seq2seq",
            "location": 315,
            "return": [
                "Seq2SeqEncoder"
            ],
            "arguments": {
                "input_dim": [
                    "int"
                ],
                "output_dim": [
                    "int"
                ],
                "num_layers": [
                    "int"
                ],
                "bidirectional": [
                    "bool"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "transformer_seq2seq": {
            "name": "transformer_seq2seq",
            "location": 327,
            "return": [
                "Seq2SeqEncoder"
            ],
            "arguments": {
                "input_dim": [
                    "int"
                ],
                "model_dim": [
                    "int"
                ],
                "feedforward_hidden_dim": [
                    "int"
                ],
                "num_layers": [
                    "int"
                ],
                "projection_dim": [
                    "int"
                ],
                "num_attention_heads": [
                    "int"
                ],
                "ttype": [
                    "str"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "lstm_encoder": {
            "name": "lstm_encoder",
            "location": 358,
            "return": [
                "Seq2VecEncoder"
            ],
            "arguments": {
                "input_dim": [
                    "int"
                ],
                "output_dim": [
                    "int"
                ],
                "num_layers": [
                    "int"
                ],
                "bidirectional": [
                    "bool"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "gru_encoder": {
            "name": "gru_encoder",
            "location": 370,
            "return": [
                "Seq2VecEncoder"
            ],
            "arguments": {
                "input_dim": [
                    "int"
                ],
                "output_dim": [
                    "int"
                ],
                "num_layers": [
                    "int"
                ],
                "bidirectional": [
                    "bool"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "cnn_encoder": {
            "name": "cnn_encoder",
            "location": 382,
            "return": [
                "Seq2VecEncoder"
            ],
            "arguments": {
                "input_dim": [
                    "int"
                ],
                "output_dim": [
                    "int"
                ],
                "num_filters": [
                    "int"
                ],
                "ngram_filter_sizes": [
                    "Tuple[(int, ...)]"
                ]
            }
        },
        "BilinearMatrixAttention.__init__": {
            "name": "__init__",
            "location": 52,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "matrix1_dim": [
                    "int"
                ],
                "matrix2_dim": [
                    "int"
                ],
                "normalise": [
                    "bool"
                ]
            }
        },
        "BilinearMatrixAttention._forward_internal": {
            "name": "_forward_internal",
            "location": 61,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "matrix1": [
                    "torch.Tensor"
                ],
                "matrix2": [
                    "torch.Tensor"
                ]
            }
        },
        "LinearAttention.__init__": {
            "name": "__init__",
            "location": 78,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [
                    "int"
                ],
                "bias": [
                    "bool"
                ]
            }
        },
        "LinearAttention.forward": {
            "name": "forward",
            "location": 85,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "torch.Tensor"
                ],
                "mask": [
                    "Optional[torch.Tensor]"
                ]
            }
        },
        "LinearAttention.get_input_dim": {
            "name": "get_input_dim",
            "location": 116,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "LinearAttention.get_output_dim": {
            "name": "get_output_dim",
            "location": 120,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "LinearSelfAttention.__init__": {
            "name": "__init__",
            "location": 147,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [
                    "int"
                ],
                "normalise": [
                    "bool"
                ],
                "bias": [
                    "bool"
                ]
            }
        },
        "LinearSelfAttention._forward_internal": {
            "name": "_forward_internal",
            "location": 157,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "vector": [
                    "torch.Tensor"
                ],
                "_": [
                    "torch.Tensor"
                ]
            }
        },
        "BilinearAttention.__init__": {
            "name": "__init__",
            "location": 186,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vector_dim": [
                    "int"
                ],
                "matrix_dim": [
                    "int"
                ],
                "normalise": [
                    "bool"
                ]
            }
        },
        "BilinearAttention._forward_internal": {
            "name": "_forward_internal",
            "location": 195,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "vector": [
                    "torch.Tensor"
                ],
                "matrix": [
                    "torch.Tensor"
                ]
            }
        },
        "SequenceAttention.__init__": {
            "name": "__init__",
            "location": 225,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [
                    "int"
                ],
                "activation": [
                    "Optional[Activation]"
                ],
                "normalise": [
                    "bool"
                ]
            }
        },
        "SequenceAttention._forward_internal": {
            "name": "_forward_internal",
            "location": 235,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "u": [
                    "torch.Tensor"
                ],
                "v": [
                    "torch.Tensor"
                ]
            }
        },
        "MultiHeadAttention.__init__": {
            "name": "__init__",
            "location": 430,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_heads": [
                    "int"
                ],
                "query_input_dim": [
                    "int"
                ],
                "key_input_dim": [
                    "int"
                ],
                "value_input_dim": [
                    "int"
                ],
                "attention_dim": [
                    "int"
                ],
                "values_dim": [
                    "int"
                ],
                "output_projection_dim": [
                    "int"
                ],
                "attention_dropout_prob": [
                    "float"
                ]
            }
        },
        "MultiHeadAttention.get_input_dim": {
            "name": "get_input_dim",
            "location": 471,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultiHeadAttention.get_output_dim": {
            "name": "get_output_dim",
            "location": 474,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultiHeadAttention.is_bidirectional": {
            "name": "is_bidirectional",
            "location": 478,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultiHeadAttention.forward": {
            "name": "forward",
            "location": 482,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "keys": [
                    "torch.Tensor"
                ],
                "queries": [
                    "torch.Tensor"
                ],
                "values": [
                    "torch.Tensor"
                ],
                "mask": [
                    "torch.Tensor"
                ]
            }
        },
        "HeterogenousSequenceAttention.__init__": {
            "name": "__init__",
            "location": 597,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "u_input_dim": [
                    "int"
                ],
                "v_input_dim": [
                    "int"
                ],
                "projection_dim": [
                    "int"
                ],
                "activation": [
                    "Optional[Activation]"
                ]
            }
        },
        "HeterogenousSequenceAttention.get_input_dim": {
            "name": "get_input_dim",
            "location": 612,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "HeterogenousSequenceAttention.get_output_dim": {
            "name": "get_output_dim",
            "location": 615,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "HeterogenousSequenceAttention.is_bidirectional": {
            "name": "is_bidirectional",
            "location": 619,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "HeterogenousSequenceAttention.forward": {
            "name": "forward",
            "location": 623,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "u": [
                    "torch.Tensor"
                ],
                "v": [
                    "torch.Tensor"
                ],
                "v_mask": [
                    "Optional[torch.Tensor]"
                ]
            }
        },
        "MultiHeadAttentionV2.__init__": {
            "name": "__init__",
            "location": 668,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_heads": [
                    "int"
                ],
                "u_input_dim": [
                    "int"
                ],
                "v_input_dim": [
                    "int"
                ],
                "attention_dim": [
                    "int"
                ],
                "output_projection_dim": [
                    "int"
                ],
                "attention_dropout_prob": [
                    "float"
                ]
            }
        },
        "MultiHeadAttentionV2.get_input_dim": {
            "name": "get_input_dim",
            "location": 696,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultiHeadAttentionV2.get_output_dim": {
            "name": "get_output_dim",
            "location": 699,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultiHeadAttentionV2.is_bidirectional": {
            "name": "is_bidirectional",
            "location": 703,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultiHeadAttentionV2._reshape_outputs": {
            "name": "_reshape_outputs",
            "location": 706,
            "return": [
                "torch.FloatTensor"
            ],
            "arguments": {
                "self": [],
                "outputs": [
                    "torch.FloatTensor"
                ]
            }
        },
        "MultiHeadAttentionV2._reshape_heads": {
            "name": "_reshape_heads",
            "location": 724,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "x": [
                    "torch.Tensor"
                ]
            }
        },
        "MultiHeadAttentionV2._multiply_and_mask": {
            "name": "_multiply_and_mask",
            "location": 737,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "q": [
                    "torch.Tensor"
                ],
                "k": [
                    "torch.Tensor"
                ],
                "k_mask": [
                    "torch.Tensor"
                ]
            }
        },
        "MultiHeadAttentionV2.forward": {
            "name": "forward",
            "location": 754,
            "return": [
                "Tuple[(torch.FloatTensor, torch.FloatTensor)]"
            ],
            "arguments": {
                "self": [],
                "u": [
                    "torch.Tensor"
                ],
                "v": [
                    "torch.Tensor"
                ],
                "u_mask": [
                    "torch.LongTensor"
                ],
                "v_mask": [
                    "torch.LongTensor"
                ]
            }
        },
        "TransformerEncoderBlock.__init__": {
            "name": "__init__",
            "location": 826,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "model_dim": [
                    "int"
                ],
                "attention_dim": [
                    "int"
                ],
                "num_heads": [
                    "int"
                ],
                "feedforward_dim": [
                    "int"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "TransformerEncoderBlock.forward": {
            "name": "forward",
            "location": 856,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "src": [
                    "torch.Tensor"
                ],
                "src_mask": [
                    "torch.Tensor"
                ]
            }
        },
        "RelationTransformerEncoderBlock.__init__": {
            "name": "__init__",
            "location": 871,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "model_dim": [
                    "int"
                ],
                "attention_dim": [
                    "int"
                ],
                "num_heads": [
                    "int"
                ],
                "feedforward_dim": [
                    "int"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "RelationTransformerEncoderBlock._second_stage": {
            "name": "_second_stage",
            "location": 899,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "x": [
                    "torch.Tensor"
                ],
                "attn": [
                    "torch.Tensor"
                ]
            }
        },
        "RelationTransformerEncoderBlock.forward": {
            "name": "forward",
            "location": 909,
            "return": [
                "Tuple[(torch.Tensor, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "src": [
                    "torch.Tensor"
                ],
                "aux": [
                    "torch.Tensor"
                ],
                "src_mask": [
                    "torch.Tensor"
                ],
                "aux_mask": [
                    "torch.Tensor"
                ]
            }
        },
        "TransformerEncoder.__init__": {
            "name": "__init__",
            "location": 958,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [
                    "int"
                ],
                "model_dim": [
                    "int"
                ],
                "feedforward_hidden_dim": [
                    "int"
                ],
                "num_layers": [
                    "int"
                ],
                "num_attention_heads": [
                    "int"
                ],
                "dropout_prob": [
                    "float"
                ]
            }
        },
        "TransformerEncoder._reset_parameters": {
            "name": "_reset_parameters",
            "location": 984,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "TransformerEncoder.get_input_dim": {
            "name": "get_input_dim",
            "location": 990,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "TransformerEncoder.get_output_dim": {
            "name": "get_output_dim",
            "location": 994,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "TransformerEncoder.is_bidirectional": {
            "name": "is_bidirectional",
            "location": 998,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "TransformerEncoder.forward": {
            "name": "forward",
            "location": 1002,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "torch.Tensor"
                ],
                "mask": [
                    "Optional[torch.Tensor]"
                ]
            }
        },
        "RelationalTransformerEncoder.__init__": {
            "name": "__init__",
            "location": 1057,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "src_input_dim": [
                    "int"
                ],
                "kb_input_dim": [
                    "int"
                ],
                "model_dim": [
                    "int"
                ],
                "feedforward_hidden_dim": [
                    "int"
                ],
                "num_layers": [
                    "int"
                ],
                "num_attention_heads": [
                    "int"
                ],
                "dropout_prob": [
                    "float"
                ],
                "return_kb": [
                    "bool"
                ]
            }
        },
        "RelationalTransformerEncoder._reset_parameters": {
            "name": "_reset_parameters",
            "location": 1099,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "RelationalTransformerEncoder.get_input_dim": {
            "name": "get_input_dim",
            "location": 1105,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "RelationalTransformerEncoder.get_output_dim": {
            "name": "get_output_dim",
            "location": 1109,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "RelationalTransformerEncoder.is_bidirectional": {
            "name": "is_bidirectional",
            "location": 1113,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "RelationalTransformerEncoder.forward": {
            "name": "forward",
            "location": 1117,
            "return": [
                "Union[(torch.Tensor, Tuple[(torch.Tensor, torch.Tensor)])]"
            ],
            "arguments": {
                "self": [],
                "src": [
                    "torch.Tensor"
                ],
                "kb": [
                    "torch.Tensor"
                ],
                "src_mask": [
                    "Optional[torch.Tensor]"
                ],
                "kb_mask": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/play.py": {
        "main": {
            "name": "main",
            "location": 15,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "literate-lamp-master/literate_lamp/predictor.py": {
        "score_questions": {
            "name": "score_questions",
            "location": 58,
            "return": [
                "float"
            ],
            "arguments": {
                "model": [
                    "Model"
                ],
                "output_file": [
                    "TextIO"
                ],
                "testset": [
                    "Sequence[Instance]"
                ]
            }
        },
        "McScriptPredictor.predict": {
            "name": "predict",
            "location": 19,
            "return": [
                "JsonDict"
            ],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str"
                ],
                "question_id": [
                    "str"
                ],
                "question_type": [
                    "str"
                ],
                "passage": [
                    "str"
                ],
                "question": [
                    "str"
                ],
                "answer0": [
                    "str"
                ],
                "answer1": [
                    "str"
                ]
            }
        },
        "McScriptPredictor._json_to_instance": {
            "name": "_json_to_instance",
            "location": 43,
            "return": [
                "Instance"
            ],
            "arguments": {
                "self": [],
                "json_dict": [
                    "JsonDict"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/preprocess.py": {
        "clean_word": {
            "name": "clean_word",
            "location": 8,
            "return": [
                "Tuple[(str, str)]"
            ],
            "arguments": {
                "string": [
                    "str"
                ]
            }
        },
        "process_file": {
            "name": "process_file",
            "location": 16,
            "return": [
                "None"
            ],
            "arguments": {
                "input_file": [
                    "TextIO"
                ],
                "output_file": [
                    "TextIO"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/stats.py": {
        "flatten": {
            "name": "flatten",
            "location": 18,
            "return": [
                "List[T]"
            ],
            "arguments": {
                "l": [
                    "Iterable[List[T]]"
                ]
            }
        },
        "extract_field": {
            "name": "extract_field",
            "location": 70,
            "return": [
                "List[List[str]]"
            ],
            "arguments": {
                "field": [
                    "str"
                ],
                "instances": [
                    "List[Instance]"
                ]
            }
        },
        "main": {
            "name": "main",
            "location": 81,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "TextStats.__init__": {
            "name": "__init__",
            "location": 30,
            "return": [],
            "arguments": {
                "self": [],
                "instance_texts": [
                    "List[List[str]]"
                ]
            }
        },
        "TextStats.__repr__": {
            "name": "__repr__",
            "location": 37,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "DatasetStats.__init__": {
            "name": "__init__",
            "location": 48,
            "return": [],
            "arguments": {
                "self": [],
                "instances": [
                    "List[Instance]"
                ]
            }
        },
        "DatasetStats.__repr__": {
            "name": "__repr__",
            "location": 61,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/train.py": {
        "make_prediction": {
            "name": "make_prediction",
            "location": 36,
            "return": [
                "JsonDict"
            ],
            "arguments": {
                "model": [
                    "Model"
                ],
                "reader": [
                    "readers.BaseReader"
                ],
                "verbose": [
                    "bool"
                ]
            }
        },
        "test_load": {
            "name": "test_load",
            "location": 61,
            "return": [
                "None"
            ],
            "arguments": {
                "build_model_fn": [
                    "Callable[([Vocabulary], Model)]"
                ],
                "reader": [
                    "readers.BaseReader"
                ],
                "save_path": [
                    "Path"
                ],
                "original_prediction": [
                    "JsonDict"
                ],
                "cuda_device": [
                    "int"
                ]
            }
        },
        "run_model": {
            "name": "run_model",
            "location": 99,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "run_model.optimiser": {
            "name": "optimiser",
            "location": 109,
            "return": [
                "torch.optim.Optimizer"
            ],
            "arguments": {
                "model": [
                    "Model"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/util.py": {
        "visualise_model": {
            "name": "visualise_model",
            "location": 77,
            "return": [
                "None"
            ],
            "arguments": {
                "model": [
                    "Model"
                ]
            }
        },
        "example_input": {
            "name": "example_input",
            "location": 90,
            "return": [
                "Tuple[(str, str, str, str)]"
            ],
            "arguments": {
                "index": [
                    "int"
                ]
            }
        },
        "is_cuda": {
            "name": "is_cuda",
            "location": 103,
            "return": [
                "bool"
            ],
            "arguments": {
                "model": [
                    "Model"
                ]
            }
        },
        "train_val_test_split": {
            "name": "train_val_test_split",
            "location": 108,
            "return": [
                "Tuple[(Sequence[Instance], Sequence[Instance], Sequence[Instance])]"
            ],
            "arguments": {
                "dataset": [
                    "Sequence[Instance]"
                ],
                "train_size": [
                    "float"
                ]
            }
        },
        "load_data": {
            "name": "load_data",
            "location": 128,
            "return": [
                "List[Instance]"
            ],
            "arguments": {
                "reader": [
                    "Optional[DatasetReader]"
                ],
                "data_path": [
                    "Optional[Path]"
                ],
                "pre_processed_path": [
                    "Optional[Path]"
                ]
            }
        },
        "train_model": {
            "name": "train_model",
            "location": 168,
            "return": [
                "Model"
            ],
            "arguments": {
                "build_model_fn": [
                    "Callable[([Vocabulary], Model)]"
                ],
                "train_data": [
                    "List[Instance]"
                ],
                "val_data": [
                    "List[Instance]"
                ],
                "test_data": [
                    "List[Instance]"
                ],
                "save_path": [
                    "Optional[Path]"
                ],
                "batch_size": [
                    "int"
                ],
                "num_epochs": [
                    "int"
                ],
                "optimiser_fn": [
                    "Optional[Callable[([Model], torch.optim.Optimizer)]]"
                ],
                "grad_norm_clip": [
                    "float"
                ],
                "sorting_keys": [
                    "Optional[List[Tuple[(str, str)]]]"
                ],
                "cuda_device": [
                    "Union[(int, List[int])]"
                ]
            }
        },
        "get_preprocessed_name": {
            "name": "get_preprocessed_name",
            "location": 270,
            "return": [
                "str"
            ],
            "arguments": {
                "split_name": [
                    "str"
                ],
                "model": [
                    "str"
                ],
                "config": [
                    "str"
                ],
                "embedding": [
                    "str"
                ]
            }
        },
        "get_experiment_name": {
            "name": "get_experiment_name",
            "location": 276,
            "return": [
                "str"
            ],
            "arguments": {
                "model": [
                    "str"
                ],
                "config": [
                    "str"
                ],
                "embedding": [
                    "str"
                ],
                "name": [
                    "Optional[str]"
                ]
            }
        },
        "is_stopword": {
            "name": "is_stopword",
            "location": 290,
            "return": [
                "bool"
            ],
            "arguments": {
                "word": [
                    "Union[(str, Token)]"
                ]
            }
        },
        "is_punctuation": {
            "name": "is_punctuation",
            "location": 299,
            "return": [
                "bool"
            ],
            "arguments": {
                "word": [
                    "Union[(str, Token)]"
                ]
            }
        },
        "get_term_frequency": {
            "name": "get_term_frequency",
            "location": 306,
            "return": [
                "float"
            ],
            "arguments": {
                "word": [
                    "Union[(str, Token)]"
                ]
            }
        },
        "clone_module": {
            "name": "clone_module",
            "location": 323,
            "return": [
                "torch.nn.ModuleList"
            ],
            "arguments": {
                "module": [
                    "torch.nn.Module"
                ],
                "num_clones": [
                    "int"
                ]
            }
        },
        "parse_cuda": {
            "name": "parse_cuda",
            "location": 331,
            "return": [
                "Union[(int, List[int])]"
            ],
            "arguments": {
                "cuda_str": [
                    "str"
                ]
            }
        },
        "tf2str": {
            "name": "tf2str",
            "location": 341,
            "return": [
                "str"
            ],
            "arguments": {
                "field": [
                    "TextField"
                ]
            }
        },
        "split_list": {
            "name": "split_list",
            "location": 350,
            "return": [
                "List[List[T]]"
            ],
            "arguments": {
                "list": [
                    "List[T]"
                ],
                "element": [
                    "T@@"
                ]
            }
        },
        "print_args": {
            "name": "print_args",
            "location": 364,
            "return": [
                "None"
            ],
            "arguments": {
                "args": [
                    "Dict[(str, Any)]"
                ]
            }
        },
        "DotDict.__init__": {
            "name": "__init__",
            "location": 47,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DotDict.__getattr__": {
            "name": "__getattr__",
            "location": 59,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "attr": [
                    "str"
                ]
            }
        },
        "DotDict.__setattr__": {
            "name": "__setattr__",
            "location": 62,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "key": [
                    "str"
                ],
                "value": [
                    "Any"
                ]
            }
        },
        "DotDict.__setitem__": {
            "name": "__setitem__",
            "location": 65,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "key": [
                    "str"
                ],
                "value": [
                    "Any"
                ]
            }
        },
        "DotDict.__delattr__": {
            "name": "__delattr__",
            "location": 69,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "key": [
                    "str"
                ]
            }
        },
        "DotDict.__delitem__": {
            "name": "__delitem__",
            "location": 72,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "key": [
                    "str"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/__init__.py": {},
    "literate-lamp-master/literate_lamp/models/advanced_attention_bert.py": {
        "AdvancedAttentionBertClassifier.__init__": {
            "name": "__init__",
            "location": 23,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "bert_path": [
                    "Path"
                ],
                "encoder": [
                    "Seq2SeqEncoder"
                ],
                "vocab": [
                    "Vocabulary"
                ],
                "hidden_dim": [
                    "int"
                ],
                "encoder_dropout": [
                    "float"
                ],
                "train_bert": [
                    "bool"
                ]
            }
        },
        "AdvancedAttentionBertClassifier.forward": {
            "name": "forward",
            "location": 61,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "bert0": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "bert1": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "label": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/advanced_bert.py": {
        "AdvancedBertClassifier.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "bert_path": [
                    "Path"
                ],
                "encoder": [
                    "Seq2VecEncoder"
                ],
                "vocab": [
                    "Vocabulary"
                ],
                "hidden_dim": [
                    "int"
                ],
                "encoder_dropout": [
                    "float"
                ],
                "train_bert": [
                    "bool"
                ]
            }
        },
        "AdvancedBertClassifier.forward": {
            "name": "forward",
            "location": 55,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "bert0": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "bert1": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "label": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/advanced_xlnet.py": {
        "AdvancedXLNetClassifier.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vocab": [
                    "Vocabulary"
                ],
                "word_embeddings": [
                    "TextFieldEmbedder"
                ],
                "encoder": [
                    "Seq2SeqEncoder"
                ],
                "encoder_dropout": [
                    "float"
                ],
                "train_xlnet": [
                    "bool"
                ]
            }
        },
        "AdvancedXLNetClassifier.forward": {
            "name": "forward",
            "location": 45,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "string0": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "string1": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "label": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/attentive_reader.py": {
        "AttentiveReader.__init__": {
            "name": "__init__",
            "location": 35,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "TextFieldEmbedder"
                ],
                "p_encoder": [
                    "Seq2SeqEncoder"
                ],
                "q_encoder": [
                    "Seq2VecEncoder"
                ],
                "a_encoder": [
                    "Seq2VecEncoder"
                ],
                "vocab": [
                    "Vocabulary"
                ]
            }
        },
        "AttentiveReader.forward": {
            "name": "forward",
            "location": 67,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "passage": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "question": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "answer0": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "answer1": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "label": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/baseline.py": {
        "BaselineClassifier.__init__": {
            "name": "__init__",
            "location": 27,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "TextFieldEmbedder"
                ],
                "encoder": [
                    "Seq2VecEncoder"
                ],
                "vocab": [
                    "Vocabulary"
                ]
            }
        },
        "BaselineClassifier.forward": {
            "name": "forward",
            "location": 58,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "passage": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "question": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "answer0": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "answer1": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "label": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/base_model.py": {
        "BaseModel.__init__": {
            "name": "__init__",
            "location": 17,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vocab": [
                    "Vocabulary"
                ]
            }
        },
        "BaseModel.get_metrics": {
            "name": "get_metrics",
            "location": 29,
            "return": [
                "Dict[(str, float)]"
            ],
            "arguments": {
                "self": [],
                "reset": [
                    "bool"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dcmn.py": {
        "Dcmn.__init__": {
            "name": "__init__",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "TextFieldEmbedder"
                ],
                "vocab": [
                    "Vocabulary"
                ],
                "embedding_dropout": [
                    "float"
                ]
            }
        },
        "Dcmn._forward_internal": {
            "name": "_forward_internal",
            "location": 55,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "passage": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "question": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "answer": [
                    "Dict[(str, torch.Tensor)]"
                ]
            }
        },
        "Dcmn.forward": {
            "name": "forward",
            "location": 107,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "passage": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "question": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "answer0": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "answer1": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "label": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/hierarchical_attention_network.py": {
        "HierarchicalAttentionNetwork.__init__": {
            "name": "__init__",
            "location": 24,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "TextFieldEmbedder"
                ],
                "sentence_encoder": [
                    "Seq2SeqEncoder"
                ],
                "document_encoder": [
                    "Seq2SeqEncoder"
                ],
                "vocab": [
                    "Vocabulary"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "HierarchicalAttentionNetwork.forward": {
            "name": "forward",
            "location": 63,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "bert0": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "bert1": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "label": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/hierarchical_bert.py": {
        "HierarchicalBert.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "bert_path": [
                    "Path"
                ],
                "sentence_encoder": [
                    "Seq2VecEncoder"
                ],
                "document_encoder": [
                    "Seq2VecEncoder"
                ],
                "vocab": [
                    "Vocabulary"
                ],
                "encoder_dropout": [
                    "float"
                ],
                "train_bert": [
                    "bool"
                ]
            }
        },
        "HierarchicalBert.forward": {
            "name": "forward",
            "location": 50,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "bert0": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "bert1": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "label": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/relational_han.py": {
        "RelationalHan.__init__": {
            "name": "__init__",
            "location": 26,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "TextFieldEmbedder"
                ],
                "sentence_encoder": [
                    "Seq2SeqEncoder"
                ],
                "document_encoder": [
                    "Seq2SeqEncoder"
                ],
                "relation_encoder": [
                    "Seq2SeqEncoder"
                ],
                "document_relation_encoder": [
                    "Seq2SeqEncoder"
                ],
                "vocab": [
                    "Vocabulary"
                ],
                "encoder_dropout": [
                    "float"
                ],
                "ffn_dropout": [
                    "float"
                ]
            }
        },
        "RelationalHan._forward_internal": {
            "name": "_forward_internal",
            "location": 76,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "bert": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "relations": [
                    "Dict[(str, torch.Tensor)]"
                ]
            }
        },
        "RelationalHan.forward": {
            "name": "forward",
            "location": 103,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "bert0": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "bert1": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "p_a0_rel": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "p_a1_rel": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "label": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/relational_transformer_model.py": {
        "RelationalTransformerModel.__init__": {
            "name": "__init__",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "TextFieldEmbedder"
                ],
                "sentence_encoder": [
                    "Seq2SeqEncoder"
                ],
                "relation_sentence_encoder": [
                    "Seq2SeqEncoder"
                ],
                "relational_encoder": [
                    "RelationalTransformerEncoder"
                ],
                "rel_embeddings": [
                    "TextFieldEmbedder"
                ],
                "vocab": [
                    "Vocabulary"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "RelationalTransformerModel.forward": {
            "name": "forward",
            "location": 64,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "bert0": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "bert1": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "p_a0_rel": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "p_a1_rel": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "label": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/relational_xlnet.py": {
        "RelationalXL.__init__": {
            "name": "__init__",
            "location": 26,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "TextFieldEmbedder"
                ],
                "text_encoder": [
                    "Seq2SeqEncoder"
                ],
                "relation_encoder": [
                    "Seq2VecEncoder"
                ],
                "vocab": [
                    "Vocabulary"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "RelationalXL._forward_internal": {
            "name": "_forward_internal",
            "location": 58,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "text": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "relations": [
                    "Dict[(str, torch.Tensor)]"
                ]
            }
        },
        "RelationalXL.forward": {
            "name": "forward",
            "location": 89,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "string0": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "string1": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "rel0": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "rel1": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "label": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/simple_bert.py": {
        "SimpleBertClassifier.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "bert_path": [
                    "Path"
                ],
                "vocab": [
                    "Vocabulary"
                ],
                "train_bert": [
                    "bool"
                ]
            }
        },
        "SimpleBertClassifier.forward": {
            "name": "forward",
            "location": 43,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "bert0": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "bert1": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "label": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/simple_trian.py": {
        "SimpleTrian.__init__": {
            "name": "__init__",
            "location": 37,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "TextFieldEmbedder"
                ],
                "rel_embeddings": [
                    "TextFieldEmbedder"
                ],
                "p_encoder": [
                    "Seq2SeqEncoder"
                ],
                "q_encoder": [
                    "Seq2SeqEncoder"
                ],
                "a_encoder": [
                    "Seq2SeqEncoder"
                ],
                "vocab": [
                    "Vocabulary"
                ],
                "embedding_dropout": [
                    "float"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "SimpleTrian.forward": {
            "name": "forward",
            "location": 97,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "passage": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "question": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "answer0": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "answer1": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "p_q_rel": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "p_a0_rel": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "p_a1_rel": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "label": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/simple_xlnet.py": {
        "SimpleXLNetClassifier.__init__": {
            "name": "__init__",
            "location": 20,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vocab": [
                    "Vocabulary"
                ],
                "config_path": [
                    "Path"
                ],
                "model_path": [
                    "Path"
                ],
                "train_xlnet": [
                    "bool"
                ]
            }
        },
        "SimpleXLNetClassifier.forward": {
            "name": "forward",
            "location": 45,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "string0": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "string1": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "label": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/trian.py": {
        "Trian.__init__": {
            "name": "__init__",
            "location": 36,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "TextFieldEmbedder"
                ],
                "pos_embeddings": [
                    "TextFieldEmbedder"
                ],
                "ner_embeddings": [
                    "TextFieldEmbedder"
                ],
                "rel_embeddings": [
                    "TextFieldEmbedder"
                ],
                "p_encoder": [
                    "Seq2SeqEncoder"
                ],
                "q_encoder": [
                    "Seq2SeqEncoder"
                ],
                "a_encoder": [
                    "Seq2SeqEncoder"
                ],
                "vocab": [
                    "Vocabulary"
                ],
                "embedding_dropout": [
                    "float"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "Trian.forward": {
            "name": "forward",
            "location": 94,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "passage": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "question": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "answer0": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "answer1": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "passage_pos": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "passage_ner": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "question_pos": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "p_q_rel": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "p_a0_rel": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "p_a1_rel": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "hc_feat": [
                    "torch.Tensor"
                ],
                "label": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/util.py": {
        "seq_over_seq": {
            "name": "seq_over_seq",
            "location": 10,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "encoder": [
                    "Seq2VecEncoder"
                ],
                "sentences": [
                    "torch.Tensor"
                ],
                "masks": [
                    "Optional[torch.Tensor]"
                ]
            }
        },
        "hierarchical_seq_over_seq": {
            "name": "hierarchical_seq_over_seq",
            "location": 30,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "encoder": [
                    "Seq2SeqEncoder"
                ],
                "sentences": [
                    "torch.Tensor"
                ],
                "masks": [
                    "torch.Tensor"
                ]
            }
        },
        "attention_over_sequence": {
            "name": "attention_over_sequence",
            "location": 46,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "attention": [
                    "Attention"
                ],
                "sequence": [
                    "torch.Tensor"
                ],
                "vector": [
                    "torch.Tensor"
                ]
            }
        },
        "initalise_weights": {
            "name": "initalise_weights",
            "location": 58,
            "return": [
                "None"
            ],
            "arguments": {
                "init": [
                    "Callable[([torch.Tensor], None)]"
                ],
                "module": [
                    "torch.nn.Module"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/zero_trian.py": {
        "ZeroTrian.__init__": {
            "name": "__init__",
            "location": 38,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "TextFieldEmbedder"
                ],
                "p_encoder": [
                    "Seq2SeqEncoder"
                ],
                "q_encoder": [
                    "Seq2SeqEncoder"
                ],
                "a_encoder": [
                    "Seq2SeqEncoder"
                ],
                "vocab": [
                    "Vocabulary"
                ],
                "embedding_dropout": [
                    "float"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "ZeroTrian.forward": {
            "name": "forward",
            "location": 96,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "passage": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "question": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "answer0": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "answer1": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "label": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/__init__.py": {},
    "literate-lamp-master/literate_lamp/models/dmn/answer_module.py": {
        "AnswerModule.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "TextFieldEmbedder"
                ],
                "encoder": [
                    "Seq2VecEncoder"
                ],
                "embedding_dropout": [
                    "float"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "AnswerModule.get_output_dim": {
            "name": "get_output_dim",
            "location": 28,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "AnswerModule.forward": {
            "name": "forward",
            "location": 32,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "answer": [
                    "Dict[(str, torch.Tensor)]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dmn/input_module.py": {
        "InputModule.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "TextFieldEmbedder"
                ],
                "sentence_encoder": [
                    "Seq2VecEncoder"
                ],
                "document_encoder": [
                    "Seq2VecEncoder"
                ],
                "embedding_dropout": [
                    "float"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "InputModule.get_output_dim": {
            "name": "get_output_dim",
            "location": 32,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "InputModule.forward": {
            "name": "forward",
            "location": 36,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "sentences": [
                    "Dict[(str, torch.Tensor)]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dmn/memory_module.py": {
        "MemoryModule.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [],
            "arguments": {
                "self": [],
                "hidden_dim": [
                    "int"
                ],
                "num_hops": [
                    "int"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "MemoryModule.get_output_dim": {
            "name": "get_output_dim",
            "location": 39,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "MemoryModule.get_gate": {
            "name": "get_gate",
            "location": 42,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "facts": [
                    "torch.Tensor"
                ],
                "question": [
                    "torch.Tensor"
                ],
                "answer": [
                    "torch.Tensor"
                ],
                "prev_mem": [
                    "torch.Tensor"
                ]
            }
        },
        "MemoryModule.forward": {
            "name": "forward",
            "location": 77,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "facts": [
                    "torch.Tensor"
                ],
                "question": [
                    "torch.Tensor"
                ],
                "answer": [
                    "torch.Tensor"
                ],
                "prev_mem": [
                    "torch.Tensor"
                ],
                "hop": [
                    "int"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dmn/model.py": {
        "_assert_equal": {
            "name": "_assert_equal",
            "location": 128,
            "return": [
                "None"
            ],
            "arguments": {
                "a": [
                    "torch.nn.Module"
                ],
                "b": [
                    "torch.nn.Module"
                ]
            }
        },
        "Dmn.__init__": {
            "name": "__init__",
            "location": 39,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "TextFieldEmbedder"
                ],
                "sentence_encoder": [
                    "Seq2VecEncoder"
                ],
                "document_encoder": [
                    "Seq2VecEncoder"
                ],
                "question_encoder": [
                    "Seq2VecEncoder"
                ],
                "answer_encoder": [
                    "Seq2VecEncoder"
                ],
                "passes": [
                    "int"
                ],
                "vocab": [
                    "Vocabulary"
                ],
                "embedding_dropout": [
                    "float"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "Dmn.forward": {
            "name": "forward",
            "location": 88,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "sentences": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "question": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "answer0": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "answer1": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "label": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dmn/output_module.py": {
        "OutputModule.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [],
            "arguments": {
                "self": [],
                "memory_size": [
                    "int"
                ],
                "answer_size": [
                    "int"
                ],
                "num_labels": [
                    "int"
                ]
            }
        },
        "OutputModule.get_input_dim": {
            "name": "get_input_dim",
            "location": 22,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "OutputModule.get_output_dim": {
            "name": "get_output_dim",
            "location": 25,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "OutputModule.forward": {
            "name": "forward",
            "location": 29,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "memory": [
                    "torch.Tensor"
                ],
                "answer": [
                    "torch.Tensor"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dmn/question_module.py": {
        "QuestionModule.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "TextFieldEmbedder"
                ],
                "encoder": [
                    "Seq2VecEncoder"
                ],
                "embedding_dropout": [
                    "float"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "QuestionModule.get_output_dim": {
            "name": "get_output_dim",
            "location": 28,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "QuestionModule.forward": {
            "name": "forward",
            "location": 32,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "question": [
                    "Dict[(str, torch.Tensor)]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dmn/__init__.py": {},
    "literate-lamp-master/literate_lamp/modules/attention_gru.py": {
        "attention_gru": {
            "name": "attention_gru",
            "location": 87,
            "return": [
                "Seq2VecEncoder"
            ],
            "arguments": {
                "input_dim": [
                    "int"
                ],
                "output_dim": [
                    "int"
                ],
                "num_layers": [
                    "int"
                ],
                "bidirectional": [
                    "bool"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "AttentionGRUCell.__init__": {
            "name": "__init__",
            "location": 9,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [
                    "int"
                ],
                "hidden_size": [
                    "int"
                ]
            }
        },
        "AttentionGRUCell.forward": {
            "name": "forward",
            "location": 22,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "torch.Tensor"
                ],
                "previous_state": [
                    "torch.Tensor"
                ],
                "gate": [
                    "torch.Tensor"
                ]
            }
        },
        "AttentionGRU.__init__": {
            "name": "__init__",
            "location": 47,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [
                    "int"
                ],
                "output_dim": [
                    "int"
                ]
            }
        },
        "AttentionGRU.forward": {
            "name": "forward",
            "location": 53,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "torch.Tensor"
                ],
                "gate": [
                    "torch.Tensor"
                ]
            }
        },
        "AttentionGRU.get_input_dim": {
            "name": "get_input_dim",
            "location": 79,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "AttentionGRU.get_output_dim": {
            "name": "get_output_dim",
            "location": 83,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/modules/position_encoder.py": {
        "position_encoder": {
            "name": "position_encoder",
            "location": 59,
            "return": [
                "Seq2VecEncoder"
            ],
            "arguments": {
                "input_dim": [
                    "int"
                ],
                "output_dim": [
                    "int"
                ],
                "num_layers": [
                    "int"
                ],
                "bidirectional": [
                    "bool"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "PositionEncoder.__init__": {
            "name": "__init__",
            "location": 9,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [
                    "int"
                ],
                "output_dim": [
                    "int"
                ]
            }
        },
        "PositionEncoder.position_matrix": {
            "name": "position_matrix",
            "location": 15,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "seq_len": [
                    "int"
                ]
            }
        },
        "PositionEncoder.forward": {
            "name": "forward",
            "location": 24,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "torch.Tensor"
                ],
                "mask": [
                    "Optional[torch.Tensor]"
                ]
            }
        },
        "PositionEncoder.get_input_dim": {
            "name": "get_input_dim",
            "location": 51,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "PositionEncoder.get_output_dim": {
            "name": "get_output_dim",
            "location": 55,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/modules/xlnet_embedder.py": {
        "PretrainedXLNetModel.load": {
            "name": "load",
            "location": 26,
            "return": [
                "XLNetModel"
            ],
            "arguments": {
                "cls": [],
                "config_path": [
                    "Path"
                ],
                "model_path": [
                    "Path"
                ],
                "cache_model": [
                    "bool"
                ]
            }
        },
        "XLNetEmbedder.__init__": {
            "name": "__init__",
            "location": 57,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "xlnet_model": [
                    "XLNetModel"
                ],
                "window_size": [
                    "Optional[int]"
                ]
            }
        },
        "XLNetEmbedder.get_output_dim": {
            "name": "get_output_dim",
            "location": 66,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "XLNetEmbedder.forward": {
            "name": "forward",
            "location": 69,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "input_ids": [
                    "torch.LongTensor"
                ],
                "cls_indexes": [
                    "Optional[torch.Tensor]"
                ],
                "token_type_ids": [
                    "Optional[torch.Tensor]"
                ]
            }
        },
        "PretrainedXLNetEmbedder.__init__": {
            "name": "__init__",
            "location": 137,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "config_path": [
                    "Path"
                ],
                "model_path": [
                    "Path"
                ],
                "window_size": [
                    "Optional[int]"
                ],
                "requires_grad": [
                    "bool"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/modules/xlnet_indexer.py": {
        "XLNetIndexer.__init__": {
            "name": "__init__",
            "location": 39,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "namespace": [
                    "str"
                ],
                "vocab_file": [
                    "str"
                ],
                "sep_token": [
                    "str"
                ],
                "cls_token": [
                    "str"
                ],
                "pad_token": [
                    "Union[(int, str)]"
                ],
                "token_min_padding_length": [
                    "int"
                ]
            }
        },
        "XLNetIndexer.count_vocab_items": {
            "name": "count_vocab_items",
            "location": 59,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "token": [
                    "Token"
                ],
                "counter": [
                    "Dict[(str, Dict[(str, int)])]"
                ]
            }
        },
        "XLNetIndexer.tokens_to_indices": {
            "name": "tokens_to_indices",
            "location": 66,
            "return": [
                "Dict[(str, List[int])]"
            ],
            "arguments": {
                "self": [],
                "tokens": [
                    "List[Token]"
                ],
                "vocabulary": [
                    "Vocabulary"
                ],
                "index_name": [
                    "str"
                ]
            }
        },
        "XLNetIndexer.get_padding_token": {
            "name": "get_padding_token",
            "location": 104,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "XLNetIndexer.get_padding_lengths": {
            "name": "get_padding_lengths",
            "location": 108,
            "return": [
                "Dict[(str, int)]"
            ],
            "arguments": {
                "self": [],
                "token": [
                    "int"
                ]
            }
        },
        "XLNetIndexer.pad_token_sequence": {
            "name": "pad_token_sequence",
            "location": 112,
            "return": [
                "Dict[(str, List[int])]"
            ],
            "arguments": {
                "self": [],
                "tokens": [
                    "Dict[(str, List[int])]"
                ],
                "desired_num_tokens": [
                    "Dict[(str, int)]"
                ],
                "padding_lengths": [
                    "Dict[(str, int)]"
                ]
            }
        },
        "XLNetIndexer.get_keys": {
            "name": "get_keys",
            "location": 121,
            "return": [
                "List[str]"
            ],
            "arguments": {
                "self": [],
                "index_name": [
                    "str"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/modules/xlnet_pooler.py": {
        "XLNetPooler.__init__": {
            "name": "__init__",
            "location": 9,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [
                    "int"
                ]
            }
        },
        "XLNetPooler.get_input_dim": {
            "name": "get_input_dim",
            "location": 16,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "XLNetPooler.get_output_dim": {
            "name": "get_output_dim",
            "location": 20,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "XLNetPooler.forward": {
            "name": "forward",
            "location": 23,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "hidden_states": [
                    "torch.Tensor"
                ],
                "cls_index": [
                    "Optional[torch.Tensor]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/modules/xlnet_word_splitter.py": {
        "PretrainedXLNetTokenizer.load": {
            "name": "load",
            "location": 18,
            "return": [
                "XLNetTokenizer"
            ],
            "arguments": {
                "cls": [],
                "vocab_file": [
                    "str"
                ],
                "cache_model": [
                    "bool"
                ]
            }
        },
        "XLNetWordSplitter.__init__": {
            "name": "__init__",
            "location": 36,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vocab_file": [
                    "str"
                ],
                "do_lower_case": [
                    "bool"
                ]
            }
        },
        "XLNetWordSplitter.split_words": {
            "name": "split_words",
            "location": 42,
            "return": [
                "List[Token]"
            ],
            "arguments": {
                "self": [],
                "sentence": [
                    "str"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/modules/__init__.py": {},
    "literate-lamp-master/literate_lamp/readers/base_reader.py": {
        "BaseReader._read": {
            "name": "_read",
            "location": 20,
            "return": [
                "Iterator[Instance]"
            ],
            "arguments": {
                "self": [],
                "file_path": [
                    "str"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/extended_xlnet_reader.py": {
        "ExtendedXLNetReader.__init__": {
            "name": "__init__",
            "location": 44,
            "return": [],
            "arguments": {
                "self": [],
                "vocab_file": [
                    "Path"
                ],
                "conceptnet_path": [
                    "Path"
                ],
                "word_indexer": [
                    "Optional[TokenIndexer]"
                ]
            }
        },
        "ExtendedXLNetReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 66,
            "return": [
                "Instance"
            ],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str"
                ],
                "question_id": [
                    "str"
                ],
                "question_type": [
                    "str"
                ],
                "passage": [
                    "str"
                ],
                "question": [
                    "str"
                ],
                "answer0": [
                    "str"
                ],
                "answer1": [
                    "str"
                ],
                "label0": [
                    "Optional[str]"
                ]
            }
        },
        "ExtendedXLNetReader.extend_passage": {
            "name": "extend_passage",
            "location": 109,
            "return": [
                "str"
            ],
            "arguments": {
                "self": [],
                "passage": [
                    "str"
                ],
                "question": [
                    "str"
                ],
                "answer": [
                    "str"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/full_trian_reader.py": {
        "FullTrianReader.__init__": {
            "name": "__init__",
            "location": 54,
            "return": [],
            "arguments": {
                "self": [],
                "word_indexer": [
                    "Optional[TokenIndexer]"
                ],
                "is_bert": [
                    "bool"
                ],
                "conceptnet_path": [
                    "Optional[Path]"
                ]
            }
        },
        "FullTrianReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 94,
            "return": [
                "Instance"
            ],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str"
                ],
                "question_id": [
                    "str"
                ],
                "question_type": [
                    "str"
                ],
                "passage": [
                    "str"
                ],
                "question": [
                    "str"
                ],
                "answer0": [
                    "str"
                ],
                "answer1": [
                    "str"
                ],
                "label0": [
                    "Optional[str]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/relation_bert_reader.py": {
        "RelationBertReader.__init__": {
            "name": "__init__",
            "location": 40,
            "return": [],
            "arguments": {
                "self": [],
                "is_bert": [
                    "bool"
                ],
                "conceptnet_path": [
                    "Path"
                ],
                "word_indexer": [
                    "Optional[TokenIndexer]"
                ]
            }
        },
        "RelationBertReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 72,
            "return": [
                "Instance"
            ],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str"
                ],
                "question_id": [
                    "str"
                ],
                "question_type": [
                    "str"
                ],
                "passage": [
                    "str"
                ],
                "question": [
                    "str"
                ],
                "answer0": [
                    "str"
                ],
                "answer1": [
                    "str"
                ],
                "label0": [
                    "Optional[str]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/relation_xlnet_reader.py": {
        "RelationXLNetReader.__init__": {
            "name": "__init__",
            "location": 40,
            "return": [],
            "arguments": {
                "self": [],
                "vocab_file": [
                    "Path"
                ],
                "conceptnet_path": [
                    "Path"
                ],
                "word_indexer": [
                    "Optional[TokenIndexer]"
                ]
            }
        },
        "RelationXLNetReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 62,
            "return": [
                "Instance"
            ],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str"
                ],
                "question_id": [
                    "str"
                ],
                "question_type": [
                    "str"
                ],
                "passage": [
                    "str"
                ],
                "question": [
                    "str"
                ],
                "answer0": [
                    "str"
                ],
                "answer1": [
                    "str"
                ],
                "label0": [
                    "Optional[str]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/sentence_reader.py": {
        "SentenceReader.__init__": {
            "name": "__init__",
            "location": 47,
            "return": [],
            "arguments": {
                "self": [],
                "embedding_type": [
                    "str"
                ],
                "xlnet_vocab_file": [
                    "Optional[Path]"
                ],
                "word_indexer": [
                    "Optional[TokenIndexer]"
                ]
            }
        },
        "SentenceReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 70,
            "return": [
                "Instance"
            ],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str"
                ],
                "question_id": [
                    "str"
                ],
                "question_type": [
                    "str"
                ],
                "passage": [
                    "str"
                ],
                "question": [
                    "str"
                ],
                "answer0": [
                    "str"
                ],
                "answer1": [
                    "str"
                ],
                "label0": [
                    "Optional[str]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/simple_bert_reader.py": {
        "SimpleBertReader.__init__": {
            "name": "__init__",
            "location": 35,
            "return": [],
            "arguments": {
                "self": [],
                "word_indexer": [
                    "Optional[TokenIndexer]"
                ]
            }
        },
        "SimpleBertReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 56,
            "return": [
                "Instance"
            ],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str"
                ],
                "question_id": [
                    "str"
                ],
                "question_type": [
                    "str"
                ],
                "passage": [
                    "str"
                ],
                "question": [
                    "str"
                ],
                "answer0": [
                    "str"
                ],
                "answer1": [
                    "str"
                ],
                "label0": [
                    "Optional[str]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/simple_mc_script_reader.py": {
        "SimpleMcScriptReader.__init__": {
            "name": "__init__",
            "location": 35,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "embedding_type": [
                    "str"
                ],
                "xlnet_vocab_file": [
                    "Optional[Path]"
                ],
                "word_indexer": [
                    "Optional[TokenIndexer]"
                ]
            }
        },
        "SimpleMcScriptReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 56,
            "return": [
                "Instance"
            ],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str"
                ],
                "question_id": [
                    "str"
                ],
                "question_type": [
                    "str"
                ],
                "passage": [
                    "str"
                ],
                "question": [
                    "str"
                ],
                "answer0": [
                    "str"
                ],
                "answer1": [
                    "str"
                ],
                "label0": [
                    "Optional[str]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/simple_trian_reader.py": {
        "SimpleTrianReader.__init__": {
            "name": "__init__",
            "location": 39,
            "return": [],
            "arguments": {
                "self": [],
                "word_indexer": [
                    "Optional[TokenIndexer]"
                ],
                "xlnet_vocab_file": [
                    "Optional[Path]"
                ],
                "embedding_type": [
                    "str"
                ],
                "conceptnet_path": [
                    "Optional[Path]"
                ]
            }
        },
        "SimpleTrianReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 62,
            "return": [
                "Instance"
            ],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str"
                ],
                "question_id": [
                    "str"
                ],
                "question_type": [
                    "str"
                ],
                "passage": [
                    "str"
                ],
                "question": [
                    "str"
                ],
                "answer0": [
                    "str"
                ],
                "answer1": [
                    "str"
                ],
                "label0": [
                    "Optional[str]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/simple_xlnet_reader.py": {
        "SimpleXLNetReader.__init__": {
            "name": "__init__",
            "location": 45,
            "return": [],
            "arguments": {
                "self": [],
                "vocab_file": [
                    "Path"
                ],
                "word_indexer": [
                    "Optional[TokenIndexer]"
                ]
            }
        },
        "SimpleXLNetReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 65,
            "return": [
                "Instance"
            ],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str"
                ],
                "question_id": [
                    "str"
                ],
                "question_type": [
                    "str"
                ],
                "passage": [
                    "str"
                ],
                "question": [
                    "str"
                ],
                "answer0": [
                    "str"
                ],
                "answer1": [
                    "str"
                ],
                "label0": [
                    "Optional[str]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/util.py": {
        "strs2toks": {
            "name": "strs2toks",
            "location": 20,
            "return": [
                "List[Token]"
            ],
            "arguments": {
                "strings": [
                    "Sequence[str]"
                ]
            }
        },
        "toks2strs": {
            "name": "toks2strs",
            "location": 25,
            "return": [
                "List[str]"
            ],
            "arguments": {
                "tokens": [
                    "Sequence[Token]"
                ]
            }
        },
        "pieces2strs": {
            "name": "pieces2strs",
            "location": 30,
            "return": [
                "List[str]"
            ],
            "arguments": {
                "tokens": [
                    "Sequence[Token]"
                ]
            }
        },
        "compute_handcrafted_features": {
            "name": "compute_handcrafted_features",
            "location": 40,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "passage": [
                    "Sequence[Token]"
                ],
                "question": [
                    "Sequence[Token]"
                ],
                "answer0": [
                    "Sequence[Token]"
                ],
                "answer1": [
                    "Sequence[Token]"
                ]
            }
        },
        "bert_sliding_window": {
            "name": "bert_sliding_window",
            "location": 83,
            "return": [
                "List[str]"
            ],
            "arguments": {
                "question": [
                    "str"
                ],
                "answer": [
                    "str"
                ],
                "passage": [
                    "str"
                ],
                "max_wordpieces": [
                    "int"
                ],
                "stride": [
                    "Optional[int]"
                ]
            }
        },
        "xlnet_input_string": {
            "name": "xlnet_input_string",
            "location": 101,
            "return": [
                "str"
            ],
            "arguments": {
                "question": [
                    "str"
                ],
                "answer": [
                    "str"
                ],
                "passage": [
                    "str"
                ]
            }
        },
        "relation_sentences": {
            "name": "relation_sentences",
            "location": 105,
            "return": [
                "List[str]"
            ],
            "arguments": {
                "conceptnet": [
                    "ConceptNet"
                ],
                "text": [
                    "Sequence[str]"
                ],
                "query": [
                    "Sequence[str]"
                ]
            }
        },
        "get_tokenizer": {
            "name": "get_tokenizer",
            "location": 112,
            "return": [
                "WordSplitter"
            ],
            "arguments": {
                "embedding_type": [
                    "str"
                ],
                "xlnet_vocab_file": [
                    "Path"
                ]
            }
        },
        "get_indexer": {
            "name": "get_indexer",
            "location": 124,
            "return": [
                "TokenIndexer"
            ],
            "arguments": {
                "embedding_type": [
                    "str"
                ],
                "xlnet_vocab_file": [
                    "Path"
                ]
            }
        },
        "split_sentences": {
            "name": "split_sentences",
            "location": 137,
            "return": [
                "Iterator[str]"
            ],
            "arguments": {
                "nlp": [
                    "spacy.language.Language"
                ],
                "text": [
                    "str"
                ]
            }
        },
        "get_sentencizer": {
            "name": "get_sentencizer",
            "location": 143,
            "return": [
                "spacy.language.Language"
            ],
            "arguments": {}
        },
        "compute_handcrafted_features.is_valid": {
            "name": "is_valid",
            "location": 44,
            "return": [
                "bool"
            ],
            "arguments": {
                "token": [
                    "Token"
                ]
            }
        },
        "compute_handcrafted_features.co_occurrence": {
            "name": "co_occurrence",
            "location": 47,
            "return": [
                "List[float]"
            ],
            "arguments": {
                "text": [
                    "Sequence[str]"
                ],
                "query": [
                    "Sequence[str]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/__init__.py": {}
}
{
    "pytorch-fast-elmo-master/setup.py": {
        "load_requirements": {
            "name": "load_requirements",
            "location": 11,
            "return": [],
            "arguments": {
                "path": []
            }
        }
    },
    "pytorch-fast-elmo-master/docs/conf.py": {},
    "pytorch-fast-elmo-master/pytorch_fast_elmo/factory.py": {
        "load_options": {
            "name": "load_options",
            "location": 18,
            "return": [],
            "arguments": {
                "options_file": [
                    "Optional[str]"
                ]
            }
        },
        "freeze_parameters": {
            "name": "freeze_parameters",
            "location": 26,
            "return": [
                "None"
            ],
            "arguments": {
                "named_parameters": [
                    "Dict[(str, torch.Tensor)]"
                ]
            }
        },
        "FactoryBase.__init__": {
            "name": "__init__",
            "location": 33,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "options_file": [
                    "Optional[str]"
                ],
                "weight_file": [
                    "Optional[str]"
                ]
            }
        },
        "ElmoCharacterEncoderFactory.from_scratch": {
            "name": "from_scratch",
            "location": 45,
            "return": [
                "'ElmoCharacterEncoderFactory'"
            ],
            "arguments": {
                "char_embedding_cnt": [
                    "int"
                ],
                "char_embedding_dim": [
                    "int"
                ],
                "filters": [
                    "List[Tuple[(int, int)]]"
                ],
                "activation": [
                    "str"
                ],
                "num_highway_layers": [
                    "int"
                ],
                "output_dim": [
                    "int"
                ]
            }
        },
        "ElmoCharacterEncoderFactory.create": {
            "name": "create",
            "location": 70,
            "return": [
                "ElmoCharacterEncoder"
            ],
            "arguments": {
                "self": [],
                "requires_grad": [
                    "bool"
                ]
            }
        },
        "ElmoCharacterEncoderFactory._load_char_embedding": {
            "name": "_load_char_embedding",
            "location": 106,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "ElmoCharacterEncoderFactory._load_cnn_weights": {
            "name": "_load_cnn_weights",
            "location": 120,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "ElmoCharacterEncoderFactory._load_highway": {
            "name": "_load_highway",
            "location": 139,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "ElmoCharacterEncoderFactory._load_projection": {
            "name": "_load_projection",
            "location": 167,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "ElmoWordEmbeddingFactory.from_scratch": {
            "name": "from_scratch",
            "location": 191,
            "return": [
                "'ElmoWordEmbeddingFactory'"
            ],
            "arguments": {
                "cnt": [
                    "int"
                ],
                "dim": [
                    "int"
                ]
            }
        },
        "ElmoWordEmbeddingFactory.weight_file_is_hdf5": {
            "name": "weight_file_is_hdf5",
            "location": 202,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "ElmoWordEmbeddingFactory.create": {
            "name": "create",
            "location": 209,
            "return": [
                "Tuple[(torch.Tensor, torch.Tensor, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "requires_grad": [
                    "bool"
                ]
            }
        },
        "ElmoLstmFactory.from_scratch": {
            "name": "from_scratch",
            "location": 303,
            "return": [
                "'ElmoLstmFactory'"
            ],
            "arguments": {
                "num_layers": [
                    "int"
                ],
                "input_size": [
                    "int"
                ],
                "hidden_size": [
                    "int"
                ],
                "cell_size": [
                    "int"
                ],
                "cell_clip": [
                    "float"
                ],
                "proj_clip": [
                    "float"
                ],
                "truncated_bptt": [
                    "int"
                ]
            }
        },
        "ElmoLstmFactory.create": {
            "name": "create",
            "location": 326,
            "return": [
                "Tuple[(StatefulUnidirectionalLstm, StatefulUnidirectionalLstm)]"
            ],
            "arguments": {
                "self": [],
                "enable_forward": [
                    "bool"
                ],
                "forward_requires_grad": [
                    "bool"
                ],
                "enable_backward": [
                    "bool"
                ],
                "backward_requires_grad": [
                    "bool"
                ]
            }
        },
        "ElmoLstmFactory._load_lstm": {
            "name": "_load_lstm",
            "location": 418,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "prefix": [
                    "str"
                ],
                "dataset": [
                    "Any"
                ]
            }
        },
        "ElmoVocabProjectionFactory.from_scratch": {
            "name": "from_scratch",
            "location": 458,
            "return": [
                "'ElmoVocabProjectionFactory'"
            ],
            "arguments": {
                "input_size": [
                    "int"
                ],
                "proj_size": [
                    "int"
                ]
            }
        },
        "ElmoVocabProjectionFactory.create": {
            "name": "create",
            "location": 471,
            "return": [
                "Tuple[(torch.Tensor, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "requires_grad": [
                    "bool"
                ]
            }
        }
    },
    "pytorch-fast-elmo-master/pytorch_fast_elmo/model.py": {
        "_raise_if_kwargs_is_invalid": {
            "name": "_raise_if_kwargs_is_invalid",
            "location": 24,
            "return": [
                "None"
            ],
            "arguments": {
                "allowed": [
                    "Set[str]"
                ],
                "kwargs": [
                    "Dict[(str, Any)]"
                ]
            }
        },
        "ScalarMix.__init__": {
            "name": "__init__",
            "location": 34,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "mixture_size": [
                    "int"
                ],
                "do_layer_norm": [
                    "bool"
                ],
                "initial_scalar_parameters": [
                    "Optional[List[float]]"
                ],
                "trainable": [
                    "bool"
                ]
            }
        },
        "ScalarMix.forward": {
            "name": "forward",
            "location": 58,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "tensors": [
                    "List[torch.Tensor]"
                ],
                "mask": [
                    "torch.Tensor"
                ]
            }
        },
        "FastElmoBase.__init__": {
            "name": "__init__",
            "location": 135,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "options_file": [
                    "Optional[str]"
                ],
                "weight_file": [
                    "Optional[str]"
                ],
                "exec_managed_lstm_bos_eos": [
                    "bool"
                ],
                "exec_managed_lstm_reset_states": [
                    "bool"
                ],
                "exec_sort_batch": [
                    "bool"
                ],
                "disable_scalar_mix": [
                    "bool"
                ],
                "num_output_representations": [
                    "int"
                ],
                "output_representation_dropout": [
                    "float"
                ],
                "scalar_mix_parameters": [
                    "Optional[List[float]]"
                ],
                "do_layer_norm": [
                    "bool"
                ],
                "disable_char_cnn": [
                    "bool"
                ],
                "char_cnn_requires_grad": [
                    "bool"
                ],
                "char_cnn_char_embedding_cnt": [
                    "int"
                ],
                "char_cnn_char_embedding_dim": [
                    "int"
                ],
                "char_cnn_filters": [
                    "List[Tuple[(int, int)]]"
                ],
                "char_cnn_activation": [
                    "str"
                ],
                "char_cnn_num_highway_layers": [
                    "int"
                ],
                "char_cnn_output_dim": [
                    "int"
                ],
                "disable_word_embedding": [
                    "bool"
                ],
                "word_embedding_weight_file": [
                    "Optional[str]"
                ],
                "word_embedding_requires_grad": [
                    "bool"
                ],
                "word_embedding_cnt": [
                    "int"
                ],
                "word_embedding_dim": [
                    "int"
                ],
                "disable_forward_lstm": [
                    "bool"
                ],
                "forward_lstm_requires_grad": [
                    "bool"
                ],
                "disable_backward_lstm": [
                    "bool"
                ],
                "backward_lstm_requires_grad": [
                    "bool"
                ],
                "lstm_num_layers": [
                    "int"
                ],
                "lstm_input_size": [
                    "int"
                ],
                "lstm_hidden_size": [
                    "int"
                ],
                "lstm_cell_size": [
                    "int"
                ],
                "lstm_cell_clip": [
                    "float"
                ],
                "lstm_proj_clip": [
                    "float"
                ],
                "lstm_truncated_bptt": [
                    "int"
                ],
                "lstm_bos_repr": [
                    "Optional[torch.Tensor]"
                ],
                "lstm_eos_repr": [
                    "Optional[torch.Tensor]"
                ],
                "disable_vocab_projection": [
                    "bool"
                ],
                "vocab_projection_requires_grad": [
                    "bool"
                ],
                "vocab_projection_input_size": [
                    "int"
                ],
                "vocab_projection_proj_size": [
                    "int"
                ]
            }
        },
        "FastElmoBase.state_dict": {
            "name": "state_dict",
            "location": 341,
            "return": [],
            "arguments": {
                "self": [],
                "destination": [],
                "prefix": [],
                "keep_vars": []
            }
        },
        "FastElmoBase._load_from_state_dict": {
            "name": "_load_from_state_dict",
            "location": 353,
            "return": [],
            "arguments": {
                "self": [],
                "state_dict": [],
                "prefix": [],
                "local_metadata": [],
                "strict": [],
                "missing_keys": [],
                "unexpected_keys": [],
                "error_msgs": []
            }
        },
        "FastElmoBase._add_cpp_module_to_buffer": {
            "name": "_add_cpp_module_to_buffer",
            "location": 369,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "name": [
                    "str"
                ],
                "cpp_module": [
                    "Any"
                ]
            }
        },
        "FastElmoBase._get_lstm_device": {
            "name": "_get_lstm_device",
            "location": 373,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "FastElmoBase.get_batched_lstm_bos_eos_repr": {
            "name": "get_batched_lstm_bos_eos_repr",
            "location": 385,
            "return": [
                "PackedSequence"
            ],
            "arguments": {
                "self": [],
                "attr_name": [
                    "str"
                ],
                "batch_size": [
                    "int"
                ]
            }
        },
        "FastElmoBase.exec_forward_backword_lstm_bos_eos": {
            "name": "exec_forward_backword_lstm_bos_eos",
            "location": 398,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "lstm_attr_name": [
                    "str"
                ],
                "bos_eos_attr_name": [
                    "str"
                ],
                "batch_size": [
                    "int"
                ]
            }
        },
        "FastElmoBase.exec_forward_lstm_bos": {
            "name": "exec_forward_lstm_bos",
            "location": 411,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "batch_size": [
                    "int"
                ]
            }
        },
        "FastElmoBase.exec_forward_lstm_eos": {
            "name": "exec_forward_lstm_eos",
            "location": 414,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "batch_size": [
                    "int"
                ]
            }
        },
        "FastElmoBase.exec_backward_lstm_bos": {
            "name": "exec_backward_lstm_bos",
            "location": 417,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "batch_size": [
                    "int"
                ]
            }
        },
        "FastElmoBase.exec_backward_lstm_eos": {
            "name": "exec_backward_lstm_eos",
            "location": 420,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "batch_size": [
                    "int"
                ]
            }
        },
        "FastElmoBase.exec_forward_lstm_permutate_states": {
            "name": "exec_forward_lstm_permutate_states",
            "location": 423,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "index": [
                    "torch.Tensor"
                ]
            }
        },
        "FastElmoBase.exec_backward_lstm_permutate_states": {
            "name": "exec_backward_lstm_permutate_states",
            "location": 426,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "index": [
                    "torch.Tensor"
                ]
            }
        },
        "FastElmoBase.exec_bilstm_permutate_states": {
            "name": "exec_bilstm_permutate_states",
            "location": 429,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "index": [
                    "torch.Tensor"
                ]
            }
        },
        "FastElmoBase.exec_char_cnn": {
            "name": "exec_char_cnn",
            "location": 435,
            "return": [
                "PackedSequence"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoBase.exec_word_embedding": {
            "name": "exec_word_embedding",
            "location": 442,
            "return": [
                "PackedSequence"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoBase.exec_forward_lstm": {
            "name": "exec_forward_lstm",
            "location": 453,
            "return": [
                "List[PackedSequence]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoBase.exec_backward_lstm": {
            "name": "exec_backward_lstm",
            "location": 477,
            "return": [
                "List[PackedSequence]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoBase.exec_bilstm": {
            "name": "exec_bilstm",
            "location": 501,
            "return": [
                "List[Tuple[(PackedSequence, PackedSequence)]]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoBase.concat_packed_sequences": {
            "name": "concat_packed_sequences",
            "location": 513,
            "return": [
                "List[PackedSequence]"
            ],
            "arguments": {
                "self": [],
                "packed_sequences": [
                    "List[Tuple[(PackedSequence, PackedSequence)]]"
                ]
            }
        },
        "FastElmoBase.combine_char_cnn_and_bilstm_outputs": {
            "name": "combine_char_cnn_and_bilstm_outputs",
            "location": 527,
            "return": [
                "List[PackedSequence]"
            ],
            "arguments": {
                "self": [],
                "char_cnn_packed": [
                    "PackedSequence"
                ],
                "bilstm_packed": [
                    "List[PackedSequence]"
                ]
            }
        },
        "FastElmoBase.exec_vocab_projection": {
            "name": "exec_vocab_projection",
            "location": 545,
            "return": [
                "PackedSequence"
            ],
            "arguments": {
                "self": [],
                "context_repr": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoBase.exec_scalar_mix": {
            "name": "exec_scalar_mix",
            "location": 557,
            "return": [
                "List[PackedSequence]"
            ],
            "arguments": {
                "self": [],
                "packed_sequences": [
                    "List[PackedSequence]"
                ]
            }
        },
        "FastElmoBase.exec_bilstm_and_scalar_mix": {
            "name": "exec_bilstm_and_scalar_mix",
            "location": 569,
            "return": [
                "List[PackedSequence]"
            ],
            "arguments": {
                "self": [],
                "token_repr": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoBase.pack_inputs": {
            "name": "pack_inputs",
            "location": 586,
            "return": [
                "PackedSequence"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "torch.Tensor"
                ],
                "lengths": [
                    "Optional[torch.Tensor]"
                ]
            }
        },
        "FastElmoBase.unpack_output": {
            "name": "unpack_output",
            "location": 593,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "output": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoBase.unpack_outputs": {
            "name": "unpack_outputs",
            "location": 599,
            "return": [
                "List[torch.Tensor]"
            ],
            "arguments": {
                "self": [],
                "mixed_reprs": [
                    "List[PackedSequence]"
                ]
            }
        },
        "FastElmoBase.to_allennlp_elmo_output_format": {
            "name": "to_allennlp_elmo_output_format",
            "location": 608,
            "return": [
                "Dict[(str, Union[(torch.Tensor, List[torch.Tensor])])]"
            ],
            "arguments": {
                "self": [],
                "unpacks": [
                    "List[torch.Tensor]"
                ],
                "mask": [
                    "torch.Tensor"
                ]
            }
        },
        "FastElmoBase.preprocess_inputs": {
            "name": "preprocess_inputs",
            "location": 615,
            "return": [
                "Tuple[(torch.Tensor, torch.Tensor, torch.Tensor, Optional[torch.Tensor])]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "torch.Tensor"
                ]
            }
        },
        "FastElmoBase.postprocess_outputs": {
            "name": "postprocess_outputs",
            "location": 631,
            "return": [
                "Tuple[(List[torch.Tensor], torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "unpacked_tensors": [
                    "List[torch.Tensor]"
                ],
                "restoration_index": [
                    "Optional[torch.Tensor]"
                ],
                "inputs": [
                    "torch.Tensor"
                ],
                "original_lengths": [
                    "torch.Tensor"
                ]
            }
        },
        "FastElmoBase.forward_with_sorting_and_packing": {
            "name": "forward_with_sorting_and_packing",
            "location": 652,
            "return": [
                "Tuple[(List[torch.Tensor], torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "torch.Tensor"
                ]
            }
        },
        "FastElmoBase.execute": {
            "name": "execute",
            "location": 671,
            "return": [
                "List[PackedSequence]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoBase.forward_like_allennlp": {
            "name": "forward_like_allennlp",
            "location": 674,
            "return": [
                "Dict[(str, Union[(torch.Tensor, List[torch.Tensor])])]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "torch.Tensor"
                ]
            }
        },
        "FastElmoBase.forward": {
            "name": "forward",
            "location": 681,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "FastElmo.__init__": {
            "name": "__init__",
            "location": 687,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "options_file": [
                    "Optional[str]"
                ],
                "weight_file": [
                    "str"
                ]
            }
        },
        "FastElmo.execute": {
            "name": "execute",
            "location": 703,
            "return": [
                "List[PackedSequence]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmo.forward": {
            "name": "forward",
            "location": 708,
            "return": [
                "Dict[(str, Union[(torch.Tensor, List[torch.Tensor])])]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "torch.Tensor"
                ]
            }
        },
        "FastElmoWordEmbedding.__init__": {
            "name": "__init__",
            "location": 722,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "options_file": [
                    "Optional[str]"
                ],
                "weight_file": [
                    "str"
                ]
            }
        },
        "FastElmoWordEmbedding.execute": {
            "name": "execute",
            "location": 742,
            "return": [
                "List[PackedSequence]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoWordEmbedding.forward": {
            "name": "forward",
            "location": 747,
            "return": [
                "Dict[(str, Union[(torch.Tensor, List[torch.Tensor])])]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "torch.Tensor"
                ]
            }
        },
        "FastElmoPlainEncoderBase.exec_context_independent_repr": {
            "name": "exec_context_independent_repr",
            "location": 759,
            "return": [
                "PackedSequence"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoPlainEncoderBase.execute": {
            "name": "execute",
            "location": 762,
            "return": [
                "List[PackedSequence]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoPlainEncoderBase.forward": {
            "name": "forward",
            "location": 773,
            "return": [
                "Tuple[(List[torch.Tensor], torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "torch.Tensor"
                ]
            }
        },
        "FastElmoPlainEncoder.__init__": {
            "name": "__init__",
            "location": 785,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "options_file": [
                    "Optional[str]"
                ],
                "weight_file": [
                    "str"
                ]
            }
        },
        "FastElmoPlainEncoder.exec_context_independent_repr": {
            "name": "exec_context_independent_repr",
            "location": 795,
            "return": [
                "PackedSequence"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoWordEmbeddingPlainEncoder.__init__": {
            "name": "__init__",
            "location": 801,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "options_file": [
                    "Optional[str]"
                ],
                "weight_file": [
                    "str"
                ]
            }
        },
        "FastElmoWordEmbeddingPlainEncoder.exec_context_independent_repr": {
            "name": "exec_context_independent_repr",
            "location": 813,
            "return": [
                "PackedSequence"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoUnidirectionalVocabDistribBase.exec_forward_vocab_prob_distrib": {
            "name": "exec_forward_vocab_prob_distrib",
            "location": 819,
            "return": [
                "List[PackedSequence]"
            ],
            "arguments": {
                "self": [],
                "token_repr": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoUnidirectionalVocabDistribBase.exec_backward_vocab_prob_distrib": {
            "name": "exec_backward_vocab_prob_distrib",
            "location": 824,
            "return": [
                "List[PackedSequence]"
            ],
            "arguments": {
                "self": [],
                "token_repr": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoUnidirectionalVocabDistribBase.forward": {
            "name": "forward",
            "location": 829,
            "return": [
                "Tuple[(torch.Tensor, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "torch.Tensor"
                ]
            }
        },
        "FastElmoForwardVocabDistrib.__init__": {
            "name": "__init__",
            "location": 839,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "options_file": [
                    "Optional[str]"
                ],
                "weight_file": [
                    "str"
                ]
            }
        },
        "FastElmoForwardVocabDistrib.execute": {
            "name": "execute",
            "location": 854,
            "return": [
                "List[PackedSequence]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoBackwardVocabDistrib.__init__": {
            "name": "__init__",
            "location": 861,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "options_file": [
                    "Optional[str]"
                ],
                "weight_file": [
                    "str"
                ]
            }
        },
        "FastElmoBackwardVocabDistrib.execute": {
            "name": "execute",
            "location": 876,
            "return": [
                "List[PackedSequence]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoWordEmbeddingForwardVocabDistrib.__init__": {
            "name": "__init__",
            "location": 883,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "options_file": [
                    "Optional[str]"
                ],
                "weight_file": [
                    "str"
                ]
            }
        },
        "FastElmoWordEmbeddingForwardVocabDistrib.execute": {
            "name": "execute",
            "location": 900,
            "return": [
                "List[PackedSequence]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "PackedSequence"
                ]
            }
        },
        "FastElmoWordEmbeddingBackwardVocabDistrib.__init__": {
            "name": "__init__",
            "location": 907,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "options_file": [
                    "Optional[str]"
                ],
                "weight_file": [
                    "str"
                ]
            }
        },
        "FastElmoWordEmbeddingBackwardVocabDistrib.execute": {
            "name": "execute",
            "location": 924,
            "return": [
                "List[PackedSequence]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "PackedSequence"
                ]
            }
        },
        "ScalarMix.forward.apply_layer_norm": {
            "name": "apply_layer_norm",
            "location": 64,
            "return": [],
            "arguments": {
                "tensor": [],
                "broadcast_mask": [],
                "num_elements_not_masked": []
            }
        }
    },
    "pytorch-fast-elmo-master/pytorch_fast_elmo/utils.py": {
        "load_vocab": {
            "name": "load_vocab",
            "location": 11,
            "return": [
                "List[str]"
            ],
            "arguments": {
                "vocab_txt": [
                    "str"
                ]
            }
        },
        "build_vocab2id": {
            "name": "build_vocab2id",
            "location": 24,
            "return": [
                "Dict[(str, int)]"
            ],
            "arguments": {
                "vocab": [
                    "List[str]"
                ]
            }
        },
        "load_and_build_vocab2id": {
            "name": "load_and_build_vocab2id",
            "location": 33,
            "return": [
                "Dict[(str, int)]"
            ],
            "arguments": {
                "vocab_txt": [
                    "str"
                ]
            }
        },
        "get_lengths_of_zero_padded_batch": {
            "name": "get_lengths_of_zero_padded_batch",
            "location": 37,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "inputs": [
                    "torch.Tensor"
                ]
            }
        },
        "pack_inputs": {
            "name": "pack_inputs",
            "location": 48,
            "return": [
                "PackedSequence"
            ],
            "arguments": {
                "inputs": [
                    "torch.Tensor"
                ],
                "lengths": [
                    "Optional[torch.Tensor]"
                ]
            }
        },
        "generate_mask_from_lengths": {
            "name": "generate_mask_from_lengths",
            "location": 61,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "batch_size": [
                    "int"
                ],
                "max_timesteps": [
                    "int"
                ],
                "lengths": [
                    "torch.Tensor"
                ]
            }
        },
        "unpack_outputs": {
            "name": "unpack_outputs",
            "location": 71,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "inputs": [
                    "PackedSequence"
                ]
            }
        },
        "make_padded_char_ids": {
            "name": "make_padded_char_ids",
            "location": 92,
            "return": [
                "List[int]"
            ],
            "arguments": {
                "char_ids": [
                    "Iterable[int]"
                ],
                "max_word_length": [
                    "int"
                ],
                "padding_character": [
                    "int"
                ],
                "beginning_of_word_character": [
                    "int"
                ],
                "end_of_word_character": [
                    "int"
                ]
            }
        },
        "make_bos": {
            "name": "make_bos",
            "location": 115,
            "return": [
                "List[int]"
            ],
            "arguments": {
                "max_word_length": [
                    "int"
                ]
            }
        },
        "make_eos": {
            "name": "make_eos",
            "location": 122,
            "return": [
                "List[int]"
            ],
            "arguments": {
                "max_word_length": [
                    "int"
                ]
            }
        },
        "word_to_char_ids": {
            "name": "word_to_char_ids",
            "location": 129,
            "return": [
                "List[int]"
            ],
            "arguments": {
                "word": [
                    "str"
                ]
            }
        },
        "batch_to_char_ids": {
            "name": "batch_to_char_ids",
            "location": 140,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "batch": [
                    "List[List[str]]"
                ],
                "max_characters_per_token": [
                    "int"
                ]
            }
        },
        "batch_to_word_ids": {
            "name": "batch_to_word_ids",
            "location": 181,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "batch": [
                    "List[List[str]]"
                ],
                "vocab2id": [
                    "Dict[(str, int)]"
                ]
            }
        },
        "get_bos_eos_token_repr": {
            "name": "get_bos_eos_token_repr",
            "location": 200,
            "return": [
                "Tuple[(torch.Tensor, torch.Tensor)]"
            ],
            "arguments": {
                "char_cnn_factory": [
                    "ElmoCharacterEncoderFactory"
                ],
                "char_cnn": [
                    "ElmoCharacterEncoder"
                ]
            }
        },
        "sort_batch_by_length": {
            "name": "sort_batch_by_length",
            "location": 222,
            "return": [
                "Tuple[(torch.Tensor, torch.Tensor, torch.Tensor)]"
            ],
            "arguments": {
                "batch": [
                    "torch.Tensor"
                ],
                "lengths": [
                    "Optional[torch.Tensor]"
                ]
            }
        },
        "export_word_embedding_to_txt": {
            "name": "export_word_embedding_to_txt",
            "location": 242,
            "return": [
                "None"
            ],
            "arguments": {
                "vocab": [
                    "List[str]"
                ],
                "embedding_weight": [
                    "np.array"
                ],
                "txt_out": [
                    "str"
                ]
            }
        },
        "cache_char_cnn_vocab": {
            "name": "cache_char_cnn_vocab",
            "location": 262,
            "return": [
                "None"
            ],
            "arguments": {
                "vocab_txt": [
                    "str"
                ],
                "options_file": [
                    "str"
                ],
                "weight_file": [
                    "str"
                ],
                "txt_out": [
                    "str"
                ],
                "max_characters_per_token": [
                    "int"
                ],
                "cuda_device": [
                    "int"
                ],
                "batch_size": [
                    "int"
                ]
            }
        },
        "export_word_embd": {
            "name": "export_word_embd",
            "location": 329,
            "return": [
                "None"
            ],
            "arguments": {
                "vocab_txt": [
                    "str"
                ],
                "weight_file": [
                    "str"
                ],
                "txt_out": [
                    "str"
                ]
            }
        }
    },
    "pytorch-fast-elmo-master/pytorch_fast_elmo/__init__.py": {},
    "pytorch-fast-elmo-master/pytorch_fast_elmo/tool/cli.py": {
        "main": {
            "name": "main",
            "location": 160,
            "return": [],
            "arguments": {}
        },
        "Main.cache_char_cnn": {
            "name": "cache_char_cnn",
            "location": 13,
            "return": [],
            "arguments": {
                "self": [],
                "vocab_txt": [],
                "options_file": [],
                "weight_file": [],
                "txt_out": [],
                "max_characters_per_token": [],
                "cuda_device": [],
                "batch_size": []
            }
        },
        "Main.export_word_embd": {
            "name": "export_word_embd",
            "location": 33,
            "return": [],
            "arguments": {
                "self": [],
                "vocab_txt": [],
                "weight_file": [],
                "txt_out": []
            }
        },
        "Main.profile_full": {
            "name": "profile_full",
            "location": 45,
            "return": [],
            "arguments": {
                "self": [],
                "mode": [],
                "options_file": [],
                "weight_file": [],
                "cuda_device": [],
                "cuda_synchronize": [],
                "batch_size": [],
                "warmup_size": [],
                "iteration_size": [],
                "word_min": [],
                "word_max": [],
                "sent_min": [],
                "sent_max": [],
                "random_seed": [],
                "profiler": [],
                "output_file": []
            }
        },
        "Main.sample_sentence": {
            "name": "sample_sentence",
            "location": 101,
            "return": [],
            "arguments": {
                "self": [],
                "options_file": [],
                "weight_file": [],
                "vocab_txt": [],
                "output_json": [],
                "enable_trace": [],
                "go_forward": [],
                "no_char_cnn": [],
                "char_cnn_maxlen": [],
                "next_token_top_k": [],
                "sample_size": [],
                "sample_constrain_txt": [],
                "warm_up_txt": [],
                "cuda_device": []
            }
        },
        "Main.encode_sentences": {
            "name": "encode_sentences",
            "location": 133,
            "return": [],
            "arguments": {
                "self": [],
                "options_file": [],
                "weight_file": [],
                "vocab_txt": [],
                "input_txt": [],
                "output_hdf5": [],
                "no_char_cnn": [],
                "char_cnn_maxlen": [],
                "scalar_mix": [],
                "warm_up_txt": [],
                "cuda_device": []
            }
        }
    },
    "pytorch-fast-elmo-master/pytorch_fast_elmo/tool/inspect.py": {
        "_generate_vocab2id_id2vocab": {
            "name": "_generate_vocab2id_id2vocab",
            "location": 28,
            "return": [
                "Tuple[(Dict[(str, int)], Dict[(int, str)])]"
            ],
            "arguments": {
                "vocab_txt": [
                    "str"
                ]
            }
        },
        "_generate_batch_to_ids": {
            "name": "_generate_batch_to_ids",
            "location": 34,
            "return": [
                "Callable[([List[List[str]]], torch.Tensor)]"
            ],
            "arguments": {
                "vocab2id": [
                    "Dict[(str, int)]"
                ],
                "char_cnn_maxlen": [
                    "int"
                ],
                "no_char_cnn": [
                    "bool"
                ],
                "cuda_device": [
                    "int"
                ]
            }
        },
        "_warm_up": {
            "name": "_warm_up",
            "location": 61,
            "return": [
                "None"
            ],
            "arguments": {
                "warm_up_txt": [
                    "str"
                ],
                "batch_to_ids": [
                    "Callable[([List[List[str]]], torch.Tensor)]"
                ],
                "elmo": [
                    "FastElmoBase"
                ]
            }
        },
        "sample_sentence": {
            "name": "sample_sentence",
            "location": 80,
            "return": [
                "None"
            ],
            "arguments": {
                "options_file": [
                    "str"
                ],
                "weight_file": [
                    "str"
                ],
                "vocab_txt": [
                    "str"
                ],
                "output_json": [
                    "str"
                ],
                "enable_trace": [
                    "bool"
                ],
                "no_char_cnn": [
                    "bool"
                ],
                "char_cnn_maxlen": [
                    "int"
                ],
                "go_forward": [
                    "bool"
                ],
                "next_token_top_k": [
                    "int"
                ],
                "sample_size": [
                    "int"
                ],
                "sample_constrain_txt": [
                    "Optional[str]"
                ],
                "warm_up_txt": [
                    "Optional[str]"
                ],
                "cuda_device": [
                    "int"
                ]
            }
        },
        "encode_sentences": {
            "name": "encode_sentences",
            "location": 194,
            "return": [
                "None"
            ],
            "arguments": {
                "options_file": [
                    "str"
                ],
                "weight_file": [
                    "str"
                ],
                "vocab_txt": [
                    "str"
                ],
                "input_txt": [
                    "str"
                ],
                "output_hdf5": [
                    "str"
                ],
                "no_char_cnn": [
                    "bool"
                ],
                "char_cnn_maxlen": [
                    "int"
                ],
                "scalar_mix": [
                    "Optional[Tuple[float]]"
                ],
                "warm_up_txt": [
                    "Optional[str]"
                ],
                "cuda_device": [
                    "int"
                ]
            }
        },
        "_generate_batch_to_ids.batch_to_ids": {
            "name": "batch_to_ids",
            "location": 49,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "batch": [
                    "List[List[str]]"
                ]
            }
        }
    },
    "pytorch-fast-elmo-master/pytorch_fast_elmo/tool/profile.py": {
        "load_fast_elmo": {
            "name": "load_fast_elmo",
            "location": 38,
            "return": [
                "FastElmo"
            ],
            "arguments": {
                "options_file": [
                    "str"
                ],
                "weight_file": [
                    "str"
                ]
            }
        },
        "load_allennlp_elmo": {
            "name": "load_allennlp_elmo",
            "location": 49,
            "return": [
                "Any"
            ],
            "arguments": {
                "options_file": [
                    "str"
                ],
                "weight_file": [
                    "str"
                ]
            }
        },
        "profile_full_elmo": {
            "name": "profile_full_elmo",
            "location": 63,
            "return": [
                "Tuple[(float, float, float)]"
            ],
            "arguments": {
                "mode": [
                    "str"
                ],
                "options_file": [
                    "str"
                ],
                "weight_file": [
                    "str"
                ],
                "cuda_device": [
                    "int"
                ],
                "cuda_synchronize": [
                    "bool"
                ],
                "batch_size": [
                    "int"
                ],
                "warmup_size": [
                    "int"
                ],
                "iteration_size": [
                    "int"
                ],
                "word_min": [
                    "int"
                ],
                "word_max": [
                    "int"
                ],
                "sent_min": [
                    "int"
                ],
                "sent_max": [
                    "int"
                ],
                "random_seed": [
                    "int"
                ]
            }
        },
        "SentenceGenerator.__init__": {
            "name": "__init__",
            "location": 13,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_min": [
                    "int"
                ],
                "word_max": [
                    "int"
                ],
                "sent_min": [
                    "int"
                ],
                "sent_max": [
                    "int"
                ]
            }
        },
        "SentenceGenerator.generate_sentence": {
            "name": "generate_sentence",
            "location": 25,
            "return": [
                "List[str]"
            ],
            "arguments": {
                "self": []
            }
        },
        "SentenceGenerator.generate_batch": {
            "name": "generate_batch",
            "location": 34,
            "return": [
                "List[List[str]]"
            ],
            "arguments": {
                "self": [],
                "batch_size": [
                    "int"
                ]
            }
        }
    },
    "pytorch-fast-elmo-master/pytorch_fast_elmo/tool/__init__.py": {},
    "pytorch-fast-elmo-master/tests/test_elmo.py": {
        "test_elmo_character_encoder_simple": {
            "name": "test_elmo_character_encoder_simple",
            "location": 35,
            "return": [],
            "arguments": {}
        },
        "_sentences_to_ids": {
            "name": "_sentences_to_ids",
            "location": 52,
            "return": [],
            "arguments": {
                "sentences": []
            }
        },
        "_unpack": {
            "name": "_unpack",
            "location": 69,
            "return": [],
            "arguments": {
                "tensor": [],
                "batch_sizes": []
            }
        },
        "test_elmo_character_encoder_with_allennlp": {
            "name": "test_elmo_character_encoder_with_allennlp",
            "location": 77,
            "return": [],
            "arguments": {}
        },
        "test_elmo_lstm_factory_simple": {
            "name": "test_elmo_lstm_factory_simple",
            "location": 177,
            "return": [],
            "arguments": {}
        },
        "test_fast_elmo_with_allennlp": {
            "name": "test_fast_elmo_with_allennlp",
            "location": 258,
            "return": [],
            "arguments": {}
        },
        "test_fast_elmo_with_allennlp_do_layer_norm": {
            "name": "test_fast_elmo_with_allennlp_do_layer_norm",
            "location": 305,
            "return": [],
            "arguments": {}
        },
        "test_fast_elmo_save_and_load": {
            "name": "test_fast_elmo_save_and_load",
            "location": 371,
            "return": [],
            "arguments": {}
        },
        "test_fast_elmo_word_embedding": {
            "name": "test_fast_elmo_word_embedding",
            "location": 392,
            "return": [],
            "arguments": {}
        }
    },
    "pytorch-fast-elmo-master/tests/test_scalar_mix.py": {
        "test_scalar_mix_can_run_forward": {
            "name": "test_scalar_mix_can_run_forward",
            "location": 10,
            "return": [],
            "arguments": {}
        },
        "test_scalar_mix_throws_error_on_incorrect_number_of_inputs": {
            "name": "test_scalar_mix_throws_error_on_incorrect_number_of_inputs",
            "location": 25,
            "return": [],
            "arguments": {}
        },
        "test_scalar_mix_throws_error_on_incorrect_initial_scalar_parameters_length": {
            "name": "test_scalar_mix_throws_error_on_incorrect_initial_scalar_parameters_length",
            "location": 32,
            "return": [],
            "arguments": {}
        },
        "test_scalar_mix_trainable_with_initial_scalar_parameters": {
            "name": "test_scalar_mix_trainable_with_initial_scalar_parameters",
            "location": 37,
            "return": [],
            "arguments": {}
        },
        "test_scalar_mix_layer_norm": {
            "name": "test_scalar_mix_layer_norm",
            "location": 45,
            "return": [],
            "arguments": {}
        }
    },
    "pytorch-fast-elmo-master/tests/test_utils.py": {
        "test_batch_to_char_ids": {
            "name": "test_batch_to_char_ids",
            "location": 15,
            "return": [],
            "arguments": {}
        },
        "test_cache_char_cnn_vocab": {
            "name": "test_cache_char_cnn_vocab",
            "location": 31,
            "return": [],
            "arguments": {
                "tmpdir": []
            }
        },
        "test_sort_batch_by_length": {
            "name": "test_sort_batch_by_length",
            "location": 87,
            "return": [],
            "arguments": {}
        }
    }
}
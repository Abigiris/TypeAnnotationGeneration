{
    "r2c-master/config.py": {},
    "r2c-master/data/get_bert_embeddings/create_pretraining_data.py": {
        "write_instance_to_example_files": {
            "name": "write_instance_to_example_files",
            "location": 89,
            "return": [],
            "arguments": {
                "instances": [],
                "tokenizer": [],
                "max_seq_length": [],
                "max_predictions_per_seq": [],
                "output_files": []
            }
        },
        "create_int_feature": {
            "name": "create_int_feature",
            "location": 162,
            "return": [],
            "arguments": {
                "values": []
            }
        },
        "create_float_feature": {
            "name": "create_float_feature",
            "location": 167,
            "return": [],
            "arguments": {
                "values": []
            }
        },
        "create_training_instances": {
            "name": "create_training_instances",
            "location": 172,
            "return": [],
            "arguments": {
                "tokenizer": [],
                "rng": []
            }
        },
        "create_masked_lm_predictions": {
            "name": "create_masked_lm_predictions",
            "location": 202,
            "return": [],
            "arguments": {
                "tokens": [],
                "masked_lm_prob": [],
                "max_predictions_per_seq": [],
                "vocab_words": [],
                "rng": []
            }
        },
        "TrainingInstance.__init__": {
            "name": "__init__",
            "location": 64,
            "return": [],
            "arguments": {
                "self": [],
                "tokens": [],
                "segment_ids": [],
                "masked_lm_positions": [],
                "masked_lm_labels": [],
                "is_random_next": []
            }
        },
        "TrainingInstance.__str__": {
            "name": "__str__",
            "location": 72,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TrainingInstance.__repr__": {
            "name": "__repr__",
            "location": 85,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "r2c-master/data/get_bert_embeddings/extract_features.py": {
        "model_fn_builder": {
            "name": "model_fn_builder",
            "location": 97,
            "return": [],
            "arguments": {
                "bert_config": [],
                "init_checkpoint": [],
                "layer_indexes": [],
                "use_tpu": [],
                "use_one_hot_embeddings": []
            }
        },
        "_truncate_seq_pair": {
            "name": "_truncate_seq_pair",
            "location": 150,
            "return": [],
            "arguments": {
                "tokens_a": [],
                "tokens_b": [],
                "max_length": []
            }
        },
        "alignment_gather": {
            "name": "alignment_gather",
            "location": 238,
            "return": [],
            "arguments": {
                "alignment": [],
                "layer": []
            }
        },
        "model_fn_builder.model_fn": {
            "name": "model_fn",
            "location": 101,
            "return": [],
            "arguments": {
                "features": [],
                "labels": [],
                "mode": [],
                "params": []
            }
        },
        "model_fn_builder.model_fn.tpu_scaffold": {
            "name": "tpu_scaffold",
            "location": 126,
            "return": [],
            "arguments": {}
        }
    },
    "r2c-master/data/get_bert_embeddings/modeling.py": {
        "gelu": {
            "name": "gelu",
            "location": 264,
            "return": [],
            "arguments": {
                "input_tensor": []
            }
        },
        "get_activation": {
            "name": "get_activation",
            "location": 280,
            "return": [],
            "arguments": {
                "activation_string": []
            }
        },
        "get_assignment_map_from_checkpoint": {
            "name": "get_assignment_map_from_checkpoint",
            "location": 317,
            "return": [],
            "arguments": {
                "tvars": [],
                "init_checkpoint": []
            }
        },
        "dropout": {
            "name": "dropout",
            "location": 344,
            "return": [],
            "arguments": {
                "input_tensor": [],
                "dropout_prob": []
            }
        },
        "layer_norm": {
            "name": "layer_norm",
            "location": 362,
            "return": [],
            "arguments": {
                "input_tensor": [],
                "name": []
            }
        },
        "layer_norm_and_dropout": {
            "name": "layer_norm_and_dropout",
            "location": 368,
            "return": [],
            "arguments": {
                "input_tensor": [],
                "dropout_prob": [],
                "name": []
            }
        },
        "create_initializer": {
            "name": "create_initializer",
            "location": 375,
            "return": [],
            "arguments": {
                "initializer_range": []
            }
        },
        "embedding_lookup": {
            "name": "embedding_lookup",
            "location": 380,
            "return": [],
            "arguments": {
                "input_ids": [],
                "vocab_size": [],
                "embedding_size": [],
                "initializer_range": [],
                "word_embedding_name": [],
                "use_one_hot_embeddings": []
            }
        },
        "embedding_postprocessor": {
            "name": "embedding_postprocessor",
            "location": 429,
            "return": [],
            "arguments": {
                "input_tensor": [],
                "use_token_type": [],
                "token_type_ids": [],
                "token_type_vocab_size": [],
                "token_type_embedding_name": [],
                "use_position_embeddings": [],
                "position_embedding_name": [],
                "initializer_range": [],
                "max_position_embeddings": [],
                "dropout_prob": []
            }
        },
        "create_attention_mask_from_input_mask": {
            "name": "create_attention_mask_from_input_mask",
            "location": 532,
            "return": [],
            "arguments": {
                "from_tensor": [],
                "to_mask": []
            }
        },
        "attention_layer": {
            "name": "attention_layer",
            "location": 566,
            "return": [],
            "arguments": {
                "from_tensor": [],
                "to_tensor": [],
                "attention_mask": [],
                "num_attention_heads": [],
                "size_per_head": [],
                "query_act": [],
                "key_act": [],
                "value_act": [],
                "attention_probs_dropout_prob": [],
                "initializer_range": [],
                "do_return_2d_tensor": [],
                "batch_size": [],
                "from_seq_length": [],
                "to_seq_length": []
            }
        },
        "transformer_model": {
            "name": "transformer_model",
            "location": 762,
            "return": [],
            "arguments": {
                "input_tensor": [],
                "attention_mask": [],
                "hidden_size": [],
                "num_hidden_layers": [],
                "num_attention_heads": [],
                "intermediate_size": [],
                "intermediate_act_fn": [],
                "hidden_dropout_prob": [],
                "attention_probs_dropout_prob": [],
                "initializer_range": [],
                "do_return_all_layers": []
            }
        },
        "get_shape_list": {
            "name": "get_shape_list",
            "location": 903,
            "return": [],
            "arguments": {
                "tensor": [],
                "expected_rank": [],
                "name": []
            }
        },
        "reshape_to_matrix": {
            "name": "reshape_to_matrix",
            "location": 940,
            "return": [],
            "arguments": {
                "input_tensor": []
            }
        },
        "reshape_from_matrix": {
            "name": "reshape_from_matrix",
            "location": 954,
            "return": [],
            "arguments": {
                "output_tensor": [],
                "orig_shape_list": []
            }
        },
        "assert_rank": {
            "name": "assert_rank",
            "location": 967,
            "return": [],
            "arguments": {
                "tensor": [],
                "expected_rank": [],
                "name": []
            }
        },
        "create_model": {
            "name": "create_model",
            "location": 997,
            "return": [],
            "arguments": {
                "bert_config": [],
                "is_training": [],
                "input_ids": [],
                "input_mask": [],
                "segment_ids": [],
                "labels": [],
                "num_labels": [],
                "use_one_hot_embeddings": []
            }
        },
        "BertConfig.__init__": {
            "name": "__init__",
            "location": 32,
            "return": [],
            "arguments": {
                "self": [],
                "vocab_size": [],
                "hidden_size": [],
                "num_hidden_layers": [],
                "num_attention_heads": [],
                "intermediate_size": [],
                "hidden_act": [],
                "hidden_dropout_prob": [],
                "attention_probs_dropout_prob": [],
                "max_position_embeddings": [],
                "type_vocab_size": [],
                "initializer_range": []
            }
        },
        "BertConfig.from_dict": {
            "name": "from_dict",
            "location": 81,
            "return": [],
            "arguments": {
                "cls": [],
                "json_object": []
            }
        },
        "BertConfig.from_json_file": {
            "name": "from_json_file",
            "location": 89,
            "return": [],
            "arguments": {
                "cls": [],
                "json_file": []
            }
        },
        "BertConfig.to_dict": {
            "name": "to_dict",
            "location": 95,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "BertConfig.to_json_string": {
            "name": "to_json_string",
            "location": 100,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "BertModel.__init__": {
            "name": "__init__",
            "location": 129,
            "return": [],
            "arguments": {
                "self": [],
                "config": [],
                "is_training": [],
                "input_ids": [],
                "input_mask": [],
                "token_type_ids": [],
                "use_one_hot_embeddings": [],
                "scope": []
            }
        },
        "BertModel.get_pooled_output": {
            "name": "get_pooled_output",
            "location": 234,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "BertModel.get_sequence_output": {
            "name": "get_sequence_output",
            "location": 237,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "BertModel.get_all_encoder_layers": {
            "name": "get_all_encoder_layers",
            "location": 246,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "BertModel.get_embedding_output": {
            "name": "get_embedding_output",
            "location": 249,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "BertModel.get_embedding_table": {
            "name": "get_embedding_table",
            "location": 260,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "attention_layer.transpose_for_scores": {
            "name": "transpose_for_scores",
            "location": 637,
            "return": [],
            "arguments": {
                "input_tensor": [],
                "batch_size": [],
                "num_attention_heads": [],
                "seq_length": [],
                "width": []
            }
        }
    },
    "r2c-master/data/get_bert_embeddings/optimization.py": {
        "create_optimizer": {
            "name": "create_optimizer",
            "location": 25,
            "return": [],
            "arguments": {
                "loss": [],
                "init_lr": [],
                "num_train_steps": [],
                "num_warmup_steps": [],
                "use_tpu": []
            }
        },
        "AdamWeightDecayOptimizer.__init__": {
            "name": "__init__",
            "location": 87,
            "return": [],
            "arguments": {
                "self": [],
                "learning_rate": [],
                "weight_decay_rate": [],
                "beta_1": [],
                "beta_2": [],
                "epsilon": [],
                "exclude_from_weight_decay": [],
                "name": []
            }
        },
        "AdamWeightDecayOptimizer.apply_gradients": {
            "name": "apply_gradients",
            "location": 105,
            "return": [],
            "arguments": {
                "self": [],
                "grads_and_vars": [],
                "global_step": [],
                "name": []
            }
        },
        "AdamWeightDecayOptimizer._do_use_weight_decay": {
            "name": "_do_use_weight_decay",
            "location": 156,
            "return": [],
            "arguments": {
                "self": [],
                "param_name": []
            }
        },
        "AdamWeightDecayOptimizer._get_variable_name": {
            "name": "_get_variable_name",
            "location": 166,
            "return": [],
            "arguments": {
                "self": [],
                "param_name": []
            }
        }
    },
    "r2c-master/data/get_bert_embeddings/pretrain_on_vcr.py": {
        "model_fn_builder": {
            "name": "model_fn_builder",
            "location": 120,
            "return": [],
            "arguments": {
                "bert_config": [],
                "init_checkpoint": [],
                "learning_rate": [],
                "num_train_steps": [],
                "num_warmup_steps": [],
                "use_tpu": [],
                "use_one_hot_embeddings": []
            }
        },
        "get_masked_lm_output": {
            "name": "get_masked_lm_output",
            "location": 251,
            "return": [],
            "arguments": {
                "bert_config": [],
                "input_tensor": [],
                "output_weights": [],
                "positions": [],
                "label_ids": [],
                "label_weights": []
            }
        },
        "get_next_sentence_output": {
            "name": "get_next_sentence_output",
            "location": 296,
            "return": [],
            "arguments": {
                "bert_config": [],
                "input_tensor": [],
                "labels": []
            }
        },
        "gather_indexes": {
            "name": "gather_indexes",
            "location": 319,
            "return": [],
            "arguments": {
                "sequence_tensor": [],
                "positions": []
            }
        },
        "input_fn_builder": {
            "name": "input_fn_builder",
            "location": 335,
            "return": [],
            "arguments": {
                "input_files": [],
                "max_seq_length": [],
                "max_predictions_per_seq": [],
                "is_training": [],
                "num_cpu_threads": []
            }
        },
        "_decode_record": {
            "name": "_decode_record",
            "location": 402,
            "return": [],
            "arguments": {
                "record": [],
                "name_to_features": []
            }
        },
        "model_fn_builder.model_fn": {
            "name": "model_fn",
            "location": 125,
            "return": [],
            "arguments": {
                "features": [],
                "labels": [],
                "mode": [],
                "params": []
            }
        },
        "input_fn_builder.input_fn": {
            "name": "input_fn",
            "location": 342,
            "return": [],
            "arguments": {
                "params": []
            }
        },
        "model_fn_builder.model_fn.tpu_scaffold": {
            "name": "tpu_scaffold",
            "location": 170,
            "return": [],
            "arguments": {}
        },
        "model_fn_builder.model_fn.metric_fn": {
            "name": "metric_fn",
            "location": 198,
            "return": [],
            "arguments": {
                "masked_lm_example_loss": [],
                "masked_lm_log_probs": [],
                "masked_lm_ids": [],
                "masked_lm_weights": [],
                "next_sentence_example_loss": [],
                "next_sentence_log_probs": [],
                "next_sentence_labels": []
            }
        }
    },
    "r2c-master/data/get_bert_embeddings/tokenization.py": {
        "convert_to_unicode": {
            "name": "convert_to_unicode",
            "location": 27,
            "return": [],
            "arguments": {
                "text": [],
                "errors": []
            }
        },
        "printable_text": {
            "name": "printable_text",
            "location": 37,
            "return": [],
            "arguments": {
                "text": []
            }
        },
        "load_vocab": {
            "name": "load_vocab",
            "location": 60,
            "return": [],
            "arguments": {
                "vocab_file": []
            }
        },
        "convert_tokens_to_ids": {
            "name": "convert_tokens_to_ids",
            "location": 75,
            "return": [],
            "arguments": {
                "vocab": [],
                "tokens": []
            }
        },
        "whitespace_tokenize": {
            "name": "whitespace_tokenize",
            "location": 83,
            "return": [],
            "arguments": {
                "text": []
            }
        },
        "_is_whitespace": {
            "name": "_is_whitespace",
            "location": 245,
            "return": [],
            "arguments": {
                "char": []
            }
        },
        "_is_control": {
            "name": "_is_control",
            "location": 257,
            "return": [],
            "arguments": {
                "char": []
            }
        },
        "_is_punctuation": {
            "name": "_is_punctuation",
            "location": 269,
            "return": [],
            "arguments": {
                "char": []
            }
        },
        "FullTokenizer.__init__": {
            "name": "__init__",
            "location": 95,
            "return": [],
            "arguments": {
                "self": [],
                "vocab_file": [],
                "do_lower_case": []
            }
        },
        "FullTokenizer.tokenize": {
            "name": "tokenize",
            "location": 100,
            "return": [],
            "arguments": {
                "self": [],
                "text": []
            }
        },
        "FullTokenizer.convert_tokens_to_ids": {
            "name": "convert_tokens_to_ids",
            "location": 108,
            "return": [],
            "arguments": {
                "self": [],
                "tokens": []
            }
        },
        "BasicTokenizer.__init__": {
            "name": "__init__",
            "location": 115,
            "return": [],
            "arguments": {
                "self": [],
                "do_lower_case": []
            }
        },
        "BasicTokenizer.tokenize": {
            "name": "tokenize",
            "location": 123,
            "return": [],
            "arguments": {
                "self": [],
                "text": []
            }
        },
        "BasicTokenizer._run_strip_accents": {
            "name": "_run_strip_accents",
            "location": 138,
            "return": [],
            "arguments": {
                "self": [],
                "text": []
            }
        },
        "BasicTokenizer._run_split_on_punc": {
            "name": "_run_split_on_punc",
            "location": 149,
            "return": [],
            "arguments": {
                "self": [],
                "text": []
            }
        },
        "BasicTokenizer._clean_text": {
            "name": "_clean_text",
            "location": 169,
            "return": [],
            "arguments": {
                "self": [],
                "text": []
            }
        },
        "WordpieceTokenizer.__init__": {
            "name": "__init__",
            "location": 186,
            "return": [],
            "arguments": {
                "self": [],
                "vocab": [],
                "unk_token": [],
                "max_input_chars_per_word": []
            }
        },
        "WordpieceTokenizer.tokenize": {
            "name": "tokenize",
            "location": 191,
            "return": [],
            "arguments": {
                "self": [],
                "text": []
            }
        }
    },
    "r2c-master/data/get_bert_embeddings/vcr_loader.py": {
        "input_fn_builder": {
            "name": "input_fn_builder",
            "location": 28,
            "return": [],
            "arguments": {
                "features": [],
                "seq_length": []
            }
        },
        "convert_examples_to_features": {
            "name": "convert_examples_to_features",
            "location": 81,
            "return": [],
            "arguments": {
                "examples": [],
                "seq_length": [],
                "tokenizer": []
            }
        },
        "_fix_tokenization": {
            "name": "_fix_tokenization",
            "location": 168,
            "return": [],
            "arguments": {
                "tokenized_sent": [],
                "obj_to_type": [],
                "det_hist": []
            }
        },
        "fix_item": {
            "name": "fix_item",
            "location": 195,
            "return": [],
            "arguments": {
                "item": [],
                "answer_label": [],
                "rationales": []
            }
        },
        "retokenize_with_alignment": {
            "name": "retokenize_with_alignment",
            "location": 208,
            "return": [],
            "arguments": {
                "span": [],
                "tokenizer": []
            }
        },
        "process_ctx_ans_for_bert": {
            "name": "process_ctx_ans_for_bert",
            "location": 219,
            "return": [],
            "arguments": {
                "ctx_raw": [],
                "ans_raw": [],
                "tokenizer": [],
                "counter": [],
                "endingonly": [],
                "max_seq_length": [],
                "is_correct": []
            }
        },
        "data_iter": {
            "name": "data_iter",
            "location": 262,
            "return": [],
            "arguments": {
                "data_fn": [],
                "tokenizer": [],
                "max_seq_length": [],
                "endingonly": []
            }
        },
        "data_iter_test": {
            "name": "data_iter_test",
            "location": 279,
            "return": [],
            "arguments": {
                "data_fn": [],
                "tokenizer": [],
                "max_seq_length": [],
                "endingonly": []
            }
        },
        "InputExample.__init__": {
            "name": "__init__",
            "location": 9,
            "return": [],
            "arguments": {
                "self": [],
                "unique_id": [],
                "text_a": [],
                "text_b": [],
                "is_correct": []
            }
        },
        "InputFeatures.__init__": {
            "name": "__init__",
            "location": 19,
            "return": [],
            "arguments": {
                "self": [],
                "unique_id": [],
                "tokens": [],
                "input_ids": [],
                "input_mask": [],
                "input_type_ids": [],
                "is_correct": []
            }
        },
        "input_fn_builder.input_fn": {
            "name": "input_fn",
            "location": 42,
            "return": [],
            "arguments": {
                "params": []
            }
        }
    },
    "r2c-master/data/get_bert_embeddings/__init__.py": {},
    "r2c-master/dataloaders/bert_field.py": {
        "BertField.__init__": {
            "name": "__init__",
            "location": 25,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "tokens": [
                    "List[Token]"
                ],
                "embs": [
                    "numpy.ndarray"
                ],
                "padding_value": [
                    "int"
                ],
                "token_indexers": []
            }
        },
        "BertField.sequence_length": {
            "name": "sequence_length",
            "location": 37,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "BertField.get_padding_lengths": {
            "name": "get_padding_lengths",
            "location": 42,
            "return": [
                "Dict[(str, int)]"
            ],
            "arguments": {
                "self": []
            }
        },
        "BertField.as_tensor": {
            "name": "as_tensor",
            "location": 46,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "padding_lengths": [
                    "Dict[(str, int)]"
                ]
            }
        },
        "BertField.empty_field": {
            "name": "empty_field",
            "location": 57,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "BertField.batch_tensors": {
            "name": "batch_tensors",
            "location": 61,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "tensor_list": [
                    "List[Dict[(str, torch.Tensor)]]"
                ]
            }
        },
        "BertField.__str__": {
            "name": "__str__",
            "location": 68,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "r2c-master/dataloaders/box_utils.py": {
        "load_image": {
            "name": "load_image",
            "location": 12,
            "return": [],
            "arguments": {
                "img_fn": []
            }
        },
        "resize_image": {
            "name": "resize_image",
            "location": 31,
            "return": [],
            "arguments": {
                "image": [],
                "desired_width": [],
                "desired_height": [],
                "random_pad": []
            }
        },
        "to_tensor_and_normalize": {
            "name": "to_tensor_and_normalize",
            "location": 72,
            "return": [],
            "arguments": {
                "image": []
            }
        }
    },
    "r2c-master/dataloaders/mask_utils.py": {
        "_spaced_points": {
            "name": "_spaced_points",
            "location": 7,
            "return": [],
            "arguments": {
                "low": [],
                "high": [],
                "n": []
            }
        },
        "make_mask": {
            "name": "make_mask",
            "location": 12,
            "return": [],
            "arguments": {
                "mask_size": [],
                "box": [],
                "polygons_list": []
            }
        }
    },
    "r2c-master/dataloaders/vcr.py": {
        "_fix_tokenization": {
            "name": "_fix_tokenization",
            "location": 66,
            "return": [],
            "arguments": {
                "tokenized_sent": [],
                "bert_embs": [],
                "old_det_to_new_ind": [],
                "obj_to_type": [],
                "token_indexers": [],
                "pad_ind": []
            }
        },
        "collate_fn": {
            "name": "collate_fn",
            "location": 311,
            "return": [],
            "arguments": {
                "data": [],
                "to_gpu": []
            }
        },
        "VCR.__init__": {
            "name": "__init__",
            "location": 99,
            "return": [],
            "arguments": {
                "self": [],
                "split": [],
                "mode": [],
                "only_use_relevant_dets": [],
                "add_image_as_a_box": [],
                "embs_to_load": [],
                "conditioned_answer_choice": []
            }
        },
        "VCR.is_train": {
            "name": "is_train",
            "location": 144,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "VCR.splits": {
            "name": "splits",
            "location": 148,
            "return": [],
            "arguments": {
                "cls": []
            }
        },
        "VCR.eval_splits": {
            "name": "eval_splits",
            "location": 159,
            "return": [],
            "arguments": {
                "cls": []
            }
        },
        "VCR.__len__": {
            "name": "__len__",
            "location": 170,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "VCR._get_dets_to_use": {
            "name": "_get_dets_to_use",
            "location": 173,
            "return": [],
            "arguments": {
                "self": [],
                "item": []
            }
        },
        "VCR.__getitem__": {
            "name": "__getitem__",
            "location": 213,
            "return": [],
            "arguments": {
                "self": [],
                "index": []
            }
        },
        "VCRLoader.from_dataset": {
            "name": "from_dataset",
            "location": 352,
            "return": [],
            "arguments": {
                "cls": [],
                "data": [],
                "batch_size": [],
                "num_workers": [],
                "num_gpus": []
            }
        }
    },
    "r2c-master/dataloaders/__init__.py": {},
    "r2c-master/models/eval_for_leaderboard.py": {},
    "r2c-master/models/eval_q2ar.py": {},
    "r2c-master/models/train.py": {
        "_to_gpu": {
            "name": "_to_gpu",
            "location": 71,
            "return": [],
            "arguments": {
                "td": []
            }
        }
    },
    "r2c-master/models/__init__.py": {},
    "r2c-master/models/multiatt/model.py": {
        "AttentionQA.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [],
            "arguments": {
                "self": [],
                "vocab": [
                    "Vocabulary"
                ],
                "span_encoder": [
                    "Seq2SeqEncoder"
                ],
                "reasoning_encoder": [
                    "Seq2SeqEncoder"
                ],
                "input_dropout": [
                    "float"
                ],
                "hidden_dim_maxpool": [
                    "int"
                ],
                "class_embs": [
                    "bool"
                ],
                "reasoning_use_obj": [
                    "bool"
                ],
                "reasoning_use_answer": [
                    "bool"
                ],
                "reasoning_use_question": [
                    "bool"
                ],
                "pool_reasoning": [
                    "bool"
                ],
                "pool_answer": [
                    "bool"
                ],
                "pool_question": [
                    "bool"
                ],
                "initializer": [
                    "InitializerApplicator"
                ]
            }
        },
        "AttentionQA._collect_obj_reps": {
            "name": "_collect_obj_reps",
            "location": 77,
            "return": [],
            "arguments": {
                "self": [],
                "span_tags": [],
                "object_reps": []
            }
        },
        "AttentionQA.embed_span": {
            "name": "embed_span",
            "location": 95,
            "return": [],
            "arguments": {
                "self": [],
                "span": [],
                "span_tags": [],
                "span_mask": [],
                "object_reps": []
            }
        },
        "AttentionQA.forward": {
            "name": "forward",
            "location": 112,
            "return": [
                "Dict[(str, torch.Tensor)]"
            ],
            "arguments": {
                "self": [],
                "images": [
                    "torch.Tensor"
                ],
                "objects": [
                    "torch.LongTensor"
                ],
                "segms": [
                    "torch.Tensor"
                ],
                "boxes": [
                    "torch.Tensor"
                ],
                "box_mask": [
                    "torch.LongTensor"
                ],
                "question": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "question_tags": [
                    "torch.LongTensor"
                ],
                "question_mask": [
                    "torch.LongTensor"
                ],
                "answers": [
                    "Dict[(str, torch.Tensor)]"
                ],
                "answer_tags": [
                    "torch.LongTensor"
                ],
                "answer_mask": [
                    "torch.LongTensor"
                ],
                "metadata": [
                    "List[Dict[(str, Any)]]"
                ],
                "label": [
                    "torch.LongTensor"
                ]
            }
        },
        "AttentionQA.get_metrics": {
            "name": "get_metrics",
            "location": 215,
            "return": [
                "Dict[(str, float)]"
            ],
            "arguments": {
                "self": [],
                "reset": [
                    "bool"
                ]
            }
        }
    },
    "r2c-master/models/multiatt/__init__.py": {},
    "r2c-master/utils/detector.py": {
        "_load_resnet": {
            "name": "_load_resnet",
            "location": 18,
            "return": [],
            "arguments": {
                "pretrained": []
            }
        },
        "_load_resnet_imagenet": {
            "name": "_load_resnet_imagenet",
            "location": 30,
            "return": [],
            "arguments": {
                "pretrained": []
            }
        },
        "SimpleDetector.__init__": {
            "name": "__init__",
            "location": 49,
            "return": [],
            "arguments": {
                "self": [],
                "pretrained": [],
                "average_pool": [],
                "semantic": [],
                "final_dim": []
            }
        },
        "SimpleDetector.forward": {
            "name": "forward",
            "location": 97,
            "return": [],
            "arguments": {
                "self": [],
                "images": [
                    "torch.Tensor"
                ],
                "boxes": [
                    "torch.Tensor"
                ],
                "box_mask": [
                    "torch.LongTensor"
                ],
                "classes": [
                    "torch.Tensor"
                ],
                "segms": [
                    "torch.Tensor"
                ]
            }
        }
    },
    "r2c-master/utils/pytorch_misc.py": {
        "time_batch": {
            "name": "time_batch",
            "location": 20,
            "return": [],
            "arguments": {
                "gen": [],
                "reset_every": []
            }
        },
        "pad_sequence": {
            "name": "pad_sequence",
            "location": 48,
            "return": [],
            "arguments": {
                "sequence": [],
                "lengths": []
            }
        },
        "extra_leading_dim_in_sequence": {
            "name": "extra_leading_dim_in_sequence",
            "location": 63,
            "return": [],
            "arguments": {
                "f": [],
                "x": [],
                "mask": []
            }
        },
        "clip_grad_norm": {
            "name": "clip_grad_norm",
            "location": 67,
            "return": [],
            "arguments": {
                "named_parameters": [],
                "max_norm": [],
                "clip": [],
                "verbose": []
            }
        },
        "find_latest_checkpoint": {
            "name": "find_latest_checkpoint",
            "location": 109,
            "return": [],
            "arguments": {
                "serialization_dir": []
            }
        },
        "save_checkpoint": {
            "name": "save_checkpoint",
            "location": 152,
            "return": [
                "None"
            ],
            "arguments": {
                "model": [],
                "optimizer": [],
                "serialization_dir": [],
                "epoch": [],
                "val_metric_per_epoch": [],
                "is_best": [],
                "learning_rate_scheduler": []
            }
        },
        "restore_best_checkpoint": {
            "name": "restore_best_checkpoint",
            "location": 187,
            "return": [],
            "arguments": {
                "model": [],
                "serialization_dir": []
            }
        },
        "restore_checkpoint": {
            "name": "restore_checkpoint",
            "location": 197,
            "return": [],
            "arguments": {
                "model": [],
                "optimizer": [],
                "serialization_dir": [],
                "learning_rate_scheduler": []
            }
        },
        "detokenize": {
            "name": "detokenize",
            "location": 256,
            "return": [],
            "arguments": {
                "array": [],
                "vocab": []
            }
        },
        "print_para": {
            "name": "print_para",
            "location": 268,
            "return": [],
            "arguments": {
                "model": []
            }
        },
        "batch_index_iterator": {
            "name": "batch_index_iterator",
            "location": 295,
            "return": [],
            "arguments": {
                "len_l": [],
                "batch_size": [],
                "skip_end": []
            }
        },
        "batch_iterator": {
            "name": "batch_iterator",
            "location": 313,
            "return": [],
            "arguments": {
                "seq": [],
                "batch_size": [],
                "skip_end": []
            }
        },
        "Flattener.__init__": {
            "name": "__init__",
            "location": 38,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "Flattener.forward": {
            "name": "forward",
            "location": 44,
            "return": [],
            "arguments": {
                "self": [],
                "x": []
            }
        }
    },
    "r2c-master/utils/__init__.py": {}
}
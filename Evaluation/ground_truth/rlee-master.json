{
    "rlee-master/eval.py": {
        "main": {
            "name": "main",
            "location": 13,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "rlee-master/setup.py": {},
    "rlee-master/train.py": {
        "main": {
            "name": "main",
            "location": 17,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "rlee-master/rlee/__init__.py": {},
    "rlee-master/rlee/agents/DoubleDQNAgent.py": {
        "DoubleDQNAgent.__init__": {
            "name": "__init__",
            "location": 22,
            "return": [],
            "arguments": {
                "self": [],
                "env": [
                    "Any"
                ],
                "dqn": [
                    "Any"
                ],
                "optimizer": [
                    "Any"
                ],
                "criterion": [
                    "Any"
                ],
                "replay_buffer": [
                    "Any"
                ],
                "epsilon_func": [
                    "Callable[([int], float)]"
                ],
                "device": [
                    "bool"
                ],
                "ENV_RENDER": [
                    "bool"
                ],
                "DISCOUNT": [
                    "float"
                ],
                "BATCH_SIZE": [
                    "int"
                ],
                "MIN_REPLAY_BUFFER_SIZE": [
                    "int"
                ],
                "TARGET_UPDATE_FREQ": [
                    "int"
                ],
                "WANDB": [
                    "bool"
                ],
                "WANDB_INTERVAL": [
                    "int"
                ],
                "SAVE_PREFIX": [
                    "str"
                ]
            }
        },
        "DoubleDQNAgent._compute_loss": {
            "name": "_compute_loss",
            "location": 58,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "batch": [
                    "Tuple"
                ]
            }
        }
    },
    "rlee-master/rlee/agents/DQN2015Agent.py": {
        "DQN2015Agent.__init__": {
            "name": "__init__",
            "location": 29,
            "return": [],
            "arguments": {
                "self": [],
                "env": [
                    "Any"
                ],
                "dqn": [
                    "Any"
                ],
                "optimizer": [
                    "Any"
                ],
                "criterion": [
                    "Any"
                ],
                "replay_buffer": [
                    "Any"
                ],
                "epsilon_func": [
                    "Callable[([int], float)]"
                ],
                "device": [
                    "bool"
                ],
                "ENV_RENDER": [
                    "bool"
                ],
                "DISCOUNT": [
                    "float"
                ],
                "BATCH_SIZE": [
                    "int"
                ],
                "MIN_REPLAY_BUFFER_SIZE": [
                    "int"
                ],
                "TARGET_UPDATE_FREQ": [
                    "int"
                ],
                "WANDB": [
                    "bool"
                ],
                "WANDB_INTERVAL": [
                    "int"
                ],
                "SAVE_PREFIX": [
                    "str"
                ]
            }
        },
        "DQN2015Agent.act": {
            "name": "act",
            "location": 65,
            "return": [
                "int"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "torch.Tensor"
                ],
                "epsilon": [
                    "float"
                ]
            }
        },
        "DQN2015Agent.train": {
            "name": "train",
            "location": 92,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "nb_frames": [
                    "int"
                ]
            }
        },
        "DQN2015Agent._compute_loss": {
            "name": "_compute_loss",
            "location": 191,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "batch": [
                    "Tuple"
                ]
            }
        },
        "DQN2015Agent._update_target": {
            "name": "_update_target",
            "location": 245,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQN2015Agent.save": {
            "name": "save",
            "location": 249,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQN2015Agent.load_for_training": {
            "name": "load_for_training",
            "location": 259,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "LOAD_PREFIX": [
                    "str"
                ]
            }
        },
        "DQN2015Agent.load_model": {
            "name": "load_model",
            "location": 267,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "LOAD_PREFIX": [
                    "str"
                ]
            }
        }
    },
    "rlee-master/rlee/agents/__init__.py": {},
    "rlee-master/rlee/commons/decay.py": {
        "get_linear_decay": {
            "name": "get_linear_decay",
            "location": 5,
            "return": [
                "Callable[([int], float)]"
            ],
            "arguments": {
                "decay_start": [
                    "float"
                ],
                "decay_final": [
                    "float"
                ],
                "decay_duration": [
                    "int"
                ]
            }
        },
        "get_linear_decay.decay_func": {
            "name": "decay_func",
            "location": 30,
            "return": [
                "float"
            ],
            "arguments": {
                "idx": [
                    "int"
                ]
            }
        }
    },
    "rlee-master/rlee/commons/eval_parser.py": {
        "get_eval_args": {
            "name": "get_eval_args",
            "location": 7,
            "return": [
                "configargparse.Namespace"
            ],
            "arguments": {
                "description": [
                    "str"
                ],
                "default_args": [
                    "Optional[dict]"
                ]
            }
        }
    },
    "rlee-master/rlee/commons/test_decay.py": {
        "test_get_linear_decay_start": {
            "name": "test_get_linear_decay_start",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_get_linear_decay_final": {
            "name": "test_get_linear_decay_final",
            "location": 15,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_get_linear_decay_no_decay": {
            "name": "test_get_linear_decay_no_decay",
            "location": 23,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_get_linear_decay_after_duration": {
            "name": "test_get_linear_decay_after_duration",
            "location": 31,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_get_linear_decay_thorough": {
            "name": "test_get_linear_decay_thorough",
            "location": 39,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "rlee-master/rlee/commons/train_parser.py": {
        "get_train_args": {
            "name": "get_train_args",
            "location": 7,
            "return": [
                "configargparse.Namespace"
            ],
            "arguments": {
                "description": [
                    "str"
                ],
                "default_args": [
                    "Optional[dict]"
                ]
            }
        }
    },
    "rlee-master/rlee/commons/__init__.py": {},
    "rlee-master/rlee/networks/dqn.py": {
        "FCDQN.__init__": {
            "name": "__init__",
            "location": 16,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_inputs": [
                    "int"
                ],
                "num_actions": [
                    "int"
                ],
                "layer_sizes": [
                    "List[int]"
                ]
            }
        },
        "FCDQN.forward": {
            "name": "forward",
            "location": 36,
            "return": [
                "torch.tensor"
            ],
            "arguments": {
                "self": [],
                "x": [
                    "torch.tensor"
                ]
            }
        },
        "DQN.__init__": {
            "name": "__init__",
            "location": 50,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_inputs": [
                    "int"
                ],
                "num_actions": [
                    "int"
                ]
            }
        },
        "DQN.forward": {
            "name": "forward",
            "location": 64,
            "return": [
                "torch.tensor"
            ],
            "arguments": {
                "self": [],
                "x": [
                    "torch.tensor"
                ]
            }
        }
    },
    "rlee-master/rlee/networks/__init__.py": {},
    "rlee-master/rlee/replays/combined_replay.py": {
        "CombinedReplayBuffer.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "capacity": [
                    "int"
                ]
            }
        },
        "CombinedReplayBuffer.__len__": {
            "name": "__len__",
            "location": 24,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "CombinedReplayBuffer.push": {
            "name": "push",
            "location": 27,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "torch.Tensor"
                ],
                "action": [
                    "int"
                ],
                "reward": [
                    "torch.Tensor"
                ],
                "next_state": [
                    "torch.Tensor"
                ],
                "done": [
                    "torch.Tensor"
                ]
            }
        },
        "CombinedReplayBuffer.sample": {
            "name": "sample",
            "location": 57,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "batch_size": [
                    "int"
                ]
            }
        }
    },
    "rlee-master/rlee/replays/sum_tree.py": {
        "SumTree.__init__": {
            "name": "__init__",
            "location": 49,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "capacity": [
                    "int"
                ]
            }
        },
        "SumTree._total_priority": {
            "name": "_total_priority",
            "location": 78,
            "return": [
                "float"
            ],
            "arguments": {
                "self": []
            }
        },
        "SumTree.sample": {
            "name": "sample",
            "location": 88,
            "return": [
                "int"
            ],
            "arguments": {
                "self": [],
                "query_value": [
                    "float"
                ]
            }
        },
        "SumTree.stratified_sample": {
            "name": "stratified_sample",
            "location": 134,
            "return": [
                "List[Any]"
            ],
            "arguments": {
                "self": [],
                "batch_size": [
                    "int"
                ]
            }
        },
        "SumTree.get": {
            "name": "get",
            "location": 161,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "node_index": [
                    "int"
                ]
            }
        },
        "SumTree.set": {
            "name": "set",
            "location": 173,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "node_index": [
                    "int"
                ],
                "value": [
                    "float"
                ]
            }
        }
    },
    "rlee-master/rlee/replays/test_deque_uniform_replay.py": {
        "test_uniform_batch_type": {
            "name": "test_uniform_batch_type",
            "location": 8,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_uniform_batch_shape": {
            "name": "test_uniform_batch_shape",
            "location": 35,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "rlee-master/rlee/replays/test_list_uniform_replay.py": {
        "test_uniform_batch_type": {
            "name": "test_uniform_batch_type",
            "location": 8,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_uniform_batch_shape": {
            "name": "test_uniform_batch_shape",
            "location": 35,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "rlee-master/rlee/replays/test_sum_tree.py": {
        "test_sum_tree_zero_total_priority_on_init": {
            "name": "test_sum_tree_zero_total_priority_on_init",
            "location": 5,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_sum_tree_zero_set": {
            "name": "test_sum_tree_zero_set",
            "location": 13,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_sum_tree_zero_sample_from_one_nonzero_value": {
            "name": "test_sum_tree_zero_sample_from_one_nonzero_value",
            "location": 30,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_sum_tree_zero_sample_from_two_nonzero_values": {
            "name": "test_sum_tree_zero_sample_from_two_nonzero_values",
            "location": 41,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "rlee-master/rlee/replays/uniform_replay.py": {
        "DequeUniformReplayBuffer.__init__": {
            "name": "__init__",
            "location": 15,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "capacity": [
                    "int"
                ]
            }
        },
        "DequeUniformReplayBuffer.__len__": {
            "name": "__len__",
            "location": 18,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "DequeUniformReplayBuffer.push": {
            "name": "push",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "torch.Tensor"
                ],
                "action": [
                    "int"
                ],
                "reward": [
                    "torch.Tensor"
                ],
                "next_state": [
                    "torch.Tensor"
                ],
                "done": [
                    "torch.Tensor"
                ]
            }
        },
        "DequeUniformReplayBuffer.sample": {
            "name": "sample",
            "location": 51,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "batch_size": [
                    "int"
                ]
            }
        },
        "ListUniformReplayBuffer.__init__": {
            "name": "__init__",
            "location": 90,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "capacity": [
                    "int"
                ]
            }
        },
        "ListUniformReplayBuffer.__len__": {
            "name": "__len__",
            "location": 94,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "ListUniformReplayBuffer.push": {
            "name": "push",
            "location": 97,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "torch.Tensor"
                ],
                "action": [
                    "int"
                ],
                "reward": [
                    "torch.Tensor"
                ],
                "next_state": [
                    "torch.Tensor"
                ],
                "done": [
                    "torch.Tensor"
                ]
            }
        },
        "ListUniformReplayBuffer.sample": {
            "name": "sample",
            "location": 131,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "batch_size": [
                    "int"
                ]
            }
        }
    },
    "rlee-master/rlee/replays/__init__.py": {},
    "rlee-master/rlee/wrappers/atari_wrappers.py": {
        "make_atari": {
            "name": "make_atari",
            "location": 259,
            "return": [],
            "arguments": {
                "env_id": [],
                "timelimit": []
            }
        },
        "wrap_deepmind": {
            "name": "wrap_deepmind",
            "location": 271,
            "return": [],
            "arguments": {
                "env": [],
                "episode_life": [],
                "clip_rewards": [],
                "frame_stack": [],
                "scale": []
            }
        },
        "NoopResetEnv.__init__": {
            "name": "__init__",
            "location": 20,
            "return": [],
            "arguments": {
                "self": [],
                "env": [],
                "noop_max": []
            }
        },
        "NoopResetEnv.reset": {
            "name": "reset",
            "location": 30,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "NoopResetEnv.step": {
            "name": "step",
            "location": 47,
            "return": [],
            "arguments": {
                "self": [],
                "ac": []
            }
        },
        "FireResetEnv.__init__": {
            "name": "__init__",
            "location": 52,
            "return": [],
            "arguments": {
                "self": [],
                "env": []
            }
        },
        "FireResetEnv.reset": {
            "name": "reset",
            "location": 60,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "FireResetEnv.step": {
            "name": "step",
            "location": 70,
            "return": [],
            "arguments": {
                "self": [],
                "ac": []
            }
        },
        "EpisodicLifeEnv.__init__": {
            "name": "__init__",
            "location": 75,
            "return": [],
            "arguments": {
                "self": [],
                "env": []
            }
        },
        "EpisodicLifeEnv.step": {
            "name": "step",
            "location": 84,
            "return": [],
            "arguments": {
                "self": [],
                "action": []
            }
        },
        "EpisodicLifeEnv.reset": {
            "name": "reset",
            "location": 98,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "MaxAndSkipEnv.__init__": {
            "name": "__init__",
            "location": 115,
            "return": [],
            "arguments": {
                "self": [],
                "env": [],
                "skip": []
            }
        },
        "MaxAndSkipEnv.step": {
            "name": "step",
            "location": 122,
            "return": [],
            "arguments": {
                "self": [],
                "action": []
            }
        },
        "MaxAndSkipEnv.reset": {
            "name": "reset",
            "location": 141,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ClipRewardEnv.__init__": {
            "name": "__init__",
            "location": 146,
            "return": [],
            "arguments": {
                "self": [],
                "env": []
            }
        },
        "ClipRewardEnv.reward": {
            "name": "reward",
            "location": 149,
            "return": [],
            "arguments": {
                "self": [],
                "reward": []
            }
        },
        "WarpFrame.__init__": {
            "name": "__init__",
            "location": 155,
            "return": [],
            "arguments": {
                "self": [],
                "env": [],
                "width": [],
                "height": [],
                "grayscale": []
            }
        },
        "WarpFrame.observation": {
            "name": "observation",
            "location": 170,
            "return": [],
            "arguments": {
                "self": [],
                "frame": []
            }
        },
        "FrameStack.__init__": {
            "name": "__init__",
            "location": 182,
            "return": [],
            "arguments": {
                "self": [],
                "env": [],
                "k": []
            }
        },
        "FrameStack.reset": {
            "name": "reset",
            "location": 200,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "FrameStack.step": {
            "name": "step",
            "location": 206,
            "return": [],
            "arguments": {
                "self": [],
                "action": []
            }
        },
        "FrameStack._get_ob": {
            "name": "_get_ob",
            "location": 211,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ScaledFloatFrame.__init__": {
            "name": "__init__",
            "location": 217,
            "return": [],
            "arguments": {
                "self": [],
                "env": []
            }
        },
        "ScaledFloatFrame.observation": {
            "name": "observation",
            "location": 223,
            "return": [],
            "arguments": {
                "self": [],
                "observation": []
            }
        },
        "LazyFrames.__init__": {
            "name": "__init__",
            "location": 230,
            "return": [],
            "arguments": {
                "self": [],
                "frames": []
            }
        },
        "LazyFrames._force": {
            "name": "_force",
            "location": 240,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "LazyFrames.__array__": {
            "name": "__array__",
            "location": 246,
            "return": [],
            "arguments": {
                "self": [],
                "dtype": []
            }
        },
        "LazyFrames.__len__": {
            "name": "__len__",
            "location": 252,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "LazyFrames.__getitem__": {
            "name": "__getitem__",
            "location": 255,
            "return": [],
            "arguments": {
                "self": [],
                "i": []
            }
        }
    },
    "rlee-master/rlee/wrappers/envs.py": {
        "make_env": {
            "name": "make_env",
            "location": 10,
            "return": [
                "Any"
            ],
            "arguments": {
                "env_id": [
                    "str"
                ]
            }
        }
    },
    "rlee-master/rlee/wrappers/raw_wrappers.py": {
        "ClassicControlWrapper.__init__": {
            "name": "__init__",
            "location": 12,
            "return": [],
            "arguments": {
                "self": [],
                "env": [
                    "Any"
                ]
            }
        },
        "ClassicControlWrapper.observation": {
            "name": "observation",
            "location": 15,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "original_obs": [
                    "Any"
                ]
            }
        }
    },
    "rlee-master/rlee/wrappers/torch_wrappers.py": {
        "wrap_pytorch": {
            "name": "wrap_pytorch",
            "location": 57,
            "return": [
                "Any"
            ],
            "arguments": {
                "env": [
                    "Any"
                ],
                "visual": [
                    "bool"
                ]
            }
        },
        "TorchTensorWrapper.__init__": {
            "name": "__init__",
            "location": 19,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [
                    "Any"
                ]
            }
        },
        "TorchTensorWrapper.reset": {
            "name": "reset",
            "location": 22,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": []
            }
        },
        "TorchTensorWrapper.step": {
            "name": "step",
            "location": 28,
            "return": [
                "Tuple[(torch.Tensor, torch.Tensor, torch.Tensor, Any)]"
            ],
            "arguments": {
                "self": [],
                "action": [
                    "int"
                ]
            }
        },
        "TorchPermuteWrapper.__init__": {
            "name": "__init__",
            "location": 45,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [
                    "Any"
                ]
            }
        },
        "TorchPermuteWrapper.observation": {
            "name": "observation",
            "location": 52,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "observation": [
                    "torch.Tensor"
                ]
            }
        }
    },
    "rlee-master/rlee/wrappers/__init__.py": {}
}
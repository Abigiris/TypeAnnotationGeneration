{
    "stylenet-pytorch-master/stylenet/config_loader.py": {
        "HParams.__init__": {
            "name": "__init__",
            "location": 19,
            "return": [],
            "arguments": {
                "self": [],
                "configs": [
                    "Dict"
                ]
            }
        },
        "HParams.__str__": {
            "name": "__str__",
            "location": 23,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "HParams.load": {
            "name": "load",
            "location": 31,
            "return": [
                "'HParams'"
            ],
            "arguments": {
                "cls": [],
                "config_path": [
                    "Union[(str, Path)]"
                ]
            }
        },
        "HParams.parse": {
            "name": "parse",
            "location": 53,
            "return": [
                "'HParams'"
            ],
            "arguments": {
                "cls": [],
                "args": [
                    "Union[(Dict, 'argparse.Namespace')]"
                ]
            }
        },
        "HParams.parse_and_add": {
            "name": "parse_and_add",
            "location": 68,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "args": [
                    "Union[(Dict, 'argparse.Namespace')]"
                ],
                "update": [
                    "bool"
                ]
            }
        },
        "HParams.save": {
            "name": "save",
            "location": 89,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "save_path": [
                    "Union[(str, Path)]"
                ]
            }
        },
        "HParams.add_hparam": {
            "name": "add_hparam",
            "location": 109,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "key": [
                    "str"
                ],
                "value": [
                    "Any"
                ],
                "update": [
                    "bool"
                ]
            }
        },
        "HParams.del_hparam": {
            "name": "del_hparam",
            "location": 121,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "key": [
                    "str"
                ]
            }
        },
        "HParams.get": {
            "name": "get",
            "location": 129,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "key": [],
                "default": [
                    "Optional[Any]"
                ]
            }
        }
    },
    "stylenet-pytorch-master/stylenet/data_loader.py": {
        "get_image_caption_loader": {
            "name": "get_image_caption_loader",
            "location": 147,
            "return": [],
            "arguments": {
                "img_dir": [
                    "Union[(str, Path)]"
                ],
                "caption_path": [
                    "Union[(str, Path)]"
                ],
                "text_preprocessor": [
                    "TextPreprocessor"
                ],
                "batch_size": [
                    "int"
                ],
                "transform": [
                    "Optional[transforms.Compose]"
                ],
                "shuffle": [
                    "bool"
                ],
                "num_workers": [
                    "int"
                ]
            }
        },
        "get_caption_loader": {
            "name": "get_caption_loader",
            "location": 197,
            "return": [
                "DataLoader"
            ],
            "arguments": {
                "caption_path": [
                    "Union[(str, Path)]"
                ],
                "text_preprocessor": [
                    "TextPreprocessor"
                ],
                "batch_size": [
                    "int"
                ],
                "shuffle": [
                    "bool"
                ],
                "num_workers": [
                    "int"
                ]
            }
        },
        "merge": {
            "name": "merge",
            "location": 232,
            "return": [],
            "arguments": {
                "captions": [
                    "List[torch.Tensor]"
                ]
            }
        },
        "img_caption_collate_fn": {
            "name": "img_caption_collate_fn",
            "location": 248,
            "return": [
                "Tuple[(torch.Tensor, ...)]"
            ],
            "arguments": {
                "img_caption": [
                    "List[Tuple[(torch.Tensor, torch.Tensor)]]"
                ]
            }
        },
        "caption_collate_fn": {
            "name": "caption_collate_fn",
            "location": 271,
            "return": [
                "Tuple[(torch.Tensor, ...)]"
            ],
            "arguments": {
                "captions": [
                    "torch.Tensor"
                ]
            }
        },
        "ImageCaptionDataset.__init__": {
            "name": "__init__",
            "location": 22,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "img_dir": [
                    "Union[(str, Path)]"
                ],
                "img_caption_pairs": [
                    "List[List[str]]"
                ],
                "text_preprocessor": [
                    "TextPreprocessor"
                ],
                "transform": [
                    "Optional[transforms.Compose]"
                ]
            }
        },
        "ImageCaptionDataset.create": {
            "name": "create",
            "location": 45,
            "return": [
                "'ImageCaptionDataset'"
            ],
            "arguments": {
                "cls": [],
                "img_dir": [
                    "Union[(str, Path)]"
                ],
                "caption_path": [
                    "Union[(str, Path)]"
                ],
                "text_preprocessor": [
                    "TextPreprocessor"
                ],
                "transform": [
                    "Optional[transforms.Compose]"
                ]
            }
        },
        "ImageCaptionDataset.__len__": {
            "name": "__len__",
            "location": 78,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ImageCaptionDataset.__getitem__": {
            "name": "__getitem__",
            "location": 81,
            "return": [],
            "arguments": {
                "self": [],
                "idx": [
                    "int"
                ]
            }
        },
        "CaptionDataset.__init__": {
            "name": "__init__",
            "location": 102,
            "return": [],
            "arguments": {
                "self": [],
                "caption_list": [
                    "List[str]"
                ],
                "text_preprocessor": [
                    "TextPreprocessor"
                ]
            }
        },
        "CaptionDataset.__len__": {
            "name": "__len__",
            "location": 116,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "CaptionDataset.__getitem__": {
            "name": "__getitem__",
            "location": 119,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "idx": [
                    "int"
                ]
            }
        },
        "CaptionDataset.create": {
            "name": "create",
            "location": 127,
            "return": [
                "'CaptionDataset'"
            ],
            "arguments": {
                "cls": [],
                "caption_path": [
                    "Union[(str, Path)]"
                ],
                "text_preprocessor": [
                    "TextPreprocessor"
                ]
            }
        }
    },
    "stylenet-pytorch-master/stylenet/generate.py": {
        "load_images": {
            "name": "load_images",
            "location": 14,
            "return": [
                "Tuple"
            ],
            "arguments": {
                "img_dir": [
                    "Union[(str, Path)]"
                ],
                "transform": [
                    "Optional[transforms.Compose]"
                ]
            }
        },
        "main": {
            "name": "main",
            "location": 40,
            "return": [],
            "arguments": {
                "hparams": [
                    "HParams"
                ]
            }
        }
    },
    "stylenet-pytorch-master/stylenet/modules.py": {},
    "stylenet-pytorch-master/stylenet/optim.py": {
        "Optim.__init__": {
            "name": "__init__",
            "location": 13,
            "return": [],
            "arguments": {
                "self": [],
                "method": [
                    "str"
                ],
                "lr": [
                    "float"
                ],
                "max_grad_norm": [
                    "Optional[float]"
                ],
                "lr_decay": [
                    "int"
                ],
                "start_decay_at": [
                    "Optional[int]"
                ]
            }
        },
        "Optim.set_parameters": {
            "name": "set_parameters",
            "location": 40,
            "return": [],
            "arguments": {
                "self": [],
                "params": [
                    "List"
                ]
            }
        },
        "Optim.step": {
            "name": "step",
            "location": 60,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "Optim.update_learning_rate": {
            "name": "update_learning_rate",
            "location": 65,
            "return": [],
            "arguments": {
                "self": [],
                "ppl": [
                    "float"
                ],
                "epoch": [
                    "int"
                ]
            }
        }
    },
    "stylenet-pytorch-master/stylenet/text_preprocessor.py": {
        "TextPreprocessor.__init__": {
            "name": "__init__",
            "location": 34,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "token2index": [
                    "Mapping[(str, int)]"
                ],
                "index2token": [
                    "Mapping[(int, str)]"
                ],
                "embed_matrix": [
                    "Optional[np.ndarray]"
                ]
            }
        },
        "TextPreprocessor.embed_matrix": {
            "name": "embed_matrix",
            "location": 46,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": []
            }
        },
        "TextPreprocessor.vocab_size": {
            "name": "vocab_size",
            "location": 55,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "TextPreprocessor.create": {
            "name": "create",
            "location": 64,
            "return": [
                "'TextPreprocessor'"
            ],
            "arguments": {
                "cls": [],
                "text_list": [
                    "Sequence[str]"
                ],
                "max_vocab_size": [
                    "Optional[int]"
                ],
                "symbol_order": [
                    "Optional[str]"
                ],
                "train_embed_matrix": [
                    "bool"
                ],
                "dim_size": [
                    "int"
                ],
                "window_size": [
                    "int"
                ]
            }
        },
        "TextPreprocessor.load": {
            "name": "load",
            "location": 114,
            "return": [
                "'TextPreprocessor'"
            ],
            "arguments": {
                "cls": [],
                "path": [
                    "Union[(str, Path)]"
                ]
            }
        },
        "TextPreprocessor.save": {
            "name": "save",
            "location": 130,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "Union[(str, Path)]"
                ]
            }
        },
        "TextPreprocessor.token2index": {
            "name": "token2index",
            "location": 144,
            "return": [
                "int"
            ],
            "arguments": {
                "self": [],
                "token": [
                    "str"
                ]
            }
        },
        "TextPreprocessor.index2token": {
            "name": "index2token",
            "location": 153,
            "return": [
                "str"
            ],
            "arguments": {
                "self": [],
                "index": [
                    "int"
                ]
            }
        },
        "TextPreprocessor.tokens2indice": {
            "name": "tokens2indice",
            "location": 162,
            "return": [
                "List[int]"
            ],
            "arguments": {
                "self": [],
                "tokens": [
                    "List[str]"
                ],
                "sos": [
                    "bool"
                ],
                "eos": [
                    "bool"
                ]
            }
        },
        "TextPreprocessor.indice2tokens": {
            "name": "indice2tokens",
            "location": 179,
            "return": [
                "List[str]"
            ],
            "arguments": {
                "self": [],
                "indice": [
                    "List[int]"
                ],
                "sos": [
                    "bool"
                ],
                "eos": [
                    "bool"
                ]
            }
        },
        "TextPreprocessor.create_embed_matrix": {
            "name": "create_embed_matrix",
            "location": 197,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "cls": [],
                "text_list": [
                    "Sequence[str]"
                ],
                "index2token": [
                    "Mapping[(int, str)]"
                ],
                "dim": [
                    "int"
                ],
                "window_size": [
                    "int"
                ],
                "seed": [
                    "int"
                ]
            }
        },
        "TextPreprocessor.fix_symbol_order": {
            "name": "fix_symbol_order",
            "location": 234,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "symbol_list": [
                    "List[str]"
                ]
            }
        }
    },
    "stylenet-pytorch-master/stylenet/train.py": {
        "main": {
            "name": "main",
            "location": 17,
            "return": [],
            "arguments": {
                "hparams": [
                    "HParams"
                ]
            }
        }
    },
    "stylenet-pytorch-master/stylenet/__init__.py": {},
    "stylenet-pytorch-master/test/__init__.py": {},
    "stylenet-pytorch-master/test/stylenet/test_config_loader.py": {},
    "stylenet-pytorch-master/test/stylenet/test_data_loader.py": {
        "test_image_caption_dataset": {
            "name": "test_image_caption_dataset",
            "location": 23,
            "return": [],
            "arguments": {}
        }
    },
    "stylenet-pytorch-master/test/stylenet/test_modules.py": {
        "test_encoder": {
            "name": "test_encoder",
            "location": 5,
            "return": [],
            "arguments": {}
        },
        "TestFactoredLSTM.test_intput_feed": {
            "name": "test_intput_feed",
            "location": 23,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestFactoredLSTM.test_backward": {
            "name": "test_backward",
            "location": 53,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "stylenet-pytorch-master/test/stylenet/test_optim.py": {},
    "stylenet-pytorch-master/test/stylenet/test_text_preprocessor.py": {
        "TestTextPreprocessor.test_create": {
            "name": "test_create",
            "location": 14,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTextPreprocessor.test_symbols_id": {
            "name": "test_symbols_id",
            "location": 30,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTextPreprocessor.test_token2index": {
            "name": "test_token2index",
            "location": 46,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTextPreprocessor.test_index2token": {
            "name": "test_index2token",
            "location": 52,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTextPreprocessor.test_tokens2indice": {
            "name": "test_tokens2indice",
            "location": 57,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTextPreprocessor.test_indice2tokens": {
            "name": "test_indice2tokens",
            "location": 66,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTextPreprocessor.test_save_and_load": {
            "name": "test_save_and_load",
            "location": 72,
            "return": [],
            "arguments": {
                "self": [],
                "tmpdir": []
            }
        },
        "TestTextPreprocessor.test_array_type_is_nparray": {
            "name": "test_array_type_is_nparray",
            "location": 107,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTextPreprocessor.test_fix_symbol_order": {
            "name": "test_fix_symbol_order",
            "location": 121,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "stylenet-pytorch-master/test/stylenet/__init__.py": {}
}
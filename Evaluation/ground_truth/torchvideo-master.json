{
    "torchvideo-master/conftest.py": {},
    "torchvideo-master/setup.py": {
        "UploadCommand.status": {
            "name": "status",
            "location": 60,
            "return": [],
            "arguments": {
                "s": []
            }
        },
        "UploadCommand.initialize_options": {
            "name": "initialize_options",
            "location": 64,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "UploadCommand.finalize_options": {
            "name": "finalize_options",
            "location": 67,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "UploadCommand.run": {
            "name": "run",
            "location": 70,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/docs/source/conf.py": {},
    "torchvideo-master/src/torchvideo/samplers.py": {
        "frame_idx_to_list": {
            "name": "frame_idx_to_list",
            "location": 313,
            "return": [
                "List[int]"
            ],
            "arguments": {
                "frames_idx": [
                    "Union[(slice, List[slice], List[int])]"
                ]
            }
        },
        "compute_sample_length": {
            "name": "compute_sample_length",
            "location": 346,
            "return": [],
            "arguments": {
                "clip_length": [],
                "step_size": []
            }
        },
        "_slice_to_list": {
            "name": "_slice_to_list",
            "location": 362,
            "return": [
                "List[int]"
            ],
            "arguments": {
                "slice_": [
                    "slice"
                ]
            }
        },
        "_oversample": {
            "name": "_oversample",
            "location": 371,
            "return": [
                "List[int]"
            ],
            "arguments": {
                "video_length": [
                    "int"
                ],
                "sample_length": [
                    "int"
                ]
            }
        },
        "FrameSampler.sample": {
            "name": "sample",
            "location": 15,
            "return": [
                "Union[(slice, List[int], List[slice])]"
            ],
            "arguments": {
                "self": [],
                "video_length": [
                    "int"
                ]
            }
        },
        "FullVideoSampler.__init__": {
            "name": "__init__",
            "location": 35,
            "return": [],
            "arguments": {
                "self": [],
                "frame_step": []
            }
        },
        "FullVideoSampler.sample": {
            "name": "sample",
            "location": 38,
            "return": [
                "Union[(slice, List[int], List[slice])]"
            ],
            "arguments": {
                "self": [],
                "video_length": [
                    "int"
                ]
            }
        },
        "FullVideoSampler.__str__": {
            "name": "__str__",
            "location": 57,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "FullVideoSampler.__repr__": {
            "name": "__repr__",
            "location": 60,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ClipSampler.__init__": {
            "name": "__init__",
            "location": 67,
            "return": [],
            "arguments": {
                "self": [],
                "clip_length": [
                    "int"
                ],
                "frame_step": [
                    "int"
                ],
                "test": [
                    "bool"
                ]
            }
        },
        "ClipSampler.sample": {
            "name": "sample",
            "location": 80,
            "return": [
                "Union[(slice, List[int], List[slice])]"
            ],
            "arguments": {
                "self": [],
                "video_length": [
                    "int"
                ]
            }
        },
        "ClipSampler.__repr__": {
            "name": "__repr__",
            "location": 99,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TemporalSegmentSampler.__init__": {
            "name": "__init__",
            "location": 132,
            "return": [],
            "arguments": {
                "self": [],
                "segment_count": [
                    "int"
                ],
                "snippet_length": [
                    "int"
                ]
            }
        },
        "TemporalSegmentSampler.sample": {
            "name": "sample",
            "location": 171,
            "return": [
                "Union[(List[slice], List[int])]"
            ],
            "arguments": {
                "self": [],
                "video_length": [
                    "int"
                ]
            }
        },
        "TemporalSegmentSampler._sample": {
            "name": "_sample",
            "location": 204,
            "return": [],
            "arguments": {
                "self": [],
                "video_length": []
            }
        },
        "TemporalSegmentSampler._oversample_segments": {
            "name": "_oversample_segments",
            "location": 212,
            "return": [],
            "arguments": {
                "self": [],
                "video_length": []
            }
        },
        "TemporalSegmentSampler._oversample_snippet": {
            "name": "_oversample_snippet",
            "location": 234,
            "return": [],
            "arguments": {
                "self": [],
                "video_length": []
            }
        },
        "TemporalSegmentSampler._get_segment_offsets": {
            "name": "_get_segment_offsets",
            "location": 238,
            "return": [
                "Union[(float, np.ndarray)]"
            ],
            "arguments": {
                "self": [],
                "segment_length": [
                    "float"
                ]
            }
        },
        "TemporalSegmentSampler.segment_video": {
            "name": "segment_video",
            "location": 246,
            "return": [
                "Tuple[(np.ndarray, float)]"
            ],
            "arguments": {
                "self": [],
                "video_length": [
                    "int"
                ]
            }
        },
        "TemporalSegmentSampler.__str__": {
            "name": "__str__",
            "location": 262,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TemporalSegmentSampler.__repr__": {
            "name": "__repr__",
            "location": 265,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TemporalSegmentSampler._make_snippet_slice": {
            "name": "_make_snippet_slice",
            "location": 279,
            "return": [
                "slice"
            ],
            "arguments": {
                "self": [],
                "start": [
                    "int"
                ]
            }
        },
        "LambdaSampler.__init__": {
            "name": "__init__",
            "location": 288,
            "return": [],
            "arguments": {
                "self": [],
                "sampler": [
                    "Callable[([int], Union[(slice, List[slice], List[int])])]"
                ]
            }
        },
        "LambdaSampler.sample": {
            "name": "sample",
            "location": 299,
            "return": [
                "Union[(slice, List[int], List[slice])]"
            ],
            "arguments": {
                "self": [],
                "video_length": [
                    "int"
                ]
            }
        },
        "LambdaSampler.__repr__": {
            "name": "__repr__",
            "location": 309,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/tools.py": {
        "show_video": {
            "name": "show_video",
            "location": 16,
            "return": [],
            "arguments": {
                "frames": [
                    "Union[(torch.Tensor, np.ndarray, List[Image])]"
                ],
                "fps": [],
                "ndarray_format": []
            }
        },
        "convert_to_clip": {
            "name": "convert_to_clip",
            "location": 44,
            "return": [],
            "arguments": {
                "frames": [],
                "fps": [],
                "ndarray_format": []
            }
        },
        "_to_list_of_np_frames": {
            "name": "_to_list_of_np_frames",
            "location": 70,
            "return": [
                "List[np.ndarray]"
            ],
            "arguments": {
                "frames": [
                    "Union[(torch.Tensor, np.ndarray, List[Image])]"
                ],
                "ndarray_format": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/__init__.py": {
        "get_video_backend": {
            "name": "get_video_backend",
            "location": 10,
            "return": [
                "str"
            ],
            "arguments": {}
        }
    },
    "torchvideo-master/src/torchvideo/__version__.py": {},
    "torchvideo-master/src/torchvideo/datasets/gulp_video_dataset.py": {
        "GulpVideoDataset.__init__": {
            "name": "__init__",
            "location": 30,
            "return": [],
            "arguments": {
                "self": [],
                "root_path": [
                    "Union[(str, Path)]"
                ]
            }
        },
        "GulpVideoDataset.video_ids": {
            "name": "video_ids",
            "location": 86,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "GulpVideoDataset.__len__": {
            "name": "__len__",
            "location": 89,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "GulpVideoDataset.__getitem__": {
            "name": "__getitem__",
            "location": 92,
            "return": [
                "Union[(torch.Tensor, Tuple[(torch.Tensor, Label)])]"
            ],
            "arguments": {
                "self": [],
                "index": []
            }
        },
        "GulpVideoDataset._label_examples": {
            "name": "_label_examples",
            "location": 134,
            "return": [],
            "arguments": {
                "video_ids": [
                    "List[str]"
                ],
                "label_set": [
                    "Optional[LabelSet]"
                ]
            }
        },
        "GulpVideoDataset._get_video_ids": {
            "name": "_get_video_ids",
            "location": 141,
            "return": [
                "List[str]"
            ],
            "arguments": {
                "gulp_dir": [],
                "filter_fn": [
                    "Optional[Callable[([str], bool)]]"
                ]
            }
        },
        "GulpVideoDataset._get_label_set": {
            "name": "_get_label_set",
            "location": 153,
            "return": [],
            "arguments": {
                "gulp_dir": [],
                "label_field": [
                    "Optional[str]"
                ],
                "label_set": [
                    "Optional[LabelSet]"
                ]
            }
        },
        "GulpVideoDataset._load_frames": {
            "name": "_load_frames",
            "location": 162,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "id_": [
                    "str"
                ],
                "frame_idx": [
                    "slice"
                ]
            }
        },
        "GulpVideoDataset._get_frame_count": {
            "name": "_get_frame_count",
            "location": 166,
            "return": [],
            "arguments": {
                "self": [],
                "id_": [
                    "str"
                ]
            }
        },
        "GulpVideoDataset.__init__.transform": {
            "name": "transform",
            "location": 65,
            "return": [],
            "arguments": {
                "frames": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/helpers.py": {
        "invoke_transform": {
            "name": "invoke_transform",
            "location": 4,
            "return": [],
            "arguments": {
                "transform": [],
                "frames": [],
                "label": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/image_folder_video_dataset.py": {
        "ImageFolderVideoDataset.__init__": {
            "name": "__init__",
            "location": 35,
            "return": [],
            "arguments": {
                "self": [],
                "root_path": [
                    "Union[(str, Path)]"
                ],
                "filename_template": [
                    "str"
                ],
                "filter": [
                    "Optional[Callable[([Path], bool)]]"
                ],
                "label_set": [
                    "Optional[LabelSet]"
                ],
                "sampler": [
                    "FrameSampler"
                ],
                "transform": [
                    "Optional[PILVideoTransform]"
                ],
                "frame_counter": [
                    "Optional[Callable[([Path], int)]]"
                ]
            }
        },
        "ImageFolderVideoDataset.video_ids": {
            "name": "video_ids",
            "location": 78,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ImageFolderVideoDataset.__len__": {
            "name": "__len__",
            "location": 81,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "ImageFolderVideoDataset.__getitem__": {
            "name": "__getitem__",
            "location": 84,
            "return": [
                "Union[(torch.Tensor, Tuple[(torch.Tensor, Label)])]"
            ],
            "arguments": {
                "self": [],
                "index": [
                    "int"
                ]
            }
        },
        "ImageFolderVideoDataset._measure_video_lengths": {
            "name": "_measure_video_lengths",
            "location": 103,
            "return": [],
            "arguments": {
                "video_dirs": [],
                "frame_counter": [
                    "Optional[Callable[([Path], int)]]"
                ]
            }
        },
        "ImageFolderVideoDataset._label_examples": {
            "name": "_label_examples",
            "location": 112,
            "return": [],
            "arguments": {
                "video_dirs": [],
                "label_set": [
                    "Optional[LabelSet]"
                ]
            }
        },
        "ImageFolderVideoDataset._load_frames": {
            "name": "_load_frames",
            "location": 118,
            "return": [
                "Iterator[Image]"
            ],
            "arguments": {
                "self": [],
                "frames_idx": [
                    "Union[(slice, List[slice], List[int])]"
                ],
                "video_folder": [
                    "Path"
                ]
            }
        },
        "ImageFolderVideoDataset._load_image": {
            "name": "_load_image",
            "location": 130,
            "return": [
                "Image"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "Path"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/types.py": {},
    "torchvideo-master/src/torchvideo/datasets/video_dataset.py": {
        "VideoDataset.__init__": {
            "name": "__init__",
            "location": 16,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "root_path": [
                    "Union[(str, Path)]"
                ],
                "label_set": [
                    "Optional[LabelSet]"
                ],
                "sampler": [
                    "FrameSampler"
                ],
                "transform": [
                    "Optional[Transform]"
                ]
            }
        },
        "VideoDataset.video_ids": {
            "name": "video_ids",
            "location": 42,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "VideoDataset.__getitem__": {
            "name": "__getitem__",
            "location": 45,
            "return": [
                "Union[(torch.Tensor, Tuple[(torch.Tensor, Label)])]"
            ],
            "arguments": {
                "self": [],
                "index": [
                    "int"
                ]
            }
        },
        "VideoDataset.__len__": {
            "name": "__len__",
            "location": 61,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/video_folder_dataset.py": {
        "VideoFolderDataset.__init__": {
            "name": "__init__",
            "location": 27,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "root_path": [
                    "Union[(str, Path)]"
                ],
                "filter": [
                    "Optional[Callable[([Path], bool)]]"
                ],
                "label_set": [
                    "Optional[LabelSet]"
                ],
                "sampler": [
                    "FrameSampler"
                ],
                "transform": [
                    "Optional[PILVideoTransform]"
                ],
                "frame_counter": [
                    "Optional[Callable[([Path], int)]]"
                ]
            }
        },
        "VideoFolderDataset.video_ids": {
            "name": "video_ids",
            "location": 63,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "VideoFolderDataset.__getitem__": {
            "name": "__getitem__",
            "location": 68,
            "return": [
                "Union[(Any, Tuple[(Any, Label)])]"
            ],
            "arguments": {
                "self": [],
                "index": [
                    "int"
                ]
            }
        },
        "VideoFolderDataset.__len__": {
            "name": "__len__",
            "location": 85,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "VideoFolderDataset._measure_video_lengths": {
            "name": "_measure_video_lengths",
            "location": 89,
            "return": [],
            "arguments": {
                "video_paths": [],
                "frame_counter": []
            }
        },
        "VideoFolderDataset._label_examples": {
            "name": "_label_examples",
            "location": 95,
            "return": [],
            "arguments": {
                "video_paths": [],
                "label_set": [
                    "Optional[LabelSet]"
                ]
            }
        },
        "VideoFolderDataset._get_video_paths": {
            "name": "_get_video_paths",
            "location": 102,
            "return": [],
            "arguments": {
                "root_path": [],
                "filter": []
            }
        },
        "VideoFolderDataset._load_frames": {
            "name": "_load_frames",
            "location": 112,
            "return": [
                "Iterator[Image]"
            ],
            "arguments": {
                "frame_idx": [
                    "Union[(slice, List[slice], List[int])]"
                ],
                "video_file": [
                    "Path"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/__init__.py": {},
    "torchvideo-master/src/torchvideo/datasets/label_sets/csv_label_set.py": {
        "CsvLabelSet.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [],
            "arguments": {
                "self": [],
                "df": [],
                "col": [
                    "Optional[str]"
                ]
            }
        },
        "CsvLabelSet.__getitem__": {
            "name": "__getitem__",
            "location": 32,
            "return": [
                "Label"
            ],
            "arguments": {
                "self": [],
                "video_name": [
                    "str"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/label_sets/dummy_label_set.py": {
        "DummyLabelSet.__init__": {
            "name": "__init__",
            "location": 7,
            "return": [],
            "arguments": {
                "self": [],
                "label": [
                    "Label"
                ]
            }
        },
        "DummyLabelSet.__getitem__": {
            "name": "__getitem__",
            "location": 14,
            "return": [
                "Label"
            ],
            "arguments": {
                "self": [],
                "video_name": []
            }
        },
        "DummyLabelSet.__repr__": {
            "name": "__repr__",
            "location": 17,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/label_sets/gulp_label_set.py": {
        "GulpLabelSet.__init__": {
            "name": "__init__",
            "location": 13,
            "return": [],
            "arguments": {
                "self": [],
                "merged_meta_dict": [
                    "Dict[(str, Any)]"
                ],
                "label_field": [
                    "str"
                ]
            }
        },
        "GulpLabelSet.__getitem__": {
            "name": "__getitem__",
            "location": 17,
            "return": [
                "Label"
            ],
            "arguments": {
                "self": [],
                "video_name": [
                    "str"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/label_sets/label_set.py": {
        "LabelSet.__getitem__": {
            "name": "__getitem__",
            "location": 12,
            "return": [
                "Label"
            ],
            "arguments": {
                "self": [],
                "video_name": [
                    "str"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/label_sets/lambda_label_set.py": {
        "LambdaLabelSet.__init__": {
            "name": "__init__",
            "location": 9,
            "return": [],
            "arguments": {
                "self": [],
                "labeller_fn": [
                    "Callable[([str], Label)]"
                ]
            }
        },
        "LambdaLabelSet.__getitem__": {
            "name": "__getitem__",
            "location": 16,
            "return": [
                "Label"
            ],
            "arguments": {
                "self": [],
                "video_name": [
                    "str"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/label_sets/__init__.py": {},
    "torchvideo-master/src/torchvideo/internal/readers.py": {
        "lintel_loader": {
            "name": "lintel_loader",
            "location": 30,
            "return": [
                "Iterator[Image.Image]"
            ],
            "arguments": {
                "file": [
                    "Union[(str, Path, IO[bytes])]"
                ],
                "frames_idx": [
                    "Union[(slice, List[slice], List[int])]"
                ]
            }
        },
        "default_loader": {
            "name": "default_loader",
            "location": 58,
            "return": [
                "Iterator[Image.Image]"
            ],
            "arguments": {
                "file": [
                    "Union[(str, Path, IO[bytes])]"
                ],
                "frames_idx": [
                    "Union[(slice, List[slice], List[int])]"
                ]
            }
        },
        "_get_videofile_frame_count": {
            "name": "_get_videofile_frame_count",
            "location": 71,
            "return": [
                "int"
            ],
            "arguments": {
                "video_file_path": [
                    "Path"
                ]
            }
        },
        "_is_video_file": {
            "name": "_is_video_file",
            "location": 92,
            "return": [
                "bool"
            ],
            "arguments": {
                "path": [
                    "Path"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/internal/utils.py": {
        "_is_int": {
            "name": "_is_int",
            "location": 1,
            "return": [],
            "arguments": {
                "maybe_int": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/internal/__init__.py": {},
    "torchvideo-master/src/torchvideo/scripts/dataloader_benchmark.py": {
        "benchmark_dataloader": {
            "name": "benchmark_dataloader",
            "location": 56,
            "return": [
                "None"
            ],
            "arguments": {
                "loader": [
                    "DataLoader"
                ],
                "max_iterations": [
                    "int"
                ],
                "profile": [
                    "bool"
                ],
                "profile_callgrind": [
                    "Path"
                ]
            }
        },
        "main": {
            "name": "main",
            "location": 99,
            "return": [
                "None"
            ],
            "arguments": {
                "args": []
            }
        },
        "make_dataset": {
            "name": "make_dataset",
            "location": 121,
            "return": [
                "VideoDataset"
            ],
            "arguments": {
                "args": [],
                "sampler": [
                    "Optional[FrameSampler]"
                ],
                "transform": []
            }
        },
        "make_sampler": {
            "name": "make_sampler",
            "location": 155,
            "return": [
                "FrameSampler"
            ],
            "arguments": {
                "args": []
            }
        },
        "benchmark_dataloader.run_dataloader": {
            "name": "run_dataloader",
            "location": 64,
            "return": [],
            "arguments": {}
        }
    },
    "torchvideo-master/src/torchvideo/transforms/__init__.py": {},
    "torchvideo-master/src/torchvideo/transforms/functional/normalize.py": {
        "normalize": {
            "name": "normalize",
            "location": 6,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "tensor": [
                    "torch.Tensor"
                ],
                "mean": [
                    "Sequence"
                ],
                "std": [
                    "Sequence"
                ],
                "channel_dim": [
                    "int"
                ],
                "inplace": [
                    "bool"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/functional/time_to_channel.py": {
        "time_to_channel": {
            "name": "time_to_channel",
            "location": 4,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "tensor": [
                    "torch.Tensor"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/functional/__init__.py": {},
    "torchvideo-master/src/torchvideo/transforms/transforms/center_crop_video.py": {
        "CenterCropVideo.__init__": {
            "name": "__init__",
            "location": 19,
            "return": [],
            "arguments": {
                "self": [],
                "size": [
                    "Union[(Tuple[(int, int)], int)]"
                ]
            }
        },
        "CenterCropVideo._gen_params": {
            "name": "_gen_params",
            "location": 23,
            "return": [],
            "arguments": {
                "self": [],
                "frames": []
            }
        },
        "CenterCropVideo.__repr__": {
            "name": "__repr__",
            "location": 26,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "CenterCropVideo._transform": {
            "name": "_transform",
            "location": 29,
            "return": [],
            "arguments": {
                "self": [],
                "frames": [
                    "PILVideo"
                ],
                "params": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/collect_frames.py": {
        "CollectFrames._gen_params": {
            "name": "_gen_params",
            "location": 15,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "PILVideo"
                ]
            }
        },
        "CollectFrames._transform": {
            "name": "_transform",
            "location": 18,
            "return": [
                "List[Image]"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "PILVideo"
                ],
                "params": [
                    "None"
                ]
            }
        },
        "CollectFrames.__repr__": {
            "name": "__repr__",
            "location": 21,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/compose.py": {
        "_supports_target": {
            "name": "_supports_target",
            "location": 52,
            "return": [],
            "arguments": {
                "transform": []
            }
        },
        "_requires_target": {
            "name": "_requires_target",
            "location": 58,
            "return": [],
            "arguments": {
                "transform": []
            }
        },
        "Compose.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [],
            "arguments": {
                "self": [],
                "transforms": [
                    "List[Transform]"
                ]
            }
        },
        "Compose.__call__": {
            "name": "__call__",
            "location": 24,
            "return": [],
            "arguments": {
                "self": [],
                "frames": [],
                "target": []
            }
        },
        "Compose._check_transforms_dont_require_target": {
            "name": "_check_transforms_dont_require_target",
            "location": 38,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "Compose.__repr__": {
            "name": "__repr__",
            "location": 46,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/identity_transform.py": {
        "IdentityTransform._transform": {
            "name": "_transform",
            "location": 12,
            "return": [
                "InputFramesType"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "InputFramesType"
                ],
                "params": [
                    "None"
                ]
            }
        },
        "IdentityTransform.__repr__": {
            "name": "__repr__",
            "location": 15,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/internal.py": {
        "canonicalize_size": {
            "name": "canonicalize_size",
            "location": 7,
            "return": [
                "ImageShape"
            ],
            "arguments": {
                "size": [
                    "ImageSizeParam"
                ]
            }
        },
        "to_iter": {
            "name": "to_iter",
            "location": 28,
            "return": [
                "Iterator[T]"
            ],
            "arguments": {
                "seq": [
                    "Union[(Iterator[T], Iterable[T])]"
                ]
            }
        },
        "peek_iter": {
            "name": "peek_iter",
            "location": 37,
            "return": [
                "Tuple[(T, Iterator[T])]"
            ],
            "arguments": {
                "iterator": [
                    "Iterator[T]"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/multiscale_crop_video.py": {
        "MultiScaleCropVideo._gen_params": {
            "name": "_gen_params",
            "location": 43,
            "return": [
                "FramesAndParams[(PILVideo, Tuple[(ImageShape, Point)])]"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "PILVideo"
                ]
            }
        },
        "MultiScaleCropVideo._transform": {
            "name": "_transform",
            "location": 63,
            "return": [
                "PILVideoI"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "PILVideo"
                ],
                "params": [
                    "Tuple[(ImageShape, Point)]"
                ]
            }
        },
        "MultiScaleCropVideo.__init__": {
            "name": "__init__",
            "location": 79,
            "return": [],
            "arguments": {
                "self": [],
                "size": [],
                "scales": [
                    "Sequence[float]"
                ],
                "max_distortion": [
                    "int"
                ],
                "fixed_crops": [
                    "bool"
                ],
                "more_fixed_crops": [
                    "bool"
                ]
            }
        },
        "MultiScaleCropVideo.__repr__": {
            "name": "__repr__",
            "location": 96,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "MultiScaleCropVideo.get_params": {
            "name": "get_params",
            "location": 110,
            "return": [
                "Tuple[(ImageShape, Point)]"
            ],
            "arguments": {
                "cls": [],
                "frame": [
                    "Image"
                ],
                "output_shape": [
                    "Tuple[(int, int)]"
                ],
                "scales": [
                    "Sequence[float]"
                ],
                "max_distortion": [
                    "int"
                ],
                "fixed_crops": [
                    "bool"
                ],
                "more_fixed_crops": [
                    "bool"
                ]
            }
        },
        "MultiScaleCropVideo._sample_crop_shape": {
            "name": "_sample_crop_shape",
            "location": 136,
            "return": [
                "ImageShape"
            ],
            "arguments": {
                "cls": [],
                "crop_sizes": [
                    "List[int]"
                ],
                "max_distortion": [
                    "int"
                ],
                "output_shape": [
                    "ImageShape"
                ]
            }
        },
        "MultiScaleCropVideo._sample_random_offset": {
            "name": "_sample_random_offset",
            "location": 156,
            "return": [
                "Point"
            ],
            "arguments": {
                "input_shape": [],
                "crop_shape": []
            }
        },
        "MultiScaleCropVideo._sample_fixed_offset": {
            "name": "_sample_fixed_offset",
            "location": 162,
            "return": [
                "Point"
            ],
            "arguments": {
                "cls": [],
                "input_shape": [
                    "ImageShape"
                ],
                "crop_shape": [
                    "ImageShape"
                ],
                "more_fixed_crops": []
            }
        },
        "MultiScaleCropVideo._fixed_crop_offsets": {
            "name": "_fixed_crop_offsets",
            "location": 171,
            "return": [
                "List[Point]"
            ],
            "arguments": {
                "image_shape": [
                    "ImageShape"
                ],
                "crop_shape": [
                    "ImageShape"
                ],
                "more_fixed_crops": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/ndarray_to_pil_video.py": {
        "NDArrayToPILVideo.__init__": {
            "name": "__init__",
            "location": 13,
            "return": [],
            "arguments": {
                "self": [],
                "format": []
            }
        },
        "NDArrayToPILVideo._transform": {
            "name": "_transform",
            "location": 26,
            "return": [
                "PILVideoI"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "np.ndarray"
                ],
                "params": [
                    "None"
                ]
            }
        },
        "NDArrayToPILVideo._gen_params": {
            "name": "_gen_params",
            "location": 32,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "np.ndarray"
                ]
            }
        },
        "NDArrayToPILVideo.__repr__": {
            "name": "__repr__",
            "location": 35,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/normalize_video.py": {
        "NormalizeVideo.__init__": {
            "name": "__init__",
            "location": 30,
            "return": [],
            "arguments": {
                "self": [],
                "mean": [
                    "Union[(Sequence[numbers.Number], numbers.Number)]"
                ],
                "std": [
                    "Union[(Sequence[numbers.Number], numbers.Number)]"
                ],
                "channel_dim": [
                    "int"
                ],
                "inplace": [
                    "bool"
                ]
            }
        },
        "NormalizeVideo._gen_params": {
            "name": "_gen_params",
            "location": 46,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "torch.Tensor"
                ]
            }
        },
        "NormalizeVideo.__repr__": {
            "name": "__repr__",
            "location": 49,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "NormalizeVideo._transform": {
            "name": "_transform",
            "location": 57,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "torch.Tensor"
                ],
                "params": [
                    "None"
                ]
            }
        },
        "NormalizeVideo._broadcast_to_seq": {
            "name": "_broadcast_to_seq",
            "location": 66,
            "return": [
                "Sequence[numbers.Number]"
            ],
            "arguments": {
                "x": [
                    "Union[(numbers.Number, Sequence)]"
                ],
                "channel_count": [
                    "int"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/pil_video_to_tensor.py": {
        "PILVideoToTensor.__init__": {
            "name": "__init__",
            "location": 15,
            "return": [],
            "arguments": {
                "self": [],
                "rescale": [
                    "bool"
                ],
                "ordering": [
                    "str"
                ]
            }
        },
        "PILVideoToTensor._gen_params": {
            "name": "_gen_params",
            "location": 34,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "PILVideo"
                ]
            }
        },
        "PILVideoToTensor._transform": {
            "name": "_transform",
            "location": 37,
            "return": [
                "torch.Tensor"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "PILVideo"
                ],
                "params": [
                    "None"
                ]
            }
        },
        "PILVideoToTensor.__repr__": {
            "name": "__repr__",
            "location": 53,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/random_crop_video.py": {
        "RandomCropVideo.__init__": {
            "name": "__init__",
            "location": 43,
            "return": [],
            "arguments": {
                "self": [],
                "size": [
                    "Union[(Tuple[(int, int)], int)]"
                ],
                "padding": [
                    "Optional[Union[(Tuple[(int, int, int, int)], Tuple[(int, int)])]]"
                ],
                "pad_if_needed": [
                    "bool"
                ],
                "fill": [
                    "int"
                ],
                "padding_mode": [
                    "str"
                ]
            }
        },
        "RandomCropVideo._gen_params": {
            "name": "_gen_params",
            "location": 58,
            "return": [
                "Tuple[(int, int, int, int)]"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "PILVideo"
                ]
            }
        },
        "RandomCropVideo._transform": {
            "name": "_transform",
            "location": 65,
            "return": [
                "PILVideoI"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "PILVideo"
                ],
                "params": [
                    "Tuple[(int, int, int, int)]"
                ]
            }
        },
        "RandomCropVideo._maybe_pad": {
            "name": "_maybe_pad",
            "location": 71,
            "return": [],
            "arguments": {
                "self": [],
                "frame": [
                    "Image"
                ]
            }
        },
        "RandomCropVideo.__repr__": {
            "name": "__repr__",
            "location": 88,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/random_horizontal_flip_video.py": {
        "RandomHorizontalFlipVideo.__init__": {
            "name": "__init__",
            "location": 19,
            "return": [],
            "arguments": {
                "self": [],
                "p": []
            }
        },
        "RandomHorizontalFlipVideo._gen_params": {
            "name": "_gen_params",
            "location": 22,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "PILVideo"
                ]
            }
        },
        "RandomHorizontalFlipVideo._transform": {
            "name": "_transform",
            "location": 28,
            "return": [
                "Iterator[Image]"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "PILVideo"
                ],
                "params": [
                    "bool"
                ]
            }
        },
        "RandomHorizontalFlipVideo.__repr__": {
            "name": "__repr__",
            "location": 36,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/random_resized_crop_video.py": {
        "RandomResizedCropVideo._gen_params": {
            "name": "_gen_params",
            "location": 29,
            "return": [
                "FramesAndParams[(PILVideo, Tuple[(int, int, int, int)])]"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "PILVideo"
                ]
            }
        },
        "RandomResizedCropVideo._transform": {
            "name": "_transform",
            "location": 36,
            "return": [
                "PILVideoI"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "PILVideo"
                ],
                "params": [
                    "Tuple[(int, int, int, int)]"
                ]
            }
        },
        "RandomResizedCropVideo.__init__": {
            "name": "__init__",
            "location": 43,
            "return": [],
            "arguments": {
                "self": [],
                "size": [
                    "Union[(Tuple[(int, int)], int)]"
                ],
                "scale": [
                    "Tuple[(float, float)]"
                ],
                "ratio": [
                    "Tuple[(float, float)]"
                ],
                "interpolation": []
            }
        },
        "RandomResizedCropVideo.__repr__": {
            "name": "__repr__",
            "location": 55,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "RandomResizedCropVideo._transform_frame": {
            "name": "_transform_frame",
            "location": 66,
            "return": [
                "Image"
            ],
            "arguments": {
                "self": [],
                "frame": [
                    "Image"
                ],
                "i": [
                    "int"
                ],
                "j": [
                    "int"
                ],
                "h": [
                    "int"
                ],
                "w": [
                    "int"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/resize_video.py": {
        "ResizeVideo.__init__": {
            "name": "__init__",
            "location": 24,
            "return": [],
            "arguments": {
                "self": [],
                "size": [
                    "Union[(Tuple[(int, int)], int)]"
                ],
                "interpolation": []
            }
        },
        "ResizeVideo.__repr__": {
            "name": "__repr__",
            "location": 30,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ResizeVideo._transform": {
            "name": "_transform",
            "location": 36,
            "return": [
                "PILVideoI"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "PILVideo"
                ],
                "params": [
                    "None"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/time_apply.py": {
        "TimeApply.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "img_transform": [
                    "Callable[([Image], Image)]"
                ]
            }
        },
        "TimeApply._transform": {
            "name": "_transform",
            "location": 28,
            "return": [
                "PILVideoI"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "PILVideo"
                ],
                "params": [
                    "None"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/time_to_channel.py": {
        "TimeToChannel._gen_params": {
            "name": "_gen_params",
            "location": 12,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "torch.Tensor"
                ]
            }
        },
        "TimeToChannel._transform": {
            "name": "_transform",
            "location": 15,
            "return": [],
            "arguments": {
                "self": [],
                "frames": [
                    "torch.Tensor"
                ],
                "params": [
                    "None"
                ]
            }
        },
        "TimeToChannel.__repr__": {
            "name": "__repr__",
            "location": 18,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/transform.py": {
        "FramesAndParams.__init__": {
            "name": "__init__",
            "location": 13,
            "return": [],
            "arguments": {
                "self": [],
                "frames": [
                    "InputFramesType"
                ],
                "params": [
                    "ParamsType"
                ]
            }
        },
        "Transform.__call__": {
            "name": "__call__",
            "location": 19,
            "return": [],
            "arguments": {
                "self": [],
                "frames": [],
                "target": []
            }
        },
        "Transform._gen_params": {
            "name": "_gen_params",
            "location": 40,
            "return": [
                "Union[(ParamsType, FramesAndParams[(InputFramesType, ParamsType)])]"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "InputFramesType"
                ]
            }
        },
        "Transform._transform": {
            "name": "_transform",
            "location": 46,
            "return": [
                "OutputFramesType"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "InputFramesType"
                ],
                "params": [
                    "ParamsType"
                ]
            }
        },
        "StatelessTransform._gen_params": {
            "name": "_gen_params",
            "location": 53,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "InputFramesType"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/types.py": {},
    "torchvideo-master/src/torchvideo/transforms/transforms/__init__.py": {},
    "torchvideo-master/tests/__init__.py": {
        "TorchRandomState.getstate": {
            "name": "getstate",
            "location": 9,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": []
            }
        },
        "TorchRandomState.setstate": {
            "name": "setstate",
            "location": 12,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "TorchRandomState.seed": {
            "name": "seed",
            "location": 15,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "seed": []
            }
        }
    },
    "torchvideo-master/tests/assertions/seq.py": {
        "assert_ordered": {
            "name": "assert_ordered",
            "location": 4,
            "return": [],
            "arguments": {
                "seq": []
            }
        },
        "assert_elems_lt": {
            "name": "assert_elems_lt",
            "location": 18,
            "return": [],
            "arguments": {
                "seq": [],
                "upper_bound": []
            }
        },
        "assert_elems_gte": {
            "name": "assert_elems_gte",
            "location": 22,
            "return": [],
            "arguments": {
                "seq": [],
                "lower_bound": []
            }
        }
    },
    "torchvideo-master/tests/assertions/__init__.py": {},
    "torchvideo-master/tests/functional/test_readers.py": {
        "TestLintelReader.test_reading_sequential_contiguous_frames": {
            "name": "test_reading_sequential_contiguous_frames",
            "location": 10,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestLintelReader.test_reading_last_frame": {
            "name": "test_reading_last_frame",
            "location": 15,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestLintelReader.test_reading_frames_out_of_order": {
            "name": "test_reading_frames_out_of_order",
            "location": 20,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestLintelReader.test_reading_frames_beyond_length_of_video": {
            "name": "test_reading_frames_beyond_length_of_video",
            "location": 25,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestLintelReader.load_frames": {
            "name": "load_frames",
            "location": 30,
            "return": [],
            "arguments": {
                "self": [],
                "frame_idx": []
            }
        },
        "TestLintelReader.check_frames": {
            "name": "check_frames",
            "location": 33,
            "return": [],
            "arguments": {
                "self": [],
                "frames": [],
                "expected_frame_count": []
            }
        }
    },
    "torchvideo-master/tests/functional/__init__.py": {},
    "torchvideo-master/tests/functional/datasets/test_gulp_video_dataset.py": {
        "gulp_path": {
            "name": "gulp_path",
            "location": 20,
            "return": [],
            "arguments": {}
        },
        "gulp_dataset": {
            "name": "gulp_dataset",
            "location": 25,
            "return": [],
            "arguments": {
                "gulp_path": []
            }
        },
        "TestGulpVideoDataset.test_dataset_length": {
            "name": "test_dataset_length",
            "location": 34,
            "return": [],
            "arguments": {
                "self": [],
                "gulp_dataset": []
            }
        },
        "TestGulpVideoDataset.test_video_id": {
            "name": "test_video_id",
            "location": 37,
            "return": [],
            "arguments": {
                "self": [],
                "gulp_dataset": []
            }
        },
        "TestGulpVideoDataset.test_video_range": {
            "name": "test_video_range",
            "location": 40,
            "return": [],
            "arguments": {
                "self": [],
                "gulp_dataset": []
            }
        },
        "TestGulpVideoDataset.test_loads_all_frames_by_default": {
            "name": "test_loads_all_frames_by_default",
            "location": 46,
            "return": [],
            "arguments": {
                "self": [],
                "gulp_dataset": []
            }
        },
        "TestGulpVideoDataset.test_loading_by_slice": {
            "name": "test_loading_by_slice",
            "location": 54,
            "return": [],
            "arguments": {
                "self": [],
                "gulp_dataset": []
            }
        },
        "TestGulpVideoDataset.test_loading_by_list_of_slices": {
            "name": "test_loading_by_list_of_slices",
            "location": 64,
            "return": [],
            "arguments": {
                "self": [],
                "gulp_dataset": []
            }
        },
        "TestGulpVideoDataset.test_loading_by_list_of_int": {
            "name": "test_loading_by_list_of_int",
            "location": 76,
            "return": [],
            "arguments": {
                "self": [],
                "gulp_dataset": []
            }
        },
        "TestGulpVideoDataset.test_filtering_videos": {
            "name": "test_filtering_videos",
            "location": 87,
            "return": [],
            "arguments": {
                "self": [],
                "gulp_path": []
            }
        },
        "TestGulpVideoDataset.test_transforms_are_passed_uint8_ndarray_video": {
            "name": "test_transforms_are_passed_uint8_ndarray_video",
            "location": 98,
            "return": [],
            "arguments": {
                "self": [],
                "gulp_path": []
            }
        },
        "TestGulpVideoDataset.test_transform_is_called": {
            "name": "test_transform_is_called",
            "location": 107,
            "return": [],
            "arguments": {
                "self": [],
                "gulp_path": []
            }
        },
        "TestGulpVideoDataset.test_transform_is_passed_target_if_it_supports_it": {
            "name": "test_transform_is_passed_target_if_it_supports_it",
            "location": 116,
            "return": [],
            "arguments": {
                "self": [],
                "gulp_path": []
            }
        },
        "TestGulpVideoDataset.test_labels_are_accessible": {
            "name": "test_labels_are_accessible",
            "location": 127,
            "return": [],
            "arguments": {
                "self": [],
                "gulp_dataset": []
            }
        },
        "TestGulpVideoDataset.test_video_ids": {
            "name": "test_video_ids",
            "location": 131,
            "return": [],
            "arguments": {
                "self": [],
                "gulp_dataset": []
            }
        },
        "TestGulpVideoDataset.test_creating_gulp_video_dataset_from_gulp_directory": {
            "name": "test_creating_gulp_video_dataset_from_gulp_directory",
            "location": 137,
            "return": [],
            "arguments": {
                "self": [],
                "gulp_path": []
            }
        },
        "TestGulpVideoDataset.test_dataset_throws_error_if_root_path_is_different_from_gulp_dir_path": {
            "name": "test_dataset_throws_error_if_root_path_is_different_from_gulp_dir_path",
            "location": 146,
            "return": [],
            "arguments": {
                "self": [],
                "gulp_path": []
            }
        },
        "TestGulpVideoDataset.test_filtering_videos.filter": {
            "name": "filter",
            "location": 90,
            "return": [],
            "arguments": {
                "video_id": [
                    "str"
                ]
            }
        }
    },
    "torchvideo-master/tests/functional/datasets/test_image_folder_video_dataset.py": {
        "image_folder": {
            "name": "image_folder",
            "location": 11,
            "return": [
                "Path"
            ],
            "arguments": {}
        },
        "image_folder_video_dataset": {
            "name": "image_folder_video_dataset",
            "location": 16,
            "return": [],
            "arguments": {
                "image_folder": []
            }
        },
        "TestImageFolderVideoDataset.test_length": {
            "name": "test_length",
            "location": 25,
            "return": [],
            "arguments": {
                "self": [],
                "image_folder_video_dataset": []
            }
        },
        "TestImageFolderVideoDataset.test_video_range": {
            "name": "test_video_range",
            "location": 29,
            "return": [],
            "arguments": {
                "self": [],
                "image_folder_video_dataset": []
            }
        },
        "TestImageFolderVideoDataset.test_loads_all_frames_by_default": {
            "name": "test_loads_all_frames_by_default",
            "location": 35,
            "return": [],
            "arguments": {
                "self": [],
                "image_folder_video_dataset": []
            }
        },
        "TestImageFolderVideoDataset.test_loading_by_slice": {
            "name": "test_loading_by_slice",
            "location": 41,
            "return": [],
            "arguments": {
                "self": [],
                "image_folder_video_dataset": []
            }
        },
        "TestImageFolderVideoDataset.test_loading_by_list_of_slice": {
            "name": "test_loading_by_list_of_slice",
            "location": 50,
            "return": [],
            "arguments": {
                "self": [],
                "image_folder_video_dataset": []
            }
        },
        "TestImageFolderVideoDataset.test_loading_by_list_of_ints": {
            "name": "test_loading_by_list_of_ints",
            "location": 61,
            "return": [],
            "arguments": {
                "self": [],
                "image_folder_video_dataset": []
            }
        },
        "TestImageFolderVideoDataset.test_using_custom_frame_counter": {
            "name": "test_using_custom_frame_counter",
            "location": 70,
            "return": [],
            "arguments": {
                "self": [],
                "image_folder": []
            }
        }
    },
    "torchvideo-master/tests/functional/datasets/test_video_folder_dataset.py": {
        "video_folder_dir": {
            "name": "video_folder_dir",
            "location": 9,
            "return": [],
            "arguments": {}
        },
        "video_folder_dataset": {
            "name": "video_folder_dataset",
            "location": 14,
            "return": [],
            "arguments": {
                "video_folder_dir": []
            }
        },
        "TestVideoFolderDataset.test_dataset_length": {
            "name": "test_dataset_length",
            "location": 23,
            "return": [],
            "arguments": {
                "self": [],
                "video_folder_dataset": []
            }
        },
        "TestVideoFolderDataset.test_video_range": {
            "name": "test_video_range",
            "location": 26,
            "return": [],
            "arguments": {
                "self": [],
                "video_folder_dataset": []
            }
        },
        "TestVideoFolderDataset.test_loads_all_frames_by_default": {
            "name": "test_loads_all_frames_by_default",
            "location": 32,
            "return": [],
            "arguments": {
                "self": [],
                "video_folder_dataset": []
            }
        },
        "TestVideoFolderDataset.test_loading_by_slice": {
            "name": "test_loading_by_slice",
            "location": 40,
            "return": [],
            "arguments": {
                "self": [],
                "video_folder_dataset": []
            }
        },
        "TestVideoFolderDataset.test_loading_by_list_of_slices": {
            "name": "test_loading_by_list_of_slices",
            "location": 50,
            "return": [],
            "arguments": {
                "self": [],
                "video_folder_dataset": []
            }
        },
        "TestVideoFolderDataset.test_loading_by_list_of_int": {
            "name": "test_loading_by_list_of_int",
            "location": 63,
            "return": [],
            "arguments": {
                "self": [],
                "video_folder_dataset": []
            }
        },
        "TestVideoFolderDataset.test_using_custom_frame_counter": {
            "name": "test_using_custom_frame_counter",
            "location": 74,
            "return": [],
            "arguments": {
                "self": [],
                "video_folder_dir": []
            }
        }
    },
    "torchvideo-master/tests/functional/datasets/__init__.py": {},
    "torchvideo-master/tests/unit/mock_transforms.py": {
        "_has_at_least_one_param": {
            "name": "_has_at_least_one_param",
            "location": 10,
            "return": [],
            "arguments": {
                "fn": []
            }
        },
        "MockTransform.__init__": {
            "name": "__init__",
            "location": 16,
            "return": [],
            "arguments": {
                "self": [],
                "return_value": [],
                "name": []
            }
        },
        "MockTransform.assert_called_once_with": {
            "name": "assert_called_once_with",
            "location": 21,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "MockTransform.__repr__": {
            "name": "__repr__",
            "location": 30,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "MockTransform._get_frames_return_value": {
            "name": "_get_frames_return_value",
            "location": 36,
            "return": [],
            "arguments": {
                "self": [],
                "frames": []
            }
        },
        "MockTransformWithTarget.__init__": {
            "name": "__init__",
            "location": 46,
            "return": [],
            "arguments": {
                "self": [],
                "frames_return_value": [],
                "target_return_value": []
            }
        },
        "MockTransformWithTarget._get_target_return_value": {
            "name": "_get_target_return_value",
            "location": 52,
            "return": [],
            "arguments": {
                "self": [],
                "target": []
            }
        },
        "MockFramesOnlyTransform.__call__": {
            "name": "__call__",
            "location": 61,
            "return": [],
            "arguments": {
                "self": [],
                "frames": []
            }
        },
        "MockFramesAndOptionalTargetTransform.__call__": {
            "name": "__call__",
            "location": 67,
            "return": [],
            "arguments": {
                "self": [],
                "frames": [],
                "target": []
            }
        },
        "MockFramesAndRequiredTargetTransform.__init__": {
            "name": "__init__",
            "location": 79,
            "return": [],
            "arguments": {
                "self": [],
                "frames_return_value": [],
                "target_return_value": [],
                "name": []
            }
        },
        "MockFramesAndRequiredTargetTransform.__call__": {
            "name": "__call__",
            "location": 85,
            "return": [],
            "arguments": {
                "self": [],
                "frames": [],
                "target": []
            }
        }
    },
    "torchvideo-master/tests/unit/strategies.py": {
        "numpy_video": {
            "name": "numpy_video",
            "location": 11,
            "return": [],
            "arguments": {
                "draw": [],
                "min_length": [],
                "max_length": [],
                "min_width": [],
                "max_width": [],
                "min_height": [],
                "max_height": [],
                "mode": []
            }
        },
        "pil_video": {
            "name": "pil_video",
            "location": 36,
            "return": [],
            "arguments": {
                "draw": [],
                "min_length": [],
                "max_length": [],
                "min_width": [],
                "max_width": [],
                "min_height": [],
                "max_height": [],
                "mode": []
            }
        },
        "tensor_video": {
            "name": "tensor_video",
            "location": 63,
            "return": [],
            "arguments": {
                "draw": [],
                "min_length": [],
                "max_length": [],
                "min_width": [],
                "max_width": [],
                "min_height": [],
                "max_height": [],
                "mode": []
            }
        },
        "video_shape": {
            "name": "video_shape",
            "location": 98,
            "return": [],
            "arguments": {
                "draw": [],
                "min_length": [],
                "max_length": [],
                "min_height": [],
                "max_height": [],
                "min_width": [],
                "max_width": []
            }
        }
    },
    "torchvideo-master/tests/unit/test_internal.py": {
        "test_compute_sample_length": {
            "name": "test_compute_sample_length",
            "location": 26,
            "return": [],
            "arguments": {
                "clip_length": [],
                "step_size": [],
                "expected_sample_size": []
            }
        }
    },
    "torchvideo-master/tests/unit/test_readers.py": {
        "loadvid_frame_nums_mock": {
            "name": "loadvid_frame_nums_mock",
            "location": 12,
            "return": [],
            "arguments": {
                "monkeypatch": []
            }
        },
        "loadvid_frame_nums_mock.side_effect": {
            "name": "side_effect",
            "location": 13,
            "return": [],
            "arguments": {
                "binary_data": [],
                "frame_nums": []
            }
        },
        "TestLintelReaderUnit.test_loading_sequential_contiguous_frames": {
            "name": "test_loading_sequential_contiguous_frames",
            "location": 26,
            "return": [],
            "arguments": {
                "self": [],
                "loadvid_frame_nums_mock": []
            }
        },
        "TestLintelReaderUnit.test_loading_duplicate_frames": {
            "name": "test_loading_duplicate_frames",
            "location": 35,
            "return": [],
            "arguments": {
                "self": [],
                "loadvid_frame_nums_mock": []
            }
        },
        "TestLintelReaderUnit.test_loading_unorderd_frames": {
            "name": "test_loading_unorderd_frames",
            "location": 45,
            "return": [],
            "arguments": {
                "self": [],
                "loadvid_frame_nums_mock": []
            }
        },
        "TestLintelReaderUnit.assert_loadvid_correctly_called": {
            "name": "assert_loadvid_correctly_called",
            "location": 55,
            "return": [],
            "arguments": {
                "self": [],
                "loadvid_frame_nums_mock": [],
                "f": [],
                "frame_nums": [],
                "frames": [],
                "expected_load_idx": []
            }
        }
    },
    "torchvideo-master/tests/unit/__init__.py": {},
    "torchvideo-master/tests/unit/datasets/conftest.py": {
        "mock_frame_count": {
            "name": "mock_frame_count",
            "location": 8,
            "return": [],
            "arguments": {
                "monkeypatch": []
            }
        },
        "dataset_dir": {
            "name": "dataset_dir",
            "location": 20,
            "return": [],
            "arguments": {
                "fs": [
                    "FakeFilesystem"
                ]
            }
        },
        "mock_frame_count.get_videofile_frame_count": {
            "name": "get_videofile_frame_count",
            "location": 9,
            "return": [],
            "arguments": {
                "path": []
            }
        }
    },
    "torchvideo-master/tests/unit/datasets/test_image_folder_video_dataset.py": {
        "TestImageFolderVideoDatasetUnit.test_all_videos_folders_are_present_in_video_dirs_by_default": {
            "name": "test_all_videos_folders_are_present_in_video_dirs_by_default",
            "location": 14,
            "return": [],
            "arguments": {
                "self": [],
                "dataset_dir": []
            }
        },
        "TestImageFolderVideoDatasetUnit.test_filtering_video_folders": {
            "name": "test_filtering_video_folders",
            "location": 22,
            "return": [],
            "arguments": {
                "self": [],
                "dataset_dir": []
            }
        },
        "TestImageFolderVideoDatasetUnit.test_labels_are_accessible": {
            "name": "test_labels_are_accessible",
            "location": 37,
            "return": [],
            "arguments": {
                "self": [],
                "dataset_dir": []
            }
        },
        "TestImageFolderVideoDatasetUnit.test_transform_is_applied": {
            "name": "test_transform_is_applied",
            "location": 49,
            "return": [],
            "arguments": {
                "self": [],
                "dataset_dir": []
            }
        },
        "TestImageFolderVideoDatasetUnit.test_transform_is_passed_target_if_it_supports_it": {
            "name": "test_transform_is_passed_target_if_it_supports_it",
            "location": 61,
            "return": [],
            "arguments": {
                "self": [],
                "dataset_dir": []
            }
        },
        "TestImageFolderVideoDatasetUnit.test_video_ids": {
            "name": "test_video_ids",
            "location": 76,
            "return": [],
            "arguments": {
                "self": [],
                "dataset_dir": []
            }
        },
        "TestImageFolderVideoDatasetUnit.make_video_dirs": {
            "name": "make_video_dirs",
            "location": 89,
            "return": [],
            "arguments": {
                "dataset_dir": [],
                "video_count": [],
                "frame_count": []
            }
        },
        "TestImageFolderVideoDatasetUnit.test_filtering_video_folders.filter": {
            "name": "filter",
            "location": 25,
            "return": [],
            "arguments": {
                "video_path": [
                    "Path"
                ]
            }
        }
    },
    "torchvideo-master/tests/unit/datasets/test_video_folder_dataset.py": {
        "TestVideoFolderDatasetUnit.test_all_videos_are_present_in_video_paths_by_default": {
            "name": "test_all_videos_are_present_in_video_paths_by_default",
            "location": 18,
            "return": [],
            "arguments": {
                "self": [],
                "dataset_dir": [],
                "fs": [],
                "mock_frame_count": []
            }
        },
        "TestVideoFolderDatasetUnit.test_filtering_video_files": {
            "name": "test_filtering_video_files",
            "location": 28,
            "return": [],
            "arguments": {
                "self": [],
                "dataset_dir": [],
                "fs": [],
                "mock_frame_count": []
            }
        },
        "TestVideoFolderDatasetUnit.test_labels_are_accessible": {
            "name": "test_labels_are_accessible",
            "location": 41,
            "return": [],
            "arguments": {
                "self": [],
                "dataset_dir": [],
                "fs": [],
                "mock_frame_count": []
            }
        },
        "TestVideoFolderDatasetUnit.test_transform_is_applied": {
            "name": "test_transform_is_applied",
            "location": 52,
            "return": [],
            "arguments": {
                "self": [],
                "dataset_dir": [],
                "fs": [],
                "monkeypatch": []
            }
        },
        "TestVideoFolderDatasetUnit.test_transform_is_passed_target_if_it_supports_it": {
            "name": "test_transform_is_passed_target_if_it_supports_it",
            "location": 73,
            "return": [],
            "arguments": {
                "self": [],
                "dataset_dir": [],
                "fs": [],
                "monkeypatch": []
            }
        },
        "TestVideoFolderDatasetUnit.test_video_ids": {
            "name": "test_video_ids",
            "location": 93,
            "return": [],
            "arguments": {
                "self": [],
                "dataset_dir": [],
                "fs": []
            }
        },
        "TestVideoFolderDatasetUnit.make_video_files": {
            "name": "make_video_files",
            "location": 106,
            "return": [],
            "arguments": {
                "dataset_dir": [],
                "fs": [],
                "video_count": []
            }
        },
        "TestVideoFolderDatasetUnit.test_filtering_video_files.filter": {
            "name": "filter",
            "location": 31,
            "return": [],
            "arguments": {
                "path": []
            }
        },
        "TestVideoFolderDatasetUnit.test_transform_is_applied._load_mock_frames": {
            "name": "_load_mock_frames",
            "location": 53,
            "return": [],
            "arguments": {
                "self": [],
                "frames_idx": [],
                "video_file": []
            }
        }
    },
    "torchvideo-master/tests/unit/datasets/__init__.py": {},
    "torchvideo-master/tests/unit/label_sets/test_csv_label_set.py": {
        "TestCsvLabelSet.test_returns_label_field_for_dataframe": {
            "name": "test_returns_label_field_for_dataframe",
            "location": 7,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestCsvLabelSet.test_returns_element_from_series": {
            "name": "test_returns_element_from_series",
            "location": 16,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/label_sets/test_dummy_label_set.py": {
        "TestDummyLabelSet.test_return_label_for_any_video_name": {
            "name": "test_return_label_for_any_video_name",
            "location": 8,
            "return": [],
            "arguments": {
                "self": [],
                "video_name": []
            }
        },
        "TestDummyLabelSet.test_repr": {
            "name": "test_repr",
            "location": 14,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/label_sets/test_gulp_label_set.py": {
        "TestGulpLabelSet.test_defaults_to_label_field": {
            "name": "test_defaults_to_label_field",
            "location": 12,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestGulpLabelSet.test_custom_label_field": {
            "name": "test_custom_label_field",
            "location": 17,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/label_sets/__init__.py": {},
    "torchvideo-master/tests/unit/samplers/assertions.py": {
        "assert_valid_frame_index": {
            "name": "assert_valid_frame_index",
            "location": 6,
            "return": [],
            "arguments": {
                "frame_idx": [
                    "List[int]"
                ],
                "expected_frame_count": [
                    "int"
                ],
                "video_length": [
                    "int"
                ]
            }
        },
        "assert_valid_snippet_index": {
            "name": "assert_valid_snippet_index",
            "location": 15,
            "return": [],
            "arguments": {
                "snippet_idx": [
                    "List[int]"
                ],
                "expected_snippet_length": [
                    "int"
                ],
                "expected_segment_count": [
                    "int"
                ],
                "video_length": [
                    "int"
                ]
            }
        }
    },
    "torchvideo-master/tests/unit/samplers/test_clip_sampler.py": {
        "TestClipSampler.test_clip_is_subsampled_from_video_when_video_is_longer_than_clip": {
            "name": "test_clip_is_subsampled_from_video_when_video_is_longer_than_clip",
            "location": 9,
            "return": [],
            "arguments": {
                "self": [],
                "data": []
            }
        },
        "TestClipSampler.test_clip_is_oversampled_when_video_is_shorter_than_clip_length": {
            "name": "test_clip_is_oversampled_when_video_is_shorter_than_clip_length",
            "location": 20,
            "return": [],
            "arguments": {
                "self": [],
                "data": []
            }
        },
        "TestClipSampler.test_clip_sampler_samples_central_clip_in_test_mode": {
            "name": "test_clip_sampler_samples_central_clip_in_test_mode",
            "location": 31,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestClipSampler.test_clip_sampler_is_deterministic_in_test_mode": {
            "name": "test_clip_sampler_is_deterministic_in_test_mode",
            "location": 37,
            "return": [],
            "arguments": {
                "self": [],
                "data": []
            }
        },
        "TestClipSampler.test_repr": {
            "name": "test_repr",
            "location": 48,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/samplers/test_full_video_sampler.py": {
        "TestFullVideoSampler.test_full_video_sampler": {
            "name": "test_full_video_sampler",
            "location": 8,
            "return": [],
            "arguments": {
                "self": [],
                "length": []
            }
        },
        "TestFullVideoSampler.test_full_video_sampler_repr": {
            "name": "test_full_video_sampler_repr",
            "location": 17,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestFullVideoSampler.test_full_video_sampler_str": {
            "name": "test_full_video_sampler_str",
            "location": 20,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/samplers/test_lambda_sampler.py": {
        "TestLambdaSampler.test_throws_error_if_user_provided_sampling_fn_returns_invalid_idx": {
            "name": "test_throws_error_if_user_provided_sampling_fn_returns_invalid_idx",
            "location": 7,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestLambdaSampler.test_repr": {
            "name": "test_repr",
            "location": 13,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestLambdaSampler.test_repr.MySampler.__call__": {
            "name": "__call__",
            "location": 15,
            "return": [],
            "arguments": {
                "self": [],
                "video_length": []
            }
        },
        "TestLambdaSampler.test_repr.MySampler.__repr__": {
            "name": "__repr__",
            "location": 18,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/samplers/test_samplers.py": {
        "full_video_sampler": {
            "name": "full_video_sampler",
            "location": 17,
            "return": [],
            "arguments": {}
        },
        "temporal_segment_sampler": {
            "name": "temporal_segment_sampler",
            "location": 21,
            "return": [],
            "arguments": {}
        },
        "clip_sampler": {
            "name": "clip_sampler",
            "location": 27,
            "return": [],
            "arguments": {}
        },
        "frame_sampler": {
            "name": "frame_sampler",
            "location": 33,
            "return": [],
            "arguments": {
                "request": []
            }
        },
        "TestFrameSampler.test_frame_sampler_raises_error_0_or_negative_frame_count": {
            "name": "test_frame_sampler_raises_error_0_or_negative_frame_count",
            "location": 43,
            "return": [],
            "arguments": {
                "self": [],
                "frame_sampler": [],
                "frame_count": []
            }
        },
        "TestFrameSampler.test_frame_sampler_generates_sequential_idx": {
            "name": "test_frame_sampler_generates_sequential_idx",
            "location": 50,
            "return": [],
            "arguments": {
                "self": [],
                "frame_sampler": [],
                "frame_count": []
            }
        }
    },
    "torchvideo-master/tests/unit/samplers/test_temporal_segment_sampler.py": {
        "TestTemporalSegmentSampler.test_raises_value_error_when_sampling_from_a_video_of_0_frames": {
            "name": "test_raises_value_error_when_sampling_from_a_video_of_0_frames",
            "location": 14,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTemporalSegmentSampler.test_oversampling_within_a_segment": {
            "name": "test_oversampling_within_a_segment",
            "location": 20,
            "return": [],
            "arguments": {
                "self": [],
                "test_mode": []
            }
        },
        "TestTemporalSegmentSampler.test_oversampling_segments_train": {
            "name": "test_oversampling_segments_train",
            "location": 36,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTemporalSegmentSampler.test_oversampling_segments_test": {
            "name": "test_oversampling_segments_test",
            "location": 52,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTemporalSegmentSampler.test_sampling_when_snippets_are_longer_than_segments": {
            "name": "test_sampling_when_snippets_are_longer_than_segments",
            "location": 73,
            "return": [],
            "arguments": {
                "self": [],
                "video_length": [],
                "segment_count": [],
                "snippet_length": [],
                "expected_idx": []
            }
        },
        "TestTemporalSegmentSampler.test_sampling_snippets_same_length_as_segments": {
            "name": "test_sampling_snippets_same_length_as_segments",
            "location": 84,
            "return": [],
            "arguments": {
                "self": [],
                "video_length": [],
                "segment_count": [],
                "snippet_length": [],
                "expected_idx": []
            }
        },
        "TestTemporalSegmentSampler.test_sampling_in_test_mode_centres_snippets_in_segments": {
            "name": "test_sampling_in_test_mode_centres_snippets_in_segments",
            "location": 103,
            "return": [],
            "arguments": {
                "self": [],
                "video_length": [],
                "segment_count": [],
                "snippet_length": [],
                "expected_idx": []
            }
        },
        "TestTemporalSegmentSampler.test_sampling_is_random": {
            "name": "test_sampling_is_random",
            "location": 111,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTemporalSegmentSampler.test_fuzz_sampler_training": {
            "name": "test_fuzz_sampler_training",
            "location": 126,
            "return": [],
            "arguments": {
                "self": [],
                "data": []
            }
        },
        "TestTemporalSegmentSampler.test_fuzz_sampler_test": {
            "name": "test_fuzz_sampler_test",
            "location": 136,
            "return": [],
            "arguments": {
                "self": [],
                "data": []
            }
        },
        "TestTemporalSegmentSampler.test_repr": {
            "name": "test_repr",
            "location": 145,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTemporalSegmentSampler.test_str": {
            "name": "test_str",
            "location": 151,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTemporalSegmentSampler.test_segment_length_should_be_greater_than_0": {
            "name": "test_segment_length_should_be_greater_than_0",
            "location": 157,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTemporalSegmentSampler.test_segment_count_should_be_greater_than_0": {
            "name": "test_segment_count_should_be_greater_than_0",
            "location": 161,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTemporalSegmentSampler.sample": {
            "name": "sample",
            "location": 165,
            "return": [],
            "arguments": {
                "self": [],
                "video_length": [],
                "segment_count": [],
                "snippet_length": [],
                "test": []
            }
        },
        "TestTemporalSegmentSampler.draw_sampler_parameters": {
            "name": "draw_sampler_parameters",
            "location": 171,
            "return": [],
            "arguments": {
                "data": []
            }
        }
    },
    "torchvideo-master/tests/unit/samplers/__init__.py": {},
    "torchvideo-master/tests/unit/tools/test_show_video.py": {
        "TestShowVideo.test_raises_error_if_moviepy_not_available": {
            "name": "test_raises_error_if_moviepy_not_available",
            "location": 20,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestShowVideo.test_uses_ipython_display_if_ipython_is_available": {
            "name": "test_uses_ipython_display_if_ipython_is_available",
            "location": 48,
            "return": [],
            "arguments": {
                "self": [],
                "monkeypatch": []
            }
        },
        "TestShowVideo.test_fallsback_on_pygame_display": {
            "name": "test_fallsback_on_pygame_display",
            "location": 61,
            "return": [],
            "arguments": {
                "self": [],
                "monkeypatch": []
            }
        }
    },
    "torchvideo-master/tests/unit/tools/test_to_list_of_np_frames.py": {
        "TestToListOfNpFrames.test_from_ndarray_cthw": {
            "name": "test_from_ndarray_cthw",
            "location": 12,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestToListOfNpFrames.test_from_ndarray_thwc": {
            "name": "test_from_ndarray_thwc",
            "location": 26,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestToListOfNpFrames.test_from_tensor_with_range_0_1": {
            "name": "test_from_tensor_with_range_0_1",
            "location": 37,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestToListOfNpFrames.test_from_list_of_pil_images": {
            "name": "test_from_list_of_pil_images",
            "location": 57,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestToListOfNpFrames.test_raises_error_on_ndarray_formats_other_than_cthw_or_thwc": {
            "name": "test_raises_error_on_ndarray_formats_other_than_cthw_or_thwc",
            "location": 73,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestToListOfNpFrames.test_raises_error_on_unknown_format": {
            "name": "test_raises_error_on_unknown_format",
            "location": 82,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/tools/__init__.py": {},
    "torchvideo-master/tests/unit/transforms/assertions.py": {
        "assert_preserves_label": {
            "name": "assert_preserves_label",
            "location": 1,
            "return": [],
            "arguments": {
                "transform": [],
                "video": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_center_crop_video.py": {
        "TestCenterCropVideo.test_repr": {
            "name": "test_repr",
            "location": 11,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestCenterCropVideo.test_crop": {
            "name": "test_crop",
            "location": 15,
            "return": [],
            "arguments": {
                "self": [],
                "video": []
            }
        },
        "TestCenterCropVideo.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 22,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_collect_frames.py": {
        "TestCollectFrames.test_repr": {
            "name": "test_repr",
            "location": 9,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestCollectFrames.test_collect_frames_make_list_from_iterator": {
            "name": "test_collect_frames_make_list_from_iterator",
            "location": 13,
            "return": [],
            "arguments": {
                "self": [],
                "video": []
            }
        },
        "TestCollectFrames.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 17,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_compose.py": {
        "TestCompose.test_calls_frames_only_transforms_sequentially": {
            "name": "test_calls_frames_only_transforms_sequentially",
            "location": 16,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestCompose.test_passes_target_to_supporting_transforms": {
            "name": "test_passes_target_to_supporting_transforms",
            "location": 30,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestCompose.test_raises_error_if_target_is_not_passed_when_a_transform_requires_target": {
            "name": "test_raises_error_if_target_is_not_passed_when_a_transform_requires_target",
            "location": 49,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestCompose.test_single_level_repr": {
            "name": "test_single_level_repr",
            "location": 61,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestCompose.test_nested_repr": {
            "name": "test_nested_repr",
            "location": 65,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestCompose.gen_transforms": {
            "name": "gen_transforms",
            "location": 73,
            "return": [
                "Tuple[(List[Mock], List[Any])]"
            ],
            "arguments": {
                "self": [],
                "count": [
                    "int"
                ]
            }
        },
        "TestCompose.make_result_class": {
            "name": "make_result_class",
            "location": 83,
            "return": [],
            "arguments": {
                "self": [],
                "result_class_name": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_identity_transform.py": {
        "TestIdentityTransform.test_identity_transform_preserves_frames": {
            "name": "test_identity_transform_preserves_frames",
            "location": 8,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestIdentityTransform.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 15,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestIdentityTransform.test_repr": {
            "name": "test_repr",
            "location": 20,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_imports.py": {
        "TestTransformImports.test_importing_center_crop": {
            "name": "test_importing_center_crop",
            "location": 2,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_collect_frames": {
            "name": "test_importing_collect_frames",
            "location": 5,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_compose": {
            "name": "test_importing_compose",
            "location": 8,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_multiscale_crop_video": {
            "name": "test_importing_multiscale_crop_video",
            "location": 11,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_ndarray_to_pil_video": {
            "name": "test_importing_ndarray_to_pil_video",
            "location": 14,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_normalize_video": {
            "name": "test_importing_normalize_video",
            "location": 17,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_pil_video_to_tensor": {
            "name": "test_importing_pil_video_to_tensor",
            "location": 20,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_random_crop_video": {
            "name": "test_importing_random_crop_video",
            "location": 23,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_random_horizontal_flip_video": {
            "name": "test_importing_random_horizontal_flip_video",
            "location": 26,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_resize_video": {
            "name": "test_importing_resize_video",
            "location": 29,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_time_apply": {
            "name": "test_importing_time_apply",
            "location": 32,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_time_to_channel": {
            "name": "test_importing_time_to_channel",
            "location": 35,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_random_resized_crop_video": {
            "name": "test_importing_random_resized_crop_video",
            "location": 38,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_multiscale_crop_video.py": {
        "TestMultiScaleCropVideo.test_transform_always_yields_crops_of_the_correct_size": {
            "name": "test_transform_always_yields_crops_of_the_correct_size",
            "location": 13,
            "return": [],
            "arguments": {
                "self": [],
                "data": []
            }
        },
        "TestMultiScaleCropVideo.test_repr": {
            "name": "test_repr",
            "location": 54,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestMultiScaleCropVideo.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 72,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_ndarray_to_pil_video.py": {
        "TestNDArrayToPILVideo.test_repr": {
            "name": "test_repr",
            "location": 15,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestNDArrayToPILVideo.test_converts_thwc_to_PIL_video": {
            "name": "test_converts_thwc_to_PIL_video",
            "location": 19,
            "return": [],
            "arguments": {
                "self": [],
                "shape": []
            }
        },
        "TestNDArrayToPILVideo.test_converts_cthw_to_PIL_video": {
            "name": "test_converts_cthw_to_PIL_video",
            "location": 32,
            "return": [],
            "arguments": {
                "self": [],
                "shape": []
            }
        },
        "TestNDArrayToPILVideo.test_only_thwc_and_cthw_are_valid_formats": {
            "name": "test_only_thwc_and_cthw_are_valid_formats",
            "location": 44,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestNDArrayToPILVideo.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 56,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestNDArrayToPILVideo.make_uint8_ndarray": {
            "name": "make_uint8_ndarray",
            "location": 63,
            "return": [],
            "arguments": {
                "shape": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_normalize_video.py": {
        "TestNormalizeVideo.test_repr": {
            "name": "test_repr",
            "location": 16,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestNormalizeVideo.test_scalar_statistics_smoke": {
            "name": "test_scalar_statistics_smoke",
            "location": 23,
            "return": [],
            "arguments": {
                "self": [],
                "video": []
            }
        },
        "TestNormalizeVideo.test_vector_statistics_smoke": {
            "name": "test_vector_statistics_smoke",
            "location": 27,
            "return": [],
            "arguments": {
                "self": [],
                "video": []
            }
        },
        "TestNormalizeVideo.test_raises_value_error_on_0_std": {
            "name": "test_raises_value_error_on_0_std",
            "location": 32,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestNormalizeVideo.test_raises_value_error_on_0_element_in_std_vector": {
            "name": "test_raises_value_error_on_0_element_in_std_vector",
            "location": 36,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestNormalizeVideo.test_raises_value_error_when_length_of_std_and_mean_dont_match": {
            "name": "test_raises_value_error_when_length_of_std_and_mean_dont_match",
            "location": 40,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestNormalizeVideo.test_raises_value_error_when_length_of_mean_is_not_equal_to_channel_count": {
            "name": "test_raises_value_error_when_length_of_mean_is_not_equal_to_channel_count",
            "location": 44,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestNormalizeVideo.test_transform_inplace": {
            "name": "test_transform_inplace",
            "location": 50,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestNormalizeVideo.test_transform_not_inplace": {
            "name": "test_transform_not_inplace",
            "location": 57,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestNormalizeVideo.test_distribution_is_normal_after_transform": {
            "name": "test_distribution_is_normal_after_transform",
            "location": 66,
            "return": [],
            "arguments": {
                "self": [],
                "ndim": [],
                "data": []
            }
        },
        "TestNormalizeVideo.test_preserves_channel_count": {
            "name": "test_preserves_channel_count",
            "location": 112,
            "return": [],
            "arguments": {
                "self": [],
                "data": []
            }
        },
        "TestNormalizeVideo.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 126,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestNormalizeVideo.test_distribution_is_normal_after_transform.samples_from_standard_normal": {
            "name": "samples_from_standard_normal",
            "location": 70,
            "return": [
                "bool"
            ],
            "arguments": {
                "tensor": [
                    "torch.Tensor"
                ],
                "significance": [
                    "float"
                ]
            }
        },
        "TestNormalizeVideo.test_distribution_is_normal_after_transform.get_stats": {
            "name": "get_stats",
            "location": 97,
            "return": [],
            "arguments": {
                "video": [
                    "torch.Tensor"
                ],
                "channel_dim": [],
                "channel_count": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_pil_video_to_tensor.py": {
        "TestPILVideoToTensor.test_repr": {
            "name": "test_repr",
            "location": 14,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestPILVideoToTensor.test_transform": {
            "name": "test_transform",
            "location": 21,
            "return": [],
            "arguments": {
                "self": [],
                "video": []
            }
        },
        "TestPILVideoToTensor.test_rescales_between_0_and_1": {
            "name": "test_rescales_between_0_and_1",
            "location": 31,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestPILVideoToTensor.test_disabled_rescale": {
            "name": "test_disabled_rescale",
            "location": 41,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestPILVideoToTensor.test_raises_exception_if_ordering_isnt_tchw_or_cthw": {
            "name": "test_raises_exception_if_ordering_isnt_tchw_or_cthw",
            "location": 51,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestPILVideoToTensor.test_mapping_to_tchw_ordering": {
            "name": "test_mapping_to_tchw_ordering",
            "location": 62,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestPILVideoToTensor.test_mapping_to_cthw_ordering": {
            "name": "test_mapping_to_cthw_ordering",
            "location": 77,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestPILVideoToTensor.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 92,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_random_crop_video.py": {
        "TestRandomCropVideo.test_repr": {
            "name": "test_repr",
            "location": 11,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestRandomCropVideo.test_crop_yields_image_of_specified_size": {
            "name": "test_crop_yields_image_of_specified_size",
            "location": 19,
            "return": [],
            "arguments": {
                "self": [],
                "video": [],
                "pad_if_needed": []
            }
        },
        "TestRandomCropVideo.test_crop_with_user_provided_padding": {
            "name": "test_crop_with_user_provided_padding",
            "location": 31,
            "return": [],
            "arguments": {
                "self": [],
                "video": [],
                "fill": []
            }
        },
        "TestRandomCropVideo.test_crop_with_different_padding_modes": {
            "name": "test_crop_with_different_padding_modes",
            "location": 44,
            "return": [],
            "arguments": {
                "self": [],
                "video": [],
                "padding_mode": []
            }
        },
        "TestRandomCropVideo.test_propagates_label_unchanges": {
            "name": "test_propagates_label_unchanges",
            "location": 53,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_random_horizontal_flip_video.py": {
        "TestRandomHorizontalFlipVideo.test_repr": {
            "name": "test_repr",
            "location": 10,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestRandomHorizontalFlipVideo.test_always_flip": {
            "name": "test_always_flip",
            "location": 16,
            "return": [],
            "arguments": {
                "self": [],
                "video": []
            }
        },
        "TestRandomHorizontalFlipVideo.test_never_flip": {
            "name": "test_never_flip",
            "location": 26,
            "return": [],
            "arguments": {
                "self": [],
                "video": []
            }
        },
        "TestRandomHorizontalFlipVideo.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 35,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_resize_video.py": {
        "TestResizeVideo.test_resizes_to_given_size": {
            "name": "test_resizes_to_given_size",
            "location": 11,
            "return": [],
            "arguments": {
                "self": [],
                "video": [],
                "interpolation": [],
                "data": []
            }
        },
        "TestResizeVideo.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 24,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_time_apply.py": {
        "TestTimeApply.test_applies_given_transform_for_each_frame": {
            "name": "test_applies_given_transform_for_each_frame",
            "location": 12,
            "return": [],
            "arguments": {
                "self": [],
                "frames": []
            }
        },
        "TestTimeApply.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 23,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_time_to_channel.py": {
        "prod": {
            "name": "prod",
            "location": 10,
            "return": [],
            "arguments": {
                "seq": []
            }
        },
        "TestTimeToChannel.test_repr": {
            "name": "test_repr",
            "location": 22,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTimeToChannel.test_reshaping": {
            "name": "test_reshaping",
            "location": 25,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTimeToChannel.test_raises_value_error_if_tensor_is_not_4d": {
            "name": "test_raises_value_error_if_tensor_is_not_4d",
            "location": 33,
            "return": [],
            "arguments": {
                "self": [],
                "ndim": []
            }
        },
        "TestTimeToChannel.test_element_count_is_preserved": {
            "name": "test_element_count_is_preserved",
            "location": 38,
            "return": [],
            "arguments": {
                "self": [],
                "frames": []
            }
        },
        "TestTimeToChannel.test_first_dim_is_always_larger": {
            "name": "test_first_dim_is_always_larger",
            "location": 47,
            "return": [],
            "arguments": {
                "self": [],
                "frames": []
            }
        },
        "TestTimeToChannel.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 52,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/tset_random_resized_crop_video.py": {
        "TestRandomResizedCropVideo.test_resulting_video_are_specified_size": {
            "name": "test_resulting_video_are_specified_size",
            "location": 11,
            "return": [],
            "arguments": {
                "self": [],
                "video": [],
                "interpolation": [],
                "data": []
            }
        },
        "TestRandomResizedCropVideo.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 25,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/__init__.py": {}
}
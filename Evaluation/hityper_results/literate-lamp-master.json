{
    "literate-lamp-master/literate_lamp/args.py": {
        "list_models": {
            "name": "list_models",
            "location": 12,
            "return": [
                "None"
            ],
            "arguments": {
                "models": [
                    "list[str]",
                    "list[tuple[typing.Union[str,str]]]"
                ]
            }
        },
        "get_args": {
            "name": "get_args",
            "location": 19,
            "return": [
                "DotDict"
            ],
            "arguments": {
                "arguments": [
                    "None",
                    "str",
                    "list[str]",
                    "bool",
                    "list[dict[, ]]"
                ]
            }
        },
        "get_args.preprocessed_name": {
            "name": "preprocessed_name",
            "location": 138,
            "return": [],
            "arguments": {
                "split_type": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/common.py": {
        "set_args": {
            "name": "set_args",
            "location": 30,
            "return": [
                "None"
            ],
            "arguments": {
                "args": []
            }
        },
        "get_seq2seq": {
            "name": "get_seq2seq",
            "location": 35,
            "return": [],
            "arguments": {
                "encoder_type": [
                    "None"
                ]
            }
        },
        "get_encoder": {
            "name": "get_encoder",
            "location": 48,
            "return": [],
            "arguments": {
                "encoder_type": [
                    "None"
                ]
            }
        },
        "get_word_embeddings": {
            "name": "get_word_embeddings",
            "location": 64,
            "return": [],
            "arguments": {
                "vocabulary": []
            }
        },
        "build_dmn": {
            "name": "build_dmn",
            "location": 81,
            "return": [
                "Dmn"
            ],
            "arguments": {
                "vocabulary": []
            }
        },
        "build_relational_xl": {
            "name": "build_relational_xl",
            "location": 115,
            "return": [
                "RelationalXL"
            ],
            "arguments": {
                "vocabulary": []
            }
        },
        "build_advanced_xlnet": {
            "name": "build_advanced_xlnet",
            "location": 167,
            "return": [
                "AdvancedXLNetClassifier"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_simple_xlnet": {
            "name": "build_simple_xlnet",
            "location": 210,
            "return": [
                "SimpleXLNetClassifier"
            ],
            "arguments": {
                "vocabulary": []
            }
        },
        "build_dcmn": {
            "name": "build_dcmn",
            "location": 219,
            "return": [
                "Dcmn"
            ],
            "arguments": {
                "vocabulary": []
            }
        },
        "build_rel_han": {
            "name": "build_rel_han",
            "location": 242,
            "return": [
                "RelationalHan"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_relational_transformer": {
            "name": "build_relational_transformer",
            "location": 341,
            "return": [
                "RelationalTransformerModel"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_hierarchical_attn_net": {
            "name": "build_hierarchical_attn_net",
            "location": 427,
            "return": [
                "HierarchicalAttentionNetwork"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_advanced_attn_bert": {
            "name": "build_advanced_attn_bert",
            "location": 499,
            "return": [
                "AdvancedAttentionBertClassifier"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_hierarchical_bert": {
            "name": "build_hierarchical_bert",
            "location": 554,
            "return": [
                "HierarchicalBert"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_zero_trian": {
            "name": "build_zero_trian",
            "location": 605,
            "return": [
                "ZeroTrian"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_simple_trian": {
            "name": "build_simple_trian",
            "location": 694,
            "return": [
                "SimpleTrian"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_advanced_bert": {
            "name": "build_advanced_bert",
            "location": 785,
            "return": [
                "AdvancedBertClassifier"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_simple_bert": {
            "name": "build_simple_bert",
            "location": 830,
            "return": [
                "SimpleBertClassifier"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_baseline": {
            "name": "build_baseline",
            "location": 846,
            "return": [
                "BaselineClassifier"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_attentive_reader": {
            "name": "build_attentive_reader",
            "location": 869,
            "return": [
                "AttentiveReader"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_trian": {
            "name": "build_trian",
            "location": 898,
            "return": [
                "Trian"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "create_reader": {
            "name": "create_reader",
            "location": 998,
            "return": [
                "SimpleMcScriptReader",
                "FullTrianReader",
                "SimpleBertReader",
                "SimpleTrianReader",
                "RelationBertReader",
                "SimpleXLNetReader",
                "RelationXLNetReader",
                "ExtendedXLNetReader",
                "SentenceReader"
            ],
            "arguments": {
                "reader_type": []
            }
        },
        "get_modelfn_reader": {
            "name": "get_modelfn_reader",
            "location": 1063,
            "return": [
                "tuple[]"
            ],
            "arguments": {}
        },
        "split_list": {
            "name": "split_list",
            "location": 1071,
            "return": [],
            "arguments": {
                "data": []
            }
        },
        "evaluate": {
            "name": "evaluate",
            "location": 1081,
            "return": [
                "None"
            ],
            "arguments": {
                "model": [],
                "reader": [],
                "test_data": []
            }
        },
        "print_dmn_instance": {
            "name": "print_dmn_instance",
            "location": 1111,
            "return": [
                "None"
            ],
            "arguments": {
                "instance": [],
                "prediction": []
            }
        },
        "print_base_instance": {
            "name": "print_base_instance",
            "location": 1124,
            "return": [
                "None"
            ],
            "arguments": {
                "instance": [],
                "prediction": []
            }
        },
        "process_dmn_list": {
            "name": "process_dmn_list",
            "location": 1137,
            "return": [
                "str"
            ],
            "arguments": {
                "fields": []
            }
        },
        "print_xlnet_instance": {
            "name": "print_xlnet_instance",
            "location": 1143,
            "return": [
                "None"
            ],
            "arguments": {
                "instance": [],
                "probability": []
            }
        },
        "process_bert_list": {
            "name": "process_bert_list",
            "location": 1168,
            "return": [
                "tuple[str]"
            ],
            "arguments": {
                "fields": []
            }
        },
        "print_bert_instance": {
            "name": "print_bert_instance",
            "location": 1181,
            "return": [
                "None"
            ],
            "arguments": {
                "instance": [],
                "prediction": []
            }
        },
        "error_analysis": {
            "name": "error_analysis",
            "location": 1195,
            "return": [
                "None"
            ],
            "arguments": {
                "model": [],
                "test_data": [],
                "sample_size": [
                    "int"
                ]
            }
        },
        "print_instance": {
            "name": "print_instance",
            "location": 1231,
            "return": [
                "None"
            ],
            "arguments": {
                "passage_id": [],
                "question_id": [],
                "question_type": [],
                "passage": [],
                "question": [],
                "answer1": [],
                "answer2": [],
                "probability": [],
                "label": []
            }
        },
        "print_xlnet_instance.clean": {
            "name": "clean",
            "location": 1146,
            "return": [],
            "arguments": {
                "string": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/conceptnet.py": {
        "triple_as_sentence": {
            "name": "triple_as_sentence",
            "location": 95,
            "return": [
                "typing.Text"
            ],
            "arguments": {
                "triple": [
                    "tuple[]",
                    "tuple[typing.Union[str,str,str]]",
                    "float"
                ]
            }
        },
        "ConceptNet.__init__": {
            "name": "__init__",
            "location": 19,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "conceptnet_path": [
                    "str",
                    "list[str]"
                ]
            }
        },
        "ConceptNet.get_relation": {
            "name": "get_relation",
            "location": 35,
            "return": [],
            "arguments": {
                "self": [],
                "word1": [
                    "str",
                    "dict[str, typing.Any]",
                    "None"
                ],
                "word2": [
                    "str",
                    "dict[str, typing.Any]",
                    "bool"
                ]
            }
        },
        "ConceptNet.get_all_text_query_triples": {
            "name": "get_all_text_query_triples",
            "location": 50,
            "return": [
                "set[tuple[typing.Union[typing.Type,float,int,list[int],dict[int, float],str]]]"
            ],
            "arguments": {
                "self": [],
                "text": [
                    "tuple[typing.Type]"
                ],
                "query": [
                    "tuple[typing.Type]"
                ]
            }
        },
        "ConceptNet.get_text_query_relations": {
            "name": "get_text_query_relations",
            "location": 73,
            "return": [
                "list[]"
            ],
            "arguments": {
                "self": [],
                "text": [],
                "query": [
                    "set[T]",
                    "list[dict[, ]]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/graph.py": {
        "main": {
            "name": "main",
            "location": 5,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "literate-lamp-master/literate_lamp/layers.py": {
        "learned_embeddings": {
            "name": "learned_embeddings",
            "location": 243,
            "return": [
                "BasicTextFieldEmbedder"
            ],
            "arguments": {
                "vocab": [],
                "dimension": [
                    "str",
                    "int"
                ],
                "namespace": [
                    "typing.Text"
                ]
            }
        },
        "bert_embeddings": {
            "name": "bert_embeddings",
            "location": 253,
            "return": [
                "BasicTextFieldEmbedder"
            ],
            "arguments": {
                "pretrained_model": [
                    "typing.IO",
                    "dict[, ]",
                    "set[]",
                    "bool",
                    "list[str]",
                    "str"
                ],
                "training": [
                    "bool"
                ],
                "top_layer_only": [
                    "bool"
                ]
            }
        },
        "xlnet_embeddings": {
            "name": "xlnet_embeddings",
            "location": 269,
            "return": [
                "BasicTextFieldEmbedder"
            ],
            "arguments": {
                "config_path": [
                    "str",
                    "bool",
                    "typing.Any",
                    "None"
                ],
                "model_path": [
                    "str",
                    "bool",
                    "typing.Any",
                    "None"
                ],
                "window_size": [
                    "None",
                    "str",
                    "bool",
                    "typing.Any"
                ],
                "training": [
                    "bool"
                ],
                "top_layer_only": [
                    "bool"
                ]
            }
        },
        "glove_embeddings": {
            "name": "glove_embeddings",
            "location": 289,
            "return": [
                "BasicTextFieldEmbedder"
            ],
            "arguments": {
                "vocab": [
                    "str"
                ],
                "file_path": [
                    "str"
                ],
                "dimension": [
                    "str"
                ],
                "training": [
                    "bool"
                ],
                "namespace": [
                    "typing.Text"
                ]
            }
        },
        "lstm_seq2seq": {
            "name": "lstm_seq2seq",
            "location": 303,
            "return": [
                "PytorchSeq2SeqWrapper"
            ],
            "arguments": {
                "input_dim": [
                    "int",
                    "float"
                ],
                "output_dim": [
                    "int",
                    "float"
                ],
                "num_layers": [
                    "int"
                ],
                "bidirectional": [
                    "bool"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "gru_seq2seq": {
            "name": "gru_seq2seq",
            "location": 315,
            "return": [
                "PytorchSeq2SeqWrapper"
            ],
            "arguments": {
                "input_dim": [
                    "int",
                    "float"
                ],
                "output_dim": [
                    "int",
                    "float"
                ],
                "num_layers": [
                    "int"
                ],
                "bidirectional": [
                    "bool"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "transformer_seq2seq": {
            "name": "transformer_seq2seq",
            "location": 327,
            "return": [
                "TransformerEncoder",
                "StackedSelfAttentionEncoder"
            ],
            "arguments": {
                "input_dim": [
                    "int",
                    "float",
                    "str"
                ],
                "model_dim": [
                    "int",
                    "float",
                    "str"
                ],
                "feedforward_hidden_dim": [
                    "int"
                ],
                "num_layers": [
                    "int"
                ],
                "projection_dim": [
                    "int"
                ],
                "num_attention_heads": [
                    "int"
                ],
                "ttype": [
                    "typing.Text"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "lstm_encoder": {
            "name": "lstm_encoder",
            "location": 358,
            "return": [
                "PytorchSeq2VecWrapper"
            ],
            "arguments": {
                "input_dim": [
                    "int",
                    "float"
                ],
                "output_dim": [
                    "int",
                    "float"
                ],
                "num_layers": [
                    "int"
                ],
                "bidirectional": [
                    "bool"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "gru_encoder": {
            "name": "gru_encoder",
            "location": 370,
            "return": [
                "PytorchSeq2VecWrapper"
            ],
            "arguments": {
                "input_dim": [
                    "int",
                    "float"
                ],
                "output_dim": [
                    "int",
                    "float"
                ],
                "num_layers": [
                    "int"
                ],
                "bidirectional": [
                    "bool"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "cnn_encoder": {
            "name": "cnn_encoder",
            "location": 382,
            "return": [
                "CnnEncoder"
            ],
            "arguments": {
                "input_dim": [
                    "int",
                    "tuple[int]",
                    "None"
                ],
                "output_dim": [
                    "int",
                    "tuple[int]",
                    "None"
                ],
                "num_filters": [
                    "int",
                    "tuple[int]",
                    "None"
                ],
                "ngram_filter_sizes": [
                    "tuple[int]"
                ]
            }
        },
        "BilinearMatrixAttention.__init__": {
            "name": "__init__",
            "location": 52,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "matrix1_dim": [
                    "int",
                    "float"
                ],
                "matrix2_dim": [
                    "int",
                    "float"
                ],
                "normalise": [
                    "bool"
                ]
            }
        },
        "BilinearMatrixAttention._forward_internal": {
            "name": "_forward_internal",
            "location": 61,
            "return": [],
            "arguments": {
                "self": [],
                "matrix1": [
                    "int",
                    "typing.Callable[, ]",
                    "str"
                ],
                "matrix2": [
                    "int",
                    "typing.Callable[, ]",
                    "str"
                ]
            }
        },
        "LinearAttention.__init__": {
            "name": "__init__",
            "location": 78,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [
                    "int",
                    "float"
                ],
                "bias": [
                    "bool"
                ]
            }
        },
        "LinearAttention.forward": {
            "name": "forward",
            "location": 85,
            "return": [],
            "arguments": {
                "self": [],
                "inputs": [
                    "float",
                    "str",
                    "None"
                ],
                "mask": [
                    "None",
                    "int",
                    "float"
                ]
            }
        },
        "LinearAttention.get_input_dim": {
            "name": "get_input_dim",
            "location": 116,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "LinearAttention.get_output_dim": {
            "name": "get_output_dim",
            "location": 120,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "LinearSelfAttention.__init__": {
            "name": "__init__",
            "location": 147,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [
                    "int",
                    "float"
                ],
                "normalise": [
                    "bool"
                ],
                "bias": [
                    "bool"
                ]
            }
        },
        "LinearSelfAttention._forward_internal": {
            "name": "_forward_internal",
            "location": 157,
            "return": [
                "int",
                "tuple[typing.Union[typing.Literal,typing.Literal,typing.Literal,typing.Literal,typing.Literal,typing.Literal,typing.Literal,typing.Literal,typing.Literal,typing.Literal,typing.Literal,typing.Literal,typing.Literal]]",
                "typing.Type"
            ],
            "arguments": {
                "self": [],
                "vector": [
                    "int",
                    "typing.Callable[, ]",
                    "str"
                ],
                "_": [
                    "int",
                    "str",
                    "typing.Iterable[C]"
                ]
            }
        },
        "BilinearAttention.__init__": {
            "name": "__init__",
            "location": 186,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vector_dim": [
                    "int",
                    "float"
                ],
                "matrix_dim": [
                    "int",
                    "float"
                ],
                "normalise": [
                    "bool"
                ]
            }
        },
        "BilinearAttention._forward_internal": {
            "name": "_forward_internal",
            "location": 195,
            "return": [
                "int",
                "dict[, ]",
                "list[int]",
                "list[list[int]]",
                "str"
            ],
            "arguments": {
                "self": [],
                "vector": [
                    "int",
                    "typing.Callable[, ]",
                    "str"
                ],
                "matrix": [
                    "int",
                    "typing.Callable[, ]",
                    "str"
                ]
            }
        },
        "SequenceAttention.__init__": {
            "name": "__init__",
            "location": 225,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [
                    "int",
                    "float"
                ],
                "activation": [
                    "None",
                    "bool",
                    "str"
                ],
                "normalise": [
                    "bool"
                ]
            }
        },
        "SequenceAttention._forward_internal": {
            "name": "_forward_internal",
            "location": 235,
            "return": [],
            "arguments": {
                "self": [],
                "u": [
                    "int"
                ],
                "v": [
                    "int"
                ]
            }
        },
        "MultiHeadAttention.__init__": {
            "name": "__init__",
            "location": 430,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_heads": [
                    "int",
                    "float"
                ],
                "query_input_dim": [
                    "dict[, ]",
                    "None",
                    "list[C]",
                    "bool"
                ],
                "key_input_dim": [
                    "list[str]",
                    "str",
                    "None",
                    "dict[str, list[str]]"
                ],
                "value_input_dim": [
                    "int",
                    "float",
                    "None"
                ],
                "attention_dim": [
                    "int",
                    "float"
                ],
                "values_dim": [
                    "float",
                    "int"
                ],
                "output_projection_dim": [
                    "int",
                    "str",
                    "float",
                    "None"
                ],
                "attention_dropout_prob": [
                    "float"
                ]
            }
        },
        "MultiHeadAttention.get_input_dim": {
            "name": "get_input_dim",
            "location": 471,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "MultiHeadAttention.get_output_dim": {
            "name": "get_output_dim",
            "location": 474,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "MultiHeadAttention.is_bidirectional": {
            "name": "is_bidirectional",
            "location": 478,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultiHeadAttention.forward": {
            "name": "forward",
            "location": 482,
            "return": [],
            "arguments": {
                "self": [],
                "keys": [
                    "typing.Sequence[typing.Any]",
                    "float",
                    "str",
                    "list[]"
                ],
                "queries": [
                    "int",
                    "float",
                    "str",
                    "dict[str, torch.LongTensor]"
                ],
                "values": [
                    "bytes",
                    "int",
                    "dict[str, str]"
                ],
                "mask": [
                    "None",
                    "str",
                    "bytes",
                    "typing.Sequence[typing.Any]",
                    "list[set[int]]"
                ]
            }
        },
        "HeterogenousSequenceAttention.__init__": {
            "name": "__init__",
            "location": 597,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "u_input_dim": [
                    "int",
                    "typing.Callable[, ]"
                ],
                "v_input_dim": [
                    "int",
                    "typing.Callable[, ]"
                ],
                "projection_dim": [
                    "str",
                    "None",
                    "float",
                    "set[str]"
                ],
                "activation": [
                    "None",
                    "str",
                    "bool",
                    "tuple[typing.Union[float,float]]",
                    "float"
                ]
            }
        },
        "HeterogenousSequenceAttention.get_input_dim": {
            "name": "get_input_dim",
            "location": 612,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "HeterogenousSequenceAttention.get_output_dim": {
            "name": "get_output_dim",
            "location": 615,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "HeterogenousSequenceAttention.is_bidirectional": {
            "name": "is_bidirectional",
            "location": 619,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "HeterogenousSequenceAttention.forward": {
            "name": "forward",
            "location": 623,
            "return": [],
            "arguments": {
                "self": [],
                "u": [],
                "v": [],
                "v_mask": [
                    "tuple[typing.Union[int,int]]",
                    "str",
                    "None"
                ]
            }
        },
        "MultiHeadAttentionV2.__init__": {
            "name": "__init__",
            "location": 668,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_heads": [
                    "int"
                ],
                "u_input_dim": [
                    "dict[str, int]",
                    "bool",
                    "str"
                ],
                "v_input_dim": [
                    "int",
                    "float",
                    "str"
                ],
                "attention_dim": [
                    "int",
                    "float"
                ],
                "output_projection_dim": [
                    "int",
                    "dict[int, int]",
                    "float"
                ],
                "attention_dropout_prob": [
                    "float"
                ]
            }
        },
        "MultiHeadAttentionV2.get_input_dim": {
            "name": "get_input_dim",
            "location": 696,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "MultiHeadAttentionV2.get_output_dim": {
            "name": "get_output_dim",
            "location": 699,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "MultiHeadAttentionV2.is_bidirectional": {
            "name": "is_bidirectional",
            "location": 703,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultiHeadAttentionV2._reshape_outputs": {
            "name": "_reshape_outputs",
            "location": 706,
            "return": [],
            "arguments": {
                "self": [],
                "outputs": [
                    "bytes",
                    "str"
                ]
            }
        },
        "MultiHeadAttentionV2._reshape_heads": {
            "name": "_reshape_heads",
            "location": 724,
            "return": [],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "MultiHeadAttentionV2._multiply_and_mask": {
            "name": "_multiply_and_mask",
            "location": 737,
            "return": [],
            "arguments": {
                "self": [],
                "q": [
                    "str",
                    "typing.Callable[T, None]",
                    "int",
                    "dict[str, typing.Any]"
                ],
                "k": [],
                "k_mask": [
                    "int"
                ]
            }
        },
        "MultiHeadAttentionV2.forward": {
            "name": "forward",
            "location": 754,
            "return": [
                "tuple[]"
            ],
            "arguments": {
                "self": [],
                "u": [],
                "v": [],
                "u_mask": [
                    "None",
                    "int",
                    "dict[, ]",
                    "str",
                    "typing.Callable[, ]"
                ],
                "v_mask": [
                    "None",
                    "bool",
                    "dict[str, str]",
                    "dict[, ]"
                ]
            }
        },
        "TransformerEncoderBlock.__init__": {
            "name": "__init__",
            "location": 826,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "model_dim": [
                    "int",
                    "tuple[typing.Union[int,int]]",
                    "float"
                ],
                "attention_dim": [
                    "int",
                    "tuple[typing.Union[int,int]]",
                    "float"
                ],
                "num_heads": [
                    "int",
                    "tuple[typing.Union[int,int]]",
                    "float"
                ],
                "feedforward_dim": [
                    "float",
                    "None",
                    "int"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "TransformerEncoderBlock.forward": {
            "name": "forward",
            "location": 856,
            "return": [
                "list[]",
                "int",
                "list[int]",
                "str"
            ],
            "arguments": {
                "self": [],
                "src": [
                    "str"
                ],
                "src_mask": [
                    "str",
                    "dict[, ]",
                    "int"
                ]
            }
        },
        "RelationTransformerEncoderBlock.__init__": {
            "name": "__init__",
            "location": 871,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "model_dim": [
                    "tuple[typing.Union[int,int]]",
                    "int",
                    "float"
                ],
                "attention_dim": [
                    "tuple[typing.Union[int,int]]",
                    "int",
                    "float"
                ],
                "num_heads": [
                    "tuple[typing.Union[int,int]]",
                    "int",
                    "float"
                ],
                "feedforward_dim": [
                    "float",
                    "None",
                    "int"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "RelationTransformerEncoderBlock._second_stage": {
            "name": "_second_stage",
            "location": 899,
            "return": [
                "list[]",
                "int",
                "list[int]",
                "str"
            ],
            "arguments": {
                "self": [],
                "x": [
                    "float"
                ],
                "attn": [
                    "int",
                    "float"
                ]
            }
        },
        "RelationTransformerEncoderBlock.forward": {
            "name": "forward",
            "location": 909,
            "return": [
                "tuple[typing.Union[str,int,float,None,dict[, ],list[],list[list[str]]]]"
            ],
            "arguments": {
                "self": [],
                "src": [
                    "float",
                    "int"
                ],
                "aux": [
                    "float",
                    "typing.IO",
                    "str",
                    "int"
                ],
                "src_mask": [
                    "float",
                    "str"
                ],
                "aux_mask": [
                    "float",
                    "str"
                ]
            }
        },
        "TransformerEncoder.__init__": {
            "name": "__init__",
            "location": 958,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [
                    "int",
                    "float"
                ],
                "model_dim": [
                    "list[str]",
                    "None",
                    "str",
                    "dict[str, int]"
                ],
                "feedforward_hidden_dim": [
                    "int",
                    "float",
                    "typing.Callable[, ]"
                ],
                "num_layers": [
                    "int",
                    "float",
                    "str"
                ],
                "num_attention_heads": [
                    "int",
                    "float",
                    "typing.Callable[, ]"
                ],
                "dropout_prob": [
                    "float"
                ]
            }
        },
        "TransformerEncoder._reset_parameters": {
            "name": "_reset_parameters",
            "location": 984,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "TransformerEncoder.get_input_dim": {
            "name": "get_input_dim",
            "location": 990,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TransformerEncoder.get_output_dim": {
            "name": "get_output_dim",
            "location": 994,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TransformerEncoder.is_bidirectional": {
            "name": "is_bidirectional",
            "location": 998,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "TransformerEncoder.forward": {
            "name": "forward",
            "location": 1002,
            "return": [
                "str",
                "list[pathlib.Path]",
                "dict[, ]"
            ],
            "arguments": {
                "self": [],
                "inputs": [
                    "int"
                ],
                "mask": [
                    "None",
                    "int",
                    "typing.Callable[str, bool]",
                    "float"
                ]
            }
        },
        "RelationalTransformerEncoder.__init__": {
            "name": "__init__",
            "location": 1057,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "src_input_dim": [
                    "bytes",
                    "int",
                    "dict[, ]",
                    "dict[str, typing.Any]",
                    "tuple[]"
                ],
                "kb_input_dim": [
                    "int",
                    "typing.Iterator",
                    "None",
                    "str",
                    "float",
                    "tuple[int]"
                ],
                "model_dim": [
                    "str",
                    "bool",
                    "typing.IO",
                    "bytes"
                ],
                "feedforward_hidden_dim": [
                    "int",
                    "float"
                ],
                "num_layers": [
                    "int",
                    "str",
                    "float"
                ],
                "num_attention_heads": [
                    "int",
                    "float"
                ],
                "dropout_prob": [
                    "float"
                ],
                "return_kb": [
                    "bool"
                ]
            }
        },
        "RelationalTransformerEncoder._reset_parameters": {
            "name": "_reset_parameters",
            "location": 1099,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "RelationalTransformerEncoder.get_input_dim": {
            "name": "get_input_dim",
            "location": 1105,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "RelationalTransformerEncoder.get_output_dim": {
            "name": "get_output_dim",
            "location": 1109,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "RelationalTransformerEncoder.is_bidirectional": {
            "name": "is_bidirectional",
            "location": 1113,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "RelationalTransformerEncoder.forward": {
            "name": "forward",
            "location": 1117,
            "return": [
                "tuple[typing.Union[dict[str, typing.Any],str,dict[int, str],int,tuple[]]]",
                "dict[str, typing.Any]"
            ],
            "arguments": {
                "self": [],
                "src": [
                    "str",
                    "None"
                ],
                "kb": [
                    "float",
                    "int"
                ],
                "src_mask": [
                    "None",
                    "int",
                    "str"
                ],
                "kb_mask": [
                    "None",
                    "int"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/play.py": {
        "main": {
            "name": "main",
            "location": 15,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "literate-lamp-master/literate_lamp/predictor.py": {
        "score_questions": {
            "name": "score_questions",
            "location": 58,
            "return": [],
            "arguments": {
                "model": [
                    "str"
                ],
                "output_file": [
                    "typing.TextIO",
                    "str",
                    "list[str]",
                    "int",
                    "None"
                ],
                "testset": []
            }
        },
        "McScriptPredictor.predict": {
            "name": "predict",
            "location": 19,
            "return": [],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str",
                    "None",
                    "bool"
                ],
                "question_id": [
                    "str",
                    "None",
                    "bool"
                ],
                "question_type": [
                    "str",
                    "None",
                    "bool"
                ],
                "passage": [
                    "str",
                    "None",
                    "bool"
                ],
                "question": [
                    "str",
                    "None",
                    "bool"
                ],
                "answer0": [
                    "str",
                    "None",
                    "bool"
                ],
                "answer1": [
                    "str",
                    "None",
                    "bool"
                ]
            }
        },
        "McScriptPredictor._json_to_instance": {
            "name": "_json_to_instance",
            "location": 43,
            "return": [],
            "arguments": {
                "self": [],
                "json_dict": [
                    "str"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/preprocess.py": {
        "clean_word": {
            "name": "clean_word",
            "location": 8,
            "return": [
                "tuple[str]"
            ],
            "arguments": {
                "string": [
                    "str"
                ]
            }
        },
        "process_file": {
            "name": "process_file",
            "location": 16,
            "return": [
                "None"
            ],
            "arguments": {
                "input_file": [
                    "str"
                ],
                "output_file": [
                    "typing.TextIO",
                    "str"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/stats.py": {
        "flatten": {
            "name": "flatten",
            "location": 18,
            "return": [
                "list[typing.Text]"
            ],
            "arguments": {
                "l": [
                    "dict[str, set[str]]",
                    "list[list[str]]"
                ]
            }
        },
        "extract_field": {
            "name": "extract_field",
            "location": 70,
            "return": [
                "list[list[]]"
            ],
            "arguments": {
                "field": [],
                "instances": [
                    "str"
                ]
            }
        },
        "main": {
            "name": "main",
            "location": 81,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "TextStats.__init__": {
            "name": "__init__",
            "location": 30,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "instance_texts": []
            }
        },
        "TextStats.__repr__": {
            "name": "__repr__",
            "location": 37,
            "return": [
                "typing.Text"
            ],
            "arguments": {
                "self": []
            }
        },
        "DatasetStats.__init__": {
            "name": "__init__",
            "location": 48,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "instances": [
                    "str",
                    "bool"
                ]
            }
        },
        "DatasetStats.__repr__": {
            "name": "__repr__",
            "location": 61,
            "return": [
                "typing.Text"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/train.py": {
        "make_prediction": {
            "name": "make_prediction",
            "location": 36,
            "return": [],
            "arguments": {
                "model": [],
                "reader": [
                    "int",
                    "typing.Type",
                    "set[int]"
                ],
                "verbose": [
                    "bool"
                ]
            }
        },
        "test_load": {
            "name": "test_load",
            "location": 61,
            "return": [
                "None"
            ],
            "arguments": {
                "build_model_fn": [
                    "typing.MutableMapping",
                    "tuple[]",
                    "str",
                    "list[dict[, ]]"
                ],
                "reader": [
                    "typing.Mapping",
                    "dict[str, typing.Any]"
                ],
                "save_path": [
                    "int"
                ],
                "original_prediction": [
                    "str",
                    "list[int]"
                ],
                "cuda_device": [
                    "int"
                ]
            }
        },
        "run_model": {
            "name": "run_model",
            "location": 99,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "run_model.optimiser": {
            "name": "optimiser",
            "location": 109,
            "return": [
                "AdamW"
            ],
            "arguments": {
                "model": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/util.py": {
        "visualise_model": {
            "name": "visualise_model",
            "location": 77,
            "return": [
                "None"
            ],
            "arguments": {
                "model": []
            }
        },
        "example_input": {
            "name": "example_input",
            "location": 90,
            "return": [
                "tuple[]"
            ],
            "arguments": {
                "index": [
                    "int"
                ]
            }
        },
        "is_cuda": {
            "name": "is_cuda",
            "location": 103,
            "return": [
                "bool"
            ],
            "arguments": {
                "model": []
            }
        },
        "train_val_test_split": {
            "name": "train_val_test_split",
            "location": 108,
            "return": [
                "tuple[]"
            ],
            "arguments": {
                "dataset": [],
                "train_size": []
            }
        },
        "load_data": {
            "name": "load_data",
            "location": 128,
            "return": [
                "list[allennlp.data.Instance]",
                "list[T]",
                "list[]",
                "list[bytes]"
            ],
            "arguments": {
                "reader": [
                    "None",
                    "str",
                    "typing.TextIO",
                    "list[str]"
                ],
                "data_path": [
                    "None",
                    "str",
                    "typing.TextIO"
                ],
                "pre_processed_path": []
            }
        },
        "train_model": {
            "name": "train_model",
            "location": 168,
            "return": [],
            "arguments": {
                "build_model_fn": [
                    "dict[str, typing.Any]",
                    "set[str]",
                    "tuple[]",
                    "bool",
                    "list[dict[, ]]"
                ],
                "train_data": [],
                "val_data": [],
                "test_data": [],
                "save_path": [
                    "None"
                ],
                "batch_size": [
                    "int"
                ],
                "num_epochs": [
                    "int"
                ],
                "optimiser_fn": [
                    "None",
                    "typing.Iterable[str]",
                    "str",
                    "typing.Callable[, ]",
                    "typing.Any"
                ],
                "grad_norm_clip": [
                    "float"
                ],
                "sorting_keys": [
                    "None",
                    "int",
                    "dict[, ]",
                    "bytes",
                    "tuple[typing.Union[pathlib.Path,C,int]]",
                    "str"
                ],
                "cuda_device": [
                    "int"
                ]
            }
        },
        "get_preprocessed_name": {
            "name": "get_preprocessed_name",
            "location": 270,
            "return": [
                "typing.Text"
            ],
            "arguments": {
                "split_name": [
                    "dict[str, typing.Any]",
                    "dict[, ]",
                    "None"
                ],
                "model": [
                    "dict[str, typing.Any]",
                    "dict[, ]",
                    "None"
                ],
                "config": [
                    "dict[str, typing.Any]",
                    "dict[, ]",
                    "None"
                ],
                "embedding": [
                    "dict[str, typing.Any]",
                    "dict[, ]",
                    "None"
                ]
            }
        },
        "get_experiment_name": {
            "name": "get_experiment_name",
            "location": 276,
            "return": [
                "typing.Text"
            ],
            "arguments": {
                "model": [
                    "str",
                    "dict[, ]"
                ],
                "config": [
                    "str",
                    "dict[, ]"
                ],
                "embedding": [
                    "str",
                    "dict[, ]"
                ],
                "name": [
                    "str",
                    "None",
                    "float",
                    "dict[str, typing.Any]",
                    "list[str]"
                ]
            }
        },
        "is_stopword": {
            "name": "is_stopword",
            "location": 290,
            "return": [
                "bool"
            ],
            "arguments": {
                "word": [
                    "str"
                ]
            }
        },
        "is_punctuation": {
            "name": "is_punctuation",
            "location": 299,
            "return": [
                "bool"
            ],
            "arguments": {
                "word": [
                    "str",
                    "typing.Type"
                ]
            }
        },
        "get_term_frequency": {
            "name": "get_term_frequency",
            "location": 306,
            "return": [],
            "arguments": {
                "word": [
                    "str",
                    "dict[, ]",
                    "int",
                    "bytes"
                ]
            }
        },
        "clone_module": {
            "name": "clone_module",
            "location": 323,
            "return": [],
            "arguments": {
                "module": [
                    "int",
                    "str",
                    "None",
                    "typing.Callable[, ]",
                    "list[tuple[typing.Union[int,int]]]"
                ],
                "num_clones": [
                    "int",
                    "str",
                    "None",
                    "typing.Callable[, ]",
                    "list[tuple[typing.Union[int,int]]]"
                ]
            }
        },
        "parse_cuda": {
            "name": "parse_cuda",
            "location": 331,
            "return": [
                "list[int]",
                "int"
            ],
            "arguments": {
                "cuda_str": []
            }
        },
        "tf2str": {
            "name": "tf2str",
            "location": 341,
            "return": [
                "str"
            ],
            "arguments": {
                "field": [
                    "str"
                ]
            }
        },
        "split_list": {
            "name": "split_list",
            "location": 350,
            "return": [
                "list[]"
            ],
            "arguments": {
                "list": [
                    "list[T]",
                    "list[str]",
                    "str",
                    "list[int]"
                ],
                "element": []
            }
        },
        "print_args": {
            "name": "print_args",
            "location": 364,
            "return": [
                "None"
            ],
            "arguments": {
                "args": []
            }
        },
        "DotDict.__init__": {
            "name": "__init__",
            "location": 47,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DotDict.__getattr__": {
            "name": "__getattr__",
            "location": 59,
            "return": [],
            "arguments": {
                "self": [],
                "attr": [
                    "str",
                    "list[]",
                    "list[T]"
                ]
            }
        },
        "DotDict.__setattr__": {
            "name": "__setattr__",
            "location": 62,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "key": [
                    "str"
                ],
                "value": [
                    "str"
                ]
            }
        },
        "DotDict.__setitem__": {
            "name": "__setitem__",
            "location": 65,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "key": [
                    "str",
                    "set[]",
                    "bool",
                    "dict[str, typing.Any]"
                ],
                "value": [
                    "str",
                    "set[]",
                    "bool",
                    "dict[str, typing.Any]"
                ]
            }
        },
        "DotDict.__delattr__": {
            "name": "__delattr__",
            "location": 69,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "key": [
                    "str",
                    "None",
                    "tuple[]",
                    "dict[str, str]",
                    "int",
                    "typing.Callable[T, T]",
                    "typing.Type"
                ]
            }
        },
        "DotDict.__delitem__": {
            "name": "__delitem__",
            "location": 72,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "key": [
                    "str"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/__init__.py": {},
    "literate-lamp-master/literate_lamp/models/advanced_attention_bert.py": {
        "AdvancedAttentionBertClassifier.__init__": {
            "name": "__init__",
            "location": 23,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "bert_path": [
                    "str",
                    "dict[str, typing.Any]",
                    "typing.Callable[typing.Any, None]",
                    "None"
                ],
                "encoder": [
                    "str",
                    "bool",
                    "None"
                ],
                "vocab": [
                    "str",
                    "list[str]",
                    "None"
                ],
                "hidden_dim": [
                    "int"
                ],
                "encoder_dropout": [
                    "float"
                ],
                "train_bert": [
                    "bool"
                ]
            }
        },
        "AdvancedAttentionBertClassifier.forward": {
            "name": "forward",
            "location": 61,
            "return": [
                "dict[typing.Text, ]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "bool",
                    "typing.Mapping"
                ],
                "bert0": [
                    "int",
                    "list[str]",
                    "list[int]",
                    "str",
                    "typing.Collection",
                    "list[tuple[typing.Union[str,str]]]",
                    "typing.Sequence[T]"
                ],
                "bert1": [
                    "int",
                    "list[str]",
                    "list[int]",
                    "str",
                    "typing.Collection",
                    "list[tuple[typing.Union[str,str]]]",
                    "typing.Sequence[T]"
                ],
                "label": [
                    "None",
                    "str",
                    "list[str]",
                    "bytes",
                    "float",
                    "bool"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/advanced_bert.py": {
        "AdvancedBertClassifier.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "bert_path": [
                    "str",
                    "dict[str, typing.Any]",
                    "typing.Callable[typing.Any, None]",
                    "None"
                ],
                "encoder": [],
                "vocab": [
                    "str",
                    "list[str]",
                    "None"
                ],
                "hidden_dim": [
                    "int"
                ],
                "encoder_dropout": [
                    "float"
                ],
                "train_bert": [
                    "bool"
                ]
            }
        },
        "AdvancedBertClassifier.forward": {
            "name": "forward",
            "location": 55,
            "return": [
                "dict[typing.Text, ]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "bool",
                    "typing.Mapping"
                ],
                "bert0": [
                    "int",
                    "list[str]",
                    "list[int]",
                    "str",
                    "typing.Collection",
                    "list[tuple[typing.Union[str,str]]]",
                    "typing.Sequence[T]"
                ],
                "bert1": [
                    "int",
                    "list[str]",
                    "list[int]",
                    "str",
                    "typing.Collection",
                    "list[tuple[typing.Union[str,str]]]",
                    "typing.Sequence[T]"
                ],
                "label": [
                    "None",
                    "str",
                    "list[str]",
                    "bytes",
                    "float",
                    "bool"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/advanced_xlnet.py": {
        "AdvancedXLNetClassifier.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vocab": [
                    "bool",
                    "dict[str, typing.Any]",
                    "typing.Callable[A, bool]"
                ],
                "word_embeddings": [
                    "int",
                    "float",
                    "list[allennlp.data.Instance]"
                ],
                "encoder": [
                    "int",
                    "str"
                ],
                "encoder_dropout": [
                    "float"
                ],
                "train_xlnet": [
                    "bool"
                ]
            }
        },
        "AdvancedXLNetClassifier.forward": {
            "name": "forward",
            "location": 45,
            "return": [
                "dict[typing.Text, ]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "str",
                    "typing.Callable[[], bool]",
                    "bool"
                ],
                "string0": [
                    "str",
                    "typing.Callable[, ]",
                    "None",
                    "tuple[typing.Union[str,str]]"
                ],
                "string1": [
                    "str",
                    "typing.Callable[, ]",
                    "None",
                    "tuple[typing.Union[str,str]]"
                ],
                "label": [
                    "None",
                    "str",
                    "dict[str, str]",
                    "bool"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/attentive_reader.py": {
        "AttentiveReader.__init__": {
            "name": "__init__",
            "location": 35,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "float",
                    "int",
                    "list[float]",
                    "typing.Type"
                ],
                "p_encoder": [
                    "bool",
                    "typing.Type",
                    "typing.Mapping",
                    "None"
                ],
                "q_encoder": [
                    "float",
                    "str"
                ],
                "a_encoder": [
                    "typing.Mapping"
                ],
                "vocab": [
                    "str",
                    "int",
                    "tuple[typing.Union[int,int]]"
                ]
            }
        },
        "AttentiveReader.forward": {
            "name": "forward",
            "location": 67,
            "return": [
                "dict[typing.Text, ]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "int",
                    "str",
                    "typing.Any"
                ],
                "passage": [
                    "str",
                    "None"
                ],
                "question": [
                    "int",
                    "list[]"
                ],
                "answer0": [
                    "bytes",
                    "bool",
                    "typing.Type",
                    "None",
                    "str"
                ],
                "answer1": [
                    "bytes",
                    "bool",
                    "typing.Type",
                    "None",
                    "str"
                ],
                "label": [
                    "None",
                    "set[int]",
                    "str"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/baseline.py": {
        "BaselineClassifier.__init__": {
            "name": "__init__",
            "location": 27,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "int",
                    "float",
                    "list[allennlp.data.Instance]"
                ],
                "encoder": [
                    "int",
                    "float"
                ],
                "vocab": []
            }
        },
        "BaselineClassifier.forward": {
            "name": "forward",
            "location": 58,
            "return": [
                "dict[typing.Text, ]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "int",
                    "str",
                    "typing.Any"
                ],
                "passage": [
                    "str",
                    "dict[str, typing.Any]",
                    "None",
                    "int"
                ],
                "question": [
                    "int"
                ],
                "answer0": [
                    "int",
                    "dict[str, typing.Any]",
                    "None"
                ],
                "answer1": [
                    "int",
                    "dict[str, typing.Any]",
                    "None"
                ],
                "label": [
                    "None",
                    "set[int]",
                    "str"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/base_model.py": {
        "BaseModel.__init__": {
            "name": "__init__",
            "location": 17,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vocab": [
                    "bool",
                    "dict[str, typing.Any]",
                    "typing.Callable[Any,Any, bool]"
                ]
            }
        },
        "BaseModel.get_metrics": {
            "name": "get_metrics",
            "location": 29,
            "return": [
                "dict[typing.Text, ]"
            ],
            "arguments": {
                "self": [],
                "reset": [
                    "bool"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dcmn.py": {
        "Dcmn.__init__": {
            "name": "__init__",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [],
                "vocab": [
                    "bool",
                    "dict[str, typing.Any]",
                    "typing.Callable[Any,Any, bool]"
                ],
                "embedding_dropout": [
                    "float"
                ]
            }
        },
        "Dcmn._forward_internal": {
            "name": "_forward_internal",
            "location": 55,
            "return": [
                "str",
                "int",
                "dict[str, typing.Any]",
                "dict[str, float]",
                "dict[int, str]",
                "typing.Pattern"
            ],
            "arguments": {
                "self": [],
                "passage": [
                    "int",
                    "bytes"
                ],
                "question": [
                    "int",
                    "bytes"
                ],
                "answer": [
                    "int",
                    "bytearray"
                ]
            }
        },
        "Dcmn.forward": {
            "name": "forward",
            "location": 107,
            "return": [
                "dict[typing.Text, ]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "int",
                    "str",
                    "typing.Any"
                ],
                "passage": [
                    "str",
                    "bool"
                ],
                "question": [
                    "str",
                    "bool"
                ],
                "answer0": [
                    "bool",
                    "dict[str, typing.Any]",
                    "None",
                    "typing.Sequence[str]",
                    "typing.Mapping"
                ],
                "answer1": [
                    "bool",
                    "dict[str, typing.Any]",
                    "None",
                    "typing.Sequence[str]",
                    "typing.Mapping"
                ],
                "label": [
                    "None",
                    "set[int]",
                    "str"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/hierarchical_attention_network.py": {
        "HierarchicalAttentionNetwork.__init__": {
            "name": "__init__",
            "location": 24,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "int",
                    "float",
                    "list[allennlp.data.Instance]"
                ],
                "sentence_encoder": [
                    "str"
                ],
                "document_encoder": [],
                "vocab": [
                    "bool",
                    "dict[str, typing.Any]",
                    "typing.Callable[Any,Any, bool]"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "HierarchicalAttentionNetwork.forward": {
            "name": "forward",
            "location": 63,
            "return": [
                "dict[typing.Text, ]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "bool",
                    "typing.Mapping"
                ],
                "bert0": [],
                "bert1": [],
                "label": [
                    "None",
                    "str",
                    "list[str]",
                    "bytes",
                    "float",
                    "bool"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/hierarchical_bert.py": {
        "HierarchicalBert.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "bert_path": [
                    "str",
                    "typing.Callable[typing.Any, None]",
                    "None",
                    "dict[str, typing.Any]"
                ],
                "sentence_encoder": [
                    "dict[, ]",
                    "bool"
                ],
                "document_encoder": [],
                "vocab": [
                    "str",
                    "list[str]",
                    "None"
                ],
                "encoder_dropout": [
                    "float"
                ],
                "train_bert": [
                    "bool"
                ]
            }
        },
        "HierarchicalBert.forward": {
            "name": "forward",
            "location": 50,
            "return": [
                "dict[typing.Text, ]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "bool",
                    "typing.Mapping"
                ],
                "bert0": [
                    "bool",
                    "list[]",
                    "str"
                ],
                "bert1": [
                    "bool",
                    "list[]",
                    "str"
                ],
                "label": [
                    "None",
                    "str",
                    "list[str]",
                    "bytes",
                    "float",
                    "bool"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/relational_han.py": {
        "RelationalHan.__init__": {
            "name": "__init__",
            "location": 26,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "int",
                    "float",
                    "list[allennlp.data.Instance]"
                ],
                "sentence_encoder": [
                    "float"
                ],
                "document_encoder": [],
                "relation_encoder": [
                    "float"
                ],
                "document_relation_encoder": [
                    "int",
                    "dict[str, typing.Any]",
                    "str"
                ],
                "vocab": [
                    "bool",
                    "dict[str, typing.Any]",
                    "typing.Callable[Any,Any, bool]"
                ],
                "encoder_dropout": [
                    "float"
                ],
                "ffn_dropout": [
                    "float"
                ]
            }
        },
        "RelationalHan._forward_internal": {
            "name": "_forward_internal",
            "location": 76,
            "return": [],
            "arguments": {
                "self": [],
                "bert": [
                    "int",
                    "list[int]",
                    "None"
                ],
                "relations": [
                    "int",
                    "str",
                    "typing.Iterable['Context']"
                ]
            }
        },
        "RelationalHan.forward": {
            "name": "forward",
            "location": 103,
            "return": [
                "dict[typing.Text, ]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "bool"
                ],
                "bert0": [
                    "dict[str, torch.Tensor]",
                    "bool",
                    "None",
                    "str"
                ],
                "bert1": [
                    "dict[str, torch.Tensor]",
                    "bool",
                    "None",
                    "str"
                ],
                "p_a0_rel": [
                    "dict[str, torch.Tensor]",
                    "bool",
                    "None",
                    "str"
                ],
                "p_a1_rel": [
                    "dict[str, torch.Tensor]",
                    "bool",
                    "None",
                    "str"
                ],
                "label": [
                    "None",
                    "str",
                    "int",
                    "typing.Callable[str, bool]",
                    "typing.Sequence[typing.Any]",
                    "float"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/relational_transformer_model.py": {
        "RelationalTransformerModel.__init__": {
            "name": "__init__",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "int",
                    "float",
                    "list[allennlp.data.Instance]"
                ],
                "sentence_encoder": [
                    "float"
                ],
                "relation_sentence_encoder": [
                    "int",
                    "float"
                ],
                "relational_encoder": [
                    "bool"
                ],
                "rel_embeddings": [
                    "int",
                    "float"
                ],
                "vocab": [
                    "bool",
                    "dict[str, typing.Any]",
                    "typing.Callable[Any,Any, bool]"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "RelationalTransformerModel.forward": {
            "name": "forward",
            "location": 64,
            "return": [
                "dict[typing.Text, ]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "bool"
                ],
                "bert0": [
                    "float",
                    "int",
                    "None",
                    "dict[str, torch.LongTensor]"
                ],
                "bert1": [
                    "float",
                    "int",
                    "None",
                    "dict[str, torch.LongTensor]"
                ],
                "p_a0_rel": [
                    "int",
                    "None",
                    "float"
                ],
                "p_a1_rel": [
                    "int",
                    "None",
                    "float"
                ],
                "label": [
                    "None",
                    "str",
                    "int",
                    "typing.Callable[str, bool]",
                    "typing.Sequence[typing.Any]",
                    "float"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/relational_xlnet.py": {
        "RelationalXL.__init__": {
            "name": "__init__",
            "location": 26,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "int",
                    "str",
                    "typing.Container"
                ],
                "text_encoder": [],
                "relation_encoder": [],
                "vocab": [
                    "str"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "RelationalXL._forward_internal": {
            "name": "_forward_internal",
            "location": 58,
            "return": [],
            "arguments": {
                "self": [],
                "text": [
                    "str",
                    "dict[, ]",
                    "int",
                    "None"
                ],
                "relations": [
                    "int",
                    "str"
                ]
            }
        },
        "RelationalXL.forward": {
            "name": "forward",
            "location": 89,
            "return": [
                "dict[typing.Text, ]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "bool",
                    "None",
                    "str",
                    "list[str]"
                ],
                "string0": [
                    "str"
                ],
                "string1": [
                    "bool",
                    "None",
                    "str",
                    "list[str]"
                ],
                "rel0": [
                    "str",
                    "bool"
                ],
                "rel1": [
                    "str",
                    "bool"
                ],
                "label": [
                    "None",
                    "bytes",
                    "set[int]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/simple_bert.py": {
        "SimpleBertClassifier.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "bert_path": [
                    "str",
                    "dict[str, typing.Any]",
                    "typing.Callable[typing.Any, None]",
                    "None"
                ],
                "vocab": [
                    "str",
                    "list[str]",
                    "None"
                ],
                "train_bert": [
                    "bool"
                ]
            }
        },
        "SimpleBertClassifier.forward": {
            "name": "forward",
            "location": 43,
            "return": [
                "dict[typing.Text, ]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "bool",
                    "typing.Mapping"
                ],
                "bert0": [
                    "bool",
                    "list[]",
                    "str"
                ],
                "bert1": [
                    "bool",
                    "list[]",
                    "str"
                ],
                "label": [
                    "None",
                    "str",
                    "list[str]",
                    "bytes",
                    "float",
                    "bool"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/simple_trian.py": {
        "SimpleTrian.__init__": {
            "name": "__init__",
            "location": 37,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [],
                "rel_embeddings": [
                    "float",
                    "bool"
                ],
                "p_encoder": [
                    "float",
                    "int",
                    "str",
                    "typing.Type"
                ],
                "q_encoder": [
                    "float",
                    "typing.Any",
                    "None",
                    "typing.Iterable[O]",
                    "str"
                ],
                "a_encoder": [
                    "int",
                    "typing.Mapping"
                ],
                "vocab": [
                    "bool",
                    "str"
                ],
                "embedding_dropout": [
                    "float"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "SimpleTrian.forward": {
            "name": "forward",
            "location": 97,
            "return": [],
            "arguments": {
                "self": [],
                "metadata": [
                    "bool",
                    "typing.Mapping"
                ],
                "passage": [
                    "float",
                    "str",
                    "dict[str, typing.Any]",
                    "None"
                ],
                "question": [
                    "str",
                    "dict[str, typing.Any]",
                    "None"
                ],
                "answer0": [
                    "float",
                    "bool",
                    "str",
                    "None"
                ],
                "answer1": [
                    "float",
                    "bool",
                    "str",
                    "None"
                ],
                "p_q_rel": [
                    "str",
                    "int",
                    "float",
                    "None"
                ],
                "p_a0_rel": [
                    "int",
                    "float",
                    "None",
                    "str"
                ],
                "p_a1_rel": [
                    "int",
                    "float",
                    "None",
                    "str"
                ],
                "label": [
                    "None",
                    "str",
                    "typing.Any",
                    "bool",
                    "set[int]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/simple_xlnet.py": {
        "SimpleXLNetClassifier.__init__": {
            "name": "__init__",
            "location": 20,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vocab": [
                    "str",
                    "list[str]",
                    "None"
                ],
                "config_path": [
                    "str"
                ],
                "model_path": [
                    "str"
                ],
                "train_xlnet": [
                    "bool"
                ]
            }
        },
        "SimpleXLNetClassifier.forward": {
            "name": "forward",
            "location": 45,
            "return": [
                "dict[typing.Text, ]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "str",
                    "typing.Callable[[], bool]",
                    "bool"
                ],
                "string0": [
                    "str"
                ],
                "string1": [
                    "str"
                ],
                "label": [
                    "None",
                    "str",
                    "dict[str, str]",
                    "bool"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/trian.py": {
        "Trian.__init__": {
            "name": "__init__",
            "location": 36,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [],
                "pos_embeddings": [
                    "int",
                    "float"
                ],
                "ner_embeddings": [
                    "int",
                    "float"
                ],
                "rel_embeddings": [
                    "int",
                    "float"
                ],
                "p_encoder": [
                    "int",
                    "float"
                ],
                "q_encoder": [
                    "str",
                    "int"
                ],
                "a_encoder": [
                    "int"
                ],
                "vocab": [
                    "bool",
                    "dict[str, typing.Any]",
                    "typing.Callable[Any,Any, bool]"
                ],
                "embedding_dropout": [
                    "float"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "Trian.forward": {
            "name": "forward",
            "location": 94,
            "return": [],
            "arguments": {
                "self": [],
                "metadata": [
                    "bool"
                ],
                "passage": [
                    "bool",
                    "dict[, ]",
                    "None"
                ],
                "question": [
                    "bool",
                    "float",
                    "str"
                ],
                "answer0": [
                    "bool",
                    "str"
                ],
                "answer1": [
                    "bool",
                    "str"
                ],
                "passage_pos": [
                    "bool",
                    "str",
                    "list[typing.Any]",
                    "None"
                ],
                "passage_ner": [
                    "bool",
                    "str",
                    "list[typing.Any]",
                    "None"
                ],
                "question_pos": [
                    "bool",
                    "str",
                    "list[typing.Any]",
                    "None"
                ],
                "p_q_rel": [
                    "bool",
                    "bytes"
                ],
                "p_a0_rel": [
                    "bool",
                    "bytes",
                    "float"
                ],
                "p_a1_rel": [
                    "bool",
                    "bytes",
                    "float"
                ],
                "hc_feat": [
                    "float",
                    "None",
                    "str",
                    "list[str]",
                    "dict[int, set[int]]"
                ],
                "label": [
                    "None",
                    "set[int]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/util.py": {
        "seq_over_seq": {
            "name": "seq_over_seq",
            "location": 10,
            "return": [],
            "arguments": {
                "encoder": [],
                "sentences": [],
                "masks": [
                    "str",
                    "None"
                ]
            }
        },
        "hierarchical_seq_over_seq": {
            "name": "hierarchical_seq_over_seq",
            "location": 30,
            "return": [],
            "arguments": {
                "encoder": [],
                "sentences": [],
                "masks": [
                    "list[]",
                    "tuple[typing.Union[int,int,int]]",
                    "list[str]"
                ]
            }
        },
        "attention_over_sequence": {
            "name": "attention_over_sequence",
            "location": 46,
            "return": [
                "int",
                "float",
                "dict[str, int]",
                "list[int]"
            ],
            "arguments": {
                "attention": [
                    "int",
                    "list[]",
                    "str"
                ],
                "sequence": [
                    "str",
                    "list[]"
                ],
                "vector": [
                    "int",
                    "list[]",
                    "str"
                ]
            }
        },
        "initalise_weights": {
            "name": "initalise_weights",
            "location": 58,
            "return": [
                "None"
            ],
            "arguments": {
                "init": [
                    "list[str]",
                    "int",
                    "str"
                ],
                "module": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/zero_trian.py": {
        "ZeroTrian.__init__": {
            "name": "__init__",
            "location": 38,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [],
                "p_encoder": [
                    "bool",
                    "typing.Type",
                    "typing.Mapping",
                    "None"
                ],
                "q_encoder": [
                    "float",
                    "str"
                ],
                "a_encoder": [
                    "typing.Mapping",
                    "typing.Collection"
                ],
                "vocab": [
                    "str",
                    "int",
                    "tuple[typing.Union[int,int]]"
                ],
                "embedding_dropout": [
                    "float"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "ZeroTrian.forward": {
            "name": "forward",
            "location": 96,
            "return": [],
            "arguments": {
                "self": [],
                "metadata": [
                    "int",
                    "str",
                    "typing.Any"
                ],
                "passage": [
                    "str",
                    "None"
                ],
                "question": [
                    "int",
                    "list[]"
                ],
                "answer0": [
                    "bytes",
                    "bool",
                    "typing.Type",
                    "None",
                    "str"
                ],
                "answer1": [
                    "bytes",
                    "bool",
                    "typing.Type",
                    "None",
                    "str"
                ],
                "label": [
                    "None",
                    "set[int]",
                    "str"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/__init__.py": {},
    "literate-lamp-master/literate_lamp/models/dmn/answer_module.py": {
        "AnswerModule.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "int",
                    "float",
                    "list[allennlp.data.Instance]"
                ],
                "encoder": [
                    "int",
                    "float"
                ],
                "embedding_dropout": [
                    "float"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "AnswerModule.get_output_dim": {
            "name": "get_output_dim",
            "location": 28,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "AnswerModule.forward": {
            "name": "forward",
            "location": 32,
            "return": [],
            "arguments": {
                "self": [],
                "answer": [
                    "str",
                    "bool",
                    "typing.Mapping",
                    "list[str]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dmn/input_module.py": {
        "InputModule.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "int",
                    "float",
                    "list[allennlp.data.Instance]"
                ],
                "sentence_encoder": [
                    "int",
                    "float"
                ],
                "document_encoder": [
                    "int",
                    "float"
                ],
                "embedding_dropout": [
                    "float"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "InputModule.get_output_dim": {
            "name": "get_output_dim",
            "location": 32,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "InputModule.forward": {
            "name": "forward",
            "location": 36,
            "return": [],
            "arguments": {
                "self": [],
                "sentences": [
                    "float",
                    "None",
                    "str",
                    "int",
                    "list[str]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dmn/memory_module.py": {
        "MemoryModule.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "hidden_dim": [
                    "int",
                    "float",
                    "bytes"
                ],
                "num_hops": [
                    "str",
                    "int",
                    "None"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "MemoryModule.get_output_dim": {
            "name": "get_output_dim",
            "location": 39,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "MemoryModule.get_gate": {
            "name": "get_gate",
            "location": 42,
            "return": [],
            "arguments": {
                "self": [],
                "facts": [
                    "list[]",
                    "list[tuple[typing.Union[int,int]]]",
                    "float",
                    "str",
                    "list[dict[, ]]"
                ],
                "question": [
                    "str",
                    "None",
                    "list[str]"
                ],
                "answer": [
                    "str",
                    "int",
                    "typing.Callable[str, bool]",
                    "None"
                ],
                "prev_mem": [
                    "bool",
                    "str"
                ]
            }
        },
        "MemoryModule.forward": {
            "name": "forward",
            "location": 77,
            "return": [],
            "arguments": {
                "self": [],
                "facts": [
                    "dict[, ]",
                    "list[str]",
                    "bool",
                    "bytes",
                    "str",
                    "typing.IO"
                ],
                "question": [
                    "str",
                    "list[torch.Tensor]",
                    "dict[, ]"
                ],
                "answer": [
                    "str",
                    "list[torch.Tensor]",
                    "dict[, ]"
                ],
                "prev_mem": [
                    "str",
                    "list[torch.Tensor]",
                    "dict[, ]"
                ],
                "hop": [
                    "complex",
                    "bytes",
                    "float",
                    "bool",
                    "str",
                    "None"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dmn/model.py": {
        "_assert_equal": {
            "name": "_assert_equal",
            "location": 128,
            "return": [
                "None"
            ],
            "arguments": {
                "a": [],
                "b": []
            }
        },
        "Dmn.__init__": {
            "name": "__init__",
            "location": 39,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "int",
                    "float"
                ],
                "sentence_encoder": [],
                "document_encoder": [
                    "int",
                    "float"
                ],
                "question_encoder": [
                    "int",
                    "float"
                ],
                "answer_encoder": [
                    "int",
                    "float"
                ],
                "passes": [
                    "str",
                    "bool"
                ],
                "vocab": [
                    "str",
                    "int"
                ],
                "embedding_dropout": [
                    "float"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "Dmn.forward": {
            "name": "forward",
            "location": 88,
            "return": [
                "dict[typing.Text, ]"
            ],
            "arguments": {
                "self": [],
                "metadata": [
                    "int",
                    "str",
                    "typing.Any"
                ],
                "sentences": [
                    "str",
                    "tuple[]",
                    "tuple[typing.Union[str,str,int,int]]"
                ],
                "question": [
                    "str",
                    "tuple[]",
                    "tuple[typing.Union[str,str,int,int]]"
                ],
                "answer0": [
                    "str",
                    "tuple[]",
                    "tuple[typing.Union[str,str,int,int]]"
                ],
                "answer1": [
                    "str",
                    "tuple[]",
                    "tuple[typing.Union[str,str,int,int]]"
                ],
                "label": [
                    "None",
                    "set[int]",
                    "str"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dmn/output_module.py": {
        "OutputModule.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "memory_size": [
                    "int",
                    "tuple[typing.Union[int,int]]",
                    "float"
                ],
                "answer_size": [
                    "int",
                    "tuple[typing.Union[int,int]]",
                    "float"
                ],
                "num_labels": [
                    "int",
                    "dict[str, typing.Any]"
                ]
            }
        },
        "OutputModule.get_input_dim": {
            "name": "get_input_dim",
            "location": 22,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "OutputModule.get_output_dim": {
            "name": "get_output_dim",
            "location": 25,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "OutputModule.forward": {
            "name": "forward",
            "location": 29,
            "return": [],
            "arguments": {
                "self": [],
                "memory": [],
                "answer": [
                    "str",
                    "dict[str, int]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dmn/question_module.py": {
        "QuestionModule.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [
                    "int",
                    "float",
                    "list[allennlp.data.Instance]"
                ],
                "encoder": [
                    "int",
                    "float"
                ],
                "embedding_dropout": [
                    "float"
                ],
                "encoder_dropout": [
                    "float"
                ]
            }
        },
        "QuestionModule.get_output_dim": {
            "name": "get_output_dim",
            "location": 28,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "QuestionModule.forward": {
            "name": "forward",
            "location": 32,
            "return": [],
            "arguments": {
                "self": [],
                "question": [
                    "typing.Any"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dmn/__init__.py": {},
    "literate-lamp-master/literate_lamp/modules/attention_gru.py": {
        "attention_gru": {
            "name": "attention_gru",
            "location": 87,
            "return": [],
            "arguments": {
                "input_dim": [
                    "int",
                    "tuple[int]",
                    "str"
                ],
                "output_dim": [
                    "int",
                    "tuple[int]",
                    "str"
                ],
                "num_layers": [
                    "int"
                ],
                "bidirectional": [
                    "bool"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "AttentionGRUCell.__init__": {
            "name": "__init__",
            "location": 9,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [
                    "int",
                    "None"
                ],
                "hidden_size": [
                    "int",
                    "str",
                    "bytes"
                ]
            }
        },
        "AttentionGRUCell.forward": {
            "name": "forward",
            "location": 22,
            "return": [],
            "arguments": {
                "self": [],
                "inputs": [],
                "previous_state": [],
                "gate": []
            }
        },
        "AttentionGRU.__init__": {
            "name": "__init__",
            "location": 47,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [
                    "int",
                    "str",
                    "typing.Callable[, ]",
                    "float"
                ],
                "output_dim": [
                    "int",
                    "bytes",
                    "str",
                    "bytearray"
                ]
            }
        },
        "AttentionGRU.forward": {
            "name": "forward",
            "location": 53,
            "return": [],
            "arguments": {
                "self": [],
                "inputs": [
                    "list[torch.Tensor]"
                ],
                "gate": [
                    "BaseException"
                ]
            }
        },
        "AttentionGRU.get_input_dim": {
            "name": "get_input_dim",
            "location": 79,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "AttentionGRU.get_output_dim": {
            "name": "get_output_dim",
            "location": 83,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/modules/position_encoder.py": {
        "position_encoder": {
            "name": "position_encoder",
            "location": 59,
            "return": [
                "PositionEncoder"
            ],
            "arguments": {
                "input_dim": [
                    "int",
                    "tuple[int]",
                    "str"
                ],
                "output_dim": [
                    "int",
                    "tuple[int]",
                    "str"
                ],
                "num_layers": [
                    "int"
                ],
                "bidirectional": [
                    "bool"
                ],
                "dropout": [
                    "float"
                ]
            }
        },
        "PositionEncoder.__init__": {
            "name": "__init__",
            "location": 9,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [
                    "int",
                    "str",
                    "float",
                    "typing.Callable[, ]"
                ],
                "output_dim": [
                    "int"
                ]
            }
        },
        "PositionEncoder.position_matrix": {
            "name": "position_matrix",
            "location": 15,
            "return": [],
            "arguments": {
                "self": [],
                "seq_len": [
                    "bool"
                ]
            }
        },
        "PositionEncoder.forward": {
            "name": "forward",
            "location": 24,
            "return": [
                "str"
            ],
            "arguments": {
                "self": [],
                "inputs": [],
                "mask": [
                    "None",
                    "int",
                    "float",
                    "typing.Any",
                    "typing.Mapping",
                    "str"
                ]
            }
        },
        "PositionEncoder.get_input_dim": {
            "name": "get_input_dim",
            "location": 51,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "PositionEncoder.get_output_dim": {
            "name": "get_output_dim",
            "location": 55,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/modules/xlnet_embedder.py": {
        "PretrainedXLNetModel.load": {
            "name": "load",
            "location": 26,
            "return": [],
            "arguments": {
                "cls": [
                    "dict[, ]",
                    "str",
                    "int",
                    "None"
                ],
                "config_path": [
                    "str",
                    "list[str]"
                ],
                "model_path": [
                    "typing.Sequence[str]",
                    "None",
                    "str",
                    "dict[str, float]",
                    "typing.Callable[, ]"
                ],
                "cache_model": [
                    "bool"
                ]
            }
        },
        "XLNetEmbedder.__init__": {
            "name": "__init__",
            "location": 57,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "xlnet_model": [
                    "str",
                    "bool",
                    "dict[, ]"
                ],
                "window_size": [
                    "None",
                    "int",
                    "list[str]",
                    "tuple[typing.Union[int,int]]"
                ]
            }
        },
        "XLNetEmbedder.get_output_dim": {
            "name": "get_output_dim",
            "location": 66,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "XLNetEmbedder.forward": {
            "name": "forward",
            "location": 69,
            "return": [],
            "arguments": {
                "self": [],
                "input_ids": [
                    "None"
                ],
                "cls_indexes": [
                    "None",
                    "bool",
                    "str"
                ],
                "token_type_ids": [
                    "None",
                    "str",
                    "int"
                ]
            }
        },
        "PretrainedXLNetEmbedder.__init__": {
            "name": "__init__",
            "location": 137,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "config_path": [
                    "str",
                    "dict[str, typing.Any]",
                    "bool"
                ],
                "model_path": [
                    "str",
                    "dict[str, typing.Any]",
                    "bool"
                ],
                "window_size": [
                    "None",
                    "int",
                    "str",
                    "typing.Callable[None, None]"
                ],
                "requires_grad": [
                    "bool"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/modules/xlnet_indexer.py": {
        "XLNetIndexer.__init__": {
            "name": "__init__",
            "location": 39,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "namespace": [
                    "typing.Text"
                ],
                "vocab_file": [
                    "typing.Text"
                ],
                "sep_token": [
                    "typing.Text"
                ],
                "cls_token": [
                    "typing.Text"
                ],
                "pad_token": [
                    "int"
                ],
                "token_min_padding_length": [
                    "int"
                ]
            }
        },
        "XLNetIndexer.count_vocab_items": {
            "name": "count_vocab_items",
            "location": 59,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "token": [
                    "dict[str, dict[str, int]]"
                ],
                "counter": [
                    "dict[str, dict[str, int]]"
                ]
            }
        },
        "XLNetIndexer.tokens_to_indices": {
            "name": "tokens_to_indices",
            "location": 66,
            "return": [
                "dict[str, list[int]]"
            ],
            "arguments": {
                "self": [],
                "tokens": [
                    "str",
                    "dict[, ]",
                    "dict[str, str]"
                ],
                "vocabulary": [
                    "str",
                    "list[allennlp.data.tokenizers.token.Token]"
                ],
                "index_name": [
                    "str"
                ]
            }
        },
        "XLNetIndexer.get_padding_token": {
            "name": "get_padding_token",
            "location": 104,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "XLNetIndexer.get_padding_lengths": {
            "name": "get_padding_lengths",
            "location": 108,
            "return": [
                "dict[, ]"
            ],
            "arguments": {
                "self": [],
                "token": [
                    "int",
                    "list[int]",
                    "str"
                ]
            }
        },
        "XLNetIndexer.pad_token_sequence": {
            "name": "pad_token_sequence",
            "location": 112,
            "return": [
                "dict[typing.Union[tuple[typing.Union[str,list[int]]],tuple[typing.Union[str,int]]], ]"
            ],
            "arguments": {
                "self": [],
                "tokens": [
                    "dict[str, list[int]]",
                    "dict[str, int]"
                ],
                "desired_num_tokens": [],
                "padding_lengths": [
                    "dict[str, int]",
                    "int"
                ]
            }
        },
        "XLNetIndexer.get_keys": {
            "name": "get_keys",
            "location": 121,
            "return": [
                "list[typing.Optional[str]]"
            ],
            "arguments": {
                "self": [],
                "index_name": [
                    "str",
                    "None"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/modules/xlnet_pooler.py": {
        "XLNetPooler.__init__": {
            "name": "__init__",
            "location": 9,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [
                    "int",
                    "float"
                ]
            }
        },
        "XLNetPooler.get_input_dim": {
            "name": "get_input_dim",
            "location": 16,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "XLNetPooler.get_output_dim": {
            "name": "get_output_dim",
            "location": 20,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "XLNetPooler.forward": {
            "name": "forward",
            "location": 23,
            "return": [
                "list[]",
                "dict[, ]",
                "str"
            ],
            "arguments": {
                "self": [],
                "hidden_states": [],
                "cls_index": [
                    "None",
                    "tuple[typing.Union[torch.Tensor,torch.Tensor]]",
                    "dict[str, torch.LongTensor]",
                    "int",
                    "typing.Callable[str, int]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/modules/xlnet_word_splitter.py": {
        "PretrainedXLNetTokenizer.load": {
            "name": "load",
            "location": 18,
            "return": [
                "XLNetTokenizer"
            ],
            "arguments": {
                "cls": [
                    "dict[, ]",
                    "bytes",
                    "str"
                ],
                "vocab_file": [
                    "str",
                    "bool"
                ],
                "cache_model": [
                    "bool"
                ]
            }
        },
        "XLNetWordSplitter.__init__": {
            "name": "__init__",
            "location": 36,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vocab_file": [
                    "int",
                    "None",
                    "list[]"
                ],
                "do_lower_case": [
                    "bool"
                ]
            }
        },
        "XLNetWordSplitter.split_words": {
            "name": "split_words",
            "location": 42,
            "return": [
                "list[Token]"
            ],
            "arguments": {
                "self": [],
                "sentence": [
                    "str",
                    "float",
                    "list[str]",
                    "list[tuple[typing.Union[float,str]]]",
                    "int"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/modules/__init__.py": {},
    "literate-lamp-master/literate_lamp/readers/base_reader.py": {
        "BaseReader._read": {
            "name": "_read",
            "location": 20,
            "return": [
                "typing.Generator[]"
            ],
            "arguments": {
                "self": [],
                "file_path": [
                    "str"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/extended_xlnet_reader.py": {
        "ExtendedXLNetReader.__init__": {
            "name": "__init__",
            "location": 44,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vocab_file": [
                    "str"
                ],
                "conceptnet_path": [
                    "str"
                ],
                "word_indexer": [
                    "None",
                    "str"
                ]
            }
        },
        "ExtendedXLNetReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 66,
            "return": [
                "Instance"
            ],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str",
                    "None",
                    "list[]"
                ],
                "question_id": [
                    "str",
                    "None",
                    "list[]"
                ],
                "question_type": [
                    "str",
                    "None",
                    "list[]"
                ],
                "passage": [
                    "str",
                    "bool"
                ],
                "question": [
                    "str",
                    "bool",
                    "dict[str, typing.Any]",
                    "None"
                ],
                "answer0": [
                    "str",
                    "int"
                ],
                "answer1": [
                    "str",
                    "int"
                ],
                "label0": [
                    "None",
                    "str",
                    "int",
                    "dict[str, typing.Any]",
                    "typing.Any",
                    "typing.Sequence[int]"
                ]
            }
        },
        "ExtendedXLNetReader.extend_passage": {
            "name": "extend_passage",
            "location": 109,
            "return": [
                "str"
            ],
            "arguments": {
                "self": [],
                "passage": [
                    "str"
                ],
                "question": [
                    "complex",
                    "bytes",
                    "float",
                    "bool",
                    "str",
                    "None"
                ],
                "answer": [
                    "bool",
                    "list[str]",
                    "str"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/full_trian_reader.py": {
        "FullTrianReader.__init__": {
            "name": "__init__",
            "location": 54,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_indexer": [
                    "None",
                    "float",
                    "bool",
                    "list[]"
                ],
                "is_bert": [
                    "bool"
                ],
                "conceptnet_path": [
                    "None",
                    "str",
                    "typing.Iterable[typing.Any]"
                ]
            }
        },
        "FullTrianReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 94,
            "return": [
                "Instance"
            ],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str",
                    "None",
                    "list[]"
                ],
                "question_id": [
                    "str",
                    "None",
                    "list[]"
                ],
                "question_type": [
                    "str",
                    "None",
                    "list[]"
                ],
                "passage": [
                    "str",
                    "list[]",
                    "list[str]",
                    "dict[, ]"
                ],
                "question": [
                    "str",
                    "list[]",
                    "list[str]",
                    "dict[, ]"
                ],
                "answer0": [
                    "str",
                    "dict[str, typing.Any]",
                    "dict[str, tuple[typing.Union[typing.Any,typing.Any]]]",
                    "list[]",
                    "dict[str, str]",
                    "typing.Pattern"
                ],
                "answer1": [
                    "str",
                    "dict[str, typing.Any]",
                    "dict[str, tuple[typing.Union[typing.Any,typing.Any]]]",
                    "list[]",
                    "dict[str, str]",
                    "typing.Pattern"
                ],
                "label0": [
                    "None",
                    "str",
                    "int",
                    "dict[str, typing.Any]",
                    "typing.Any",
                    "typing.Sequence[int]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/relation_bert_reader.py": {
        "RelationBertReader.__init__": {
            "name": "__init__",
            "location": 40,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "is_bert": [
                    "bool",
                    "str",
                    "list[str]"
                ],
                "conceptnet_path": [
                    "str",
                    "None"
                ],
                "word_indexer": [
                    "None",
                    "str",
                    "bool"
                ]
            }
        },
        "RelationBertReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 72,
            "return": [],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str",
                    "None",
                    "list[]"
                ],
                "question_id": [
                    "str",
                    "None",
                    "list[]"
                ],
                "question_type": [
                    "str",
                    "None",
                    "list[]"
                ],
                "passage": [
                    "str"
                ],
                "question": [
                    "str",
                    "None"
                ],
                "answer0": [
                    "str"
                ],
                "answer1": [
                    "str"
                ],
                "label0": [
                    "None",
                    "str",
                    "int",
                    "dict[str, typing.Any]",
                    "typing.Any",
                    "typing.Sequence[int]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/relation_xlnet_reader.py": {
        "RelationXLNetReader.__init__": {
            "name": "__init__",
            "location": 40,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vocab_file": [
                    "str"
                ],
                "conceptnet_path": [
                    "str"
                ],
                "word_indexer": [
                    "None",
                    "str"
                ]
            }
        },
        "RelationXLNetReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 62,
            "return": [
                "Instance"
            ],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str",
                    "None",
                    "list[]"
                ],
                "question_id": [
                    "str",
                    "None",
                    "list[]"
                ],
                "question_type": [
                    "str",
                    "None",
                    "list[]"
                ],
                "passage": [
                    "int",
                    "str",
                    "dict[str, str]",
                    "typing.Any",
                    "None"
                ],
                "question": [
                    "int",
                    "str",
                    "dict[str, str]",
                    "typing.Any",
                    "None"
                ],
                "answer0": [
                    "int",
                    "str",
                    "typing.Any",
                    "None"
                ],
                "answer1": [
                    "int",
                    "str",
                    "typing.Any",
                    "None"
                ],
                "label0": [
                    "None",
                    "str",
                    "int",
                    "dict[str, typing.Any]",
                    "typing.Any",
                    "typing.Sequence[int]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/sentence_reader.py": {
        "SentenceReader.__init__": {
            "name": "__init__",
            "location": 47,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "embedding_type": [
                    "str",
                    "int",
                    "None",
                    "float"
                ],
                "xlnet_vocab_file": [
                    "None",
                    "str",
                    "int",
                    "float"
                ],
                "word_indexer": [
                    "None",
                    "str"
                ]
            }
        },
        "SentenceReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 70,
            "return": [
                "Instance"
            ],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str",
                    "None",
                    "list[]"
                ],
                "question_id": [
                    "str",
                    "None",
                    "list[]"
                ],
                "question_type": [
                    "str",
                    "None",
                    "list[]"
                ],
                "passage": [
                    "str",
                    "None"
                ],
                "question": [
                    "str",
                    "bool"
                ],
                "answer0": [
                    "str",
                    "bool"
                ],
                "answer1": [
                    "str",
                    "bool"
                ],
                "label0": [
                    "None",
                    "str",
                    "int",
                    "dict[str, typing.Any]",
                    "typing.Any",
                    "typing.Sequence[int]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/simple_bert_reader.py": {
        "SimpleBertReader.__init__": {
            "name": "__init__",
            "location": 35,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_indexer": [
                    "None",
                    "int",
                    "str",
                    "float"
                ]
            }
        },
        "SimpleBertReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 56,
            "return": [
                "Instance"
            ],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str",
                    "None",
                    "list[]"
                ],
                "question_id": [
                    "str",
                    "None",
                    "list[]"
                ],
                "question_type": [
                    "str",
                    "None",
                    "list[]"
                ],
                "passage": [
                    "str",
                    "None"
                ],
                "question": [
                    "str",
                    "None"
                ],
                "answer0": [
                    "str",
                    "None",
                    "dict[str, str]",
                    "set[int]"
                ],
                "answer1": [
                    "str",
                    "None",
                    "dict[str, str]",
                    "set[int]"
                ],
                "label0": [
                    "None",
                    "str",
                    "int",
                    "dict[str, typing.Any]",
                    "typing.Any",
                    "typing.Sequence[int]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/simple_mc_script_reader.py": {
        "SimpleMcScriptReader.__init__": {
            "name": "__init__",
            "location": 35,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "embedding_type": [
                    "typing.Text"
                ],
                "xlnet_vocab_file": [
                    "None",
                    "str",
                    "typing.BinaryIO"
                ],
                "word_indexer": [
                    "None",
                    "str",
                    "typing.Sequence[str]"
                ]
            }
        },
        "SimpleMcScriptReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 56,
            "return": [
                "Instance"
            ],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str",
                    "None",
                    "list[]"
                ],
                "question_id": [
                    "str",
                    "None",
                    "list[]"
                ],
                "question_type": [
                    "str",
                    "None",
                    "list[]"
                ],
                "passage": [
                    "str",
                    "bytes",
                    "dict[str, str]"
                ],
                "question": [
                    "str",
                    "bytes",
                    "dict[str, str]"
                ],
                "answer0": [
                    "str",
                    "bytes",
                    "dict[str, str]"
                ],
                "answer1": [
                    "str",
                    "bytes",
                    "dict[str, str]"
                ],
                "label0": [
                    "None",
                    "str",
                    "int",
                    "dict[str, typing.Any]",
                    "typing.Any",
                    "typing.Sequence[int]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/simple_trian_reader.py": {
        "SimpleTrianReader.__init__": {
            "name": "__init__",
            "location": 39,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_indexer": [
                    "None",
                    "str"
                ],
                "xlnet_vocab_file": [
                    "None",
                    "str",
                    "int",
                    "float"
                ],
                "embedding_type": [
                    "typing.Text"
                ],
                "conceptnet_path": [
                    "None",
                    "str",
                    "typing.Callable[str,str, None]",
                    "int"
                ]
            }
        },
        "SimpleTrianReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 62,
            "return": [
                "Instance"
            ],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str",
                    "None",
                    "list[]"
                ],
                "question_id": [
                    "str",
                    "None",
                    "list[]"
                ],
                "question_type": [
                    "str",
                    "None",
                    "list[]"
                ],
                "passage": [
                    "str",
                    "bytes",
                    "dict[str, str]"
                ],
                "question": [
                    "str",
                    "bytes",
                    "dict[str, str]"
                ],
                "answer0": [
                    "str",
                    "bytes",
                    "dict[str, str]"
                ],
                "answer1": [
                    "str",
                    "bytes",
                    "dict[str, str]"
                ],
                "label0": [
                    "None",
                    "str",
                    "int",
                    "dict[str, typing.Any]",
                    "typing.Any",
                    "typing.Sequence[int]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/simple_xlnet_reader.py": {
        "SimpleXLNetReader.__init__": {
            "name": "__init__",
            "location": 45,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vocab_file": [
                    "bool"
                ],
                "word_indexer": [
                    "None",
                    "str",
                    "list[str]",
                    "dict[str, str]",
                    "int"
                ]
            }
        },
        "SimpleXLNetReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 65,
            "return": [
                "Instance"
            ],
            "arguments": {
                "self": [],
                "passage_id": [
                    "str",
                    "None",
                    "list[]"
                ],
                "question_id": [
                    "str",
                    "None",
                    "list[]"
                ],
                "question_type": [
                    "str",
                    "None",
                    "list[]"
                ],
                "passage": [
                    "str",
                    "int",
                    "typing.Any",
                    "None"
                ],
                "question": [
                    "str",
                    "int",
                    "typing.Any",
                    "None"
                ],
                "answer0": [
                    "str"
                ],
                "answer1": [
                    "str"
                ],
                "label0": [
                    "None",
                    "str",
                    "int",
                    "dict[str, typing.Any]",
                    "typing.Any",
                    "typing.Sequence[int]"
                ]
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/util.py": {
        "strs2toks": {
            "name": "strs2toks",
            "location": 20,
            "return": [
                "list[Token]"
            ],
            "arguments": {
                "strings": [
                    "str"
                ]
            }
        },
        "toks2strs": {
            "name": "toks2strs",
            "location": 25,
            "return": [
                "list[]"
            ],
            "arguments": {
                "tokens": [
                    "str"
                ]
            }
        },
        "pieces2strs": {
            "name": "pieces2strs",
            "location": 30,
            "return": [
                "list[]"
            ],
            "arguments": {
                "tokens": [
                    "str"
                ]
            }
        },
        "compute_handcrafted_features": {
            "name": "compute_handcrafted_features",
            "location": 40,
            "return": [],
            "arguments": {
                "passage": [],
                "question": [
                    "str",
                    "list[str]",
                    "dict[, ]",
                    "list[]"
                ],
                "answer0": [
                    "str"
                ],
                "answer1": [
                    "str"
                ]
            }
        },
        "bert_sliding_window": {
            "name": "bert_sliding_window",
            "location": 83,
            "return": [
                "list[typing.Text]"
            ],
            "arguments": {
                "question": [],
                "answer": [],
                "passage": [],
                "max_wordpieces": [
                    "bool"
                ],
                "stride": [
                    "None",
                    "int",
                    "typing.Iterable[typing.Any]",
                    "typing.Type",
                    "str"
                ]
            }
        },
        "xlnet_input_string": {
            "name": "xlnet_input_string",
            "location": 101,
            "return": [
                "typing.Text"
            ],
            "arguments": {
                "question": [
                    "str",
                    "bool",
                    "None",
                    "dict[, ]"
                ],
                "answer": [
                    "str",
                    "bool",
                    "None",
                    "dict[, ]"
                ],
                "passage": [
                    "str",
                    "bool",
                    "None",
                    "dict[, ]"
                ]
            }
        },
        "relation_sentences": {
            "name": "relation_sentences",
            "location": 105,
            "return": [
                "list[]"
            ],
            "arguments": {
                "conceptnet": [],
                "text": [
                    "str",
                    "int"
                ],
                "query": [
                    "str",
                    "int"
                ]
            }
        },
        "get_tokenizer": {
            "name": "get_tokenizer",
            "location": 112,
            "return": [
                "WordTokenizer"
            ],
            "arguments": {
                "embedding_type": [
                    "str"
                ],
                "xlnet_vocab_file": [
                    "str",
                    "bool"
                ]
            }
        },
        "get_indexer": {
            "name": "get_indexer",
            "location": 124,
            "return": [
                "PretrainedBertIndexer",
                "SingleIdTokenIndexer",
                "XLNetIndexer"
            ],
            "arguments": {
                "embedding_type": [
                    "str",
                    "list[str]",
                    "float",
                    "int"
                ],
                "xlnet_vocab_file": [
                    "bytes",
                    "float",
                    "str",
                    "None",
                    "int",
                    "typing.TextIO"
                ]
            }
        },
        "split_sentences": {
            "name": "split_sentences",
            "location": 137,
            "return": [
                "typing.Generator[]"
            ],
            "arguments": {
                "nlp": [
                    "str"
                ],
                "text": [
                    "str"
                ]
            }
        },
        "get_sentencizer": {
            "name": "get_sentencizer",
            "location": 143,
            "return": [
                "English"
            ],
            "arguments": {}
        },
        "compute_handcrafted_features.is_valid": {
            "name": "is_valid",
            "location": 44,
            "return": [
                "bool"
            ],
            "arguments": {
                "token": []
            }
        },
        "compute_handcrafted_features.co_occurrence": {
            "name": "co_occurrence",
            "location": 47,
            "return": [
                "list[bool]"
            ],
            "arguments": {
                "text": [],
                "query": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/__init__.py": {}
}
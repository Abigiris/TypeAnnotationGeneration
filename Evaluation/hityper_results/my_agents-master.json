{
    "my_agents-master/setup.py": {},
    "my_agents-master/my_agents/comparison.py": {},
    "my_agents-master/my_agents/evaluate.py": {},
    "my_agents-master/my_agents/main.py": {},
    "my_agents-master/my_agents/vectorize_test.py": {},
    "my_agents-master/my_agents/agents/ddqn_agent.py": {
        "build_dense_network": {
            "name": "build_dense_network",
            "location": 24,
            "return": [],
            "arguments": {
                "num_actions": [
                    "dict[, ]",
                    "bool"
                ],
                "state_shape": [],
                "hidden_layers": [
                    "list[int]"
                ]
            }
        },
        "DDQNAgent.__init__": {
            "name": "__init__",
            "location": 63,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_actions": [
                    "str",
                    "None",
                    "int",
                    "tuple[]"
                ],
                "state_shape": [
                    "str",
                    "None",
                    "int",
                    "tuple[]"
                ],
                "gamma": [
                    "float"
                ],
                "target_update_freq": [
                    "int"
                ],
                "prebuilt_model": [
                    "None",
                    "bool",
                    "str",
                    "dict[str, np.ndarray]",
                    "tuple[typing.Union[float,float]]"
                ]
            }
        },
        "DDQNAgent.act": {
            "name": "act",
            "location": 82,
            "return": [],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "dict[str, typing.Any]",
                    "dict[, ]"
                ]
            }
        },
        "DDQNAgent.process_observation": {
            "name": "process_observation",
            "location": 86,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ],
                "action": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ],
                "reward": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ],
                "next_state": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ],
                "done": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ]
            }
        },
        "DDQNAgent.train": {
            "name": "train",
            "location": 91,
            "return": [
                "None",
                "int",
                "bytes",
                "tuple[typing.Union[int,int]]"
            ],
            "arguments": {
                "self": [],
                "step_num": [
                    "int",
                    "typing.Callable[, ]",
                    "float"
                ],
                "batch_size": [
                    "int"
                ],
                "epochs": [
                    "int"
                ]
            }
        },
        "DDQNAgent._update_target_model": {
            "name": "_update_target_model",
            "location": 112,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDQNAgent._observations_to_train_data": {
            "name": "_observations_to_train_data",
            "location": 115,
            "return": [
                "tuple[typing.Union[typing.Sequence[int],list[],list[list[]],list[str]]]"
            ],
            "arguments": {
                "self": [],
                "states": [
                    "typing.Sequence[int]",
                    "list[]",
                    "list[list[]]",
                    "list[str]"
                ],
                "actions": [],
                "rewards": [
                    "tuple[typing.Union[int,...]]",
                    "None",
                    "bool",
                    "str"
                ],
                "next_states": [],
                "dones": [
                    "tuple[typing.Union[int,...]]",
                    "None",
                    "bool",
                    "str"
                ]
            }
        },
        "DDQNAgent.Q": {
            "name": "Q",
            "location": 129,
            "return": [],
            "arguments": {
                "self": [],
                "states": [
                    "str",
                    "list[str]"
                ],
                "use_target": [
                    "bool"
                ]
            }
        },
        "DDQNAgent.policy": {
            "name": "policy",
            "location": 142,
            "return": [],
            "arguments": {
                "self": [],
                "states": [
                    "bool",
                    "str",
                    "None",
                    "dict[, ]"
                ],
                "use_target": [
                    "bool"
                ]
            }
        },
        "DDQNAgent.V": {
            "name": "V",
            "location": 146,
            "return": [],
            "arguments": {
                "self": [],
                "states": [
                    "bool"
                ],
                "use_target": [
                    "bool"
                ]
            }
        },
        "DDQNAgent.save": {
            "name": "save",
            "location": 150,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "file_path": [
                    "typing.Text"
                ]
            }
        },
        "DDQNAgent.from_h5": {
            "name": "from_h5",
            "location": 158,
            "return": [
                "DDQNAgent"
            ],
            "arguments": {
                "file_path": [
                    "typing.Text"
                ],
                "gamma": [
                    "float"
                ],
                "target_update_freq": [
                    "int"
                ]
            }
        }
    },
    "my_agents-master/my_agents/agents/distributional_agent.py": {
        "build_distributional_network": {
            "name": "build_distributional_network",
            "location": 19,
            "return": [],
            "arguments": {
                "num_actions": [
                    "int",
                    "str",
                    "None",
                    "float"
                ],
                "state_shape": [
                    "int",
                    "str",
                    "bytes"
                ],
                "num_atoms": [
                    "int",
                    "str",
                    "None",
                    "float"
                ],
                "hidden_layers": [
                    "list[int]"
                ]
            }
        },
        "DistributionalAgent.__init__": {
            "name": "__init__",
            "location": 61,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_actions": [
                    "int",
                    "tuple[]",
                    "None"
                ],
                "state_shape": [
                    "int",
                    "tuple[]",
                    "None"
                ],
                "v_min": [
                    "int",
                    "float",
                    "str",
                    "None"
                ],
                "v_max": [
                    "int",
                    "float",
                    "str",
                    "None"
                ],
                "num_atoms": [
                    "int"
                ],
                "gamma": [
                    "float"
                ],
                "target_update_freq": [
                    "int"
                ],
                "prebuilt_model": [
                    "None",
                    "list[]",
                    "typing.Any",
                    "int",
                    "str",
                    "dict[str, typing.Any]",
                    "typing.Callable[str, bool]"
                ]
            }
        },
        "DistributionalAgent.act": {
            "name": "act",
            "location": 83,
            "return": [],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "dict[str, typing.Any]",
                    "dict[, ]"
                ]
            }
        },
        "DistributionalAgent.process_observation": {
            "name": "process_observation",
            "location": 87,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ],
                "action": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ],
                "reward": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ],
                "next_state": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ],
                "done": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ]
            }
        },
        "DistributionalAgent.train": {
            "name": "train",
            "location": 92,
            "return": [
                "None",
                "int",
                "bytes",
                "tuple[typing.Union[int,int]]"
            ],
            "arguments": {
                "self": [],
                "step_num": [
                    "int",
                    "typing.Callable[, ]",
                    "float"
                ],
                "batch_size": [
                    "int"
                ],
                "epochs": [
                    "int"
                ]
            }
        },
        "DistributionalAgent._update_target_model": {
            "name": "_update_target_model",
            "location": 113,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistributionalAgent._observations_to_train_data": {
            "name": "_observations_to_train_data",
            "location": 116,
            "return": [],
            "arguments": {
                "self": [],
                "states": [
                    "typing.Sequence[int]",
                    "list[]",
                    "list[str]",
                    "list[list[]]"
                ],
                "actions": [],
                "rewards": [
                    "int",
                    "list[set[int]]",
                    "str"
                ],
                "next_states": [
                    "list[]"
                ],
                "dones": [
                    "int",
                    "str"
                ]
            }
        },
        "DistributionalAgent.Z": {
            "name": "Z",
            "location": 149,
            "return": [],
            "arguments": {
                "self": [],
                "states": [
                    "str",
                    "int"
                ]
            }
        },
        "DistributionalAgent.Q": {
            "name": "Q",
            "location": 156,
            "return": [],
            "arguments": {
                "self": [],
                "states": []
            }
        },
        "DistributionalAgent.policy": {
            "name": "policy",
            "location": 168,
            "return": [],
            "arguments": {
                "self": [],
                "states": [
                    "int",
                    "dict[str, typing.Any]",
                    "dict[, ]"
                ]
            }
        },
        "DistributionalAgent.V": {
            "name": "V",
            "location": 172,
            "return": [],
            "arguments": {
                "self": [],
                "states": [
                    "dict[, ]",
                    "float",
                    "int"
                ]
            }
        },
        "DistributionalAgent.save": {
            "name": "save",
            "location": 176,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "file_path": [
                    "typing.Text"
                ]
            }
        },
        "DistributionalAgent.from_h5": {
            "name": "from_h5",
            "location": 184,
            "return": [
                "DistributionalAgent"
            ],
            "arguments": {
                "file_path": [
                    "typing.Text"
                ],
                "v_min": [
                    "int"
                ],
                "v_max": [
                    "int"
                ],
                "gamma": [
                    "float"
                ],
                "target_update_freq": [
                    "int"
                ]
            }
        },
        "DistributionalAgent.Distribution.__init__": {
            "name": "__init__",
            "location": 47,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "v_min": [],
                "v_max": [],
                "num_atoms": []
            }
        },
        "DistributionalAgent.Distribution.project_to_distribution": {
            "name": "project_to_distribution",
            "location": 54,
            "return": [
                "tuple[]"
            ],
            "arguments": {
                "self": [],
                "values": []
            }
        }
    },
    "my_agents-master/my_agents/agents/dqn_agent.py": {
        "build_dense_network": {
            "name": "build_dense_network",
            "location": 24,
            "return": [],
            "arguments": {
                "num_actions": [
                    "dict[, ]",
                    "bool"
                ],
                "state_shape": [],
                "hidden_layers": [
                    "list[int]"
                ]
            }
        },
        "DQNAgent.__init__": {
            "name": "__init__",
            "location": 65,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_actions": [
                    "str",
                    "None",
                    "int",
                    "tuple[]"
                ],
                "state_shape": [
                    "str",
                    "None",
                    "int",
                    "tuple[]"
                ],
                "gamma": [
                    "float"
                ],
                "target_update_freq": [
                    "int"
                ],
                "prebuilt_model": [
                    "None",
                    "bool",
                    "str",
                    "dict[str, np.ndarray]",
                    "tuple[typing.Union[float,float]]"
                ]
            }
        },
        "DQNAgent.act": {
            "name": "act",
            "location": 84,
            "return": [],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "dict[str, typing.Any]",
                    "dict[, ]"
                ]
            }
        },
        "DQNAgent.process_observation": {
            "name": "process_observation",
            "location": 88,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ],
                "action": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ],
                "reward": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ],
                "next_state": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ],
                "done": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ]
            }
        },
        "DQNAgent.train": {
            "name": "train",
            "location": 93,
            "return": [
                "None",
                "int",
                "bytes",
                "tuple[typing.Union[int,int]]"
            ],
            "arguments": {
                "self": [],
                "step_num": [
                    "int",
                    "typing.Callable[, ]",
                    "float"
                ],
                "batch_size": [
                    "int"
                ],
                "epochs": [
                    "int"
                ]
            }
        },
        "DQNAgent._update_target_model": {
            "name": "_update_target_model",
            "location": 114,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQNAgent._observations_to_train_data": {
            "name": "_observations_to_train_data",
            "location": 117,
            "return": [
                "tuple[typing.Union[typing.Sequence[int],list[],list[list[]],list[str]]]"
            ],
            "arguments": {
                "self": [],
                "states": [
                    "typing.Sequence[int]",
                    "list[]",
                    "list[list[]]",
                    "list[str]"
                ],
                "actions": [],
                "rewards": [
                    "tuple[typing.Union[int,...]]",
                    "None",
                    "int"
                ],
                "next_states": [],
                "dones": [
                    "tuple[typing.Union[int,...]]",
                    "None",
                    "int"
                ]
            }
        },
        "DQNAgent.Q": {
            "name": "Q",
            "location": 131,
            "return": [],
            "arguments": {
                "self": [],
                "states": [
                    "typing.Iterable[typing.Any]",
                    "bytes"
                ]
            }
        },
        "DQNAgent.policy": {
            "name": "policy",
            "location": 140,
            "return": [],
            "arguments": {
                "self": [],
                "states": [
                    "int",
                    "dict[str, typing.Any]",
                    "dict[, ]"
                ]
            }
        },
        "DQNAgent.V": {
            "name": "V",
            "location": 144,
            "return": [],
            "arguments": {
                "self": [],
                "states": [
                    "dict[, ]",
                    "float",
                    "int"
                ]
            }
        },
        "DQNAgent.save": {
            "name": "save",
            "location": 148,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "file_path": [
                    "typing.Text"
                ]
            }
        },
        "DQNAgent.from_h5": {
            "name": "from_h5",
            "location": 156,
            "return": [
                "DQNAgent"
            ],
            "arguments": {
                "file_path": [
                    "typing.Text"
                ],
                "gamma": [
                    "float"
                ],
                "target_update_freq": [
                    "int"
                ]
            }
        }
    },
    "my_agents-master/my_agents/agents/nstep_agent.py": {
        "build_dense_network": {
            "name": "build_dense_network",
            "location": 21,
            "return": [],
            "arguments": {
                "num_actions": [
                    "dict[, ]",
                    "bool"
                ],
                "state_shape": [],
                "hidden_layers": [
                    "list[int]"
                ]
            }
        },
        "NStepDDQNAgent.__init__": {
            "name": "__init__",
            "location": 61,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_actions": [
                    "int",
                    "None",
                    "float",
                    "tuple[]",
                    "str",
                    "bytes"
                ],
                "state_shape": [
                    "int",
                    "None",
                    "float",
                    "tuple[]",
                    "str",
                    "bytes"
                ],
                "update_horizon": [
                    "int"
                ],
                "gamma": [
                    "float"
                ],
                "target_update_freq": [
                    "int"
                ],
                "prebuilt_model": [
                    "None",
                    "bool",
                    "float",
                    "dict[str, np.ndarray]",
                    "tuple[typing.Union[float,float]]",
                    "list[]"
                ]
            }
        },
        "NStepDDQNAgent.act": {
            "name": "act",
            "location": 82,
            "return": [],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "dict[str, typing.Any]",
                    "dict[, ]"
                ]
            }
        },
        "NStepDDQNAgent.process_observation": {
            "name": "process_observation",
            "location": 86,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ],
                "action": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ],
                "reward": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ],
                "next_state": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ],
                "done": [
                    "int",
                    "list[list[int]]",
                    "list[int]",
                    "typing.Callable[T, bool]",
                    "list['Entity']"
                ]
            }
        },
        "NStepDDQNAgent.train": {
            "name": "train",
            "location": 91,
            "return": [
                "None",
                "int",
                "bytes",
                "tuple[typing.Union[int,int]]"
            ],
            "arguments": {
                "self": [],
                "step_num": [
                    "int",
                    "typing.Callable[, ]",
                    "float"
                ],
                "batch_size": [
                    "int"
                ],
                "epochs": [
                    "int"
                ]
            }
        },
        "NStepDDQNAgent._sample_n_transitions": {
            "name": "_sample_n_transitions",
            "location": 113,
            "return": [
                "tuple[list[int]]"
            ],
            "arguments": {
                "self": [],
                "batch_size": [
                    "int",
                    "tuple[typing.Union[int,int]]",
                    "list[]",
                    "str",
                    "typing.Sequence[]"
                ]
            }
        },
        "NStepDDQNAgent._update_target_model": {
            "name": "_update_target_model",
            "location": 141,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "NStepDDQNAgent._observations_to_train_data": {
            "name": "_observations_to_train_data",
            "location": 144,
            "return": [
                "tuple[typing.Union[typing.Sequence[int],list[],list[list[]],list[str]]]"
            ],
            "arguments": {
                "self": [],
                "states": [
                    "typing.Sequence[int]",
                    "list[]",
                    "list[list[]]",
                    "list[str]"
                ],
                "actions": [],
                "rewards": [
                    "typing.Callable[, ]",
                    "list[list[int]]"
                ],
                "next_states": [],
                "dones": [
                    "typing.Callable[, ]",
                    "list[list[int]]"
                ],
                "gammas": [
                    "typing.Callable[, ]",
                    "list[list[int]]"
                ]
            }
        },
        "NStepDDQNAgent.Q": {
            "name": "Q",
            "location": 159,
            "return": [],
            "arguments": {
                "self": [],
                "states": [
                    "str",
                    "list[str]"
                ],
                "use_target": [
                    "bool"
                ]
            }
        },
        "NStepDDQNAgent.policy": {
            "name": "policy",
            "location": 172,
            "return": [],
            "arguments": {
                "self": [],
                "states": [
                    "bool",
                    "str",
                    "None",
                    "dict[, ]"
                ],
                "use_target": [
                    "bool"
                ]
            }
        },
        "NStepDDQNAgent.V": {
            "name": "V",
            "location": 176,
            "return": [],
            "arguments": {
                "self": [],
                "states": [
                    "bool"
                ],
                "use_target": [
                    "bool"
                ]
            }
        },
        "NStepDDQNAgent.save": {
            "name": "save",
            "location": 180,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "file_path": [
                    "typing.Text"
                ]
            }
        },
        "NStepDDQNAgent.from_h5": {
            "name": "from_h5",
            "location": 188,
            "return": [
                "NStepDDQNAgent"
            ],
            "arguments": {
                "file_path": [
                    "typing.Text"
                ],
                "update_horizon": [
                    "int"
                ],
                "gamma": [
                    "float"
                ],
                "target_update_freq": [
                    "int"
                ]
            }
        }
    },
    "my_agents-master/my_agents/agents/prioritized_ddqn_agent.py": {
        "build_dense_network": {
            "name": "build_dense_network",
            "location": 16,
            "return": [],
            "arguments": {
                "num_actions": [
                    "dict[, ]",
                    "bool"
                ],
                "state_shape": [],
                "hidden_layers": [
                    "list[int]"
                ]
            }
        },
        "PrioritizedDDQNAgent.__init__": {
            "name": "__init__",
            "location": 55,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_actions": [
                    "str",
                    "None",
                    "int",
                    "tuple[]"
                ],
                "state_shape": [
                    "str",
                    "None",
                    "int",
                    "tuple[]"
                ],
                "gamma": [
                    "float"
                ],
                "target_update_freq": [
                    "int"
                ],
                "prebuilt_model": [
                    "None",
                    "bool",
                    "str",
                    "dict[str, np.ndarray]",
                    "tuple[typing.Union[float,float]]"
                ]
            }
        },
        "PrioritizedDDQNAgent.act": {
            "name": "act",
            "location": 74,
            "return": [],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "dict[str, typing.Any]",
                    "dict[, ]"
                ]
            }
        },
        "PrioritizedDDQNAgent.process_observation": {
            "name": "process_observation",
            "location": 78,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "bool",
                    "float"
                ],
                "action": [
                    "bool",
                    "float"
                ],
                "reward": [
                    "bool",
                    "float"
                ],
                "next_state": [
                    "bool",
                    "float"
                ],
                "done": [
                    "bool",
                    "float"
                ]
            }
        },
        "PrioritizedDDQNAgent.train": {
            "name": "train",
            "location": 83,
            "return": [
                "None",
                "int",
                "str"
            ],
            "arguments": {
                "self": [],
                "step_num": [
                    "int",
                    "typing.Callable[, ]",
                    "float"
                ],
                "batch_size": [
                    "int"
                ],
                "epochs": [
                    "int"
                ]
            }
        },
        "PrioritizedDDQNAgent._update_target_model": {
            "name": "_update_target_model",
            "location": 108,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "PrioritizedDDQNAgent._observations_to_train_data": {
            "name": "_observations_to_train_data",
            "location": 111,
            "return": [
                "tuple[typing.Union[typing.Sequence[int],list[],list[list[]],list[str]]]"
            ],
            "arguments": {
                "self": [],
                "states": [
                    "typing.Sequence[int]",
                    "list[]",
                    "list[list[]]",
                    "list[str]"
                ],
                "actions": [],
                "rewards": [
                    "tuple[typing.Union[int,...]]",
                    "None",
                    "bool",
                    "str"
                ],
                "next_states": [],
                "dones": [
                    "tuple[typing.Union[int,...]]",
                    "None",
                    "bool",
                    "str"
                ]
            }
        },
        "PrioritizedDDQNAgent.Q": {
            "name": "Q",
            "location": 125,
            "return": [],
            "arguments": {
                "self": [],
                "states": [
                    "str",
                    "list[str]"
                ],
                "use_target": [
                    "bool"
                ]
            }
        },
        "PrioritizedDDQNAgent.policy": {
            "name": "policy",
            "location": 138,
            "return": [],
            "arguments": {
                "self": [],
                "states": [
                    "bool",
                    "str",
                    "None",
                    "dict[, ]"
                ],
                "use_target": [
                    "bool"
                ]
            }
        },
        "PrioritizedDDQNAgent.V": {
            "name": "V",
            "location": 142,
            "return": [],
            "arguments": {
                "self": [],
                "states": [
                    "bool"
                ],
                "use_target": [
                    "bool"
                ]
            }
        },
        "PrioritizedDDQNAgent.save": {
            "name": "save",
            "location": 146,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "file_path": [
                    "typing.Text"
                ]
            }
        },
        "PrioritizedDDQNAgent.from_h5": {
            "name": "from_h5",
            "location": 154,
            "return": [
                "PrioritizedDDQNAgent"
            ],
            "arguments": {
                "file_path": [
                    "typing.Text"
                ],
                "gamma": [
                    "float"
                ],
                "target_update_freq": [
                    "int"
                ]
            }
        }
    },
    "my_agents-master/my_agents/agents/prioritized_memory.py": {
        "SumTree.__init__": {
            "name": "__init__",
            "location": 15,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "capacity": [
                    "bytes",
                    "str"
                ]
            }
        },
        "SumTree.add": {
            "name": "add",
            "location": 22,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "priority": [
                    "str",
                    "bool",
                    "dict[, ]",
                    "None"
                ],
                "data": [
                    "dict[, ]",
                    "list[str]",
                    "dict[str, str]"
                ]
            }
        },
        "SumTree.update": {
            "name": "update",
            "location": 36,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "tree_index": [],
                "priority": [
                    "dict[, ]"
                ]
            }
        },
        "SumTree.get_leaf": {
            "name": "get_leaf",
            "location": 46,
            "return": [
                "tuple[int]"
            ],
            "arguments": {
                "self": [],
                "v": [
                    "int",
                    "str",
                    "float",
                    "None"
                ]
            }
        },
        "SumTree.total_priority": {
            "name": "total_priority",
            "location": 73,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "SumTree.max_priority": {
            "name": "max_priority",
            "location": 77,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "SumTree.min_priority": {
            "name": "min_priority",
            "location": 81,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "SumTree.__len__": {
            "name": "__len__",
            "location": 84,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "PrioritizedMemory.__init__": {
            "name": "__init__",
            "location": 95,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "capacity": [
                    "bool",
                    "Exception",
                    "list[str]"
                ],
                "alpha": [
                    "float"
                ],
                "beta": [
                    "float"
                ],
                "max_error": [
                    "float"
                ]
            }
        },
        "PrioritizedMemory.store": {
            "name": "store",
            "location": 103,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "int"
                ]
            }
        },
        "PrioritizedMemory.sample": {
            "name": "sample",
            "location": 110,
            "return": [
                "tuple[list[typing.Union[str,dict[str, dict[str, typing.Any]]]]]"
            ],
            "arguments": {
                "self": [],
                "batch_size": [
                    "int",
                    "float"
                ]
            }
        },
        "PrioritizedMemory.batch_update": {
            "name": "batch_update",
            "location": 141,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "tree_idx": [
                    "bool",
                    "float",
                    "list[]",
                    "list[tuple[typing.Union[float,typing.Any]]]"
                ],
                "abs_errors": [
                    "str",
                    "bool"
                ]
            }
        },
        "PrioritizedMemory.__len__": {
            "name": "__len__",
            "location": 150,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "my_agents-master/my_agents/agents/table_agent.py": {
        "TableAgent.__init__": {
            "name": "__init__",
            "location": 6,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_actions": [
                    "int",
                    "list[int]"
                ],
                "num_states": [
                    "int",
                    "str"
                ],
                "gamma": [
                    "float"
                ],
                "alpha": [
                    "float"
                ]
            }
        },
        "TableAgent.act": {
            "name": "act",
            "location": 14,
            "return": [],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "dict[str, typing.Any]",
                    "dict[, ]"
                ]
            }
        },
        "TableAgent.process_observation": {
            "name": "process_observation",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "bool"
                ],
                "action": [
                    "bool"
                ],
                "reward": [
                    "list[list[str]]",
                    "list[int]",
                    "bool",
                    "str",
                    "None"
                ],
                "next_state": [
                    "str",
                    "int",
                    "list[int]",
                    "tuple[typing.Union[int,int]]",
                    "tuple[typing.Union[float,float]]"
                ],
                "done": [
                    "bool",
                    "list[typing.Callable[, ]]"
                ]
            }
        },
        "TableAgent.train": {
            "name": "train",
            "location": 26,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "step_num": [
                    "bool",
                    "typing.Iterable[T]",
                    "typing.Sequence[str]",
                    "float"
                ]
            }
        },
        "TableAgent.Q": {
            "name": "Q",
            "location": 30,
            "return": [],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "dict[str, typing.Any]",
                    "dict[, ]"
                ]
            }
        },
        "TableAgent.policy": {
            "name": "policy",
            "location": 34,
            "return": [],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "dict[str, typing.Any]",
                    "dict[, ]"
                ]
            }
        },
        "TableAgent.V": {
            "name": "V",
            "location": 38,
            "return": [],
            "arguments": {
                "self": [],
                "state": [
                    "dict[, ]",
                    "float",
                    "int"
                ]
            }
        },
        "TableAgent.print_q_map": {
            "name": "print_q_map",
            "location": 42,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "my_agents-master/my_agents/core/runner.py": {
        "constant_decay_epsilon": {
            "name": "constant_decay_epsilon",
            "location": 20,
            "return": [
                "int",
                "float"
            ],
            "arguments": {
                "epoch": [
                    "int"
                ],
                "initial_epsilon": [
                    "int"
                ],
                "decay_rate": [
                    "float"
                ],
                "min_epsilon": [
                    "float"
                ]
            }
        },
        "Runner.__init__": {
            "name": "__init__",
            "location": 30,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [
                    "str",
                    "typing.Mapping",
                    "list[str]"
                ],
                "serializer": [
                    "str",
                    "typing.Mapping",
                    "list[str]"
                ],
                "agent": [
                    "str",
                    "typing.Mapping",
                    "list[str]"
                ],
                "epsilon_policy": [
                    "typing.Callable[, ]"
                ],
                "training_period": [
                    "int"
                ],
                "max_episode_steps": [
                    "int"
                ]
            }
        },
        "Runner.warm_up": {
            "name": "warm_up",
            "location": 44,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_steps": [
                    "int"
                ]
            }
        },
        "Runner.train": {
            "name": "train",
            "location": 56,
            "return": [],
            "arguments": {
                "self": [],
                "num_epochs": [
                    "int"
                ],
                "num_episodes": [
                    "int",
                    "float",
                    "None",
                    "str"
                ],
                "render_frequency": [
                    "int"
                ]
            }
        },
        "Runner.demonstrate": {
            "name": "demonstrate",
            "location": 69,
            "return": [
                "tuple[]"
            ],
            "arguments": {
                "self": [],
                "num_episodes": [
                    "int",
                    "None"
                ]
            }
        },
        "Runner.render": {
            "name": "render",
            "location": 78,
            "return": [
                "tuple[str]"
            ],
            "arguments": {
                "self": []
            }
        },
        "Runner.history": {
            "name": "history",
            "location": 84,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "Runner.run_episode": {
            "name": "run_episode",
            "location": 87,
            "return": [
                "tuple[typing.Union[int,float,list[]]]"
            ],
            "arguments": {
                "self": [],
                "epsilon": [
                    "float",
                    "int"
                ],
                "training": [
                    "bool"
                ],
                "render": [
                    "bool"
                ]
            }
        },
        "Runner.run_epoch": {
            "name": "run_epoch",
            "location": 119,
            "return": [
                "tuple[typing.Union[list[typing.Union[int,dict[int, typing.Any]]],list[typing.Union[float,int,list[],dict[, ],tuple[typing.Union[typing.Literal,typing.Literal,typing.Literal,typing.Literal]]]],int]]"
            ],
            "arguments": {
                "self": [],
                "epsilon": [
                    "list[str]",
                    "bytes",
                    "int"
                ],
                "num_episodes": [
                    "int"
                ],
                "training": [
                    "bool"
                ],
                "render_frequency": [
                    "int"
                ]
            }
        }
    },
    "my_agents-master/my_agents/core/states.py": {
        "one_hot": {
            "name": "one_hot",
            "location": 3,
            "return": [],
            "arguments": {
                "size": [
                    "str",
                    "int",
                    "float"
                ],
                "idx": [
                    "float",
                    "int",
                    "str"
                ]
            }
        },
        "StateSerializer.__init__": {
            "name": "__init__",
            "location": 16,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_shape": [
                    "str"
                ]
            }
        },
        "StateSerializer.serialize": {
            "name": "serialize",
            "location": 20,
            "return": [
                "int",
                "dict[str, typing.Any]",
                "dict[, ]"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "dict[str, typing.Any]",
                    "dict[, ]"
                ]
            }
        },
        "StateSerializer.deserialize": {
            "name": "deserialize",
            "location": 25,
            "return": [
                "int",
                "dict[str, typing.Any]",
                "dict[, ]"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "dict[str, typing.Any]",
                    "dict[, ]"
                ]
            }
        },
        "StateSerializer.shape": {
            "name": "shape",
            "location": 31,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "StateSerializer.from_num_states": {
            "name": "from_num_states",
            "location": 35,
            "return": [
                "StateSerializer"
            ],
            "arguments": {
                "num_states": [
                    "int",
                    "float"
                ]
            }
        }
    },
    "my_agents-master/my_agents/core/visualization.py": {
        "rolling_mean": {
            "name": "rolling_mean",
            "location": 12,
            "return": [
                "list[]",
                "tuple[typing.Union[typing.Any,typing.Any,typing.Any,typing.Any]]",
                "int"
            ],
            "arguments": {
                "history": [],
                "window": [
                    "int"
                ],
                "label": [
                    "None",
                    "str",
                    "typing.Sequence[typing.Any]",
                    "int"
                ],
                "axis": [
                    "None",
                    "list[list[typing.Callable[, ]]]",
                    "list[]",
                    "int"
                ],
                "show": [
                    "bool"
                ]
            }
        }
    }
}
{
    "Baseline_RL-master/main.py": {
        "main": {
            "name": "main",
            "location": 8,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "Baseline_RL-master/algorithms/A2C.py": {
        "A2C.__init__": {
            "name": "__init__",
            "location": 20,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "model": [],
                "optim": [],
                "device": [],
                "hyperparams": [],
                "tensorboard_path": []
            }
        },
        "A2C.memory_reset": {
            "name": "memory_reset",
            "location": 41,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "A2C.select_action": {
            "name": "select_action",
            "location": 48,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": []
            }
        },
        "A2C.compute_return": {
            "name": "compute_return",
            "location": 61,
            "return": [
                "list"
            ],
            "arguments": {
                "self": [],
                "last_value": []
            }
        },
        "A2C.train_model": {
            "name": "train_model",
            "location": 70,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "last_state": []
            }
        },
        "A2C.train": {
            "name": "train",
            "location": 93,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "Baseline_RL-master/algorithms/DDPG.py": {
        "DDPG.__init__": {
            "name": "__init__",
            "location": 22,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "actor": [],
                "critic": [],
                "target_actor": [],
                "target_critic": [],
                "actor_optim": [],
                "critic_optim": [],
                "device": [],
                "hyperparams": [],
                "tensorboard_path": []
            }
        },
        "DDPG.select_action": {
            "name": "select_action",
            "location": 53,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": []
            }
        },
        "DDPG.train_model": {
            "name": "train_model",
            "location": 60,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPG.train": {
            "name": "train",
            "location": 101,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "Baseline_RL-master/algorithms/DQN.py": {
        "DQN.__init__": {
            "name": "__init__",
            "location": 11,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "online_net": [],
                "target_net": [],
                "optim": [],
                "device": [],
                "hyperparams": [],
                "tensorboard_path": []
            }
        },
        "DQN.decay_epsilon": {
            "name": "decay_epsilon",
            "location": 44,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQN.increase_beta": {
            "name": "increase_beta",
            "location": 47,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQN.select_action": {
            "name": "select_action",
            "location": 50,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": []
            }
        },
        "DQN.train_model": {
            "name": "train_model",
            "location": 60,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQN.train": {
            "name": "train",
            "location": 106,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "Baseline_RL-master/algorithms/PPO.py": {
        "PPO.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "model": [],
                "optim": [],
                "device": [],
                "hyperparams": [],
                "tensorboard_path": []
            }
        },
        "PPO.memory_reset": {
            "name": "memory_reset",
            "location": 41,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "PPO.select_action": {
            "name": "select_action",
            "location": 49,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": []
            }
        },
        "PPO.compute_gae": {
            "name": "compute_gae",
            "location": 64,
            "return": [
                "list"
            ],
            "arguments": {
                "self": [],
                "last_value": []
            }
        },
        "PPO.ppo_iter": {
            "name": "ppo_iter",
            "location": 79,
            "return": [
                "Generator[(Tuple[(Any, Any, Any, Any, Any)], Any, None)]"
            ],
            "arguments": {
                "self": [],
                "states": [],
                "actions": [],
                "log_probs": [],
                "returns": [],
                "advantage": []
            }
        },
        "PPO.ppo_update": {
            "name": "ppo_update",
            "location": 92,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "states": [],
                "actions": [],
                "log_probs": [],
                "returns": [],
                "advantage": []
            }
        },
        "PPO.train_model": {
            "name": "train_model",
            "location": 129,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "last_state": []
            }
        },
        "PPO.train": {
            "name": "train",
            "location": 145,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "Baseline_RL-master/algorithms/TD3.py": {
        "TD3.__init__": {
            "name": "__init__",
            "location": 32,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "actor": [],
                "critic1": [],
                "critic2": [],
                "target_actor": [],
                "target_critic1": [],
                "target_critic2": [],
                "actor_optim": [],
                "critic_optim1": [],
                "critic_optim2": [],
                "device": [],
                "hyperparams": [],
                "tensorboard_path": []
            }
        },
        "TD3.select_action": {
            "name": "select_action",
            "location": 74,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": []
            }
        },
        "TD3.train_model": {
            "name": "train_model",
            "location": 81,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "step": []
            }
        },
        "TD3.train": {
            "name": "train",
            "location": 135,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "Baseline_RL-master/algorithms/models/cnn.py": {
        "CNN.__init__": {
            "name": "__init__",
            "location": 11,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_size": [],
                "output_size": [],
                "conv_layers": [],
                "hidden_sizes": [],
                "hidden_activation": [],
                "output_activation": []
            }
        },
        "CNN.forward": {
            "name": "forward",
            "location": 46,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        }
    },
    "Baseline_RL-master/algorithms/models/mlp.py": {
        "MLP.__init__": {
            "name": "__init__",
            "location": 13,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_size": [],
                "hidden_sizes": [],
                "output_size": [],
                "hidden_activation": [],
                "output_activation": []
            }
        },
        "MLP.forward": {
            "name": "forward",
            "location": 56,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "SepMLP.__init__": {
            "name": "__init__",
            "location": 62,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_size": [],
                "hidden_sizes1": [],
                "hidden_sizes2": [],
                "output_size1": [],
                "output_size2": [],
                "hidden_activation": [],
                "output_activation1": [],
                "output_activation2": []
            }
        },
        "SepMLP.forward": {
            "name": "forward",
            "location": 91,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "ShareMLP.__init__": {
            "name": "__init__",
            "location": 98,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_size": [],
                "hidden_sizes": [],
                "output_sizes1": [],
                "output_sizes2": [],
                "hidden_activation": [],
                "output_activation1": [],
                "output_activation2": []
            }
        },
        "ShareMLP.forward": {
            "name": "forward",
            "location": 142,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "CategoricalDist.__init__": {
            "name": "__init__",
            "location": 151,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_size": [],
                "hidden_sizes": [],
                "output_size": [],
                "hidden_activation": [],
                "output_activation": []
            }
        },
        "CategoricalDist.forward": {
            "name": "forward",
            "location": 167,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "NormalDist.__init__": {
            "name": "__init__",
            "location": 172,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_size": [],
                "hidden_sizes": [],
                "output_size": [],
                "hidden_activation": [],
                "output_activation": [],
                "std": []
            }
        },
        "NormalDist.forward": {
            "name": "forward",
            "location": 190,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "SepNormalDist.__init__": {
            "name": "__init__",
            "location": 196,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_size": [],
                "mu_hidden_sizes": [],
                "sigma_hidden_sizes": [],
                "mu_output_size": [],
                "sigma_output_size": [],
                "hidden_activation": [],
                "mu_output_activation": [],
                "sigma_output_activation": []
            }
        },
        "SepNormalDist.forward": {
            "name": "forward",
            "location": 218,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "ShareNormalDist.__init__": {
            "name": "__init__",
            "location": 224,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_size": [],
                "hidden_sizes": [],
                "mu_output_size": [],
                "sigma_output_size": [],
                "hidden_activation": [],
                "mu_output_activation": [],
                "sigma_output_activation": []
            }
        },
        "ShareNormalDist.forward": {
            "name": "forward",
            "location": 244,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "SepActorCritic.__init__": {
            "name": "__init__",
            "location": 250,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "actor": [],
                "critic": []
            }
        },
        "SepActorCritic.forward": {
            "name": "forward",
            "location": 261,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "ShareActorCritic.__init__": {
            "name": "__init__",
            "location": 268,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_size": [],
                "hidden_sizes": [],
                "actor_output_size": [],
                "critic_output_size": [],
                "dist": [],
                "std": [],
                "hidden_activation": [],
                "actor_output_activation": [],
                "critic_output_activation": []
            }
        },
        "ShareActorCritic.forward": {
            "name": "forward",
            "location": 295,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "DuelingMLP.forward": {
            "name": "forward",
            "location": 310,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": []
            }
        }
    },
    "Baseline_RL-master/algorithms/models/utils.py": {
        "init_linear_weights_xavier": {
            "name": "init_linear_weights_xavier",
            "location": 3,
            "return": [
                "None"
            ],
            "arguments": {
                "m": []
            }
        }
    },
    "Baseline_RL-master/algorithms/utils/buffer.py": {
        "ReplayMemory.__init__": {
            "name": "__init__",
            "location": 5,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "capacity": []
            }
        },
        "ReplayMemory.__len__": {
            "name": "__len__",
            "location": 21,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "ReplayMemory.save": {
            "name": "save",
            "location": 24,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "ReplayMemory.sample": {
            "name": "sample",
            "location": 71,
            "return": [
                "List[nothing]"
            ],
            "arguments": {
                "self": [],
                "n_sample": []
            }
        },
        "PrioritizedReplayMemory.__init__": {
            "name": "__init__",
            "location": 81,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "capacity": [],
                "prob_alpha": []
            }
        },
        "PrioritizedReplayMemory.save": {
            "name": "save",
            "location": 87,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "PrioritizedReplayMemory.sample": {
            "name": "sample",
            "location": 96,
            "return": [
                "list"
            ],
            "arguments": {
                "self": [],
                "batch_size": [],
                "beta": []
            }
        },
        "PrioritizedReplayMemory.update_priorities": {
            "name": "update_priorities",
            "location": 116,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "indices": [],
                "priorities": []
            }
        }
    },
    "Baseline_RL-master/algorithms/utils/noise.py": {
        "GaussianNoise.__init__": {
            "name": "__init__",
            "location": 15,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "action_dim": [],
                "min_sigma": [],
                "max_sigma": [],
                "decay_period": []
            }
        },
        "GaussianNoise.sample": {
            "name": "sample",
            "location": 28,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "t": []
            }
        },
        "OUNoise.__init__": {
            "name": "__init__",
            "location": 46,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "size": [],
                "mu": [],
                "theta": [],
                "sigma": []
            }
        },
        "OUNoise.reset": {
            "name": "reset",
            "location": 56,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "OUNoise.sample": {
            "name": "sample",
            "location": 60,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "Baseline_RL-master/algorithms/utils/update.py": {
        "soft_update": {
            "name": "soft_update",
            "location": 4,
            "return": [
                "None"
            ],
            "arguments": {
                "local": [],
                "target": [],
                "tau": []
            }
        },
        "hard_update": {
            "name": "hard_update",
            "location": 10,
            "return": [
                "None"
            ],
            "arguments": {
                "local": [],
                "target": []
            }
        }
    },
    "Baseline_RL-master/common/logger.py": {},
    "Baseline_RL-master/common/parse.py": {
        "get_config": {
            "name": "get_config",
            "location": 3,
            "return": [
                "argparse.Namespace"
            ],
            "arguments": {}
        }
    },
    "Baseline_RL-master/common/pyinquirer.py": {
        "select_project": {
            "name": "select_project",
            "location": 15,
            "return": [
                "Any"
            ],
            "arguments": {
                "projects_dir": []
            }
        }
    },
    "Baseline_RL-master/common/utils.py": {
        "restore_wandb": {
            "name": "restore_wandb",
            "location": 11,
            "return": [
                "None"
            ],
            "arguments": {
                "user_name": [],
                "project": [],
                "run_id": [],
                "params_path": [],
                "hyperparams_path": []
            }
        },
        "restore_hyperparams": {
            "name": "restore_hyperparams",
            "location": 33,
            "return": [
                "Any"
            ],
            "arguments": {
                "hyperparams_path": []
            }
        },
        "save_hyperparams": {
            "name": "save_hyperparams",
            "location": 42,
            "return": [
                "None"
            ],
            "arguments": {
                "hyperparams": [],
                "hyperparams_path": []
            }
        },
        "restore_model_params": {
            "name": "restore_model_params",
            "location": 48,
            "return": [
                "None"
            ],
            "arguments": {
                "model": [],
                "params_path": []
            }
        },
        "save_model_params": {
            "name": "save_model_params",
            "location": 53,
            "return": [
                "None"
            ],
            "arguments": {
                "model": [],
                "params_path": []
            }
        },
        "save_wandb": {
            "name": "save_wandb",
            "location": 64,
            "return": [
                "None"
            ],
            "arguments": {
                "params_path": [],
                "hyperparams_path": [],
                "video_dir": []
            }
        },
        "check_path_and_make_dir": {
            "name": "check_path_and_make_dir",
            "location": 71,
            "return": [
                "None"
            ],
            "arguments": {
                "path": []
            }
        },
        "remove_dir": {
            "name": "remove_dir",
            "location": 76,
            "return": [
                "None"
            ],
            "arguments": {
                "dir_name": []
            }
        }
    },
    "Baseline_RL-master/common/abstract/base_agent.py": {
        "BaseAgent.__init__": {
            "name": "__init__",
            "location": 9,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "tensorboard_path": []
            }
        },
        "BaseAgent.train": {
            "name": "train",
            "location": 13,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "BaseAgent.test": {
            "name": "test",
            "location": 16,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "BaseAgent.write_log": {
            "name": "write_log",
            "location": 28,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "global_step": []
            }
        }
    },
    "Baseline_RL-master/common/abstract/base_env.py": {
        "worker": {
            "name": "worker",
            "location": 15,
            "return": [
                "None"
            ],
            "arguments": {
                "remote": [],
                "parent_remote": [],
                "env_fn_wrapper": []
            }
        },
        "VecEnv.__init__": {
            "name": "__init__",
            "location": 51,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_envs": [],
                "observation_space": [],
                "action_space": []
            }
        },
        "VecEnv.reset": {
            "name": "reset",
            "location": 56,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "VecEnv.step_async": {
            "name": "step_async",
            "location": 65,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "actions": []
            }
        },
        "VecEnv.step_wait": {
            "name": "step_wait",
            "location": 74,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "VecEnv.close": {
            "name": "close",
            "location": 85,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "VecEnv.step": {
            "name": "step",
            "location": 90,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "actions": []
            }
        },
        "CloudpickleWrapper.__init__": {
            "name": "__init__",
            "location": 99,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "CloudpickleWrapper.__getstate__": {
            "name": "__getstate__",
            "location": 102,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "CloudpickleWrapper.__setstate__": {
            "name": "__setstate__",
            "location": 106,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "ob": []
            }
        },
        "MultipleEnv.__init__": {
            "name": "__init__",
            "location": 111,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env_id": [],
                "n_envs": [],
                "max_episode_steps": [],
                "monitor_func": []
            }
        },
        "MultipleEnv.step_async": {
            "name": "step_async",
            "location": 148,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "actions": []
            }
        },
        "MultipleEnv.step_wait": {
            "name": "step_wait",
            "location": 153,
            "return": [
                "Tuple[(Any, Any, Any, Any)]"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultipleEnv.seed": {
            "name": "seed",
            "location": 159,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "seed": []
            }
        },
        "MultipleEnv.render": {
            "name": "render",
            "location": 169,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultipleEnv.env": {
            "name": "env",
            "location": 174,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultipleEnv.reset": {
            "name": "reset",
            "location": 178,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultipleEnv.reset_task": {
            "name": "reset_task",
            "location": 183,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultipleEnv.random_action": {
            "name": "random_action",
            "location": 188,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultipleEnv.close": {
            "name": "close",
            "location": 193,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultipleEnv._gen_env_func": {
            "name": "_gen_env_func",
            "location": 205,
            "return": [
                "Callable[([], Any)]"
            ],
            "arguments": {
                "self": [],
                "monitor_func": []
            }
        },
        "MultipleEnv._make_env_fns": {
            "name": "_make_env_fns",
            "location": 220,
            "return": [
                "list"
            ],
            "arguments": {
                "self": [],
                "monitor_func": []
            }
        },
        "MultipleEnv._set_space": {
            "name": "_set_space",
            "location": 229,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "observation_space": [],
                "action_space": []
            }
        },
        "MultipleEnv.__len__": {
            "name": "__len__",
            "location": 245,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultipleEnv.env.close": {
            "name": "close",
            "location": 175,
            "return": [],
            "arguments": {}
        },
        "MultipleEnv._gen_env_func._thunk": {
            "name": "_thunk",
            "location": 206,
            "return": [],
            "arguments": {}
        }
    },
    "Baseline_RL-master/common/abstract/base_project.py": {
        "BaseProject.__init__": {
            "name": "__init__",
            "location": 26,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "config": []
            }
        },
        "BaseProject.init_hyperparams": {
            "name": "init_hyperparams",
            "location": 47,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "BaseProject.init_env": {
            "name": "init_env",
            "location": 60,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "hyperparams": []
            }
        },
        "BaseProject.init_model": {
            "name": "init_model",
            "location": 76,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "hyperparams": []
            }
        },
        "BaseProject.init_agent": {
            "name": "init_agent",
            "location": 95,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "model": [],
                "hyperparams": []
            }
        },
        "BaseProject.is_render": {
            "name": "is_render",
            "location": 115,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "BaseProject.is_test": {
            "name": "is_test",
            "location": 119,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "BaseProject.is_load": {
            "name": "is_load",
            "location": 123,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "BaseProject.is_record": {
            "name": "is_record",
            "location": 127,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "BaseProject.monitor_func": {
            "name": "monitor_func",
            "location": 130,
            "return": [
                "Callable[([Any], Any)]"
            ],
            "arguments": {
                "self": [],
                "video_callable": [],
                "force": []
            }
        },
        "BaseProject.run": {
            "name": "run",
            "location": 157,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "BaseProject.monitor_func._func": {
            "name": "_func",
            "location": 140,
            "return": [],
            "arguments": {
                "env": []
            }
        }
    },
    "Baseline_RL-master/environments/atari.py": {
        "cvt_gray_resize_half": {
            "name": "cvt_gray_resize_half",
            "location": 7,
            "return": [
                "Any"
            ],
            "arguments": {
                "frame": [],
                "height": [],
                "width": []
            }
        },
        "Atari.__init__": {
            "name": "__init__",
            "location": 15,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env_id": [],
                "max_episode": [],
                "max_episode_steps": [],
                "recent_score_len": [],
                "monitor_func": [],
                "n_history": [],
                "width": [],
                "height": [],
                "no_op": []
            }
        },
        "Atari._reset": {
            "name": "_reset",
            "location": 42,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": []
            }
        },
        "Atari.reset": {
            "name": "reset",
            "location": 51,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "Atari.step": {
            "name": "step",
            "location": 57,
            "return": [
                "Tuple[(Any, Any, np.ndarray, Any)]"
            ],
            "arguments": {
                "self": [],
                "action": []
            }
        }
    },
    "Baseline_RL-master/environments/gym.py": {
        "Gym.__init__": {
            "name": "__init__",
            "location": 6,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env_id": [],
                "n_envs": [],
                "is_render": [],
                "max_episode": [],
                "max_episode_steps": [],
                "recent_score_len": [],
                "monitor_func": [],
                "clip_action": [],
                "scale_action": []
            }
        },
        "Gym.reset": {
            "name": "reset",
            "location": 55,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "Gym.close": {
            "name": "close",
            "location": 61,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Gym.step": {
            "name": "step",
            "location": 64,
            "return": [
                "Tuple[(Any, Any, Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "action": []
            }
        },
        "Gym.render": {
            "name": "render",
            "location": 111,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Gym.seed": {
            "name": "seed",
            "location": 115,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "seed": []
            }
        },
        "Gym.random_action": {
            "name": "random_action",
            "location": 118,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "Gym.first_env_ep_done": {
            "name": "first_env_ep_done",
            "location": 121,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "Baseline_RL-master/projects/policy_based/A2C_CartPole-v1.py": {
        "Project.init_hyperparams": {
            "name": "init_hyperparams",
            "location": 10,
            "return": [
                "Dict[(str, Union[(float, int, List[int])])]"
            ],
            "arguments": {
                "self": []
            }
        },
        "Project.init_env": {
            "name": "init_env",
            "location": 24,
            "return": [
                "environments.gym.Gym"
            ],
            "arguments": {
                "self": [],
                "hyperparams": []
            }
        },
        "Project.init_model": {
            "name": "init_model",
            "location": 35,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "hyperparams": []
            }
        },
        "Project.init_agent": {
            "name": "init_agent",
            "location": 55,
            "return": [
                "algorithms.A2C.A2C"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "model": [],
                "hyperparams": []
            }
        }
    },
    "Baseline_RL-master/projects/policy_based/DDPG_Pendulum-v0.py": {
        "Project.init_hyperparams": {
            "name": "init_hyperparams",
            "location": 11,
            "return": [
                "Dict[(str, Union[(float, int, List[int])])]"
            ],
            "arguments": {
                "self": []
            }
        },
        "Project.init_env": {
            "name": "init_env",
            "location": 27,
            "return": [
                "environments.gym.Gym"
            ],
            "arguments": {
                "self": [],
                "hyperparams": []
            }
        },
        "Project.init_model": {
            "name": "init_model",
            "location": 39,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "hyperparams": []
            }
        },
        "Project.init_agent": {
            "name": "init_agent",
            "location": 76,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "model": [],
                "hyperparams": []
            }
        }
    },
    "Baseline_RL-master/projects/policy_based/PPO_Acrobot-v1.py": {
        "Project.init_hyperparams": {
            "name": "init_hyperparams",
            "location": 10,
            "return": [
                "Dict[(str, Union[(float, int, List[int])])]"
            ],
            "arguments": {
                "self": []
            }
        },
        "Project.init_env": {
            "name": "init_env",
            "location": 29,
            "return": [
                "environments.gym.Gym"
            ],
            "arguments": {
                "self": [],
                "hyperparams": []
            }
        },
        "Project.init_model": {
            "name": "init_model",
            "location": 38,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "hyperparams": []
            }
        },
        "Project.init_agent": {
            "name": "init_agent",
            "location": 58,
            "return": [
                "algorithms.PPO.PPO"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "models": [],
                "hyperparams": []
            }
        }
    },
    "Baseline_RL-master/projects/policy_based/PPO_BipedalWalker-v2.py": {
        "Project.init_hyperparams": {
            "name": "init_hyperparams",
            "location": 11,
            "return": [
                "Dict[(str, Union[(float, int, List[int])])]"
            ],
            "arguments": {
                "self": []
            }
        },
        "Project.init_env": {
            "name": "init_env",
            "location": 29,
            "return": [
                "environments.gym.Gym"
            ],
            "arguments": {
                "self": [],
                "hyperparams": []
            }
        },
        "Project.init_model": {
            "name": "init_model",
            "location": 39,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "hyperparams": []
            }
        },
        "Project.init_agent": {
            "name": "init_agent",
            "location": 60,
            "return": [
                "algorithms.PPO.PPO"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "models": [],
                "hyperparams": []
            }
        }
    },
    "Baseline_RL-master/projects/policy_based/PPO_LunarLander-v2.py": {
        "Project.init_hyperparams": {
            "name": "init_hyperparams",
            "location": 12,
            "return": [
                "Dict[(str, Union[(float, int, List[int])])]"
            ],
            "arguments": {
                "self": []
            }
        },
        "Project.init_env": {
            "name": "init_env",
            "location": 31,
            "return": [
                "environments.gym.Gym"
            ],
            "arguments": {
                "self": [],
                "hyperparams": []
            }
        },
        "Project.init_model": {
            "name": "init_model",
            "location": 40,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "hyperparams": []
            }
        },
        "Project.init_agent": {
            "name": "init_agent",
            "location": 61,
            "return": [
                "algorithms.PPO.PPO"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "models": [],
                "hyperparams": []
            }
        }
    },
    "Baseline_RL-master/projects/policy_based/PPO_Pendulum-v0.py": {
        "Project.init_hyperparams": {
            "name": "init_hyperparams",
            "location": 11,
            "return": [
                "Dict[(str, Union[(float, int, List[int])])]"
            ],
            "arguments": {
                "self": []
            }
        },
        "Project.init_env": {
            "name": "init_env",
            "location": 29,
            "return": [
                "environments.gym.Gym"
            ],
            "arguments": {
                "self": [],
                "hyperparams": []
            }
        },
        "Project.init_model": {
            "name": "init_model",
            "location": 39,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "hyperparams": []
            }
        },
        "Project.init_agent": {
            "name": "init_agent",
            "location": 60,
            "return": [
                "algorithms.PPO.PPO"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "models": [],
                "hyperparams": []
            }
        }
    },
    "Baseline_RL-master/projects/policy_based/PPO_RoboschoolHalfCheetah-v1.py": {
        "Project.init_hyperparams": {
            "name": "init_hyperparams",
            "location": 11,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": []
            }
        },
        "Project.init_env": {
            "name": "init_env",
            "location": 31,
            "return": [
                "environments.gym.Gym"
            ],
            "arguments": {
                "self": [],
                "hyperparams": []
            }
        },
        "Project.init_model": {
            "name": "init_model",
            "location": 42,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "hyperparams": []
            }
        },
        "Project.init_agent": {
            "name": "init_agent",
            "location": 63,
            "return": [
                "algorithms.PPO.PPO"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "models": [],
                "hyperparams": []
            }
        }
    },
    "Baseline_RL-master/projects/policy_based/TD3_BipedalWalker-v2.py": {
        "Project.init_hyperparams": {
            "name": "init_hyperparams",
            "location": 14,
            "return": [
                "Dict[(str, Union[(float, int, List[int])])]"
            ],
            "arguments": {
                "self": []
            }
        },
        "Project.init_env": {
            "name": "init_env",
            "location": 33,
            "return": [
                "environments.gym.Gym"
            ],
            "arguments": {
                "self": [],
                "hyperparams": []
            }
        },
        "Project.init_model": {
            "name": "init_model",
            "location": 43,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "hyperparams": []
            }
        },
        "Project.init_agent": {
            "name": "init_agent",
            "location": 99,
            "return": [
                "algorithms.TD3.TD3"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "models": [],
                "hyperparams": []
            }
        }
    },
    "Baseline_RL-master/projects/policy_based/TD3_Pendulum-v0.py": {
        "Project.init_hyperparams": {
            "name": "init_hyperparams",
            "location": 14,
            "return": [
                "Dict[(str, Union[(float, int, List[int])])]"
            ],
            "arguments": {
                "self": []
            }
        },
        "Project.init_env": {
            "name": "init_env",
            "location": 33,
            "return": [
                "environments.gym.Gym"
            ],
            "arguments": {
                "self": [],
                "hyperparams": []
            }
        },
        "Project.init_model": {
            "name": "init_model",
            "location": 43,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "hyperparams": []
            }
        },
        "Project.init_agent": {
            "name": "init_agent",
            "location": 96,
            "return": [
                "algorithms.TD3.TD3"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "models": [],
                "hyperparams": []
            }
        }
    },
    "Baseline_RL-master/projects/value_based/DoubleDQN_CartPole-v1.py": {
        "Project.init_hyperparams": {
            "name": "init_hyperparams",
            "location": 10,
            "return": [
                "Dict[(str, Union[(float, int, List[int])])]"
            ],
            "arguments": {
                "self": []
            }
        },
        "Project.init_env": {
            "name": "init_env",
            "location": 29,
            "return": [
                "environments.gym.Gym"
            ],
            "arguments": {
                "self": [],
                "hyperparams": []
            }
        },
        "Project.init_model": {
            "name": "init_model",
            "location": 40,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "hyperparams": []
            }
        },
        "Project.init_agent": {
            "name": "init_agent",
            "location": 57,
            "return": [
                "algorithms.DQN.DQN"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "model": [],
                "hyperparams": []
            }
        },
        "Project.init_model.modeling": {
            "name": "modeling",
            "location": 41,
            "return": [],
            "arguments": {}
        }
    },
    "Baseline_RL-master/projects/value_based/DQN_BreakoutDeterministic-v4.py": {
        "Project.init_hyperparams": {
            "name": "init_hyperparams",
            "location": 10,
            "return": [
                "Dict[(str, Union[(float, int)])]"
            ],
            "arguments": {
                "self": []
            }
        },
        "Project.init_env": {
            "name": "init_env",
            "location": 27,
            "return": [
                "environments.atari.Atari"
            ],
            "arguments": {
                "self": [],
                "hyperparams": []
            }
        },
        "Project.init_model": {
            "name": "init_model",
            "location": 40,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "hyperparams": []
            }
        },
        "Project.init_agent": {
            "name": "init_agent",
            "location": 64,
            "return": [
                "algorithms.DQN.DQN"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "model": [],
                "hyperparams": []
            }
        },
        "Project.init_model.modeling": {
            "name": "modeling",
            "location": 42,
            "return": [],
            "arguments": {}
        }
    },
    "Baseline_RL-master/projects/value_based/DQN_CartPole-v1.py": {
        "Project.init_hyperparams": {
            "name": "init_hyperparams",
            "location": 10,
            "return": [
                "Dict[(str, Union[(float, int, List[int])])]"
            ],
            "arguments": {
                "self": []
            }
        },
        "Project.init_env": {
            "name": "init_env",
            "location": 28,
            "return": [
                "environments.gym.Gym"
            ],
            "arguments": {
                "self": [],
                "hyperparams": []
            }
        },
        "Project.init_model": {
            "name": "init_model",
            "location": 39,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "hyperparams": []
            }
        },
        "Project.init_agent": {
            "name": "init_agent",
            "location": 56,
            "return": [
                "algorithms.DQN.DQN"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "model": [],
                "hyperparams": []
            }
        },
        "Project.init_model.modeling": {
            "name": "modeling",
            "location": 40,
            "return": [],
            "arguments": {}
        }
    },
    "Baseline_RL-master/projects/value_based/DuelingDQN_CartPole-v1.py": {
        "Project.init_hyperparams": {
            "name": "init_hyperparams",
            "location": 10,
            "return": [
                "Dict[(str, Union[(float, int, List[int])])]"
            ],
            "arguments": {
                "self": []
            }
        },
        "Project.init_env": {
            "name": "init_env",
            "location": 28,
            "return": [
                "environments.gym.Gym"
            ],
            "arguments": {
                "self": [],
                "hyperparams": []
            }
        },
        "Project.init_model": {
            "name": "init_model",
            "location": 39,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "hyperparams": []
            }
        },
        "Project.init_agent": {
            "name": "init_agent",
            "location": 57,
            "return": [
                "algorithms.DQN.DQN"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "model": [],
                "hyperparams": []
            }
        },
        "Project.init_model.modeling": {
            "name": "modeling",
            "location": 40,
            "return": [],
            "arguments": {}
        }
    },
    "Baseline_RL-master/projects/value_based/PER_DQN_CartPole-v1.py": {
        "Project.init_hyperparams": {
            "name": "init_hyperparams",
            "location": 10,
            "return": [
                "Dict[(str, Union[(float, int, List[int])])]"
            ],
            "arguments": {
                "self": []
            }
        },
        "Project.init_env": {
            "name": "init_env",
            "location": 32,
            "return": [
                "environments.gym.Gym"
            ],
            "arguments": {
                "self": [],
                "hyperparams": []
            }
        },
        "Project.init_model": {
            "name": "init_model",
            "location": 43,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "hyperparams": []
            }
        },
        "Project.init_agent": {
            "name": "init_agent",
            "location": 60,
            "return": [
                "algorithms.DQN.DQN"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "model": [],
                "hyperparams": []
            }
        },
        "Project.init_model.modeling": {
            "name": "modeling",
            "location": 44,
            "return": [],
            "arguments": {}
        }
    }
}
{
    "Multi-Agent-DRL-master/src/agent.py": {
        "Agent.__init__": {
            "name": "__init__",
            "location": 16,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "config": [],
                "ckpt_path": []
            }
        },
        "Agent.learn": {
            "name": "learn",
            "location": 31,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent.remember": {
            "name": "remember",
            "location": 34,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "action": [],
                "reward": [],
                "next_state": []
            }
        },
        "Agent.act": {
            "name": "act",
            "location": 37,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "epsilon": []
            }
        },
        "Agent.close": {
            "name": "close",
            "location": 55,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "save_model_path": []
            }
        }
    },
    "Multi-Agent-DRL-master/src/cpr_environment.py": {
        "CPREnvironment.__init__": {
            "name": "__init__",
            "location": 10,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "conf": []
            }
        },
        "CPREnvironment.growth": {
            "name": "growth",
            "location": 21,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "N": []
            }
        },
        "CPREnvironment.harvest": {
            "name": "harvest",
            "location": 24,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "x": [],
                "N": []
            }
        },
        "CPREnvironment.reward": {
            "name": "reward",
            "location": 28,
            "return": [
                "list"
            ],
            "arguments": {
                "self": [],
                "delta_n": [],
                "pis": []
            }
        },
        "CPREnvironment.step": {
            "name": "step",
            "location": 37,
            "return": [
                "Tuple[(List[list], Any, bool)]"
            ],
            "arguments": {
                "self": [],
                "xs": []
            }
        },
        "CPREnvironment.reset": {
            "name": "reset",
            "location": 55,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "CPREnvironment.reward.step_func": {
            "name": "step_func",
            "location": 29,
            "return": [],
            "arguments": {
                "x": []
            }
        }
    },
    "Multi-Agent-DRL-master/src/helper.py": {
        "save_result": {
            "name": "save_result",
            "location": 4,
            "return": [
                "None"
            ],
            "arguments": {
                "result_dict": [],
                "save_path": []
            }
        }
    },
    "Multi-Agent-DRL-master/src/main.py": {
        "main": {
            "name": "main",
            "location": 14,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "Multi-Agent-DRL-master/src/step_counter.py": {
        "StepCounter.__init__": {
            "name": "__init__",
            "location": 2,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "StepCounter.reset": {
            "name": "reset",
            "location": 5,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "StepCounter.start": {
            "name": "start",
            "location": 8,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "Multi-Agent-DRL-master/src/model/base_model.py": {
        "BaseModel.__init__": {
            "name": "__init__",
            "location": 6,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "model_id": [],
                "config": [],
                "ckpt_path": []
            }
        },
        "BaseModel._build_graph": {
            "name": "_build_graph",
            "location": 44,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "BaseModel.fit": {
            "name": "fit",
            "location": 51,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "BaseModel.predict": {
            "name": "predict",
            "location": 58,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "epsilon": []
            }
        },
        "BaseModel.save_transition": {
            "name": "save_transition",
            "location": 62,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "action": [],
                "reward": [],
                "next_state": []
            }
        },
        "BaseModel.save_model": {
            "name": "save_model",
            "location": 65,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "path": []
            }
        },
        "BaseModel.close": {
            "name": "close",
            "location": 71,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "Multi-Agent-DRL-master/src/model/ddpg.py": {
        "DDPGModel.__init__": {
            "name": "__init__",
            "location": 19,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "aid": [],
                "config": [],
                "ckpt_path": []
            }
        },
        "DDPGModel._build_graph": {
            "name": "_build_graph",
            "location": 36,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGModel.__build_actor_nn": {
            "name": "__build_actor_nn",
            "location": 119,
            "return": [],
            "arguments": {
                "self": [],
                "state": [],
                "scope": [],
                "phase": [],
                "trainable": []
            }
        },
        "DDPGModel.__build_critic": {
            "name": "__build_critic",
            "location": 166,
            "return": [],
            "arguments": {
                "state": [],
                "action": [],
                "scope": [],
                "phase": [],
                "trainable": []
            }
        },
        "DDPGModel.save_transition": {
            "name": "save_transition",
            "location": 205,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "action": [],
                "reward": [],
                "state_next": []
            }
        },
        "DDPGModel.get_sample_batch": {
            "name": "get_sample_batch",
            "location": 211,
            "return": [
                "Tuple[(Any, Any, Any, Any)]"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGModel.fit": {
            "name": "fit",
            "location": 228,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGModel.predict": {
            "name": "predict",
            "location": 244,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "epsilon": []
            }
        }
    },
    "Multi-Agent-DRL-master/src/model/dqn.py": {
        "DQNModel.__init__": {
            "name": "__init__",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "aid": [],
                "config": [],
                "ckpt_path": []
            }
        },
        "DQNModel._build_graph": {
            "name": "_build_graph",
            "location": 27,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQNModel.fit": {
            "name": "fit",
            "location": 164,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQNModel.save_transition": {
            "name": "save_transition",
            "location": 198,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "action": [],
                "reward": [],
                "state_next": []
            }
        },
        "DQNModel.update_q": {
            "name": "update_q",
            "location": 207,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQNModel.predict": {
            "name": "predict",
            "location": 213,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "epsilon": []
            }
        }
    },
    "Multi-Agent-DRL-master/src/model/drqn_agent.py": {
        "DRQNAgent.__init__": {
            "name": "__init__",
            "location": 22,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "name": [],
                "opt": [],
                "learning_mode": []
            }
        },
        "DRQNAgent._build_model": {
            "name": "_build_model",
            "location": 29,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DRQNAgent.update_q": {
            "name": "update_q",
            "location": 114,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DRQNAgent.learn": {
            "name": "learn",
            "location": 120,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "global_step": []
            }
        },
        "DRQNAgent.choose_action": {
            "name": "choose_action",
            "location": 148,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": []
            }
        },
        "DRQNAgent.save_transition": {
            "name": "save_transition",
            "location": 158,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "step": [],
                "state": [],
                "action": [],
                "reward": [],
                "done": []
            }
        }
    },
    "Multi-Agent-DRL-master/src/model/model_factory.py": {
        "ModelFactory.__init__": {
            "name": "__init__",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "uid": [],
                "config": [],
                "ckpt_path": []
            }
        },
        "ModelFactory.get_model": {
            "name": "get_model",
            "location": 12,
            "return": [
                "Union[(model.ddpg.DDPGModel, model.dqn.DQNModel)]"
            ],
            "arguments": {
                "self": [],
                "model_type": []
            }
        }
    },
    "Multi-Agent-DRL-master/src/model/rdpg_agent.py": {
        "RDPGAgent.__init__": {
            "name": "__init__",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "name": [],
                "opt": [],
                "learning_mode": []
            }
        },
        "RDPGAgent._build_model": {
            "name": "_build_model",
            "location": 26,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "RDPGAgent.__build_actor_nn": {
            "name": "__build_actor_nn",
            "location": 63,
            "return": [],
            "arguments": {
                "self": [],
                "state": [],
                "scope": [],
                "trainable": []
            }
        },
        "RDPGAgent.__build_critic": {
            "name": "__build_critic",
            "location": 99,
            "return": [],
            "arguments": {
                "self": [],
                "state": [],
                "action": [],
                "scope": [],
                "trainable": []
            }
        },
        "RDPGAgent.save_transition": {
            "name": "save_transition",
            "location": 131,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "states": [],
                "actions": [],
                "rewards": []
            }
        },
        "RDPGAgent.get_sample_batch": {
            "name": "get_sample_batch",
            "location": 140,
            "return": [
                "Tuple[(Any, Any, Any, Any)]"
            ],
            "arguments": {
                "self": []
            }
        },
        "RDPGAgent.learn": {
            "name": "learn",
            "location": 149,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "global_step": []
            }
        },
        "RDPGAgent.choose_action": {
            "name": "choose_action",
            "location": 163,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "action_upper_bound": []
            }
        }
    },
    "Multi-Agent-DRL-master/src/model/__init__.py": {}
}
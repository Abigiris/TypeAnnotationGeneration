{
    "literate-lamp-master/literate_lamp/args.py": {
        "list_models": {
            "name": "list_models",
            "location": 12,
            "return": [
                "None"
            ],
            "arguments": {
                "models": []
            }
        },
        "get_args": {
            "name": "get_args",
            "location": 19,
            "return": [
                "Any"
            ],
            "arguments": {
                "arguments": []
            }
        },
        "get_args.preprocessed_name": {
            "name": "preprocessed_name",
            "location": 138,
            "return": [],
            "arguments": {
                "split_type": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/common.py": {
        "set_args": {
            "name": "set_args",
            "location": 30,
            "return": [
                "None"
            ],
            "arguments": {
                "args": []
            }
        },
        "get_seq2seq": {
            "name": "get_seq2seq",
            "location": 35,
            "return": [
                "Any"
            ],
            "arguments": {
                "encoder_type": []
            }
        },
        "get_encoder": {
            "name": "get_encoder",
            "location": 48,
            "return": [
                "Any"
            ],
            "arguments": {
                "encoder_type": []
            }
        },
        "get_word_embeddings": {
            "name": "get_word_embeddings",
            "location": 64,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocabulary": []
            }
        },
        "build_dmn": {
            "name": "build_dmn",
            "location": 81,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocabulary": []
            }
        },
        "build_relational_xl": {
            "name": "build_relational_xl",
            "location": 115,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocabulary": []
            }
        },
        "build_advanced_xlnet": {
            "name": "build_advanced_xlnet",
            "location": 167,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_simple_xlnet": {
            "name": "build_simple_xlnet",
            "location": 210,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocabulary": []
            }
        },
        "build_dcmn": {
            "name": "build_dcmn",
            "location": 219,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocabulary": []
            }
        },
        "build_rel_han": {
            "name": "build_rel_han",
            "location": 242,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_relational_transformer": {
            "name": "build_relational_transformer",
            "location": 341,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_hierarchical_attn_net": {
            "name": "build_hierarchical_attn_net",
            "location": 427,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_advanced_attn_bert": {
            "name": "build_advanced_attn_bert",
            "location": 499,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_hierarchical_bert": {
            "name": "build_hierarchical_bert",
            "location": 554,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_zero_trian": {
            "name": "build_zero_trian",
            "location": 605,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_simple_trian": {
            "name": "build_simple_trian",
            "location": 694,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_advanced_bert": {
            "name": "build_advanced_bert",
            "location": 785,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_simple_bert": {
            "name": "build_simple_bert",
            "location": 830,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_baseline": {
            "name": "build_baseline",
            "location": 846,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_attentive_reader": {
            "name": "build_attentive_reader",
            "location": 869,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "build_trian": {
            "name": "build_trian",
            "location": 898,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocab": []
            }
        },
        "create_reader": {
            "name": "create_reader",
            "location": 998,
            "return": [
                "Any"
            ],
            "arguments": {
                "reader_type": []
            }
        },
        "get_modelfn_reader": {
            "name": "get_modelfn_reader",
            "location": 1063,
            "return": [
                "Tuple[(Callable[([Any], Any)], str)]"
            ],
            "arguments": {}
        },
        "split_list": {
            "name": "split_list",
            "location": 1071,
            "return": [
                "collections.defaultdict"
            ],
            "arguments": {
                "data": []
            }
        },
        "evaluate": {
            "name": "evaluate",
            "location": 1081,
            "return": [
                "None"
            ],
            "arguments": {
                "model": [],
                "reader": [],
                "test_data": []
            }
        },
        "print_dmn_instance": {
            "name": "print_dmn_instance",
            "location": 1111,
            "return": [
                "None"
            ],
            "arguments": {
                "instance": [],
                "prediction": []
            }
        },
        "print_base_instance": {
            "name": "print_base_instance",
            "location": 1124,
            "return": [
                "None"
            ],
            "arguments": {
                "instance": [],
                "prediction": []
            }
        },
        "process_dmn_list": {
            "name": "process_dmn_list",
            "location": 1137,
            "return": [
                "str"
            ],
            "arguments": {
                "fields": []
            }
        },
        "print_xlnet_instance": {
            "name": "print_xlnet_instance",
            "location": 1143,
            "return": [
                "None"
            ],
            "arguments": {
                "instance": [],
                "probability": []
            }
        },
        "process_bert_list": {
            "name": "process_bert_list",
            "location": 1168,
            "return": [
                "Tuple[(str, Any, Any)]"
            ],
            "arguments": {
                "fields": []
            }
        },
        "print_bert_instance": {
            "name": "print_bert_instance",
            "location": 1181,
            "return": [
                "None"
            ],
            "arguments": {
                "instance": [],
                "prediction": []
            }
        },
        "error_analysis": {
            "name": "error_analysis",
            "location": 1195,
            "return": [
                "None"
            ],
            "arguments": {
                "model": [],
                "test_data": [],
                "sample_size": []
            }
        },
        "print_instance": {
            "name": "print_instance",
            "location": 1231,
            "return": [
                "None"
            ],
            "arguments": {
                "passage_id": [],
                "question_id": [],
                "question_type": [],
                "passage": [],
                "question": [],
                "answer1": [],
                "answer2": [],
                "probability": [],
                "label": []
            }
        },
        "print_xlnet_instance.clean": {
            "name": "clean",
            "location": 1146,
            "return": [],
            "arguments": {
                "string": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/conceptnet.py": {
        "triple_as_sentence": {
            "name": "triple_as_sentence",
            "location": 95,
            "return": [
                "str"
            ],
            "arguments": {
                "triple": []
            }
        },
        "ConceptNet.__init__": {
            "name": "__init__",
            "location": 19,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "conceptnet_path": []
            }
        },
        "ConceptNet.get_relation": {
            "name": "get_relation",
            "location": 35,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "word1": [],
                "word2": []
            }
        },
        "ConceptNet.get_all_text_query_triples": {
            "name": "get_all_text_query_triples",
            "location": 50,
            "return": [
                "Set[Tuple[(Any, Any, Any)]]"
            ],
            "arguments": {
                "self": [],
                "text": [],
                "query": []
            }
        },
        "ConceptNet.get_text_query_relations": {
            "name": "get_text_query_relations",
            "location": 73,
            "return": [
                "list"
            ],
            "arguments": {
                "self": [],
                "text": [],
                "query": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/graph.py": {
        "main": {
            "name": "main",
            "location": 5,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "literate-lamp-master/literate_lamp/layers.py": {
        "learned_embeddings": {
            "name": "learned_embeddings",
            "location": 243,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocab": [],
                "dimension": [],
                "namespace": []
            }
        },
        "bert_embeddings": {
            "name": "bert_embeddings",
            "location": 253,
            "return": [
                "Any"
            ],
            "arguments": {
                "pretrained_model": [],
                "training": [],
                "top_layer_only": []
            }
        },
        "xlnet_embeddings": {
            "name": "xlnet_embeddings",
            "location": 269,
            "return": [
                "Any"
            ],
            "arguments": {
                "config_path": [],
                "model_path": [],
                "window_size": [],
                "training": [],
                "top_layer_only": []
            }
        },
        "glove_embeddings": {
            "name": "glove_embeddings",
            "location": 289,
            "return": [
                "Any"
            ],
            "arguments": {
                "vocab": [],
                "file_path": [],
                "dimension": [],
                "training": [],
                "namespace": []
            }
        },
        "lstm_seq2seq": {
            "name": "lstm_seq2seq",
            "location": 303,
            "return": [
                "Any"
            ],
            "arguments": {
                "input_dim": [],
                "output_dim": [],
                "num_layers": [],
                "bidirectional": [],
                "dropout": []
            }
        },
        "gru_seq2seq": {
            "name": "gru_seq2seq",
            "location": 315,
            "return": [
                "Any"
            ],
            "arguments": {
                "input_dim": [],
                "output_dim": [],
                "num_layers": [],
                "bidirectional": [],
                "dropout": []
            }
        },
        "transformer_seq2seq": {
            "name": "transformer_seq2seq",
            "location": 327,
            "return": [
                "Any"
            ],
            "arguments": {
                "input_dim": [],
                "model_dim": [],
                "feedforward_hidden_dim": [],
                "num_layers": [],
                "projection_dim": [],
                "num_attention_heads": [],
                "ttype": [],
                "dropout": []
            }
        },
        "lstm_encoder": {
            "name": "lstm_encoder",
            "location": 358,
            "return": [
                "Any"
            ],
            "arguments": {
                "input_dim": [],
                "output_dim": [],
                "num_layers": [],
                "bidirectional": [],
                "dropout": []
            }
        },
        "gru_encoder": {
            "name": "gru_encoder",
            "location": 370,
            "return": [
                "Any"
            ],
            "arguments": {
                "input_dim": [],
                "output_dim": [],
                "num_layers": [],
                "bidirectional": [],
                "dropout": []
            }
        },
        "cnn_encoder": {
            "name": "cnn_encoder",
            "location": 382,
            "return": [
                "Any"
            ],
            "arguments": {
                "input_dim": [],
                "output_dim": [],
                "num_filters": [],
                "ngram_filter_sizes": []
            }
        },
        "BilinearMatrixAttention.__init__": {
            "name": "__init__",
            "location": 52,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "matrix1_dim": [],
                "matrix2_dim": [],
                "normalise": []
            }
        },
        "BilinearMatrixAttention._forward_internal": {
            "name": "_forward_internal",
            "location": 61,
            "return": [],
            "arguments": {
                "self": [],
                "matrix1": [],
                "matrix2": []
            }
        },
        "LinearAttention.__init__": {
            "name": "__init__",
            "location": 78,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [],
                "bias": []
            }
        },
        "LinearAttention.forward": {
            "name": "forward",
            "location": 85,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "inputs": [],
                "mask": []
            }
        },
        "LinearAttention.get_input_dim": {
            "name": "get_input_dim",
            "location": 116,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "LinearAttention.get_output_dim": {
            "name": "get_output_dim",
            "location": 120,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "LinearSelfAttention.__init__": {
            "name": "__init__",
            "location": 147,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [],
                "normalise": [],
                "bias": []
            }
        },
        "LinearSelfAttention._forward_internal": {
            "name": "_forward_internal",
            "location": 157,
            "return": [],
            "arguments": {
                "self": [],
                "vector": [],
                "_": []
            }
        },
        "BilinearAttention.__init__": {
            "name": "__init__",
            "location": 186,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vector_dim": [],
                "matrix_dim": [],
                "normalise": []
            }
        },
        "BilinearAttention._forward_internal": {
            "name": "_forward_internal",
            "location": 195,
            "return": [],
            "arguments": {
                "self": [],
                "vector": [],
                "matrix": []
            }
        },
        "SequenceAttention.__init__": {
            "name": "__init__",
            "location": 225,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [],
                "activation": [],
                "normalise": []
            }
        },
        "SequenceAttention._forward_internal": {
            "name": "_forward_internal",
            "location": 235,
            "return": [],
            "arguments": {
                "self": [],
                "u": [],
                "v": []
            }
        },
        "MultiHeadAttention.__init__": {
            "name": "__init__",
            "location": 430,
            "return": [],
            "arguments": {
                "self": [],
                "num_heads": [],
                "query_input_dim": [],
                "key_input_dim": [],
                "value_input_dim": [],
                "attention_dim": [],
                "values_dim": [],
                "output_projection_dim": [],
                "attention_dropout_prob": []
            }
        },
        "MultiHeadAttention.get_input_dim": {
            "name": "get_input_dim",
            "location": 471,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultiHeadAttention.get_output_dim": {
            "name": "get_output_dim",
            "location": 474,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultiHeadAttention.is_bidirectional": {
            "name": "is_bidirectional",
            "location": 478,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "MultiHeadAttention.forward": {
            "name": "forward",
            "location": 482,
            "return": [],
            "arguments": {
                "self": [],
                "keys": [],
                "queries": [],
                "values": [],
                "mask": []
            }
        },
        "HeterogenousSequenceAttention.__init__": {
            "name": "__init__",
            "location": 597,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "u_input_dim": [],
                "v_input_dim": [],
                "projection_dim": [],
                "activation": []
            }
        },
        "HeterogenousSequenceAttention.get_input_dim": {
            "name": "get_input_dim",
            "location": 612,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "HeterogenousSequenceAttention.get_output_dim": {
            "name": "get_output_dim",
            "location": 615,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "HeterogenousSequenceAttention.is_bidirectional": {
            "name": "is_bidirectional",
            "location": 619,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "HeterogenousSequenceAttention.forward": {
            "name": "forward",
            "location": 623,
            "return": [],
            "arguments": {
                "self": [],
                "u": [],
                "v": [],
                "v_mask": []
            }
        },
        "MultiHeadAttentionV2.__init__": {
            "name": "__init__",
            "location": 668,
            "return": [],
            "arguments": {
                "self": [],
                "num_heads": [],
                "u_input_dim": [],
                "v_input_dim": [],
                "attention_dim": [],
                "output_projection_dim": [],
                "attention_dropout_prob": []
            }
        },
        "MultiHeadAttentionV2.get_input_dim": {
            "name": "get_input_dim",
            "location": 696,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultiHeadAttentionV2.get_output_dim": {
            "name": "get_output_dim",
            "location": 699,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultiHeadAttentionV2.is_bidirectional": {
            "name": "is_bidirectional",
            "location": 703,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "MultiHeadAttentionV2._reshape_outputs": {
            "name": "_reshape_outputs",
            "location": 706,
            "return": [],
            "arguments": {
                "self": [],
                "outputs": []
            }
        },
        "MultiHeadAttentionV2._reshape_heads": {
            "name": "_reshape_heads",
            "location": 724,
            "return": [],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "MultiHeadAttentionV2._multiply_and_mask": {
            "name": "_multiply_and_mask",
            "location": 737,
            "return": [],
            "arguments": {
                "self": [],
                "q": [],
                "k": [],
                "k_mask": []
            }
        },
        "MultiHeadAttentionV2.forward": {
            "name": "forward",
            "location": 754,
            "return": [],
            "arguments": {
                "self": [],
                "u": [],
                "v": [],
                "u_mask": [],
                "v_mask": []
            }
        },
        "TransformerEncoderBlock.__init__": {
            "name": "__init__",
            "location": 826,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "model_dim": [],
                "attention_dim": [],
                "num_heads": [],
                "feedforward_dim": [],
                "dropout": []
            }
        },
        "TransformerEncoderBlock.forward": {
            "name": "forward",
            "location": 856,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "src": [],
                "src_mask": []
            }
        },
        "RelationTransformerEncoderBlock.__init__": {
            "name": "__init__",
            "location": 871,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "model_dim": [],
                "attention_dim": [],
                "num_heads": [],
                "feedforward_dim": [],
                "dropout": []
            }
        },
        "RelationTransformerEncoderBlock._second_stage": {
            "name": "_second_stage",
            "location": 899,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "x": [],
                "attn": []
            }
        },
        "RelationTransformerEncoderBlock.forward": {
            "name": "forward",
            "location": 909,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "src": [],
                "aux": [],
                "src_mask": [],
                "aux_mask": []
            }
        },
        "TransformerEncoder.__init__": {
            "name": "__init__",
            "location": 958,
            "return": [],
            "arguments": {
                "self": [],
                "input_dim": [],
                "model_dim": [],
                "feedforward_hidden_dim": [],
                "num_layers": [],
                "num_attention_heads": [],
                "dropout_prob": []
            }
        },
        "TransformerEncoder._reset_parameters": {
            "name": "_reset_parameters",
            "location": 984,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TransformerEncoder.get_input_dim": {
            "name": "get_input_dim",
            "location": 990,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "TransformerEncoder.get_output_dim": {
            "name": "get_output_dim",
            "location": 994,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "TransformerEncoder.is_bidirectional": {
            "name": "is_bidirectional",
            "location": 998,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TransformerEncoder.forward": {
            "name": "forward",
            "location": 1002,
            "return": [],
            "arguments": {
                "self": [],
                "inputs": [],
                "mask": []
            }
        },
        "RelationalTransformerEncoder.__init__": {
            "name": "__init__",
            "location": 1057,
            "return": [],
            "arguments": {
                "self": [],
                "src_input_dim": [],
                "kb_input_dim": [],
                "model_dim": [],
                "feedforward_hidden_dim": [],
                "num_layers": [],
                "num_attention_heads": [],
                "dropout_prob": [],
                "return_kb": []
            }
        },
        "RelationalTransformerEncoder._reset_parameters": {
            "name": "_reset_parameters",
            "location": 1099,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "RelationalTransformerEncoder.get_input_dim": {
            "name": "get_input_dim",
            "location": 1105,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "RelationalTransformerEncoder.get_output_dim": {
            "name": "get_output_dim",
            "location": 1109,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "RelationalTransformerEncoder.is_bidirectional": {
            "name": "is_bidirectional",
            "location": 1113,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "RelationalTransformerEncoder.forward": {
            "name": "forward",
            "location": 1117,
            "return": [],
            "arguments": {
                "self": [],
                "src": [],
                "kb": [],
                "src_mask": [],
                "kb_mask": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/play.py": {
        "main": {
            "name": "main",
            "location": 15,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "literate-lamp-master/literate_lamp/predictor.py": {
        "score_questions": {
            "name": "score_questions",
            "location": 58,
            "return": [
                "float"
            ],
            "arguments": {
                "model": [],
                "output_file": [],
                "testset": []
            }
        },
        "McScriptPredictor.predict": {
            "name": "predict",
            "location": 19,
            "return": [],
            "arguments": {
                "self": [],
                "passage_id": [],
                "question_id": [],
                "question_type": [],
                "passage": [],
                "question": [],
                "answer0": [],
                "answer1": []
            }
        },
        "McScriptPredictor._json_to_instance": {
            "name": "_json_to_instance",
            "location": 43,
            "return": [],
            "arguments": {
                "self": [],
                "json_dict": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/preprocess.py": {
        "clean_word": {
            "name": "clean_word",
            "location": 8,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "string": []
            }
        },
        "process_file": {
            "name": "process_file",
            "location": 16,
            "return": [
                "None"
            ],
            "arguments": {
                "input_file": [],
                "output_file": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/stats.py": {
        "flatten": {
            "name": "flatten",
            "location": 18,
            "return": [
                "list"
            ],
            "arguments": {
                "l": []
            }
        },
        "extract_field": {
            "name": "extract_field",
            "location": 70,
            "return": [
                "list"
            ],
            "arguments": {
                "field": [],
                "instances": []
            }
        },
        "main": {
            "name": "main",
            "location": 81,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "TextStats.__init__": {
            "name": "__init__",
            "location": 30,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "instance_texts": []
            }
        },
        "TextStats.__repr__": {
            "name": "__repr__",
            "location": 37,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "DatasetStats.__init__": {
            "name": "__init__",
            "location": 48,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "instances": []
            }
        },
        "DatasetStats.__repr__": {
            "name": "__repr__",
            "location": 61,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/train.py": {
        "make_prediction": {
            "name": "make_prediction",
            "location": 36,
            "return": [
                "Any"
            ],
            "arguments": {
                "model": [],
                "reader": [],
                "verbose": []
            }
        },
        "test_load": {
            "name": "test_load",
            "location": 61,
            "return": [
                "None"
            ],
            "arguments": {
                "build_model_fn": [],
                "reader": [],
                "save_path": [],
                "original_prediction": [],
                "cuda_device": []
            }
        },
        "run_model": {
            "name": "run_model",
            "location": 99,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "run_model.optimiser": {
            "name": "optimiser",
            "location": 109,
            "return": [],
            "arguments": {
                "model": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/util.py": {
        "visualise_model": {
            "name": "visualise_model",
            "location": 77,
            "return": [
                "None"
            ],
            "arguments": {
                "model": []
            }
        },
        "example_input": {
            "name": "example_input",
            "location": 90,
            "return": [
                "Tuple[(Any, Any, Any, Any)]"
            ],
            "arguments": {
                "index": []
            }
        },
        "is_cuda": {
            "name": "is_cuda",
            "location": 103,
            "return": [
                "bool"
            ],
            "arguments": {
                "model": []
            }
        },
        "train_val_test_split": {
            "name": "train_val_test_split",
            "location": 108,
            "return": [
                "Tuple[(Any, Any, Any)]"
            ],
            "arguments": {
                "dataset": [],
                "train_size": []
            }
        },
        "load_data": {
            "name": "load_data",
            "location": 128,
            "return": [
                "Any"
            ],
            "arguments": {
                "reader": [],
                "data_path": [],
                "pre_processed_path": []
            }
        },
        "train_model": {
            "name": "train_model",
            "location": 168,
            "return": [
                "Any"
            ],
            "arguments": {
                "build_model_fn": [],
                "train_data": [],
                "val_data": [],
                "test_data": [],
                "save_path": [],
                "batch_size": [],
                "num_epochs": [],
                "optimiser_fn": [],
                "grad_norm_clip": [],
                "sorting_keys": [],
                "cuda_device": []
            }
        },
        "get_preprocessed_name": {
            "name": "get_preprocessed_name",
            "location": 270,
            "return": [
                "str"
            ],
            "arguments": {
                "split_name": [],
                "model": [],
                "config": [],
                "embedding": []
            }
        },
        "get_experiment_name": {
            "name": "get_experiment_name",
            "location": 276,
            "return": [
                "str"
            ],
            "arguments": {
                "model": [],
                "config": [],
                "embedding": [],
                "name": []
            }
        },
        "is_stopword": {
            "name": "is_stopword",
            "location": 290,
            "return": [
                "bool"
            ],
            "arguments": {
                "word": []
            }
        },
        "is_punctuation": {
            "name": "is_punctuation",
            "location": 299,
            "return": [
                "bool"
            ],
            "arguments": {
                "word": []
            }
        },
        "get_term_frequency": {
            "name": "get_term_frequency",
            "location": 306,
            "return": [
                "float"
            ],
            "arguments": {
                "word": []
            }
        },
        "clone_module": {
            "name": "clone_module",
            "location": 323,
            "return": [
                "Any"
            ],
            "arguments": {
                "module": [],
                "num_clones": []
            }
        },
        "parse_cuda": {
            "name": "parse_cuda",
            "location": 331,
            "return": [
                "Union[(int, List[int])]"
            ],
            "arguments": {
                "cuda_str": []
            }
        },
        "tf2str": {
            "name": "tf2str",
            "location": 341,
            "return": [
                "str"
            ],
            "arguments": {
                "field": []
            }
        },
        "split_list": {
            "name": "split_list",
            "location": 350,
            "return": [
                "list"
            ],
            "arguments": {
                "list": [],
                "element": []
            }
        },
        "print_args": {
            "name": "print_args",
            "location": 364,
            "return": [
                "None"
            ],
            "arguments": {
                "args": []
            }
        },
        "DotDict.__init__": {
            "name": "__init__",
            "location": 47,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DotDict.__getattr__": {
            "name": "__getattr__",
            "location": 59,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "attr": []
            }
        },
        "DotDict.__setattr__": {
            "name": "__setattr__",
            "location": 62,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "key": [],
                "value": []
            }
        },
        "DotDict.__setitem__": {
            "name": "__setitem__",
            "location": 65,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "key": [],
                "value": []
            }
        },
        "DotDict.__delattr__": {
            "name": "__delattr__",
            "location": 69,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "key": []
            }
        },
        "DotDict.__delitem__": {
            "name": "__delitem__",
            "location": 72,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "key": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/__init__.py": {},
    "literate-lamp-master/literate_lamp/models/advanced_attention_bert.py": {
        "AdvancedAttentionBertClassifier.__init__": {
            "name": "__init__",
            "location": 23,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "bert_path": [],
                "encoder": [],
                "vocab": [],
                "hidden_dim": [],
                "encoder_dropout": [],
                "train_bert": []
            }
        },
        "AdvancedAttentionBertClassifier.forward": {
            "name": "forward",
            "location": 61,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [],
                "bert0": [],
                "bert1": [],
                "label": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/advanced_bert.py": {
        "AdvancedBertClassifier.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "bert_path": [],
                "encoder": [],
                "vocab": [],
                "hidden_dim": [],
                "encoder_dropout": [],
                "train_bert": []
            }
        },
        "AdvancedBertClassifier.forward": {
            "name": "forward",
            "location": 55,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [],
                "bert0": [],
                "bert1": [],
                "label": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/advanced_xlnet.py": {
        "AdvancedXLNetClassifier.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vocab": [],
                "word_embeddings": [],
                "encoder": [],
                "encoder_dropout": [],
                "train_xlnet": []
            }
        },
        "AdvancedXLNetClassifier.forward": {
            "name": "forward",
            "location": 45,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [],
                "string0": [],
                "string1": [],
                "label": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/attentive_reader.py": {
        "AttentiveReader.__init__": {
            "name": "__init__",
            "location": 35,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [],
                "p_encoder": [],
                "q_encoder": [],
                "a_encoder": [],
                "vocab": []
            }
        },
        "AttentiveReader.forward": {
            "name": "forward",
            "location": 67,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [],
                "passage": [],
                "question": [],
                "answer0": [],
                "answer1": [],
                "label": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/baseline.py": {
        "BaselineClassifier.__init__": {
            "name": "__init__",
            "location": 27,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [],
                "encoder": [],
                "vocab": []
            }
        },
        "BaselineClassifier.forward": {
            "name": "forward",
            "location": 58,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [],
                "passage": [],
                "question": [],
                "answer0": [],
                "answer1": [],
                "label": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/base_model.py": {
        "BaseModel.__init__": {
            "name": "__init__",
            "location": 17,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vocab": []
            }
        },
        "BaseModel.get_metrics": {
            "name": "get_metrics",
            "location": 29,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "reset": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dcmn.py": {
        "Dcmn.__init__": {
            "name": "__init__",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [],
                "vocab": [],
                "embedding_dropout": []
            }
        },
        "Dcmn._forward_internal": {
            "name": "_forward_internal",
            "location": 55,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "passage": [],
                "question": [],
                "answer": []
            }
        },
        "Dcmn.forward": {
            "name": "forward",
            "location": 107,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [],
                "passage": [],
                "question": [],
                "answer0": [],
                "answer1": [],
                "label": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/hierarchical_attention_network.py": {
        "HierarchicalAttentionNetwork.__init__": {
            "name": "__init__",
            "location": 24,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [],
                "sentence_encoder": [],
                "document_encoder": [],
                "vocab": [],
                "encoder_dropout": []
            }
        },
        "HierarchicalAttentionNetwork.forward": {
            "name": "forward",
            "location": 63,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [],
                "bert0": [],
                "bert1": [],
                "label": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/hierarchical_bert.py": {
        "HierarchicalBert.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "bert_path": [],
                "sentence_encoder": [],
                "document_encoder": [],
                "vocab": [],
                "encoder_dropout": [],
                "train_bert": []
            }
        },
        "HierarchicalBert.forward": {
            "name": "forward",
            "location": 50,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [],
                "bert0": [],
                "bert1": [],
                "label": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/relational_han.py": {
        "RelationalHan.__init__": {
            "name": "__init__",
            "location": 26,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [],
                "sentence_encoder": [],
                "document_encoder": [],
                "relation_encoder": [],
                "document_relation_encoder": [],
                "vocab": [],
                "encoder_dropout": [],
                "ffn_dropout": []
            }
        },
        "RelationalHan._forward_internal": {
            "name": "_forward_internal",
            "location": 76,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "bert": [],
                "relations": []
            }
        },
        "RelationalHan.forward": {
            "name": "forward",
            "location": 103,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [],
                "bert0": [],
                "bert1": [],
                "p_a0_rel": [],
                "p_a1_rel": [],
                "label": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/relational_transformer_model.py": {
        "RelationalTransformerModel.__init__": {
            "name": "__init__",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [],
                "sentence_encoder": [],
                "relation_sentence_encoder": [],
                "relational_encoder": [],
                "rel_embeddings": [],
                "vocab": [],
                "encoder_dropout": []
            }
        },
        "RelationalTransformerModel.forward": {
            "name": "forward",
            "location": 64,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [],
                "bert0": [],
                "bert1": [],
                "p_a0_rel": [],
                "p_a1_rel": [],
                "label": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/relational_xlnet.py": {
        "RelationalXL.__init__": {
            "name": "__init__",
            "location": 26,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [],
                "text_encoder": [],
                "relation_encoder": [],
                "vocab": [],
                "encoder_dropout": []
            }
        },
        "RelationalXL._forward_internal": {
            "name": "_forward_internal",
            "location": 58,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "text": [],
                "relations": []
            }
        },
        "RelationalXL.forward": {
            "name": "forward",
            "location": 89,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [],
                "string0": [],
                "string1": [],
                "rel0": [],
                "rel1": [],
                "label": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/simple_bert.py": {
        "SimpleBertClassifier.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "bert_path": [],
                "vocab": [],
                "train_bert": []
            }
        },
        "SimpleBertClassifier.forward": {
            "name": "forward",
            "location": 43,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [],
                "bert0": [],
                "bert1": [],
                "label": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/simple_trian.py": {
        "SimpleTrian.__init__": {
            "name": "__init__",
            "location": 37,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [],
                "rel_embeddings": [],
                "p_encoder": [],
                "q_encoder": [],
                "a_encoder": [],
                "vocab": [],
                "embedding_dropout": [],
                "encoder_dropout": []
            }
        },
        "SimpleTrian.forward": {
            "name": "forward",
            "location": 97,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [],
                "passage": [],
                "question": [],
                "answer0": [],
                "answer1": [],
                "p_q_rel": [],
                "p_a0_rel": [],
                "p_a1_rel": [],
                "label": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/simple_xlnet.py": {
        "SimpleXLNetClassifier.__init__": {
            "name": "__init__",
            "location": 20,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vocab": [],
                "config_path": [],
                "model_path": [],
                "train_xlnet": []
            }
        },
        "SimpleXLNetClassifier.forward": {
            "name": "forward",
            "location": 45,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [],
                "string0": [],
                "string1": [],
                "label": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/trian.py": {
        "Trian.__init__": {
            "name": "__init__",
            "location": 36,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [],
                "pos_embeddings": [],
                "ner_embeddings": [],
                "rel_embeddings": [],
                "p_encoder": [],
                "q_encoder": [],
                "a_encoder": [],
                "vocab": [],
                "embedding_dropout": [],
                "encoder_dropout": []
            }
        },
        "Trian.forward": {
            "name": "forward",
            "location": 94,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [],
                "passage": [],
                "question": [],
                "answer0": [],
                "answer1": [],
                "passage_pos": [],
                "passage_ner": [],
                "question_pos": [],
                "p_q_rel": [],
                "p_a0_rel": [],
                "p_a1_rel": [],
                "hc_feat": [],
                "label": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/util.py": {
        "seq_over_seq": {
            "name": "seq_over_seq",
            "location": 10,
            "return": [
                "Any"
            ],
            "arguments": {
                "encoder": [],
                "sentences": [],
                "masks": []
            }
        },
        "hierarchical_seq_over_seq": {
            "name": "hierarchical_seq_over_seq",
            "location": 30,
            "return": [
                "Any"
            ],
            "arguments": {
                "encoder": [],
                "sentences": [],
                "masks": []
            }
        },
        "attention_over_sequence": {
            "name": "attention_over_sequence",
            "location": 46,
            "return": [
                "Any"
            ],
            "arguments": {
                "attention": [],
                "sequence": [],
                "vector": []
            }
        },
        "initalise_weights": {
            "name": "initalise_weights",
            "location": 58,
            "return": [
                "None"
            ],
            "arguments": {
                "init": [],
                "module": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/zero_trian.py": {
        "ZeroTrian.__init__": {
            "name": "__init__",
            "location": 38,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [],
                "p_encoder": [],
                "q_encoder": [],
                "a_encoder": [],
                "vocab": [],
                "embedding_dropout": [],
                "encoder_dropout": []
            }
        },
        "ZeroTrian.forward": {
            "name": "forward",
            "location": 96,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [],
                "passage": [],
                "question": [],
                "answer0": [],
                "answer1": [],
                "label": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/__init__.py": {},
    "literate-lamp-master/literate_lamp/models/dmn/answer_module.py": {
        "AnswerModule.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [],
                "encoder": [],
                "embedding_dropout": [],
                "encoder_dropout": []
            }
        },
        "AnswerModule.get_output_dim": {
            "name": "get_output_dim",
            "location": 28,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "AnswerModule.forward": {
            "name": "forward",
            "location": 32,
            "return": [],
            "arguments": {
                "self": [],
                "answer": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dmn/input_module.py": {
        "InputModule.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [],
                "sentence_encoder": [],
                "document_encoder": [],
                "embedding_dropout": [],
                "encoder_dropout": []
            }
        },
        "InputModule.get_output_dim": {
            "name": "get_output_dim",
            "location": 32,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "InputModule.forward": {
            "name": "forward",
            "location": 36,
            "return": [],
            "arguments": {
                "self": [],
                "sentences": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dmn/memory_module.py": {
        "MemoryModule.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "hidden_dim": [],
                "num_hops": [],
                "dropout": []
            }
        },
        "MemoryModule.get_output_dim": {
            "name": "get_output_dim",
            "location": 39,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "MemoryModule.get_gate": {
            "name": "get_gate",
            "location": 42,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "facts": [],
                "question": [],
                "answer": [],
                "prev_mem": []
            }
        },
        "MemoryModule.forward": {
            "name": "forward",
            "location": 77,
            "return": [],
            "arguments": {
                "self": [],
                "facts": [],
                "question": [],
                "answer": [],
                "prev_mem": [],
                "hop": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dmn/model.py": {
        "_assert_equal": {
            "name": "_assert_equal",
            "location": 128,
            "return": [
                "None"
            ],
            "arguments": {
                "a": [],
                "b": []
            }
        },
        "Dmn.__init__": {
            "name": "__init__",
            "location": 39,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [],
                "sentence_encoder": [],
                "document_encoder": [],
                "question_encoder": [],
                "answer_encoder": [],
                "passes": [],
                "vocab": [],
                "embedding_dropout": [],
                "encoder_dropout": []
            }
        },
        "Dmn.forward": {
            "name": "forward",
            "location": 88,
            "return": [
                "Dict[(str, Any)]"
            ],
            "arguments": {
                "self": [],
                "metadata": [],
                "sentences": [],
                "question": [],
                "answer0": [],
                "answer1": [],
                "label": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dmn/output_module.py": {
        "OutputModule.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "memory_size": [],
                "answer_size": [],
                "num_labels": []
            }
        },
        "OutputModule.get_input_dim": {
            "name": "get_input_dim",
            "location": 22,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "OutputModule.get_output_dim": {
            "name": "get_output_dim",
            "location": 25,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "OutputModule.forward": {
            "name": "forward",
            "location": 29,
            "return": [],
            "arguments": {
                "self": [],
                "memory": [],
                "answer": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dmn/question_module.py": {
        "QuestionModule.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_embeddings": [],
                "encoder": [],
                "embedding_dropout": [],
                "encoder_dropout": []
            }
        },
        "QuestionModule.get_output_dim": {
            "name": "get_output_dim",
            "location": 28,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "QuestionModule.forward": {
            "name": "forward",
            "location": 32,
            "return": [],
            "arguments": {
                "self": [],
                "question": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/models/dmn/__init__.py": {},
    "literate-lamp-master/literate_lamp/modules/attention_gru.py": {
        "attention_gru": {
            "name": "attention_gru",
            "location": 87,
            "return": [
                "Any"
            ],
            "arguments": {
                "input_dim": [],
                "output_dim": [],
                "num_layers": [],
                "bidirectional": [],
                "dropout": []
            }
        },
        "AttentionGRUCell.__init__": {
            "name": "__init__",
            "location": 9,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [],
                "hidden_size": []
            }
        },
        "AttentionGRUCell.forward": {
            "name": "forward",
            "location": 22,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "inputs": [],
                "previous_state": [],
                "gate": []
            }
        },
        "AttentionGRU.__init__": {
            "name": "__init__",
            "location": 47,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [],
                "output_dim": []
            }
        },
        "AttentionGRU.forward": {
            "name": "forward",
            "location": 53,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "inputs": [],
                "gate": []
            }
        },
        "AttentionGRU.get_input_dim": {
            "name": "get_input_dim",
            "location": 79,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "AttentionGRU.get_output_dim": {
            "name": "get_output_dim",
            "location": 83,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/modules/position_encoder.py": {
        "position_encoder": {
            "name": "position_encoder",
            "location": 59,
            "return": [
                "PositionEncoder"
            ],
            "arguments": {
                "input_dim": [],
                "output_dim": [],
                "num_layers": [],
                "bidirectional": [],
                "dropout": []
            }
        },
        "PositionEncoder.__init__": {
            "name": "__init__",
            "location": 9,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": [],
                "output_dim": []
            }
        },
        "PositionEncoder.position_matrix": {
            "name": "position_matrix",
            "location": 15,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "seq_len": []
            }
        },
        "PositionEncoder.forward": {
            "name": "forward",
            "location": 24,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "inputs": [],
                "mask": []
            }
        },
        "PositionEncoder.get_input_dim": {
            "name": "get_input_dim",
            "location": 51,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "PositionEncoder.get_output_dim": {
            "name": "get_output_dim",
            "location": 55,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/modules/xlnet_embedder.py": {
        "PretrainedXLNetModel.load": {
            "name": "load",
            "location": 26,
            "return": [
                "Any"
            ],
            "arguments": {
                "cls": [],
                "config_path": [],
                "model_path": [],
                "cache_model": []
            }
        },
        "XLNetEmbedder.__init__": {
            "name": "__init__",
            "location": 57,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "xlnet_model": [],
                "window_size": []
            }
        },
        "XLNetEmbedder.get_output_dim": {
            "name": "get_output_dim",
            "location": 66,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "XLNetEmbedder.forward": {
            "name": "forward",
            "location": 69,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "input_ids": [],
                "cls_indexes": [],
                "token_type_ids": []
            }
        },
        "PretrainedXLNetEmbedder.__init__": {
            "name": "__init__",
            "location": 137,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "config_path": [],
                "model_path": [],
                "window_size": [],
                "requires_grad": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/modules/xlnet_indexer.py": {
        "XLNetIndexer.__init__": {
            "name": "__init__",
            "location": 39,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "namespace": [],
                "vocab_file": [],
                "sep_token": [],
                "cls_token": [],
                "pad_token": [],
                "token_min_padding_length": []
            }
        },
        "XLNetIndexer.count_vocab_items": {
            "name": "count_vocab_items",
            "location": 59,
            "return": [],
            "arguments": {
                "self": [],
                "token": [],
                "counter": []
            }
        },
        "XLNetIndexer.tokens_to_indices": {
            "name": "tokens_to_indices",
            "location": 66,
            "return": [],
            "arguments": {
                "self": [],
                "tokens": [],
                "vocabulary": [],
                "index_name": []
            }
        },
        "XLNetIndexer.get_padding_token": {
            "name": "get_padding_token",
            "location": 104,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "XLNetIndexer.get_padding_lengths": {
            "name": "get_padding_lengths",
            "location": 108,
            "return": [],
            "arguments": {
                "self": [],
                "token": []
            }
        },
        "XLNetIndexer.pad_token_sequence": {
            "name": "pad_token_sequence",
            "location": 112,
            "return": [],
            "arguments": {
                "self": [],
                "tokens": [],
                "desired_num_tokens": [],
                "padding_lengths": []
            }
        },
        "XLNetIndexer.get_keys": {
            "name": "get_keys",
            "location": 121,
            "return": [],
            "arguments": {
                "self": [],
                "index_name": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/modules/xlnet_pooler.py": {
        "XLNetPooler.__init__": {
            "name": "__init__",
            "location": 9,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "input_dim": []
            }
        },
        "XLNetPooler.get_input_dim": {
            "name": "get_input_dim",
            "location": 16,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "XLNetPooler.get_output_dim": {
            "name": "get_output_dim",
            "location": 20,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "XLNetPooler.forward": {
            "name": "forward",
            "location": 23,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "hidden_states": [],
                "cls_index": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/modules/xlnet_word_splitter.py": {
        "PretrainedXLNetTokenizer.load": {
            "name": "load",
            "location": 18,
            "return": [
                "Any"
            ],
            "arguments": {
                "cls": [],
                "vocab_file": [],
                "cache_model": []
            }
        },
        "XLNetWordSplitter.__init__": {
            "name": "__init__",
            "location": 36,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vocab_file": [],
                "do_lower_case": []
            }
        },
        "XLNetWordSplitter.split_words": {
            "name": "split_words",
            "location": 42,
            "return": [
                "list"
            ],
            "arguments": {
                "self": [],
                "sentence": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/modules/__init__.py": {},
    "literate-lamp-master/literate_lamp/readers/base_reader.py": {
        "BaseReader._read": {
            "name": "_read",
            "location": 20,
            "return": [
                "Generator[(Any, Any, None)]"
            ],
            "arguments": {
                "self": [],
                "file_path": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/extended_xlnet_reader.py": {
        "ExtendedXLNetReader.__init__": {
            "name": "__init__",
            "location": 44,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vocab_file": [],
                "conceptnet_path": [],
                "word_indexer": []
            }
        },
        "ExtendedXLNetReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 66,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "passage_id": [],
                "question_id": [],
                "question_type": [],
                "passage": [],
                "question": [],
                "answer0": [],
                "answer1": [],
                "label0": []
            }
        },
        "ExtendedXLNetReader.extend_passage": {
            "name": "extend_passage",
            "location": 109,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "passage": [],
                "question": [],
                "answer": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/full_trian_reader.py": {
        "FullTrianReader.__init__": {
            "name": "__init__",
            "location": 54,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_indexer": [],
                "is_bert": [],
                "conceptnet_path": []
            }
        },
        "FullTrianReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 94,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "passage_id": [],
                "question_id": [],
                "question_type": [],
                "passage": [],
                "question": [],
                "answer0": [],
                "answer1": [],
                "label0": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/relation_bert_reader.py": {
        "RelationBertReader.__init__": {
            "name": "__init__",
            "location": 40,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "is_bert": [],
                "conceptnet_path": [],
                "word_indexer": []
            }
        },
        "RelationBertReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 72,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "passage_id": [],
                "question_id": [],
                "question_type": [],
                "passage": [],
                "question": [],
                "answer0": [],
                "answer1": [],
                "label0": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/relation_xlnet_reader.py": {
        "RelationXLNetReader.__init__": {
            "name": "__init__",
            "location": 40,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vocab_file": [],
                "conceptnet_path": [],
                "word_indexer": []
            }
        },
        "RelationXLNetReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 62,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "passage_id": [],
                "question_id": [],
                "question_type": [],
                "passage": [],
                "question": [],
                "answer0": [],
                "answer1": [],
                "label0": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/sentence_reader.py": {
        "SentenceReader.__init__": {
            "name": "__init__",
            "location": 47,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "embedding_type": [],
                "xlnet_vocab_file": [],
                "word_indexer": []
            }
        },
        "SentenceReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 70,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "passage_id": [],
                "question_id": [],
                "question_type": [],
                "passage": [],
                "question": [],
                "answer0": [],
                "answer1": [],
                "label0": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/simple_bert_reader.py": {
        "SimpleBertReader.__init__": {
            "name": "__init__",
            "location": 35,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_indexer": []
            }
        },
        "SimpleBertReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 56,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "passage_id": [],
                "question_id": [],
                "question_type": [],
                "passage": [],
                "question": [],
                "answer0": [],
                "answer1": [],
                "label0": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/simple_mc_script_reader.py": {
        "SimpleMcScriptReader.__init__": {
            "name": "__init__",
            "location": 35,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "embedding_type": [],
                "xlnet_vocab_file": [],
                "word_indexer": []
            }
        },
        "SimpleMcScriptReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 56,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "passage_id": [],
                "question_id": [],
                "question_type": [],
                "passage": [],
                "question": [],
                "answer0": [],
                "answer1": [],
                "label0": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/simple_trian_reader.py": {
        "SimpleTrianReader.__init__": {
            "name": "__init__",
            "location": 39,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "word_indexer": [],
                "xlnet_vocab_file": [],
                "embedding_type": [],
                "conceptnet_path": []
            }
        },
        "SimpleTrianReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 62,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "passage_id": [],
                "question_id": [],
                "question_type": [],
                "passage": [],
                "question": [],
                "answer0": [],
                "answer1": [],
                "label0": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/simple_xlnet_reader.py": {
        "SimpleXLNetReader.__init__": {
            "name": "__init__",
            "location": 45,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "vocab_file": [],
                "word_indexer": []
            }
        },
        "SimpleXLNetReader.text_to_instance": {
            "name": "text_to_instance",
            "location": 65,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "passage_id": [],
                "question_id": [],
                "question_type": [],
                "passage": [],
                "question": [],
                "answer0": [],
                "answer1": [],
                "label0": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/util.py": {
        "strs2toks": {
            "name": "strs2toks",
            "location": 20,
            "return": [
                "list"
            ],
            "arguments": {
                "strings": []
            }
        },
        "toks2strs": {
            "name": "toks2strs",
            "location": 25,
            "return": [
                "list"
            ],
            "arguments": {
                "tokens": []
            }
        },
        "pieces2strs": {
            "name": "pieces2strs",
            "location": 30,
            "return": [
                "list"
            ],
            "arguments": {
                "tokens": []
            }
        },
        "compute_handcrafted_features": {
            "name": "compute_handcrafted_features",
            "location": 40,
            "return": [
                "Any"
            ],
            "arguments": {
                "passage": [],
                "question": [],
                "answer0": [],
                "answer1": []
            }
        },
        "bert_sliding_window": {
            "name": "bert_sliding_window",
            "location": 83,
            "return": [
                "List[str]"
            ],
            "arguments": {
                "question": [],
                "answer": [],
                "passage": [],
                "max_wordpieces": [],
                "stride": []
            }
        },
        "xlnet_input_string": {
            "name": "xlnet_input_string",
            "location": 101,
            "return": [
                "str"
            ],
            "arguments": {
                "question": [],
                "answer": [],
                "passage": []
            }
        },
        "relation_sentences": {
            "name": "relation_sentences",
            "location": 105,
            "return": [
                "list"
            ],
            "arguments": {
                "conceptnet": [],
                "text": [],
                "query": []
            }
        },
        "get_tokenizer": {
            "name": "get_tokenizer",
            "location": 112,
            "return": [
                "Any"
            ],
            "arguments": {
                "embedding_type": [],
                "xlnet_vocab_file": []
            }
        },
        "get_indexer": {
            "name": "get_indexer",
            "location": 124,
            "return": [
                "Any"
            ],
            "arguments": {
                "embedding_type": [],
                "xlnet_vocab_file": []
            }
        },
        "split_sentences": {
            "name": "split_sentences",
            "location": 137,
            "return": [
                "Generator[(Any, Any, None)]"
            ],
            "arguments": {
                "nlp": [],
                "text": []
            }
        },
        "get_sentencizer": {
            "name": "get_sentencizer",
            "location": 143,
            "return": [
                "Any"
            ],
            "arguments": {}
        },
        "compute_handcrafted_features.is_valid": {
            "name": "is_valid",
            "location": 44,
            "return": [],
            "arguments": {
                "token": []
            }
        },
        "compute_handcrafted_features.co_occurrence": {
            "name": "co_occurrence",
            "location": 47,
            "return": [],
            "arguments": {
                "text": [],
                "query": []
            }
        }
    },
    "literate-lamp-master/literate_lamp/readers/__init__.py": {}
}
{
    "rl_algorithms-master/run_lunarlander_continuous_v2.py": {
        "parse_args": {
            "name": "parse_args",
            "location": 19,
            "return": [
                "argparse.Namespace"
            ],
            "arguments": {}
        },
        "main": {
            "name": "main",
            "location": 77,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "rl_algorithms-master/run_lunarlander_v2.py": {
        "parse_args": {
            "name": "parse_args",
            "location": 19,
            "return": [
                "argparse.Namespace"
            ],
            "arguments": {}
        },
        "main": {
            "name": "main",
            "location": 77,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "rl_algorithms-master/run_pong_no_frameskip_v4.py": {
        "parse_args": {
            "name": "parse_args",
            "location": 17,
            "return": [
                "argparse.Namespace"
            ],
            "arguments": {}
        },
        "env_generator": {
            "name": "env_generator",
            "location": 87,
            "return": [
                "Callable[([int], Any)]"
            ],
            "arguments": {
                "env_name": [],
                "max_episode_steps": [],
                "frame_stack": []
            }
        },
        "main": {
            "name": "main",
            "location": 96,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "env_generator._thunk": {
            "name": "_thunk",
            "location": 88,
            "return": [],
            "arguments": {
                "rank": []
            }
        }
    },
    "rl_algorithms-master/run_reacher_v2.py": {
        "parse_args": {
            "name": "parse_args",
            "location": 19,
            "return": [
                "argparse.Namespace"
            ],
            "arguments": {}
        },
        "main": {
            "name": "main",
            "location": 78,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "rl_algorithms-master/setup.py": {
        "get_version": {
            "name": "get_version",
            "location": 12,
            "return": [
                "str"
            ],
            "arguments": {}
        }
    },
    "rl_algorithms-master/configs/lunarlander_continuous_v2/__init__.py": {},
    "rl_algorithms-master/configs/lunarlander_v2/__init__.py": {},
    "rl_algorithms-master/configs/pong_no_frameskip_v4/__init__.py": {},
    "rl_algorithms-master/configs/reacher_v2/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/registry.py": {
        "build_agent": {
            "name": "build_agent",
            "location": 14,
            "return": [
                "Any"
            ],
            "arguments": {
                "cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "build_args": [
                    "dict"
                ]
            }
        },
        "build_learner": {
            "name": "build_learner",
            "location": 19,
            "return": [
                "Any"
            ],
            "arguments": {
                "cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "build_args": [
                    "dict"
                ]
            }
        },
        "build_backbone": {
            "name": "build_backbone",
            "location": 24,
            "return": [
                "Any"
            ],
            "arguments": {
                "cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "build_args": [
                    "dict"
                ]
            }
        },
        "build_head": {
            "name": "build_head",
            "location": 29,
            "return": [
                "Any"
            ],
            "arguments": {
                "cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "build_args": [
                    "dict"
                ]
            }
        },
        "build_loss": {
            "name": "build_loss",
            "location": 34,
            "return": [
                "Any"
            ],
            "arguments": {
                "cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "build_args": [
                    "dict"
                ]
            }
        },
        "build_her": {
            "name": "build_her",
            "location": 39,
            "return": [
                "Any"
            ],
            "arguments": {
                "cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "build_args": [
                    "dict"
                ]
            }
        },
        "build_worker": {
            "name": "build_worker",
            "location": 44,
            "return": [
                "Any"
            ],
            "arguments": {
                "cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "build_args": [
                    "dict"
                ]
            }
        },
        "build_logger": {
            "name": "build_logger",
            "location": 50,
            "return": [
                "Any"
            ],
            "arguments": {
                "cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "build_args": [
                    "dict"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/a2c/agent.py": {
        "A2CAgent.__init__": {
            "name": "__init__",
            "location": 42,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "env_info": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "learner_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ],
                "is_render": [
                    "bool"
                ],
                "render_after": [
                    "int"
                ],
                "is_log": [
                    "bool"
                ],
                "save_period": [
                    "int"
                ],
                "episode_num": [
                    "int"
                ],
                "max_episode_steps": [
                    "int"
                ],
                "interim_test_num": [
                    "int"
                ]
            }
        },
        "A2CAgent.select_action": {
            "name": "select_action",
            "location": 94,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "A2CAgent.step": {
            "name": "step",
            "location": 110,
            "return": [
                "Tuple[(np.ndarray, Any, bool, dict)]"
            ],
            "arguments": {
                "self": [],
                "action": []
            }
        },
        "A2CAgent.write_log": {
            "name": "write_log",
            "location": 124,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "log_value": [
                    "tuple"
                ]
            }
        },
        "A2CAgent.train": {
            "name": "train",
            "location": 144,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/a2c/learner.py": {
        "A2CLearner.__init__": {
            "name": "__init__",
            "location": 31,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "backbone": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "head": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "optim_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "env_name": [
                    "str"
                ],
                "state_size": [
                    "tuple"
                ],
                "output_size": [
                    "int"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ]
            }
        },
        "A2CLearner._init_network": {
            "name": "_init_network",
            "location": 57,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "A2CLearner.update_model": {
            "name": "update_model",
            "location": 80,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "tuple"
                ]
            }
        },
        "A2CLearner.save_params": {
            "name": "save_params",
            "location": 117,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "n_episode": [
                    "int"
                ]
            }
        },
        "A2CLearner.load_params": {
            "name": "load_params",
            "location": 128,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "A2CLearner.get_state_dict": {
            "name": "get_state_dict",
            "location": 139,
            "return": [
                "Tuple[collections.OrderedDict]"
            ],
            "arguments": {
                "self": []
            }
        },
        "A2CLearner.get_policy": {
            "name": "get_policy",
            "location": 143,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/a2c/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/acer/agent.py": {
        "ACERAgent.__init__": {
            "name": "__init__",
            "location": 37,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "env_info": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "learner_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ],
                "is_render": [
                    "bool"
                ],
                "render_after": [
                    "int"
                ],
                "is_log": [
                    "bool"
                ],
                "save_period": [
                    "int"
                ],
                "episode_num": [
                    "int"
                ],
                "max_episode_steps": [
                    "int"
                ],
                "interim_test_num": [
                    "int"
                ]
            }
        },
        "ACERAgent.select_action": {
            "name": "select_action",
            "location": 89,
            "return": [
                "Tuple[(int, Any)]"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "ACERAgent.step": {
            "name": "step",
            "location": 98,
            "return": [
                "Tuple[(np.ndarray, Any, bool, dict)]"
            ],
            "arguments": {
                "self": [],
                "action": [
                    "int"
                ]
            }
        },
        "ACERAgent.write_log": {
            "name": "write_log",
            "location": 104,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "log_value": [
                    "tuple"
                ]
            }
        },
        "ACERAgent.train": {
            "name": "train",
            "location": 115,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/acer/buffer.py": {
        "ReplayMemory.__init__": {
            "name": "__init__",
            "location": 26,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "buffer_size": [
                    "int"
                ],
                "n_rollout": [
                    "int"
                ]
            }
        },
        "ReplayMemory.add": {
            "name": "add",
            "location": 38,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "seq_data": [
                    "list"
                ]
            }
        },
        "ReplayMemory._initialize_buffers": {
            "name": "_initialize_buffers",
            "location": 59,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ],
                "probs": [
                    "np.ndarray"
                ]
            }
        },
        "ReplayMemory.sample": {
            "name": "sample",
            "location": 73,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "on_policy": []
            }
        },
        "ReplayMemory.__len__": {
            "name": "__len__",
            "location": 100,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/acer/learner.py": {
        "ACERLearner.__init__": {
            "name": "__init__",
            "location": 29,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "backbone": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "head": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "optim_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "trust_region": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "env_info": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ]
            }
        },
        "ACERLearner._init_network": {
            "name": "_init_network",
            "location": 56,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "ACERLearner.update_model": {
            "name": "update_model",
            "location": 78,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "tuple"
                ]
            }
        },
        "ACERLearner.q_retrace": {
            "name": "q_retrace",
            "location": 151,
            "return": [
                "Any"
            ],
            "arguments": {
                "reward": [],
                "done": [],
                "q_a": [],
                "v": [],
                "rho_bar": [],
                "gamma": [
                    "float"
                ]
            }
        },
        "ACERLearner.save_params": {
            "name": "save_params",
            "location": 172,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "n_episode": [
                    "int"
                ]
            }
        },
        "ACERLearner.load_params": {
            "name": "load_params",
            "location": 181,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "ACERLearner.get_state_dict": {
            "name": "get_state_dict",
            "location": 191,
            "return": [
                "Tuple[collections.OrderedDict]"
            ],
            "arguments": {
                "self": []
            }
        },
        "ACERLearner.get_policy": {
            "name": "get_policy",
            "location": 195,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/acer/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/bc/ddpg_agent.py": {
        "BCDDPGAgent._initialize": {
            "name": "_initialize",
            "location": 38,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "BCDDPGAgent._preprocess_state": {
            "name": "_preprocess_state",
            "location": 88,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "BCDDPGAgent._add_transition_to_memory": {
            "name": "_add_transition_to_memory",
            "location": 96,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "Tuple[(np.ndarray, ...)]"
                ]
            }
        },
        "BCDDPGAgent.write_log": {
            "name": "write_log",
            "location": 113,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "log_value": [
                    "tuple"
                ]
            }
        },
        "BCDDPGAgent.train": {
            "name": "train",
            "location": 146,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/bc/ddpg_learner.py": {
        "BCDDPGLearner.update_model": {
            "name": "update_model",
            "location": 28,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "tuple"
                ],
                "demos": [
                    "tuple"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/bc/her.py": {
        "L1DistanceRewardFn.__call__": {
            "name": "__call__",
            "location": 17,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "tuple"
                ],
                "goal_state": [
                    "np.ndarray"
                ]
            }
        },
        "LunarLanderContinuousHER.__init__": {
            "name": "__init__",
            "location": 40,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "reward_fn": [
                    "Callable[([tuple, np.ndarray], Any)]"
                ]
            }
        },
        "LunarLanderContinuousHER.fetch_desired_states_from_demo": {
            "name": "fetch_desired_states_from_demo",
            "location": 49,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "demo": [
                    "list"
                ]
            }
        },
        "LunarLanderContinuousHER.get_desired_state": {
            "name": "get_desired_state",
            "location": 55,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": []
            }
        },
        "LunarLanderContinuousHER._get_final_state": {
            "name": "_get_final_state",
            "location": 59,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "tuple"
                ]
            }
        },
        "LunarLanderContinuousHER.generate_demo_transitions": {
            "name": "generate_demo_transitions",
            "location": 63,
            "return": [
                "list"
            ],
            "arguments": {
                "self": [],
                "demo": [
                    "list"
                ]
            }
        },
        "ReacherRewardFn.__call__": {
            "name": "__call__",
            "location": 84,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "tuple"
                ],
                "_": []
            }
        },
        "ReacherHER.__init__": {
            "name": "__init__",
            "location": 101,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "reward_fn": [
                    "Callable[([tuple, np.ndarray], Any)]"
                ]
            }
        },
        "ReacherHER.fetch_desired_states_from_demo": {
            "name": "fetch_desired_states_from_demo",
            "location": 108,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": [],
                "_": [
                    "list"
                ]
            }
        },
        "ReacherHER.get_desired_state": {
            "name": "get_desired_state",
            "location": 115,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": []
            }
        },
        "ReacherHER._get_final_state": {
            "name": "_get_final_state",
            "location": 122,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "transition_final": [
                    "tuple"
                ]
            }
        },
        "ReacherHER.generate_demo_transitions": {
            "name": "generate_demo_transitions",
            "location": 126,
            "return": [
                "list"
            ],
            "arguments": {
                "self": [],
                "demo": [
                    "list"
                ]
            }
        },
        "ReacherHER._append_origin_transitions": {
            "name": "_append_origin_transitions",
            "location": 133,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "origin_transitions": [
                    "list"
                ],
                "transition": [
                    "tuple"
                ],
                "_": [
                    "np.ndarray"
                ]
            }
        },
        "ReacherHER._get_transition": {
            "name": "_get_transition",
            "location": 139,
            "return": [
                "Tuple[(np.ndarray, np.ndarray, Any, np.ndarray, bool)]"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "tuple"
                ],
                "goal_state": [
                    "np.ndarray"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/bc/sac_agent.py": {
        "BCSACAgent._initialize": {
            "name": "_initialize",
            "location": 40,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "BCSACAgent._preprocess_state": {
            "name": "_preprocess_state",
            "location": 85,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "BCSACAgent._add_transition_to_memory": {
            "name": "_add_transition_to_memory",
            "location": 93,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "Tuple[(np.ndarray, ...)]"
                ]
            }
        },
        "BCSACAgent.write_log": {
            "name": "write_log",
            "location": 110,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "log_value": [
                    "tuple"
                ]
            }
        },
        "BCSACAgent.train": {
            "name": "train",
            "location": 149,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/bc/sac_learner.py": {
        "BCSACLearner.update_model": {
            "name": "update_model",
            "location": 19,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "tuple"
                ],
                "demos": [
                    "tuple"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/bc/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/common/grad_cam.py": {
        "CAMBaseWrapper.__init__": {
            "name": "__init__",
            "location": 22,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "model": []
            }
        },
        "CAMBaseWrapper._encode_one_hot": {
            "name": "_encode_one_hot",
            "location": 29,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "ids": []
            }
        },
        "CAMBaseWrapper.forward": {
            "name": "forward",
            "location": 35,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "image": []
            }
        },
        "CAMBaseWrapper.backward": {
            "name": "backward",
            "location": 43,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "ids": []
            }
        },
        "CAMBaseWrapper.generate": {
            "name": "generate",
            "location": 54,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": [],
                "target_layer": [
                    "str"
                ]
            }
        },
        "CAMBaseWrapper.remove_hook": {
            "name": "remove_hook",
            "location": 57,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "GradCAM.__init__": {
            "name": "__init__",
            "location": 73,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "model": [],
                "candidate_layers": [
                    "list"
                ]
            }
        },
        "GradCAM._find": {
            "name": "_find",
            "location": 102,
            "return": [
                "Any"
            ],
            "arguments": {
                "pool": [
                    "collections.OrderedDict"
                ],
                "target_layer": [
                    "str"
                ]
            }
        },
        "GradCAM._compute_grad_weights": {
            "name": "_compute_grad_weights",
            "location": 110,
            "return": [
                "Any"
            ],
            "arguments": {
                "grads": []
            }
        },
        "GradCAM.forward": {
            "name": "forward",
            "location": 114,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "image": [
                    "np.ndarray"
                ]
            }
        },
        "GradCAM.generate": {
            "name": "generate",
            "location": 119,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "target_layer": [
                    "str"
                ]
            }
        },
        "GradCAM.__init__.forward_hook": {
            "name": "forward_hook",
            "location": 80,
            "return": [],
            "arguments": {
                "key": []
            }
        },
        "GradCAM.__init__.backward_hook": {
            "name": "backward_hook",
            "location": 87,
            "return": [],
            "arguments": {
                "key": []
            }
        },
        "GradCAM.__init__.forward_hook.forward_hook_": {
            "name": "forward_hook_",
            "location": 81,
            "return": [],
            "arguments": {
                "_": [],
                "__": [],
                "output": []
            }
        },
        "GradCAM.__init__.backward_hook.backward_hook_": {
            "name": "backward_hook_",
            "location": 88,
            "return": [],
            "arguments": {
                "_": [],
                "__": [],
                "grad_out": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/helper_functions.py": {
        "tanh": {
            "name": "tanh",
            "location": 21,
            "return": [
                "Any"
            ],
            "arguments": {
                "x": []
            }
        },
        "identity": {
            "name": "identity",
            "location": 26,
            "return": [
                "Any"
            ],
            "arguments": {
                "x": []
            }
        },
        "relu": {
            "name": "relu",
            "location": 31,
            "return": [
                "Any"
            ],
            "arguments": {
                "x": []
            }
        },
        "soft_update": {
            "name": "soft_update",
            "location": 36,
            "return": [
                "None"
            ],
            "arguments": {
                "local": [],
                "target": [],
                "tau": [
                    "float"
                ]
            }
        },
        "hard_update": {
            "name": "hard_update",
            "location": 42,
            "return": [
                "None"
            ],
            "arguments": {
                "local": [],
                "target": []
            }
        },
        "set_random_seed": {
            "name": "set_random_seed",
            "location": 47,
            "return": [
                "None"
            ],
            "arguments": {
                "seed": [
                    "int"
                ],
                "env": []
            }
        },
        "make_one_hot": {
            "name": "make_one_hot",
            "location": 55,
            "return": [
                "Any"
            ],
            "arguments": {
                "labels": [],
                "c": [
                    "int"
                ]
            }
        },
        "get_n_step_info_from_demo": {
            "name": "get_n_step_info_from_demo",
            "location": 62,
            "return": [
                "Tuple[(list, list)]"
            ],
            "arguments": {
                "demo": [
                    "list"
                ],
                "n_step": [
                    "int"
                ],
                "gamma": [
                    "float"
                ]
            }
        },
        "get_n_step_info": {
            "name": "get_n_step_info",
            "location": 88,
            "return": [
                "Tuple[(Any, np.ndarray, bool)]"
            ],
            "arguments": {
                "n_step_buffer": [
                    "Deque"
                ],
                "gamma": [
                    "float"
                ]
            }
        },
        "numpy2floattensor": {
            "name": "numpy2floattensor",
            "location": 104,
            "return": [
                "Tuple[Any]"
            ],
            "arguments": {
                "arrays": [
                    "Union[(np.ndarray, Tuple[np.ndarray])]"
                ],
                "device_": []
            }
        },
        "state_dict2numpy": {
            "name": "state_dict2numpy",
            "location": 124,
            "return": [
                "Dict[(str, np.ndarray)]"
            ],
            "arguments": {
                "state_dict": []
            }
        },
        "smoothen_graph": {
            "name": "smoothen_graph",
            "location": 132,
            "return": [
                "List[float]"
            ],
            "arguments": {
                "scalars": [
                    "List[float]"
                ],
                "weight": [
                    "float"
                ]
            }
        },
        "set_cfg_for_intergration_test": {
            "name": "set_cfg_for_intergration_test",
            "location": 150,
            "return": [
                "rl_algorithms.utils.config.ConfigDict"
            ],
            "arguments": {
                "cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/noise.py": {
        "GaussianNoise.__init__": {
            "name": "__init__",
            "location": 16,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "action_dim": [
                    "int"
                ],
                "min_sigma": [
                    "float"
                ],
                "max_sigma": [
                    "float"
                ],
                "decay_period": [
                    "int"
                ]
            }
        },
        "GaussianNoise.sample": {
            "name": "sample",
            "location": 29,
            "return": [
                "float"
            ],
            "arguments": {
                "self": [],
                "t": [
                    "int"
                ]
            }
        },
        "OUNoise.__init__": {
            "name": "__init__",
            "location": 45,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "size": [
                    "int"
                ],
                "mu": [
                    "float"
                ],
                "theta": [
                    "float"
                ],
                "sigma": [
                    "float"
                ]
            }
        },
        "OUNoise.reset": {
            "name": "reset",
            "location": 55,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "OUNoise.sample": {
            "name": "sample",
            "location": 59,
            "return": [
                "float"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/saliency_map.py": {
        "make_saliency_dir": {
            "name": "make_saliency_dir",
            "location": 22,
            "return": [
                "str"
            ],
            "arguments": {
                "date_time": [
                    "str"
                ]
            }
        },
        "compute_saliency_maps": {
            "name": "compute_saliency_maps",
            "location": 36,
            "return": [
                "Any"
            ],
            "arguments": {
                "X": [],
                "y": [],
                "model": [],
                "device": []
            }
        },
        "save_saliency_maps": {
            "name": "save_saliency_maps",
            "location": 63,
            "return": [
                "Image.Image"
            ],
            "arguments": {
                "i": [],
                "X": [],
                "y": [],
                "model": [],
                "device": [],
                "saliency_map_dir": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/common/abstract/agent.py": {
        "Agent.__init__": {
            "name": "__init__",
            "location": 36,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "env_info": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ],
                "is_render": [
                    "bool"
                ],
                "render_after": [
                    "int"
                ],
                "is_log": [
                    "bool"
                ],
                "save_period": [
                    "int"
                ],
                "episode_num": [
                    "int"
                ],
                "max_episode_steps": [
                    "int"
                ],
                "interim_test_num": [
                    "int"
                ]
            }
        },
        "Agent.select_action": {
            "name": "select_action",
            "location": 72,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "Agent.step": {
            "name": "step",
            "location": 76,
            "return": [
                "Tuple[(np.ndarray, Any, bool, dict)]"
            ],
            "arguments": {
                "self": [],
                "action": []
            }
        },
        "Agent.write_log": {
            "name": "write_log",
            "location": 82,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "log_value": [
                    "tuple"
                ]
            }
        },
        "Agent.train": {
            "name": "train",
            "location": 86,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent.set_wandb": {
            "name": "set_wandb",
            "location": 89,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent.interim_test": {
            "name": "interim_test",
            "location": 104,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent.test": {
            "name": "test",
            "location": 122,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent._test": {
            "name": "_test",
            "location": 133,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "interim_test": [
                    "bool"
                ]
            }
        },
        "Agent.test_with_gradcam": {
            "name": "test_with_gradcam",
            "location": 172,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent.test_with_saliency_map": {
            "name": "test_with_saliency_map",
            "location": 246,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/abstract/architecture.py": {
        "Architecture._spawn": {
            "name": "_spawn",
            "location": 14,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "Architecture.train": {
            "name": "train",
            "location": 18,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "Architecture.test": {
            "name": "test",
            "location": 22,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/abstract/buffer.py": {
        "BaseBuffer.add": {
            "name": "add",
            "location": 18,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "tuple"
                ]
            }
        },
        "BaseBuffer.sample": {
            "name": "sample",
            "location": 22,
            "return": [
                "Tuple[(np.ndarray, ...)]"
            ],
            "arguments": {
                "self": []
            }
        },
        "BaseBuffer.__len__": {
            "name": "__len__",
            "location": 26,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "BufferWrapper.__init__": {
            "name": "__init__",
            "location": 37,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "base_buffer": [
                    "BaseBuffer"
                ]
            }
        },
        "BufferWrapper.add": {
            "name": "add",
            "location": 45,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "tuple"
                ]
            }
        },
        "BufferWrapper.sample": {
            "name": "sample",
            "location": 48,
            "return": [
                "Tuple[(np.ndarray, ...)]"
            ],
            "arguments": {
                "self": []
            }
        },
        "BufferWrapper.__len__": {
            "name": "__len__",
            "location": 51,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/abstract/distributed_logger.py": {
        "DistributedLogger.__init__": {
            "name": "__init__",
            "location": 44,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "comm_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "backbone": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "head": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "env_name": [
                    "str"
                ],
                "is_atari": [
                    "bool"
                ],
                "state_size": [
                    "int"
                ],
                "output_size": [
                    "int"
                ],
                "max_update_step": [
                    "int"
                ],
                "episode_num": [
                    "int"
                ],
                "max_episode_steps": [
                    "int"
                ],
                "interim_test_num": [
                    "int"
                ],
                "is_log": [
                    "bool"
                ],
                "is_render": [
                    "bool"
                ]
            }
        },
        "DistributedLogger._init_env": {
            "name": "_init_env",
            "location": 83,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistributedLogger.load_params": {
            "name": "load_params",
            "location": 94,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "DistributedLogger.init_communication": {
            "name": "init_communication",
            "location": 101,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistributedLogger.select_action": {
            "name": "select_action",
            "location": 108,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "DistributedLogger.write_log": {
            "name": "write_log",
            "location": 112,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "log_value": [
                    "dict"
                ]
            }
        },
        "DistributedLogger._preprocess_state": {
            "name": "_preprocess_state",
            "location": 117,
            "return": [
                "Any"
            ],
            "arguments": {
                "state": [
                    "np.ndarray"
                ],
                "device": []
            }
        },
        "DistributedLogger.set_wandb": {
            "name": "set_wandb",
            "location": 121,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistributedLogger.recv_log_info": {
            "name": "recv_log_info",
            "location": 134,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistributedLogger.run": {
            "name": "run",
            "location": 146,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistributedLogger.write_worker_log": {
            "name": "write_worker_log",
            "location": 165,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "worker_logs": [
                    "List[dict]"
                ],
                "worker_update_interval": [
                    "int"
                ]
            }
        },
        "DistributedLogger.test": {
            "name": "test",
            "location": 214,
            "return": [
                "float"
            ],
            "arguments": {
                "self": [],
                "update_step": [
                    "int"
                ],
                "interim_test": [
                    "bool"
                ]
            }
        },
        "DistributedLogger._test": {
            "name": "_test",
            "location": 222,
            "return": [
                "float"
            ],
            "arguments": {
                "self": [],
                "update_step": [
                    "int"
                ],
                "interim_test": [
                    "bool"
                ]
            }
        },
        "DistributedLogger.synchronize": {
            "name": "synchronize",
            "location": 263,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_dict": [
                    "Dict[(str, np.ndarray)]"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/abstract/distributed_worker.py": {
        "BaseDistributedWorker.select_action": {
            "name": "select_action",
            "location": 27,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "BaseDistributedWorker.step": {
            "name": "step",
            "location": 31,
            "return": [
                "Tuple[(np.ndarray, Any, bool, dict)]"
            ],
            "arguments": {
                "self": [],
                "action": [
                    "np.ndarray"
                ]
            }
        },
        "BaseDistributedWorker.synchronize": {
            "name": "synchronize",
            "location": 35,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "new_state_dict": [
                    "Dict[(str, np.ndarray)]"
                ]
            }
        },
        "BaseDistributedWorker._synchronize": {
            "name": "_synchronize",
            "location": 39,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "network": [
                    "rl_algorithms.common.networks.brain.Brain"
                ],
                "new_state_dict": [
                    "Dict[(str, np.ndarray)]"
                ]
            }
        },
        "DistributedWorker.__init__": {
            "name": "__init__",
            "location": 61,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "rank": [
                    "int"
                ],
                "device": [
                    "str"
                ],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "env_name": [
                    "str"
                ],
                "is_atari": [
                    "bool"
                ],
                "max_episode_steps": [
                    "int"
                ]
            }
        },
        "DistributedWorker._init_env": {
            "name": "_init_env",
            "location": 82,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistributedWorker.load_params": {
            "name": "load_params",
            "location": 97,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "DistributedWorker.select_action": {
            "name": "select_action",
            "location": 104,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "DistributedWorker.step": {
            "name": "step",
            "location": 108,
            "return": [
                "Tuple[(np.ndarray, Any, bool, dict)]"
            ],
            "arguments": {
                "self": [],
                "action": [
                    "np.ndarray"
                ]
            }
        },
        "DistributedWorker.compute_priorities": {
            "name": "compute_priorities",
            "location": 113,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "Dict[(str, np.ndarray)]"
                ]
            }
        },
        "DistributedWorker.synchronize": {
            "name": "synchronize",
            "location": 117,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "new_state_dict": [
                    "Dict[(str, np.ndarray)]"
                ]
            }
        },
        "DistributedWorker._preprocess_state": {
            "name": "_preprocess_state",
            "location": 121,
            "return": [
                "Any"
            ],
            "arguments": {
                "state": [
                    "np.ndarray"
                ],
                "device": []
            }
        },
        "DistributedWorkerWrapper.__init__": {
            "name": "__init__",
            "location": 130,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "worker": [
                    "DistributedWorker"
                ],
                "comm_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ]
            }
        },
        "DistributedWorkerWrapper.init_communication": {
            "name": "init_communication",
            "location": 135,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistributedWorkerWrapper.select_action": {
            "name": "select_action",
            "location": 138,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "DistributedWorkerWrapper.step": {
            "name": "step",
            "location": 142,
            "return": [
                "Tuple[(np.ndarray, Any, bool, dict)]"
            ],
            "arguments": {
                "self": [],
                "action": [
                    "np.ndarray"
                ]
            }
        },
        "DistributedWorkerWrapper.synchronize": {
            "name": "synchronize",
            "location": 146,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "new_state_dict": [
                    "Dict[(str, np.ndarray)]"
                ]
            }
        },
        "DistributedWorkerWrapper.collect_data": {
            "name": "collect_data",
            "location": 151,
            "return": [
                "Dict[(str, np.ndarray)]"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistributedWorkerWrapper.run": {
            "name": "run",
            "location": 155,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistributedWorkerWrapper.preprocess_nstep": {
            "name": "preprocess_nstep",
            "location": 158,
            "return": [
                "Tuple[(np.ndarray, ...)]"
            ],
            "arguments": {
                "self": [],
                "nstepqueue": [
                    "Deque"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/abstract/her.py": {
        "HER.__init__": {
            "name": "__init__",
            "location": 23,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "reward_fn": [
                    "Callable[([tuple, np.ndarray], Any)]"
                ]
            }
        },
        "HER.fetch_desired_states_from_demo": {
            "name": "fetch_desired_states_from_demo",
            "location": 33,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "demo": [
                    "list"
                ]
            }
        },
        "HER.get_desired_state": {
            "name": "get_desired_state",
            "location": 37,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": []
            }
        },
        "HER.generate_demo_transitions": {
            "name": "generate_demo_transitions",
            "location": 41,
            "return": [
                "list"
            ],
            "arguments": {
                "self": [],
                "demo": [
                    "list"
                ]
            }
        },
        "HER._get_final_state": {
            "name": "_get_final_state",
            "location": 45,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "tuple"
                ]
            }
        },
        "HER._append_origin_transitions": {
            "name": "_append_origin_transitions",
            "location": 48,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "origin_transitions": [
                    "list"
                ],
                "transition": [
                    "tuple"
                ],
                "desired_state": [
                    "np.ndarray"
                ]
            }
        },
        "HER._append_new_transitions": {
            "name": "_append_new_transitions",
            "location": 54,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "new_transitions": [
                    "list"
                ],
                "transition": [
                    "tuple"
                ],
                "final_state": [
                    "np.ndarray"
                ]
            }
        },
        "HER._get_transition": {
            "name": "_get_transition",
            "location": 60,
            "return": [
                "Tuple[(np.ndarray, np.ndarray, Any, np.ndarray, bool)]"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "tuple"
                ],
                "goal_state": [
                    "np.ndarray"
                ]
            }
        },
        "HER.generate_transitions": {
            "name": "generate_transitions",
            "location": 73,
            "return": [
                "list"
            ],
            "arguments": {
                "self": [],
                "transitions": [
                    "list"
                ],
                "desired_state": [
                    "np.ndarray"
                ],
                "success_score": [
                    "float"
                ],
                "is_demo": [
                    "bool"
                ]
            }
        },
        "HER.__str__": {
            "name": "__str__",
            "location": 98,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/abstract/learner.py": {
        "BaseLearner.update_model": {
            "name": "update_model",
            "location": 25,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "tuple"
                ]
            }
        },
        "BaseLearner.save_params": {
            "name": "save_params",
            "location": 29,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "n_episode": [
                    "int"
                ]
            }
        },
        "BaseLearner.load_params": {
            "name": "load_params",
            "location": 33,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "BaseLearner.get_state_dict": {
            "name": "get_state_dict",
            "location": 40,
            "return": [
                "Union[(collections.OrderedDict, Tuple[collections.OrderedDict])]"
            ],
            "arguments": {
                "self": []
            }
        },
        "Learner.__init__": {
            "name": "__init__",
            "location": 55,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "env_name": [
                    "str"
                ],
                "is_test": [
                    "bool"
                ]
            }
        },
        "Learner._init_network": {
            "name": "_init_network",
            "location": 76,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "Learner.update_model": {
            "name": "update_model",
            "location": 80,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "tuple"
                ]
            }
        },
        "Learner.save_params": {
            "name": "save_params",
            "location": 84,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "n_episode": [
                    "int"
                ]
            }
        },
        "Learner._save_params": {
            "name": "_save_params",
            "location": 87,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "params": [
                    "dict"
                ],
                "n_episode": [
                    "int"
                ]
            }
        },
        "Learner.load_params": {
            "name": "load_params",
            "location": 97,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "Learner.get_state_dict": {
            "name": "get_state_dict",
            "location": 104,
            "return": [
                "Union[(collections.OrderedDict, Tuple[collections.OrderedDict])]"
            ],
            "arguments": {
                "self": []
            }
        },
        "Learner.get_policy": {
            "name": "get_policy",
            "location": 108,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "LearnerWrapper.__init__": {
            "name": "__init__",
            "location": 115,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "learner": [
                    "BaseLearner"
                ]
            }
        },
        "LearnerWrapper.update_model": {
            "name": "update_model",
            "location": 119,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "tuple"
                ]
            }
        },
        "LearnerWrapper.save_params": {
            "name": "save_params",
            "location": 122,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "n_episode": [
                    "int"
                ]
            }
        },
        "LearnerWrapper.load_params": {
            "name": "load_params",
            "location": 125,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "LearnerWrapper.get_state_dict": {
            "name": "get_state_dict",
            "location": 128,
            "return": [
                "Union[(collections.OrderedDict, Tuple[collections.OrderedDict])]"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistributedLearnerWrapper.__init__": {
            "name": "__init__",
            "location": 141,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "learner": [
                    "Learner"
                ],
                "comm_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ]
            }
        },
        "DistributedLearnerWrapper.init_communication": {
            "name": "init_communication",
            "location": 146,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistributedLearnerWrapper.update_model": {
            "name": "update_model",
            "location": 149,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "tuple"
                ]
            }
        },
        "DistributedLearnerWrapper.save_params": {
            "name": "save_params",
            "location": 153,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "n_update_step": [
                    "int"
                ]
            }
        },
        "DistributedLearnerWrapper.load_params": {
            "name": "load_params",
            "location": 157,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "DistributedLearnerWrapper.get_policy": {
            "name": "get_policy",
            "location": 161,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistributedLearnerWrapper.get_state_dict": {
            "name": "get_state_dict",
            "location": 165,
            "return": [
                "Union[(collections.OrderedDict, Tuple[collections.OrderedDict])]"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistributedLearnerWrapper.run": {
            "name": "run",
            "location": 170,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/abstract/reward_fn.py": {
        "RewardFn.__call__": {
            "name": "__call__",
            "location": 19,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "tuple"
                ],
                "goal_state": [
                    "np.ndarray"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/abstract/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/common/apex/architecture.py": {
        "ApeX.__init__": {
            "name": "__init__",
            "location": 52,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "env_info": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "learner_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "worker_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "logger_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "comm_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ],
                "is_render": [
                    "bool"
                ],
                "render_after": [
                    "int"
                ],
                "is_log": [
                    "bool"
                ],
                "save_period": [
                    "int"
                ],
                "episode_num": [
                    "int"
                ],
                "max_episode_steps": [
                    "int"
                ],
                "interim_test_num": [
                    "int"
                ]
            }
        },
        "ApeX._spawn": {
            "name": "_spawn",
            "location": 99,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "ApeX.train": {
            "name": "train",
            "location": 169,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "ApeX.test": {
            "name": "test",
            "location": 193,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/apex/learner.py": {
        "ApeXLearnerWrapper.__init__": {
            "name": "__init__",
            "location": 36,
            "return": [],
            "arguments": {
                "self": [],
                "learner": [],
                "comm_cfg": []
            }
        },
        "ApeXLearnerWrapper.init_communication": {
            "name": "init_communication",
            "location": 48,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ApeXLearnerWrapper.recv_replay_data": {
            "name": "recv_replay_data",
            "location": 64,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ApeXLearnerWrapper.send_new_priorities": {
            "name": "send_new_priorities",
            "location": 70,
            "return": [],
            "arguments": {
                "self": [],
                "indices": [],
                "priorities": []
            }
        },
        "ApeXLearnerWrapper.publish_params": {
            "name": "publish_params",
            "location": 76,
            "return": [],
            "arguments": {
                "self": [],
                "update_step": [],
                "np_state_dict": []
            }
        },
        "ApeXLearnerWrapper.send_info_to_logger": {
            "name": "send_info_to_logger",
            "location": 82,
            "return": [],
            "arguments": {
                "self": [],
                "np_state_dict": [],
                "step_info": []
            }
        },
        "ApeXLearnerWrapper.run": {
            "name": "run",
            "location": 93,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/apex/worker.py": {
        "ApeXWorkerWrapper.__init__": {
            "name": "__init__",
            "location": 34,
            "return": [],
            "arguments": {
                "self": [],
                "worker": [],
                "comm_cfg": []
            }
        },
        "ApeXWorkerWrapper.init_communication": {
            "name": "init_communication",
            "location": 44,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ApeXWorkerWrapper.send_data_to_buffer": {
            "name": "send_data_to_buffer",
            "location": 57,
            "return": [],
            "arguments": {
                "self": [],
                "replay_data": []
            }
        },
        "ApeXWorkerWrapper.recv_params_from_learner": {
            "name": "recv_params_from_learner",
            "location": 62,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ApeXWorkerWrapper.compute_priorities": {
            "name": "compute_priorities",
            "location": 81,
            "return": [],
            "arguments": {
                "self": [],
                "experience": []
            }
        },
        "ApeXWorkerWrapper.collect_data": {
            "name": "collect_data",
            "location": 85,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ApeXWorkerWrapper.run": {
            "name": "run",
            "location": 133,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ApeXWorkerWrapper.compute_mean_scores": {
            "name": "compute_mean_scores",
            "location": 146,
            "return": [],
            "arguments": {
                "scores": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/apex/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/common/buffer/distillation_buffer.py": {
        "DistillationBuffer.__init__": {
            "name": "__init__",
            "location": 30,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "batch_size": [
                    "int"
                ],
                "dataset_path": [
                    "List[str]"
                ]
            }
        },
        "DistillationBuffer.reset_dataloader": {
            "name": "reset_dataloader",
            "location": 50,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistillationBuffer.sample_for_diltillation": {
            "name": "sample_for_diltillation",
            "location": 61,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistillationDataset.__init__": {
            "name": "__init__",
            "location": 78,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "dataset_path": [
                    "List[str]"
                ]
            }
        },
        "DistillationDataset.__len__": {
            "name": "__len__",
            "location": 108,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistillationDataset.__getitem__": {
            "name": "__getitem__",
            "location": 112,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "index": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/buffer/gail_buffer.py": {
        "GAILBuffer.__init__": {
            "name": "__init__",
            "location": 23,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "dataset_path": [
                    "str"
                ]
            }
        },
        "GAILBuffer.load_demo": {
            "name": "load_demo",
            "location": 35,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "dataset_path": [
                    "str"
                ]
            }
        },
        "GAILBuffer.add": {
            "name": "add",
            "location": 43,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "GAILBuffer.sample": {
            "name": "sample",
            "location": 46,
            "return": [
                "Tuple[(np.ndarray, ...)]"
            ],
            "arguments": {
                "self": [],
                "batch_size": [],
                "indices": [
                    "List[int]"
                ]
            }
        },
        "GAILBuffer.__len__": {
            "name": "__len__",
            "location": 58,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/buffer/replay_buffer.py": {
        "ReplayBuffer.__init__": {
            "name": "__init__",
            "location": 35,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "max_len": [
                    "int"
                ],
                "batch_size": [
                    "int"
                ],
                "gamma": [
                    "float"
                ],
                "n_step": [
                    "int"
                ],
                "demo": [
                    "List[Tuple[(np.ndarray, np.ndarray, float, np.ndarray, bool)]]"
                ]
            }
        },
        "ReplayBuffer.add": {
            "name": "add",
            "location": 92,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "Tuple[(np.ndarray, np.ndarray, float, np.ndarray, bool)]"
                ]
            }
        },
        "ReplayBuffer.extend": {
            "name": "extend",
            "location": 129,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "transitions": [
                    "List[Tuple[(np.ndarray, np.ndarray, float, np.ndarray, bool)]]"
                ]
            }
        },
        "ReplayBuffer.sample": {
            "name": "sample",
            "location": 136,
            "return": [
                "Tuple[(np.ndarray, ...)]"
            ],
            "arguments": {
                "self": [],
                "indices": [
                    "List[int]"
                ]
            }
        },
        "ReplayBuffer._initialize_buffers": {
            "name": "_initialize_buffers",
            "location": 151,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ],
                "action": [
                    "np.ndarray"
                ]
            }
        },
        "ReplayBuffer.__len__": {
            "name": "__len__",
            "location": 164,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "RecurrentReplayBuffer.__init__": {
            "name": "__init__",
            "location": 189,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "max_len": [
                    "int"
                ],
                "batch_size": [
                    "int"
                ],
                "sequence_size": [
                    "int"
                ],
                "overlap_size": [
                    "int"
                ],
                "gamma": [
                    "float"
                ],
                "n_step": [
                    "int"
                ],
                "demo": [
                    "List[Tuple[(np.ndarray, np.ndarray, float, np.ndarray, bool)]]"
                ]
            }
        },
        "RecurrentReplayBuffer.add": {
            "name": "add",
            "location": 243,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "Tuple[(np.ndarray, np.ndarray, Any, float, np.ndarray, bool)]"
                ]
            }
        },
        "RecurrentReplayBuffer.sample": {
            "name": "sample",
            "location": 296,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "indices": [
                    "List[int]"
                ]
            }
        },
        "RecurrentReplayBuffer._initialize_local_buffers": {
            "name": "_initialize_local_buffers",
            "location": 311,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "RecurrentReplayBuffer._overlap_local_buffers": {
            "name": "_overlap_local_buffers",
            "location": 329,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "RecurrentReplayBuffer._initialize_buffers": {
            "name": "_initialize_buffers",
            "location": 344,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ],
                "action": [
                    "np.ndarray"
                ],
                "hidden": []
            }
        },
        "RecurrentReplayBuffer.__len__": {
            "name": "__len__",
            "location": 371,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/buffer/segment_tree.py": {
        "SegmentTree.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "capacity": [
                    "int"
                ],
                "operation": [
                    "Callable"
                ],
                "init_value": [
                    "float"
                ]
            }
        },
        "SegmentTree._operate_helper": {
            "name": "_operate_helper",
            "location": 37,
            "return": [
                "float"
            ],
            "arguments": {
                "self": [],
                "start": [
                    "int"
                ],
                "end": [
                    "int"
                ],
                "node": [
                    "int"
                ],
                "node_start": [
                    "int"
                ],
                "node_end": [
                    "int"
                ]
            }
        },
        "SegmentTree.operate": {
            "name": "operate",
            "location": 55,
            "return": [
                "float"
            ],
            "arguments": {
                "self": [],
                "start": [
                    "int"
                ],
                "end": [
                    "int"
                ]
            }
        },
        "SegmentTree.__setitem__": {
            "name": "__setitem__",
            "location": 63,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "idx": [
                    "int"
                ],
                "val": [
                    "float"
                ]
            }
        },
        "SegmentTree.__getitem__": {
            "name": "__getitem__",
            "location": 73,
            "return": [
                "float"
            ],
            "arguments": {
                "self": [],
                "idx": [
                    "int"
                ]
            }
        },
        "SumSegmentTree.__init__": {
            "name": "__init__",
            "location": 88,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "capacity": [
                    "int"
                ]
            }
        },
        "SumSegmentTree.sum": {
            "name": "sum",
            "location": 99,
            "return": [
                "float"
            ],
            "arguments": {
                "self": [],
                "start": [
                    "int"
                ],
                "end": [
                    "int"
                ]
            }
        },
        "SumSegmentTree.retrieve": {
            "name": "retrieve",
            "location": 103,
            "return": [
                "int"
            ],
            "arguments": {
                "self": [],
                "upperbound": [
                    "float"
                ]
            }
        },
        "MinSegmentTree.__init__": {
            "name": "__init__",
            "location": 129,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "capacity": [
                    "int"
                ]
            }
        },
        "MinSegmentTree.min": {
            "name": "min",
            "location": 140,
            "return": [
                "float"
            ],
            "arguments": {
                "self": [],
                "start": [
                    "int"
                ],
                "end": [
                    "int"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/buffer/wrapper.py": {
        "PrioritizedBufferWrapper.__init__": {
            "name": "__init__",
            "location": 45,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "base_buffer": [
                    "rl_algorithms.common.abstract.buffer.BaseBuffer"
                ],
                "alpha": [
                    "float"
                ],
                "epsilon_d": [
                    "float"
                ]
            }
        },
        "PrioritizedBufferWrapper.add": {
            "name": "add",
            "location": 77,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "Tuple[(np.ndarray, np.ndarray, float, np.ndarray, bool)]"
                ]
            }
        },
        "PrioritizedBufferWrapper._sample_proportional": {
            "name": "_sample_proportional",
            "location": 92,
            "return": [
                "list"
            ],
            "arguments": {
                "self": [],
                "batch_size": [
                    "int"
                ]
            }
        },
        "PrioritizedBufferWrapper.sample": {
            "name": "sample",
            "location": 113,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "beta": [
                    "float"
                ]
            }
        },
        "PrioritizedBufferWrapper.update_priorities": {
            "name": "update_priorities",
            "location": 138,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "indices": [
                    "list"
                ],
                "priorities": [
                    "np.ndarray"
                ]
            }
        },
        "ApeXBufferWrapper.__init__": {
            "name": "__init__",
            "location": 163,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "per_buffer": [],
                "hyper_params": [],
                "comm_cfg": []
            }
        },
        "ApeXBufferWrapper.init_communication": {
            "name": "init_communication",
            "location": 176,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ApeXBufferWrapper.recv_worker_data": {
            "name": "recv_worker_data",
            "location": 185,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ApeXBufferWrapper.send_batch_to_learner": {
            "name": "send_batch_to_learner",
            "location": 208,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ApeXBufferWrapper.update_priority_beta": {
            "name": "update_priority_beta",
            "location": 221,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ApeXBufferWrapper.run": {
            "name": "run",
            "location": 226,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/buffer/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/common/env/atari_wrappers.py": {
        "make_atari": {
            "name": "make_atari",
            "location": 307,
            "return": [
                "Union[(MaxAndSkipEnv, TimeLimit)]"
            ],
            "arguments": {
                "env_id": [],
                "max_episode_steps": []
            }
        },
        "wrap_deepmind": {
            "name": "wrap_deepmind",
            "location": 317,
            "return": [
                "Union[(ClipRewardEnv, FrameStack, ScaledFloatFrame, WarpFrame)]"
            ],
            "arguments": {
                "env": [],
                "episode_life": [],
                "clip_rewards": [],
                "frame_stack": [],
                "scale": []
            }
        },
        "wrap_pytorch": {
            "name": "wrap_pytorch",
            "location": 335,
            "return": [
                "ImageToPyTorch"
            ],
            "arguments": {
                "env": []
            }
        },
        "atari_env_generator": {
            "name": "atari_env_generator",
            "location": 339,
            "return": [
                "ImageToPyTorch"
            ],
            "arguments": {
                "env_id": [],
                "max_episode_steps": [],
                "frame_stack": [],
                "scale": []
            }
        },
        "TimeLimit.__init__": {
            "name": "__init__",
            "location": 20,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "max_episode_steps": []
            }
        },
        "TimeLimit.step": {
            "name": "step",
            "location": 26,
            "return": [
                "Tuple[(Any, Any, Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "ac": []
            }
        },
        "TimeLimit.reset": {
            "name": "reset",
            "location": 35,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "NoopResetEnv.__init__": {
            "name": "__init__",
            "location": 41,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "noop_max": []
            }
        },
        "NoopResetEnv.reset": {
            "name": "reset",
            "location": 52,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "NoopResetEnv.step": {
            "name": "step",
            "location": 70,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "ac": []
            }
        },
        "FireResetEnv.__init__": {
            "name": "__init__",
            "location": 75,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": []
            }
        },
        "FireResetEnv.reset": {
            "name": "reset",
            "location": 82,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "FireResetEnv.step": {
            "name": "step",
            "location": 93,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "ac": []
            }
        },
        "EpisodicLifeEnv.__init__": {
            "name": "__init__",
            "location": 98,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": []
            }
        },
        "EpisodicLifeEnv.step": {
            "name": "step",
            "location": 107,
            "return": [
                "Tuple[(Any, Any, Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "action": []
            }
        },
        "EpisodicLifeEnv.reset": {
            "name": "reset",
            "location": 122,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "MaxAndSkipEnv.__init__": {
            "name": "__init__",
            "location": 137,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "skip": []
            }
        },
        "MaxAndSkipEnv.step": {
            "name": "step",
            "location": 145,
            "return": [
                "Tuple[(Any, Any, Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "action": []
            }
        },
        "MaxAndSkipEnv.reset": {
            "name": "reset",
            "location": 165,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "ClipRewardEnv.__init__": {
            "name": "__init__",
            "location": 170,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": []
            }
        },
        "ClipRewardEnv.reward": {
            "name": "reward",
            "location": 173,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "reward": []
            }
        },
        "WarpFrame.__init__": {
            "name": "__init__",
            "location": 179,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "width": [],
                "height": [],
                "grayscale": []
            }
        },
        "WarpFrame.observation": {
            "name": "observation",
            "location": 194,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "frame": []
            }
        },
        "FrameStack.__init__": {
            "name": "__init__",
            "location": 206,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "k": []
            }
        },
        "FrameStack.reset": {
            "name": "reset",
            "location": 227,
            "return": [
                "LazyFrames"
            ],
            "arguments": {
                "self": []
            }
        },
        "FrameStack.step": {
            "name": "step",
            "location": 234,
            "return": [
                "Tuple[(LazyFrames, Any, Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "action": []
            }
        },
        "FrameStack._get_ob": {
            "name": "_get_ob",
            "location": 239,
            "return": [
                "LazyFrames"
            ],
            "arguments": {
                "self": []
            }
        },
        "ScaledFloatFrame.__init__": {
            "name": "__init__",
            "location": 245,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": []
            }
        },
        "ScaledFloatFrame.observation": {
            "name": "observation",
            "location": 251,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "observation": []
            }
        },
        "LazyFrames.__init__": {
            "name": "__init__",
            "location": 258,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "frames": []
            }
        },
        "LazyFrames._force": {
            "name": "_force",
            "location": 269,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "LazyFrames.__array__": {
            "name": "__array__",
            "location": 275,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "dtype": []
            }
        },
        "LazyFrames.__len__": {
            "name": "__len__",
            "location": 281,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "LazyFrames.__getitem__": {
            "name": "__getitem__",
            "location": 284,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "i": []
            }
        },
        "ImageToPyTorch.__init__": {
            "name": "__init__",
            "location": 293,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": []
            }
        },
        "ImageToPyTorch.observation": {
            "name": "observation",
            "location": 303,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "observation": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/env/multiprocessing_env.py": {
        "tile_images": {
            "name": "tile_images",
            "location": 13,
            "return": [
                "Any"
            ],
            "arguments": {
                "img_nhwc": []
            }
        },
        "worker": {
            "name": "worker",
            "location": 34,
            "return": [
                "None"
            ],
            "arguments": {
                "remote": [],
                "parent_remote": [],
                "env_fn_wrapper": []
            }
        },
        "VecEnv.__init__": {
            "name": "__init__",
            "location": 78,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_envs": [],
                "observation_space": [],
                "action_space": []
            }
        },
        "VecEnv.reset": {
            "name": "reset",
            "location": 84,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "VecEnv.step_async": {
            "name": "step_async",
            "location": 95,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "actions": []
            }
        },
        "VecEnv.step_wait": {
            "name": "step_wait",
            "location": 106,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "VecEnv.close_extras": {
            "name": "close_extras",
            "location": 118,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": []
            }
        },
        "VecEnv.close": {
            "name": "close",
            "location": 125,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": []
            }
        },
        "VecEnv.step": {
            "name": "step",
            "location": 133,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "actions": []
            }
        },
        "VecEnv.render": {
            "name": "render",
            "location": 141,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": [],
                "mode": []
            }
        },
        "VecEnv.get_images": {
            "name": "get_images",
            "location": 153,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": []
            }
        },
        "VecEnv.unwrapped": {
            "name": "unwrapped",
            "location": 160,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "VecEnv.get_viewer": {
            "name": "get_viewer",
            "location": 167,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "VecEnvWrapper.__init__": {
            "name": "__init__",
            "location": 181,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "venv": [],
                "observation_space": [],
                "action_space": []
            }
        },
        "VecEnvWrapper.step_async": {
            "name": "step_async",
            "location": 190,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "actions": []
            }
        },
        "VecEnvWrapper.reset": {
            "name": "reset",
            "location": 194,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "VecEnvWrapper.step_wait": {
            "name": "step_wait",
            "location": 198,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "VecEnvWrapper.close": {
            "name": "close",
            "location": 201,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "VecEnvWrapper.render": {
            "name": "render",
            "location": 204,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "mode": []
            }
        },
        "VecEnvWrapper.get_images": {
            "name": "get_images",
            "location": 207,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "CloudpickleWrapper.__init__": {
            "name": "__init__",
            "location": 217,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "CloudpickleWrapper.__getstate__": {
            "name": "__getstate__",
            "location": 220,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "CloudpickleWrapper.__setstate__": {
            "name": "__setstate__",
            "location": 223,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "ob": []
            }
        },
        "SubprocVecEnv.__init__": {
            "name": "__init__",
            "location": 233,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env_fns": []
            }
        },
        "SubprocVecEnv.step_async": {
            "name": "step_async",
            "location": 264,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "actions": []
            }
        },
        "SubprocVecEnv.step_wait": {
            "name": "step_wait",
            "location": 270,
            "return": [
                "Tuple[(Any, Any, Any, Any)]"
            ],
            "arguments": {
                "self": []
            }
        },
        "SubprocVecEnv.reset": {
            "name": "reset",
            "location": 277,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "SubprocVecEnv.sample": {
            "name": "sample",
            "location": 283,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "SubprocVecEnv.close_extras": {
            "name": "close_extras",
            "location": 289,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "SubprocVecEnv.get_images": {
            "name": "get_images",
            "location": 299,
            "return": [
                "list"
            ],
            "arguments": {
                "self": []
            }
        },
        "SubprocVecEnv._assert_not_closed": {
            "name": "_assert_not_closed",
            "location": 306,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/env/normalizers.py": {
        "ActionNormalizer.action": {
            "name": "action",
            "location": 15,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "action": [
                    "np.ndarray"
                ]
            }
        },
        "ActionNormalizer.reverse_action": {
            "name": "reverse_action",
            "location": 28,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "action": [
                    "np.ndarray"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/env/utils.py": {
        "set_env": {
            "name": "set_env",
            "location": 17,
            "return": [
                "Tuple[(Any, int)]"
            ],
            "arguments": {
                "env": [],
                "max_episode_steps": [
                    "int"
                ],
                "env_wrappers": [
                    "list"
                ]
            }
        },
        "env_generator": {
            "name": "env_generator",
            "location": 36,
            "return": [
                "Callable"
            ],
            "arguments": {
                "env_name": [
                    "str"
                ],
                "max_episode_steps": [
                    "int"
                ],
                "env_wrappers": [
                    "list"
                ]
            }
        },
        "make_envs": {
            "name": "make_envs",
            "location": 50,
            "return": [
                "rl_algorithms.common.env.multiprocessing_env.SubprocVecEnv"
            ],
            "arguments": {
                "env_gen": [
                    "Callable"
                ],
                "n_envs": [
                    "int"
                ]
            }
        },
        "env_generator._thunk": {
            "name": "_thunk",
            "location": 41,
            "return": [],
            "arguments": {
                "rank": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/env/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/common/networks/brain.py": {
        "Brain.__init__": {
            "name": "__init__",
            "location": 26,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "backbone_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "head_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "shared_backbone": []
            }
        },
        "Brain.forward": {
            "name": "forward",
            "location": 49,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "Brain.forward_": {
            "name": "forward_",
            "location": 56,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "x": [],
                "n_tau_samples": [
                    "int"
                ]
            }
        },
        "Brain.calculate_fc_input_size": {
            "name": "calculate_fc_input_size",
            "location": 65,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state_dim": [
                    "tuple"
                ]
            }
        },
        "GRUBrain.__init__": {
            "name": "__init__",
            "location": 77,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "backbone_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "head_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "gru_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ]
            }
        },
        "GRUBrain.forward": {
            "name": "forward",
            "location": 99,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "x": [],
                "hidden": [],
                "prev_action": [],
                "prev_reward": []
            }
        },
        "GRUBrain.forward_": {
            "name": "forward_",
            "location": 157,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "x": [],
                "hidden": [],
                "prev_action": [],
                "prev_reward": [],
                "n_tau_samples": [
                    "int"
                ]
            }
        },
        "GRUBrain.calculate_fc_input_size": {
            "name": "calculate_fc_input_size",
            "location": 218,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state_dim": [
                    "tuple"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/networks/heads.py": {
        "init_layer_uniform": {
            "name": "init_layer_uniform",
            "location": 23,
            "return": [
                "Any"
            ],
            "arguments": {
                "layer": [],
                "init_w": [
                    "float"
                ]
            }
        },
        "MLP.__init__": {
            "name": "__init__",
            "location": 49,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "configs": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "hidden_activation": [
                    "Callable"
                ],
                "linear_layer": [],
                "use_output_layer": [
                    "bool"
                ],
                "n_category": [
                    "int"
                ],
                "init_fn": [
                    "Callable"
                ]
            }
        },
        "MLP.forward": {
            "name": "forward",
            "location": 91,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "GaussianDist.__init__": {
            "name": "__init__",
            "location": 114,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "configs": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "hidden_activation": [
                    "Callable"
                ],
                "mu_activation": [
                    "Callable"
                ],
                "log_std_min": [
                    "float"
                ],
                "log_std_max": [
                    "float"
                ],
                "init_fn": [
                    "Callable"
                ]
            }
        },
        "GaussianDist.get_dist_params": {
            "name": "get_dist_params",
            "location": 148,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "GaussianDist.forward": {
            "name": "forward",
            "location": 167,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "TanhGaussianDistParams.__init__": {
            "name": "__init__",
            "location": 184,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "TanhGaussianDistParams.forward": {
            "name": "forward",
            "location": 188,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "x": [],
                "epsilon": [
                    "float"
                ]
            }
        },
        "CategoricalDist.__init__": {
            "name": "__init__",
            "location": 213,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "configs": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "hidden_activation": [
                    "Callable"
                ]
            }
        },
        "CategoricalDist.forward": {
            "name": "forward",
            "location": 225,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/networks/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/common/networks/backbones/cnn.py": {
        "CNNLayer.__init__": {
            "name": "__init__",
            "location": 25,
            "return": [],
            "arguments": {
                "self": [],
                "input_size": [],
                "output_size": [],
                "kernel_size": [],
                "stride": [],
                "padding": [],
                "pre_activation_fn": [],
                "activation_fn": [],
                "post_activation_fn": []
            }
        },
        "CNNLayer.forward": {
            "name": "forward",
            "location": 50,
            "return": [],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "CNN.__init__": {
            "name": "__init__",
            "location": 65,
            "return": [],
            "arguments": {
                "self": [],
                "configs": []
            }
        },
        "CNN.forward": {
            "name": "forward",
            "location": 73,
            "return": [],
            "arguments": {
                "self": [],
                "x": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/networks/backbones/resnet.py": {
        "BasicBlock.__init__": {
            "name": "__init__",
            "location": 25,
            "return": [],
            "arguments": {
                "self": [],
                "in_planes": [],
                "planes": [],
                "stride": [],
                "expansion": []
            }
        },
        "BasicBlock.forward": {
            "name": "forward",
            "location": 63,
            "return": [],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "Bottleneck.__init__": {
            "name": "__init__",
            "location": 76,
            "return": [],
            "arguments": {
                "self": [],
                "in_planes": [],
                "planes": [],
                "stride": [],
                "expansion": []
            }
        },
        "Bottleneck.forward": {
            "name": "forward",
            "location": 119,
            "return": [],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "ResNet.__init__": {
            "name": "__init__",
            "location": 134,
            "return": [],
            "arguments": {
                "self": [],
                "configs": []
            }
        },
        "ResNet._make_layer": {
            "name": "_make_layer",
            "location": 175,
            "return": [],
            "arguments": {
                "self": [],
                "block": [],
                "planes": [],
                "num_blocks": [],
                "stride": []
            }
        },
        "ResNet.forward": {
            "name": "forward",
            "location": 183,
            "return": [],
            "arguments": {
                "self": [],
                "x": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/common/networks/backbones/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/ddpg/agent.py": {
        "DDPGAgent.__init__": {
            "name": "__init__",
            "location": 47,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "env_info": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "learner_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "noise_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ],
                "is_render": [
                    "bool"
                ],
                "render_after": [
                    "int"
                ],
                "is_log": [
                    "bool"
                ],
                "save_period": [
                    "int"
                ],
                "episode_num": [
                    "int"
                ],
                "max_episode_steps": [
                    "int"
                ],
                "interim_test_num": [
                    "int"
                ]
            }
        },
        "DDPGAgent._initialize": {
            "name": "_initialize",
            "location": 101,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGAgent.select_action": {
            "name": "select_action",
            "location": 121,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "DDPGAgent._preprocess_state": {
            "name": "_preprocess_state",
            "location": 143,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "DDPGAgent.step": {
            "name": "step",
            "location": 148,
            "return": [
                "Tuple[(np.ndarray, Any, bool, dict)]"
            ],
            "arguments": {
                "self": [],
                "action": [
                    "np.ndarray"
                ]
            }
        },
        "DDPGAgent._add_transition_to_memory": {
            "name": "_add_transition_to_memory",
            "location": 160,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "Tuple[(np.ndarray, ...)]"
                ]
            }
        },
        "DDPGAgent.write_log": {
            "name": "write_log",
            "location": 164,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "log_value": [
                    "tuple"
                ]
            }
        },
        "DDPGAgent.pretrain": {
            "name": "pretrain",
            "location": 196,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGAgent.train": {
            "name": "train",
            "location": 200,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/ddpg/learner.py": {
        "DDPGLearner.__init__": {
            "name": "__init__",
            "location": 34,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "backbone": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "head": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "optim_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "noise_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "env_name": [
                    "str"
                ],
                "state_size": [
                    "tuple"
                ],
                "output_size": [
                    "int"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ]
            }
        },
        "DDPGLearner._init_network": {
            "name": "_init_network",
            "location": 61,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGLearner.update_model": {
            "name": "update_model",
            "location": 96,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "tuple"
                ]
            }
        },
        "DDPGLearner.save_params": {
            "name": "save_params",
            "location": 135,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "n_episode": [
                    "int"
                ]
            }
        },
        "DDPGLearner.load_params": {
            "name": "load_params",
            "location": 147,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "DDPGLearner.get_state_dict": {
            "name": "get_state_dict",
            "location": 160,
            "return": [
                "Tuple[collections.OrderedDict]"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGLearner.get_policy": {
            "name": "get_policy",
            "location": 164,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/ddpg/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/distillation/dqn_agent.py": {
        "DistillationDQNAgent._initialize": {
            "name": "_initialize",
            "location": 37,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistillationDQNAgent.make_distillation_dir": {
            "name": "make_distillation_dir",
            "location": 69,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistillationDQNAgent.get_action_and_q": {
            "name": "get_action_and_q",
            "location": 78,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "DistillationDQNAgent.step": {
            "name": "step",
            "location": 89,
            "return": [
                "Tuple[(np.ndarray, Any, bool, dict)]"
            ],
            "arguments": {
                "self": [],
                "action": [
                    "np.ndarray"
                ],
                "q_values": [
                    "np.ndarray"
                ]
            }
        },
        "DistillationDQNAgent._test": {
            "name": "_test",
            "location": 123,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "interim_test": [
                    "bool"
                ]
            }
        },
        "DistillationDQNAgent.update_distillation": {
            "name": "update_distillation",
            "location": 194,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistillationDQNAgent.add_expert_q": {
            "name": "add_expert_q",
            "location": 216,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DistillationDQNAgent.train": {
            "name": "train",
            "location": 238,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/distillation/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/dqn/agent.py": {
        "DQNAgent.__init__": {
            "name": "__init__",
            "location": 56,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "env_info": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "learner_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ],
                "is_render": [
                    "bool"
                ],
                "render_after": [
                    "int"
                ],
                "is_log": [
                    "bool"
                ],
                "save_period": [
                    "int"
                ],
                "episode_num": [
                    "int"
                ],
                "max_episode_steps": [
                    "int"
                ],
                "interim_test_num": [
                    "int"
                ]
            }
        },
        "DQNAgent._initialize": {
            "name": "_initialize",
            "location": 112,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQNAgent.select_action": {
            "name": "select_action",
            "location": 144,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "DQNAgent._preprocess_state": {
            "name": "_preprocess_state",
            "location": 159,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "DQNAgent.step": {
            "name": "step",
            "location": 164,
            "return": [
                "Tuple[(np.ndarray, Any, bool, dict)]"
            ],
            "arguments": {
                "self": [],
                "action": [
                    "np.ndarray"
                ]
            }
        },
        "DQNAgent._add_transition_to_memory": {
            "name": "_add_transition_to_memory",
            "location": 177,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "Tuple[(np.ndarray, ...)]"
                ]
            }
        },
        "DQNAgent.write_log": {
            "name": "write_log",
            "location": 188,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "log_value": [
                    "tuple"
                ]
            }
        },
        "DQNAgent.pretrain": {
            "name": "pretrain",
            "location": 219,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQNAgent.sample_experience": {
            "name": "sample_experience",
            "location": 223,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQNAgent.train": {
            "name": "train",
            "location": 241,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/dqn/distributed_logger.py": {
        "DQNLogger.load_params": {
            "name": "load_params",
            "location": 19,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "DQNLogger.select_action": {
            "name": "select_action",
            "location": 28,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "DQNLogger.write_log": {
            "name": "write_log",
            "location": 37,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "log_value": [
                    "dict"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/dqn/distributed_worker.py": {
        "DQNWorker.__init__": {
            "name": "__init__",
            "location": 32,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "rank": [
                    "int"
                ],
                "device": [
                    "str"
                ],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "env_name": [
                    "str"
                ],
                "is_atari": [
                    "bool"
                ],
                "max_episode_steps": [
                    "int"
                ],
                "loss_type": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "state_dict": [
                    "collections.OrderedDict"
                ],
                "backbone": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "head": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "state_size": [
                    "int"
                ],
                "output_size": [
                    "int"
                ]
            }
        },
        "DQNWorker._init_networks": {
            "name": "_init_networks",
            "location": 66,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_dict": [
                    "collections.OrderedDict"
                ]
            }
        },
        "DQNWorker.load_params": {
            "name": "load_params",
            "location": 72,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "DQNWorker.select_action": {
            "name": "select_action",
            "location": 80,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "DQNWorker.step": {
            "name": "step",
            "location": 101,
            "return": [
                "Tuple[(np.ndarray, Any, bool, dict)]"
            ],
            "arguments": {
                "self": [],
                "action": [
                    "np.ndarray"
                ]
            }
        },
        "DQNWorker.compute_priorities": {
            "name": "compute_priorities",
            "location": 106,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "memory": [
                    "Dict[(str, np.ndarray)]"
                ]
            }
        },
        "DQNWorker.synchronize": {
            "name": "synchronize",
            "location": 127,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "new_state_dict": [
                    "Dict[(str, np.ndarray)]"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/dqn/learner.py": {
        "DQNLearner.__init__": {
            "name": "__init__",
            "location": 37,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "loss_type": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "backbone": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "head": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "optim_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "env_name": [
                    "str"
                ],
                "state_size": [
                    "tuple"
                ],
                "output_size": [
                    "int"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ]
            }
        },
        "DQNLearner._init_network": {
            "name": "_init_network",
            "location": 65,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQNLearner.update_model": {
            "name": "update_model",
            "location": 85,
            "return": [
                "Tuple[(Any, Any, list, np.ndarray)]"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "tuple"
                ]
            }
        },
        "DQNLearner.save_params": {
            "name": "save_params",
            "location": 147,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "n_episode": [
                    "int"
                ]
            }
        },
        "DQNLearner.load_params": {
            "name": "load_params",
            "location": 158,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "DQNLearner.get_state_dict": {
            "name": "get_state_dict",
            "location": 168,
            "return": [
                "collections.OrderedDict"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQNLearner.get_policy": {
            "name": "get_policy",
            "location": 173,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/dqn/linear.py": {
        "NoisyLinear.__init__": {
            "name": "__init__",
            "location": 40,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "in_features": [
                    "int"
                ],
                "out_features": [
                    "int"
                ],
                "std_init": [
                    "float"
                ]
            }
        },
        "NoisyLinear.reset_parameters": {
            "name": "reset_parameters",
            "location": 58,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "NoisyLinear.scale_noise": {
            "name": "scale_noise",
            "location": 67,
            "return": [
                "Any"
            ],
            "arguments": {
                "size": [
                    "int"
                ]
            }
        },
        "NoisyLinear.reset_noise": {
            "name": "reset_noise",
            "location": 73,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "NoisyLinear.forward": {
            "name": "forward",
            "location": 82,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "NoisyLinearConstructor.__init__": {
            "name": "__init__",
            "location": 103,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "std_init": [
                    "float"
                ]
            }
        },
        "NoisyLinearConstructor.__call__": {
            "name": "__call__",
            "location": 107,
            "return": [
                "NoisyLinear"
            ],
            "arguments": {
                "self": [],
                "in_features": [
                    "int"
                ],
                "out_features": [
                    "int"
                ]
            }
        },
        "NoisyMLPHandler.reset_noise": {
            "name": "reset_noise",
            "location": 115,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/dqn/losses.py": {
        "IQNLoss.__call__": {
            "name": "__call__",
            "location": 24,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "model": [
                    "rl_algorithms.common.networks.brain.Brain"
                ],
                "target_model": [
                    "rl_algorithms.common.networks.brain.Brain"
                ],
                "experiences": [
                    "tuple"
                ],
                "gamma": [
                    "float"
                ],
                "head_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ]
            }
        },
        "C51Loss.__call__": {
            "name": "__call__",
            "location": 151,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "model": [
                    "rl_algorithms.common.networks.brain.Brain"
                ],
                "target_model": [
                    "rl_algorithms.common.networks.brain.Brain"
                ],
                "experiences": [
                    "tuple"
                ],
                "gamma": [
                    "float"
                ],
                "head_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ]
            }
        },
        "DQNLoss.__call__": {
            "name": "__call__",
            "location": 215,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "model": [
                    "rl_algorithms.common.networks.brain.Brain"
                ],
                "target_model": [
                    "rl_algorithms.common.networks.brain.Brain"
                ],
                "experiences": [
                    "tuple"
                ],
                "gamma": [
                    "float"
                ],
                "head_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/dqn/networks.py": {
        "DuelingMLP.__init__": {
            "name": "__init__",
            "location": 31,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "configs": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "hidden_activation": [
                    "Callable"
                ]
            }
        },
        "DuelingMLP.forward_": {
            "name": "forward_",
            "location": 61,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "DuelingMLP.forward": {
            "name": "forward",
            "location": 73,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "C51DuelingMLP.__init__": {
            "name": "__init__",
            "location": 87,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "configs": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "hidden_activation": [
                    "Callable"
                ]
            }
        },
        "C51DuelingMLP.forward_": {
            "name": "forward_",
            "location": 121,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "C51DuelingMLP.forward": {
            "name": "forward",
            "location": 141,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "IQNMLP.__init__": {
            "name": "__init__",
            "location": 157,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "configs": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "hidden_activation": [
                    "Callable"
                ]
            }
        },
        "IQNMLP.forward_": {
            "name": "forward_",
            "location": 187,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "n_tau_samples": [
                    "int"
                ]
            }
        },
        "IQNMLP.forward": {
            "name": "forward",
            "location": 216,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/dqn/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/fd/ddpg_agent.py": {
        "DDPGfDAgent._initialize": {
            "name": "_initialize",
            "location": 37,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGfDAgent._add_transition_to_memory": {
            "name": "_add_transition_to_memory",
            "location": 85,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "Tuple[(np.ndarray, ...)]"
                ]
            }
        },
        "DDPGfDAgent.sample_experience": {
            "name": "sample_experience",
            "location": 96,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGfDAgent.pretrain": {
            "name": "pretrain",
            "location": 112,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGfDAgent.train": {
            "name": "train",
            "location": 133,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/fd/ddpg_learner.py": {
        "DDPGfDLearner._get_critic_loss": {
            "name": "_get_critic_loss",
            "location": 29,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "experiences": [
                    "Tuple[(tuple, ...)]"
                ],
                "gamma": [
                    "float"
                ]
            }
        },
        "DDPGfDLearner.update_model": {
            "name": "update_model",
            "location": 50,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "tuple"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/fd/dqn_agent.py": {
        "DQfDAgent._initialize": {
            "name": "_initialize",
            "location": 33,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQfDAgent._load_demos": {
            "name": "_load_demos",
            "location": 76,
            "return": [
                "list"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQfDAgent.write_log": {
            "name": "write_log",
            "location": 84,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "log_value": [
                    "tuple"
                ]
            }
        },
        "DQfDAgent.pretrain": {
            "name": "pretrain",
            "location": 120,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQfDAgent.train": {
            "name": "train",
            "location": 141,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/fd/dqn_learner.py": {
        "DQfDLearner.update_model": {
            "name": "update_model",
            "location": 23,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "tuple"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/fd/sac_agent.py": {
        "SACfDAgent._initialize": {
            "name": "_initialize",
            "location": 38,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "SACfDAgent._add_transition_to_memory": {
            "name": "_add_transition_to_memory",
            "location": 83,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "Tuple[(np.ndarray, ...)]"
                ]
            }
        },
        "SACfDAgent.sample_experience": {
            "name": "sample_experience",
            "location": 94,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": []
            }
        },
        "SACfDAgent.pretrain": {
            "name": "pretrain",
            "location": 110,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "SACfDAgent.train": {
            "name": "train",
            "location": 137,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/fd/sac_learner.py": {
        "SACfDLearner.update_model": {
            "name": "update_model",
            "location": 16,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "Tuple[(tuple, ...)]"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/fd/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/gail/agent.py": {
        "GAILPPOAgent.__init__": {
            "name": "__init__",
            "location": 51,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "env_info": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "learner_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ],
                "is_render": [
                    "bool"
                ],
                "render_after": [
                    "int"
                ],
                "is_log": [
                    "bool"
                ],
                "save_period": [
                    "int"
                ],
                "episode_num": [
                    "int"
                ],
                "max_episode_steps": [
                    "int"
                ],
                "interim_test_num": [
                    "int"
                ]
            }
        },
        "GAILPPOAgent.step": {
            "name": "step",
            "location": 90,
            "return": [
                "Tuple[(np.ndarray, Any, bool, dict)]"
            ],
            "arguments": {
                "self": [],
                "action": []
            }
        },
        "GAILPPOAgent.write_log": {
            "name": "write_log",
            "location": 99,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "log_value": [
                    "tuple"
                ]
            }
        },
        "GAILPPOAgent.train": {
            "name": "train",
            "location": 147,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/gail/learner.py": {
        "GAILPPOLearner.__init__": {
            "name": "__init__",
            "location": 35,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "backbone": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "head": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "optim_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "env_name": [
                    "str"
                ],
                "state_size": [
                    "tuple"
                ],
                "output_size": [
                    "int"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ]
            }
        },
        "GAILPPOLearner._init_network": {
            "name": "_init_network",
            "location": 66,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "GAILPPOLearner.update_model": {
            "name": "update_model",
            "location": 119,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "tuple"
                ],
                "epsilon": [
                    "float"
                ]
            }
        },
        "GAILPPOLearner.save_params": {
            "name": "save_params",
            "location": 247,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "n_episode": [
                    "int"
                ]
            }
        },
        "GAILPPOLearner.load_params": {
            "name": "load_params",
            "location": 259,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "GAILPPOLearner.get_state_dict": {
            "name": "get_state_dict",
            "location": 270,
            "return": [
                "Tuple[collections.OrderedDict]"
            ],
            "arguments": {
                "self": []
            }
        },
        "GAILPPOLearner.set_demo_memory": {
            "name": "set_demo_memory",
            "location": 278,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "demo_memory": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/gail/networks.py": {
        "Discriminator.__init__": {
            "name": "__init__",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "backbone_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "head_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "action_embedder_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "shared_backbone": []
            }
        },
        "Discriminator.forward": {
            "name": "forward",
            "location": 50,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state_action": [
                    "Tuple[(Any, Any)]"
                ]
            }
        },
        "Discriminator.forward_action_embedder": {
            "name": "forward_action_embedder",
            "location": 60,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        },
        "Discriminator.calculate_fc_input_size": {
            "name": "calculate_fc_input_size",
            "location": 66,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state_dim": [
                    "tuple"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/gail/utils.py": {
        "compute_gail_reward": {
            "name": "compute_gail_reward",
            "location": 4,
            "return": [
                "Any"
            ],
            "arguments": {
                "discriminator_score": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/gail/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/ppo/agent.py": {
        "PPOAgent.__init__": {
            "name": "__init__",
            "location": 50,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "env_info": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "learner_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ],
                "is_render": [
                    "bool"
                ],
                "render_after": [
                    "int"
                ],
                "is_log": [
                    "bool"
                ],
                "save_period": [
                    "int"
                ],
                "episode_num": [
                    "int"
                ],
                "max_episode_steps": [
                    "int"
                ],
                "interim_test_num": [
                    "int"
                ]
            }
        },
        "PPOAgent.make_parallel_env": {
            "name": "make_parallel_env",
            "location": 125,
            "return": [
                "rl_algorithms.common.env.multiprocessing_env.SubprocVecEnv"
            ],
            "arguments": {
                "self": [],
                "max_episode_steps": [],
                "n_workers": []
            }
        },
        "PPOAgent.select_action": {
            "name": "select_action",
            "location": 133,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "PPOAgent.step": {
            "name": "step",
            "location": 161,
            "return": [
                "Tuple[(np.ndarray, Any, bool, dict)]"
            ],
            "arguments": {
                "self": [],
                "action": []
            }
        },
        "PPOAgent.decay_epsilon": {
            "name": "decay_epsilon",
            "location": 182,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "t": [
                    "int"
                ]
            }
        },
        "PPOAgent.write_log": {
            "name": "write_log",
            "location": 192,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "log_value": [
                    "tuple"
                ]
            }
        },
        "PPOAgent.train": {
            "name": "train",
            "location": 213,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/ppo/learner.py": {
        "PPOLearner.__init__": {
            "name": "__init__",
            "location": 31,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "backbone": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "head": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "optim_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "env_name": [
                    "str"
                ],
                "state_size": [
                    "tuple"
                ],
                "output_size": [
                    "int"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ]
            }
        },
        "PPOLearner._init_network": {
            "name": "_init_network",
            "location": 57,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "PPOLearner.update_model": {
            "name": "update_model",
            "location": 99,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "tuple"
                ],
                "epsilon": [
                    "float"
                ]
            }
        },
        "PPOLearner.save_params": {
            "name": "save_params",
            "location": 202,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "n_episode": [
                    "int"
                ]
            }
        },
        "PPOLearner.load_params": {
            "name": "load_params",
            "location": 212,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "PPOLearner.get_state_dict": {
            "name": "get_state_dict",
            "location": 223,
            "return": [
                "Tuple[collections.OrderedDict]"
            ],
            "arguments": {
                "self": []
            }
        },
        "PPOLearner.get_policy": {
            "name": "get_policy",
            "location": 227,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/ppo/utils.py": {
        "compute_gae": {
            "name": "compute_gae",
            "location": 18,
            "return": [
                "list"
            ],
            "arguments": {
                "next_value": [
                    "list"
                ],
                "rewards": [
                    "list"
                ],
                "masks": [
                    "list"
                ],
                "values": [
                    "list"
                ],
                "gamma": [
                    "float"
                ],
                "tau": [
                    "float"
                ]
            }
        },
        "ppo_iter": {
            "name": "ppo_iter",
            "location": 39,
            "return": [
                "Generator[(Tuple[(Any, Any, Any, Any, Any, Any, int)], Any, None)]"
            ],
            "arguments": {
                "epoch": [
                    "int"
                ],
                "mini_batch_size": [
                    "int"
                ],
                "states": [],
                "actions": [],
                "values": [],
                "log_probs": [],
                "returns": [],
                "advantages": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/ppo/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/recurrent/dqn_agent.py": {
        "R2D1Agent._initialize": {
            "name": "_initialize",
            "location": 35,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "R2D1Agent.select_action": {
            "name": "select_action",
            "location": 73,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ],
                "hidden_state": [],
                "prev_action": [],
                "prev_reward": [
                    "np.ndarray"
                ]
            }
        },
        "R2D1Agent._add_transition_to_memory": {
            "name": "_add_transition_to_memory",
            "location": 95,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "Tuple[(np.ndarray, ...)]"
                ]
            }
        },
        "R2D1Agent.step": {
            "name": "step",
            "location": 106,
            "return": [
                "Tuple[(np.ndarray, Any, bool, dict)]"
            ],
            "arguments": {
                "self": [],
                "action": [
                    "np.ndarray"
                ],
                "hidden_state": []
            }
        },
        "R2D1Agent.sample_experience": {
            "name": "sample_experience",
            "location": 127,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": []
            }
        },
        "R2D1Agent.train": {
            "name": "train",
            "location": 147,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "R2D1Agent._test": {
            "name": "_test",
            "location": 235,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "interim_test": [
                    "bool"
                ]
            }
        },
        "R2D1Agent.test_with_saliency_map": {
            "name": "test_with_saliency_map",
            "location": 287,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/recurrent/learner.py": {
        "R2D1Learner.__init__": {
            "name": "__init__",
            "location": 30,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "loss_type": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "backbone": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "head": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "gru": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "optim_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "env_name": [
                    "str"
                ],
                "state_size": [
                    "tuple"
                ],
                "output_size": [
                    "int"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ]
            }
        },
        "R2D1Learner._init_network": {
            "name": "_init_network",
            "location": 60,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "R2D1Learner.update_model": {
            "name": "update_model",
            "location": 84,
            "return": [
                "Tuple[(Any, Any, list, np.ndarray)]"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "tuple"
                ]
            }
        },
        "R2D1Learner.save_params": {
            "name": "save_params",
            "location": 150,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "n_episode": [
                    "int"
                ]
            }
        },
        "R2D1Learner.load_params": {
            "name": "load_params",
            "location": 160,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "R2D1Learner.get_state_dict": {
            "name": "get_state_dict",
            "location": 170,
            "return": [
                "collections.OrderedDict"
            ],
            "arguments": {
                "self": []
            }
        },
        "R2D1Learner.get_policy": {
            "name": "get_policy",
            "location": 174,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/recurrent/losses.py": {
        "R2D1DQNLoss.__call__": {
            "name": "__call__",
            "location": 25,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "model": [
                    "rl_algorithms.common.networks.brain.Brain"
                ],
                "target_model": [
                    "rl_algorithms.common.networks.brain.Brain"
                ],
                "experiences": [
                    "tuple"
                ],
                "gamma": [
                    "float"
                ],
                "head_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "burn_in_step": [
                    "int"
                ]
            }
        },
        "R2D1C51Loss.__call__": {
            "name": "__call__",
            "location": 110,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "model": [
                    "rl_algorithms.common.networks.brain.Brain"
                ],
                "target_model": [
                    "rl_algorithms.common.networks.brain.Brain"
                ],
                "experiences": [
                    "tuple"
                ],
                "gamma": [
                    "float"
                ],
                "head_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "burn_in_step": [
                    "int"
                ]
            }
        },
        "R2D1IQNLoss.__call__": {
            "name": "__call__",
            "location": 236,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "self": [],
                "model": [
                    "rl_algorithms.common.networks.brain.Brain"
                ],
                "target_model": [
                    "rl_algorithms.common.networks.brain.Brain"
                ],
                "experiences": [
                    "tuple"
                ],
                "gamma": [
                    "float"
                ],
                "head_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "burn_in_step": [
                    "int"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/recurrent/utils.py": {
        "infer_leading_dims": {
            "name": "infer_leading_dims",
            "location": 8,
            "return": [
                "Tuple[(int, int, int, tuple)]"
            ],
            "arguments": {
                "tensor": [],
                "dim": [
                    "int"
                ]
            }
        },
        "restore_leading_dims": {
            "name": "restore_leading_dims",
            "location": 39,
            "return": [
                "Any"
            ],
            "arguments": {
                "tensors": [],
                "lead_dim": [
                    "int"
                ],
                "first_dim": [
                    "int"
                ],
                "second_dim": [
                    "int"
                ]
            }
        },
        "valid_from_done": {
            "name": "valid_from_done",
            "location": 63,
            "return": [
                "Any"
            ],
            "arguments": {
                "done": []
            }
        },
        "slice_r2d1_arguments": {
            "name": "slice_r2d1_arguments",
            "location": 78,
            "return": [
                "tuple"
            ],
            "arguments": {
                "experiences": [
                    "tuple"
                ],
                "burn_in_step": [
                    "int"
                ],
                "output_size": [
                    "int"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/recurrent/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/sac/agent.py": {
        "SACAgent.__init__": {
            "name": "__init__",
            "location": 45,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "env_info": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "learner_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ],
                "is_render": [
                    "bool"
                ],
                "render_after": [
                    "int"
                ],
                "is_log": [
                    "bool"
                ],
                "save_period": [
                    "int"
                ],
                "episode_num": [
                    "int"
                ],
                "max_episode_steps": [
                    "int"
                ],
                "interim_test_num": [
                    "int"
                ]
            }
        },
        "SACAgent._initialize": {
            "name": "_initialize",
            "location": 90,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "SACAgent.select_action": {
            "name": "select_action",
            "location": 109,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "SACAgent._preprocess_state": {
            "name": "_preprocess_state",
            "location": 130,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "SACAgent.step": {
            "name": "step",
            "location": 135,
            "return": [
                "Tuple[(np.ndarray, Any, bool, dict)]"
            ],
            "arguments": {
                "self": [],
                "action": [
                    "np.ndarray"
                ]
            }
        },
        "SACAgent._add_transition_to_memory": {
            "name": "_add_transition_to_memory",
            "location": 147,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "Tuple[(np.ndarray, ...)]"
                ]
            }
        },
        "SACAgent.write_log": {
            "name": "write_log",
            "location": 151,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "log_value": [
                    "tuple"
                ]
            }
        },
        "SACAgent.pretrain": {
            "name": "pretrain",
            "location": 190,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "SACAgent.train": {
            "name": "train",
            "location": 194,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/sac/learner.py": {
        "SACLearner.__init__": {
            "name": "__init__",
            "location": 39,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "backbone": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "head": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "optim_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "env_name": [
                    "str"
                ],
                "state_size": [
                    "tuple"
                ],
                "output_size": [
                    "int"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ]
            }
        },
        "SACLearner._init_network": {
            "name": "_init_network",
            "location": 74,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "SACLearner.update_model": {
            "name": "update_model",
            "location": 122,
            "return": [
                "Tuple[(Any, Any, list, np.ndarray)]"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "tuple"
                ]
            }
        },
        "SACLearner.save_params": {
            "name": "save_params",
            "location": 211,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "n_episode": [
                    "int"
                ]
            }
        },
        "SACLearner.load_params": {
            "name": "load_params",
            "location": 230,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "SACLearner.get_state_dict": {
            "name": "get_state_dict",
            "location": 250,
            "return": [
                "Tuple[collections.OrderedDict]"
            ],
            "arguments": {
                "self": []
            }
        },
        "SACLearner.get_policy": {
            "name": "get_policy",
            "location": 254,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/sac/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/td3/agent.py": {
        "TD3Agent.__init__": {
            "name": "__init__",
            "location": 46,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "env_info": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "learner_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "noise_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ],
                "is_render": [
                    "bool"
                ],
                "render_after": [
                    "int"
                ],
                "is_log": [
                    "bool"
                ],
                "save_period": [
                    "int"
                ],
                "episode_num": [
                    "int"
                ],
                "max_episode_steps": [
                    "int"
                ],
                "interim_test_num": [
                    "int"
                ]
            }
        },
        "TD3Agent.select_action": {
            "name": "select_action",
            "location": 115,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "np.ndarray"
                ]
            }
        },
        "TD3Agent.step": {
            "name": "step",
            "location": 136,
            "return": [
                "Tuple[(np.ndarray, Any, bool, dict)]"
            ],
            "arguments": {
                "self": [],
                "action": [
                    "np.ndarray"
                ]
            }
        },
        "TD3Agent.write_log": {
            "name": "write_log",
            "location": 147,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "log_value": [
                    "tuple"
                ]
            }
        },
        "TD3Agent.train": {
            "name": "train",
            "location": 180,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/td3/learner.py": {
        "TD3Learner.__init__": {
            "name": "__init__",
            "location": 38,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "hyper_params": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "log_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "backbone": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "head": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "optim_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "noise_cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "env_name": [
                    "str"
                ],
                "state_size": [
                    "tuple"
                ],
                "output_size": [
                    "int"
                ],
                "is_test": [
                    "bool"
                ],
                "load_from": [
                    "str"
                ]
            }
        },
        "TD3Learner._init_network": {
            "name": "_init_network",
            "location": 73,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "TD3Learner.update_model": {
            "name": "update_model",
            "location": 122,
            "return": [
                "tuple"
            ],
            "arguments": {
                "self": [],
                "experience": [
                    "tuple"
                ]
            }
        },
        "TD3Learner.save_params": {
            "name": "save_params",
            "location": 187,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "n_episode": [
                    "int"
                ]
            }
        },
        "TD3Learner.load_params": {
            "name": "load_params",
            "location": 202,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "TD3Learner.get_state_dict": {
            "name": "get_state_dict",
            "location": 217,
            "return": [
                "Tuple[collections.OrderedDict]"
            ],
            "arguments": {
                "self": []
            }
        },
        "TD3Learner.get_policy": {
            "name": "get_policy",
            "location": 225,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/td3/__init__.py": {},
    "rl_algorithms-master/rl_algorithms/utils/config.py": {
        "add_args": {
            "name": "add_args",
            "location": 34,
            "return": [
                "_T0"
            ],
            "arguments": {
                "parser": [
                    "_T0"
                ],
                "cfg": [],
                "prefix": []
            }
        },
        "ConfigDict.__missing__": {
            "name": "__missing__",
            "location": 9,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": [],
                "name": []
            }
        },
        "ConfigDict.__getattr__": {
            "name": "__getattr__",
            "location": 12,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "name": []
            }
        },
        "ConfigDict.__setitem__": {
            "name": "__setitem__",
            "location": 27,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "name": [],
                "value": []
            }
        },
        "YamlConfig.__init__": {
            "name": "__init__",
            "location": 56,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "config_paths": [
                    "dict"
                ]
            }
        },
        "YamlConfig._yaml_to_config_dict": {
            "name": "_yaml_to_config_dict",
            "location": 63,
            "return": [
                "ConfigDict"
            ],
            "arguments": {
                "path": [
                    "str"
                ]
            }
        },
        "YamlConfig.get_config_dict": {
            "name": "get_config_dict",
            "location": 73,
            "return": [
                "ConfigDict"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/utils/registry.py": {
        "build_from_cfg": {
            "name": "build_from_cfg",
            "location": 51,
            "return": [
                "Any"
            ],
            "arguments": {
                "cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "registry": [
                    "Registry"
                ],
                "default_args": [
                    "dict"
                ]
            }
        },
        "build_ray_obj_from_cfg": {
            "name": "build_ray_obj_from_cfg",
            "location": 83,
            "return": [
                "Any"
            ],
            "arguments": {
                "cfg": [
                    "rl_algorithms.utils.config.ConfigDict"
                ],
                "registry": [
                    "Registry"
                ],
                "default_args": [
                    "dict"
                ]
            }
        },
        "Registry.__init__": {
            "name": "__init__",
            "location": 9,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "name": []
            }
        },
        "Registry.__repr__": {
            "name": "__repr__",
            "location": 13,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "Registry.name": {
            "name": "name",
            "location": 20,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "Registry.module_dict": {
            "name": "module_dict",
            "location": 24,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "Registry.get": {
            "name": "get",
            "location": 27,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "key": []
            }
        },
        "Registry._register_module": {
            "name": "_register_module",
            "location": 30,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "module_class": []
            }
        },
        "Registry.register_module": {
            "name": "register_module",
            "location": 46,
            "return": [
                "_T0"
            ],
            "arguments": {
                "self": [],
                "cls": [
                    "_T0"
                ]
            }
        }
    },
    "rl_algorithms-master/rl_algorithms/utils/__init__.py": {},
    "rl_algorithms-master/tests/test_cnn_cfg.py": {
        "test_brain": {
            "name": "test_brain",
            "location": 52,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_cnn_with_config": {
            "name": "test_cnn_with_config",
            "location": 62,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_resnet_with_config": {
            "name": "test_resnet_with_config",
            "location": 76,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "rl_algorithms-master/tests/test_config_registry.py": {
        "parse_args": {
            "name": "parse_args",
            "location": 11,
            "return": [
                "argparse.Namespace"
            ],
            "arguments": {
                "args": [
                    "list"
                ]
            }
        },
        "test_config_registry": {
            "name": "test_config_registry",
            "location": 58,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "rl_algorithms-master/tests/test_helper_funcion.py": {
        "generate_dummy_buffer": {
            "name": "generate_dummy_buffer",
            "location": 10,
            "return": [
                "Deque"
            ],
            "arguments": {
                "maxlen": [
                    "int"
                ],
                "index": [
                    "int"
                ]
            }
        },
        "check_case1": {
            "name": "check_case1",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "maxlen": [
                    "int"
                ]
            }
        },
        "check_case2": {
            "name": "check_case2",
            "location": 30,
            "return": [
                "None"
            ],
            "arguments": {
                "maxlen": [
                    "int"
                ]
            }
        },
        "check_case3": {
            "name": "check_case3",
            "location": 39,
            "return": [
                "None"
            ],
            "arguments": {
                "maxlen": [
                    "int"
                ]
            }
        },
        "test_get_n_step_info": {
            "name": "test_get_n_step_info",
            "location": 48,
            "return": [
                "None"
            ],
            "arguments": {
                "maxlen": []
            }
        }
    },
    "rl_algorithms-master/tests/buffer/test_distillation_buffer.py": {
        "gen_test_data": {
            "name": "gen_test_data",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "num_files": [
                    "int"
                ]
            }
        },
        "check_multiple_data_load": {
            "name": "check_multiple_data_load",
            "location": 37,
            "return": [
                "None"
            ],
            "arguments": {
                "num_files": [
                    "int"
                ]
            }
        },
        "check_mixture_data_assert": {
            "name": "check_mixture_data_assert",
            "location": 46,
            "return": [
                "None"
            ],
            "arguments": {
                "num_files": [
                    "int"
                ]
            }
        },
        "delete_path": {
            "name": "delete_path",
            "location": 53,
            "return": [
                "None"
            ],
            "arguments": {
                "path": [
                    "str"
                ]
            }
        },
        "test_distillation_buffer": {
            "name": "test_distillation_buffer",
            "location": 58,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "rl_algorithms-master/tests/buffer/test_prioritized_buffer.py": {
        "generate_prioritized_buffer": {
            "name": "generate_prioritized_buffer",
            "location": 10,
            "return": [
                "Tuple[(rl_algorithms.common.buffer.wrapper.PrioritizedBufferWrapper, list)]"
            ],
            "arguments": {
                "buffer_length": [
                    "int"
                ],
                "batch_size": [
                    "int"
                ],
                "idx_lst": [],
                "prior_lst": []
            }
        },
        "sample_dummy": {
            "name": "sample_dummy",
            "location": 30,
            "return": [
                "list"
            ],
            "arguments": {
                "prioritized_buffer": [
                    "rl_algorithms.common.buffer.wrapper.PrioritizedBufferWrapper"
                ],
                "times": [
                    "int"
                ]
            }
        },
        "check_prioritized": {
            "name": "check_prioritized",
            "location": 44,
            "return": [
                "bool"
            ],
            "arguments": {
                "prop_lst": [
                    "list"
                ],
                "sampled_lst": [
                    "list"
                ]
            }
        },
        "test_prioritized": {
            "name": "test_prioritized",
            "location": 54,
            "return": [
                "None"
            ],
            "arguments": {
                "buffer_length": [],
                "batch_size": []
            }
        }
    },
    "rl_algorithms-master/tests/buffer/test_uniform_buffer.py": {
        "generate_transition": {
            "name": "generate_transition",
            "location": 9,
            "return": [
                "Tuple[(np.ndarray, ...)]"
            ],
            "arguments": {
                "idx": [
                    "int"
                ]
            }
        },
        "generate_sample_idx": {
            "name": "generate_sample_idx",
            "location": 19,
            "return": [
                "int"
            ],
            "arguments": {
                "buffer": [
                    "rl_algorithms.common.buffer.replay_buffer.ReplayBuffer"
                ]
            }
        },
        "check_uniform": {
            "name": "check_uniform",
            "location": 27,
            "return": [
                "bool"
            ],
            "arguments": {
                "lst": [
                    "list"
                ]
            }
        },
        "test_uniform_sample": {
            "name": "test_uniform_sample",
            "location": 33,
            "return": [
                "None"
            ],
            "arguments": {
                "buffer_length": [],
                "batch_size": []
            }
        }
    },
    "rl_algorithms-master/tests/integration/test_run_agent.py": {
        "check_run_env": {
            "name": "check_run_env",
            "location": 10,
            "return": [
                "None"
            ],
            "arguments": {
                "config_root": [
                    "str"
                ],
                "run_file": [
                    "str"
                ]
            }
        },
        "check_save_path": {
            "name": "check_save_path",
            "location": 48,
            "return": [
                "None"
            ],
            "arguments": {
                "save_path": [
                    "str"
                ]
            }
        },
        "test_run_lunarlander_continuous": {
            "name": "test_run_lunarlander_continuous",
            "location": 56,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_run_lunarlander": {
            "name": "test_run_lunarlander",
            "location": 63,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_run_pong_no_frame_skip": {
            "name": "test_run_pong_no_frame_skip",
            "location": 68,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "rl_algorithms-master/tests/integration/test_run_apex.py": {
        "check_run_apex": {
            "name": "check_run_apex",
            "location": 10,
            "return": [
                "None"
            ],
            "arguments": {
                "config_root": [
                    "str"
                ],
                "run_file": [
                    "str"
                ]
            }
        },
        "check_save_path": {
            "name": "check_save_path",
            "location": 47,
            "return": [
                "None"
            ],
            "arguments": {
                "save_path": [
                    "str"
                ]
            }
        },
        "test_run_pong_no_frame_skip": {
            "name": "test_run_pong_no_frame_skip",
            "location": 55,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "rl_algorithms-master/tests/integration/test_run_distillation_agent.py": {
        "check_distillation_agent": {
            "name": "check_distillation_agent",
            "location": 10,
            "return": [
                "None"
            ],
            "arguments": {
                "config": [
                    "str"
                ],
                "run_file": [
                    "str"
                ]
            }
        },
        "delete_path": {
            "name": "delete_path",
            "location": 67,
            "return": [
                "None"
            ],
            "arguments": {
                "path": [
                    "str"
                ]
            }
        },
        "test_distillation": {
            "name": "test_distillation",
            "location": 73,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    }
}
{
    "rlib-master/setup.py": {},
    "rlib-master/docs/conf.py": {},
    "rlib-master/rlib/__init__.py": {},
    "rlib-master/rlib/algorithms/base.py": {
        "Agent.__init__": {
            "name": "__init__",
            "location": 16,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent.origin": {
            "name": "origin",
            "location": 28,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent.description": {
            "name": "description",
            "location": 32,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent.reset": {
            "name": "reset",
            "location": 35,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent.act": {
            "name": "act",
            "location": 40,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "add_noise": [],
                "logger": []
            }
        },
        "Agent.step": {
            "name": "step",
            "location": 44,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "action": [],
                "reward": [],
                "next_state": [],
                "done": [],
                "logger": []
            }
        },
        "Agent.learn": {
            "name": "learn",
            "location": 48,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "experiences": [],
                "logger": []
            }
        },
        "Agent.update": {
            "name": "update",
            "location": 52,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "rewards": [],
                "logger": []
            }
        },
        "Agent.get_hyperparameters": {
            "name": "get_hyperparameters",
            "location": 56,
            "return": [
                "dict"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent._set_hyperparameters": {
            "name": "_set_hyperparameters",
            "location": 64,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "new_hyperparameters": []
            }
        },
        "Agent.save_state_dicts": {
            "name": "save_state_dicts",
            "location": 74,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent.load_state_dicts": {
            "name": "load_state_dicts",
            "location": 85,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/algorithms/__init__.py": {},
    "rlib-master/rlib/algorithms/a2c/agent.py": {
        "A2CAgent.__init__": {
            "name": "__init__",
            "location": 15,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/algorithms/a2c/__init__.py": {},
    "rlib-master/rlib/algorithms/a3c/agent.py": {
        "A3CAgent.__init__": {
            "name": "__init__",
            "location": 15,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/algorithms/a3c/__init__.py": {},
    "rlib-master/rlib/algorithms/ddpg/agent.py": {
        "DDPGAgent.__init__": {
            "name": "__init__",
            "location": 30,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_size": [
                    "int"
                ],
                "action_size": [
                    "int"
                ],
                "num_agents": [
                    "int"
                ],
                "actor_local": [],
                "actor_target": [],
                "actor_optimizer": [],
                "critic_local": [],
                "critic_target": [],
                "critic_optimizer": [],
                "new_hyperparameters": [],
                "seed": [
                    "int"
                ],
                "device": [
                    "str"
                ],
                "model_output_dir": [
                    "str"
                ],
                "enable_logger": [
                    "bool"
                ],
                "logger_path": [
                    "str"
                ],
                "logger_comment": [
                    "str"
                ],
                "opt_soft_update": [
                    "bool"
                ]
            }
        },
        "DDPGAgent.__str__": {
            "name": "__str__",
            "location": 115,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGAgent.origin": {
            "name": "origin",
            "location": 132,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGAgent.description": {
            "name": "description",
            "location": 140,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGAgent.step": {
            "name": "step",
            "location": 155,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "states": [],
                "actions": [],
                "rewards": [],
                "next_states": [],
                "dones": [],
                "logger": []
            }
        },
        "DDPGAgent.act": {
            "name": "act",
            "location": 180,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "add_noise": [
                    "bool"
                ],
                "logger": []
            }
        },
        "DDPGAgent.learn": {
            "name": "learn",
            "location": 221,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "experiences": [],
                "logger": []
            }
        }
    },
    "rlib-master/rlib/algorithms/ddpg/model.py": {
        "hidden_init": {
            "name": "hidden_init",
            "location": 8,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "layer": []
            }
        },
        "Actor.__init__": {
            "name": "__init__",
            "location": 17,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_size": [
                    "int"
                ],
                "action_size": [
                    "int"
                ],
                "seed": [
                    "int"
                ],
                "fc1_units": [
                    "int"
                ],
                "fc2_units": [
                    "int"
                ]
            }
        },
        "Actor.reset_parameters": {
            "name": "reset_parameters",
            "location": 40,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Actor.forward": {
            "name": "forward",
            "location": 47,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": []
            }
        },
        "Critic.__init__": {
            "name": "__init__",
            "location": 64,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_size": [
                    "int"
                ],
                "action_size": [
                    "int"
                ],
                "seed": [
                    "int"
                ],
                "fcs1_units": [
                    "int"
                ],
                "fc2_units": [
                    "int"
                ]
            }
        },
        "Critic.reset_parameters": {
            "name": "reset_parameters",
            "location": 86,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Critic.forward": {
            "name": "forward",
            "location": 91,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "action": []
            }
        }
    },
    "rlib-master/rlib/algorithms/ddpg/__init__.py": {},
    "rlib-master/rlib/algorithms/dqn/agent.py": {
        "DQNAgent.__init__": {
            "name": "__init__",
            "location": 34,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_size": [
                    "int"
                ],
                "action_size": [
                    "int"
                ],
                "qnetwork_local": [],
                "qnetwork_target": [],
                "optimizer": [],
                "new_hyperparameters": [],
                "seed": [
                    "int"
                ],
                "device": [
                    "str"
                ],
                "model_output_dir": [
                    "str"
                ],
                "opt_soft_update": [
                    "bool"
                ],
                "opt_ddqn": [
                    "bool"
                ]
            }
        },
        "DQNAgent.__str__": {
            "name": "__str__",
            "location": 109,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQNAgent.origin": {
            "name": "origin",
            "location": 122,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQNAgent.description": {
            "name": "description",
            "location": 130,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQNAgent.step": {
            "name": "step",
            "location": 145,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "action": [],
                "reward": [],
                "next_state": [],
                "done": [],
                "logger": []
            }
        },
        "DQNAgent.act": {
            "name": "act",
            "location": 165,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "eps": [],
                "add_noise": [],
                "logger": []
            }
        },
        "DQNAgent.learn": {
            "name": "learn",
            "location": 189,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "experiences": [],
                "logger": []
            }
        }
    },
    "rlib-master/rlib/algorithms/dqn/model.py": {
        "QNetwork.__init__": {
            "name": "__init__",
            "location": 9,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_size": [
                    "int"
                ],
                "action_size": [
                    "int"
                ],
                "hidden_layer_input_size": [
                    "int"
                ],
                "hidden_layer_output_size": [
                    "int"
                ],
                "seed": [
                    "int"
                ],
                "softmax_output": [
                    "bool"
                ]
            }
        },
        "QNetwork.forward": {
            "name": "forward",
            "location": 35,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": []
            }
        }
    },
    "rlib-master/rlib/algorithms/dqn/__init__.py": {},
    "rlib-master/rlib/algorithms/maddpg/agent.py": {
        "MADDPGAgent.__init__": {
            "name": "__init__",
            "location": 33,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": [],
                "state_size": [],
                "action_size": [],
                "num_agents": [],
                "agents": [],
                "new_hyperparameters": [],
                "seed": [],
                "device": [],
                "model_output_dir": [],
                "enable_logger": [],
                "logger_path": [],
                "logger_comment": [],
                "opt_soft_update": []
            }
        },
        "MADDPGAgent.reset": {
            "name": "reset",
            "location": 82,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "MADDPGAgent.act": {
            "name": "act",
            "location": 87,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "observations": [],
                "add_noise": [],
                "logger": []
            }
        },
        "MADDPGAgent.step": {
            "name": "step",
            "location": 96,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "observations": [],
                "actions": [],
                "rewards": [],
                "next_observations": [],
                "dones": [],
                "logger": []
            }
        },
        "MADDPGAgent.learn": {
            "name": "learn",
            "location": 112,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "experiences": [],
                "agent_number": [],
                "logger": []
            }
        },
        "MADDPGAgent._get_agent_number": {
            "name": "_get_agent_number",
            "location": 142,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "i": []
            }
        },
        "DDPGAgent.__init__": {
            "name": "__init__",
            "location": 150,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_size": [],
                "action_size": [],
                "agent_id": [],
                "handler": [],
                "actor_local": [],
                "actor_target": [],
                "actor_optimizer": [],
                "critic_local": [],
                "critic_target": [],
                "critic_optimizer": [],
                "seed": [],
                "device": []
            }
        },
        "DDPGAgent.__str__": {
            "name": "__str__",
            "location": 194,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGAgent.act": {
            "name": "act",
            "location": 208,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "add_noise": [],
                "logger": []
            }
        },
        "DDPGAgent.learn": {
            "name": "learn",
            "location": 223,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "experiences": [],
                "next_actions": [],
                "actions_pred": [],
                "logger": []
            }
        },
        "DDPGAgent._decay_noise_amplification": {
            "name": "_decay_noise_amplification",
            "location": 273,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/algorithms/maddpg/model.py": {
        "hidden_init": {
            "name": "hidden_init",
            "location": 8,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "layer": []
            }
        },
        "Actor.__init__": {
            "name": "__init__",
            "location": 17,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_size": [],
                "action_size": [],
                "seed": [],
                "fc1_units": [],
                "fc2_units": []
            }
        },
        "Actor.reset_parameters": {
            "name": "reset_parameters",
            "location": 34,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Actor.forward": {
            "name": "forward",
            "location": 39,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": []
            }
        },
        "Critic.__init__": {
            "name": "__init__",
            "location": 49,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_size": [],
                "action_size": [],
                "seed": [],
                "fcs1_units": [],
                "fc2_units": []
            }
        },
        "Critic.reset_parameters": {
            "name": "reset_parameters",
            "location": 66,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Critic.forward": {
            "name": "forward",
            "location": 71,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "action": []
            }
        }
    },
    "rlib-master/rlib/algorithms/maddpg/__init__.py": {},
    "rlib-master/rlib/algorithms/ppo/agent.py": {
        "PPOAgent.__init__": {
            "name": "__init__",
            "location": 27,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": [],
                "state_size": [],
                "action_size": [],
                "policy": [],
                "optimizer": [],
                "new_hyperparameters": [],
                "seed": [],
                "device": [],
                "model_output_dir": [],
                "enable_logger": [],
                "logger_path": [],
                "logger_comment": []
            }
        },
        "PPOAgent.reset": {
            "name": "reset",
            "location": 78,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "PPOAgent.step": {
            "name": "step",
            "location": 81,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "action": [],
                "reward": [],
                "next_state": [],
                "done": [],
                "logger": []
            }
        },
        "PPOAgent.act": {
            "name": "act",
            "location": 85,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "add_noise": [],
                "logger": []
            }
        },
        "PPOAgent.update": {
            "name": "update",
            "location": 94,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "rewards": [],
                "logger": []
            }
        },
        "PPOAgent.clipped_surrogate": {
            "name": "clipped_surrogate",
            "location": 117,
            "return": [
                "Any"
            ],
            "arguments": {
                "policy": [],
                "old_probs": [],
                "states": [],
                "actions": [],
                "rewards": [],
                "discount": [],
                "epsilon": [],
                "beta": []
            }
        }
    },
    "rlib-master/rlib/algorithms/ppo/model.py": {
        "Policy.__init__": {
            "name": "__init__",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "s_size": [],
                "h_size": [],
                "a_size": []
            }
        },
        "Policy.forward": {
            "name": "forward",
            "location": 12,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        }
    },
    "rlib-master/rlib/algorithms/ppo/__init__.py": {},
    "rlib-master/rlib/algorithms/sac/agent.py": {
        "SACAgent.__init__": {
            "name": "__init__",
            "location": 15,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/algorithms/sac/__init__.py": {},
    "rlib-master/rlib/algorithms/td3/agent.py": {
        "TD3Agent.__init__": {
            "name": "__init__",
            "location": 15,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/algorithms/td3/__init__.py": {},
    "rlib-master/rlib/algorithms/trpo/agent.py": {
        "TRPOAgent.__init__": {
            "name": "__init__",
            "location": 15,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/algorithms/trpo/__init__.py": {},
    "rlib-master/rlib/algorithms/vpg/agent.py": {
        "VPGAgent.__init__": {
            "name": "__init__",
            "location": 24,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_size": [
                    "int"
                ],
                "action_size": [
                    "int"
                ],
                "policy": [],
                "optimizer": [],
                "new_hyperparameters": [],
                "seed": [
                    "int"
                ],
                "device": [
                    "str"
                ],
                "model_output_dir": [],
                "enable_logger": [
                    "bool"
                ],
                "logger_path": [
                    "str"
                ],
                "logger_comment": [
                    "str"
                ]
            }
        },
        "VPGAgent.__str__": {
            "name": "__str__",
            "location": 88,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "VPGAgent.origin": {
            "name": "origin",
            "location": 99,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "VPGAgent.description": {
            "name": "description",
            "location": 107,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "VPGAgent.reset": {
            "name": "reset",
            "location": 121,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "VPGAgent.step": {
            "name": "step",
            "location": 125,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "action": [],
                "reward": [],
                "next_state": [],
                "done": [],
                "logger": []
            }
        },
        "VPGAgent.act": {
            "name": "act",
            "location": 129,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "add_noise": [],
                "logger": []
            }
        },
        "VPGAgent.update": {
            "name": "update",
            "location": 148,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "rewards": [],
                "logger": []
            }
        }
    },
    "rlib-master/rlib/algorithms/vpg/model.py": {
        "Policy.__init__": {
            "name": "__init__",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "s_size": [],
                "h_size": [],
                "a_size": []
            }
        },
        "Policy.forward": {
            "name": "forward",
            "location": 12,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "x": []
            }
        }
    },
    "rlib-master/rlib/algorithms/vpg/__init__.py": {},
    "rlib-master/rlib/environments/base.py": {
        "BaseEnvironment.act": {
            "name": "act",
            "location": 6,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "observations": [],
                "add_noise": [],
                "logger": []
            }
        },
        "BaseEnvironment.plot_scores": {
            "name": "plot_scores",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "scores": [],
                "env_solved_score": []
            }
        },
        "BaseEnvironment.get_max_score_per_episode": {
            "name": "get_max_score_per_episode",
            "location": 43,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "BaseEnvironment.get_rolling_score_averages": {
            "name": "get_rolling_score_averages",
            "location": 47,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "window": []
            }
        },
        "BaseEnvironment.get_current_average_score": {
            "name": "get_current_average_score",
            "location": 59,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "window": []
            }
        }
    },
    "rlib-master/rlib/environments/gym.py": {
        "GymEnvironment.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [],
                "algorithm": [],
                "seed": [
                    "int"
                ],
                "logger": [
                    "rlib.shared.utils.Logger"
                ],
                "gifs_recorder": [
                    "rlib.shared.utils.GIFRecorder"
                ]
            }
        },
        "GymEnvironment.__str__": {
            "name": "__str__",
            "location": 47,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "GymEnvironment.start_env": {
            "name": "start_env",
            "location": 59,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "GymEnvironment.close_env": {
            "name": "close_env",
            "location": 64,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "GymEnvironment.is_observation_box": {
            "name": "is_observation_box",
            "location": 68,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "GymEnvironment.is_observation_discrete": {
            "name": "is_observation_discrete",
            "location": 71,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "GymEnvironment.is_action_box": {
            "name": "is_action_box",
            "location": 74,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "GymEnvironment.is_action_discrete": {
            "name": "is_action_discrete",
            "location": 77,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "GymEnvironment.normalize_observation": {
            "name": "normalize_observation",
            "location": 80,
            "return": [
                "_T0"
            ],
            "arguments": {
                "self": [],
                "obs": [
                    "_T0"
                ]
            }
        },
        "GymEnvironment.train": {
            "name": "train",
            "location": 90,
            "return": [
                "List[float]"
            ],
            "arguments": {
                "self": [],
                "num_episodes": [
                    "int"
                ],
                "max_t": [
                    "int"
                ],
                "add_noise": [
                    "bool"
                ],
                "scores_window_size": [
                    "int"
                ],
                "save_every": [
                    "int"
                ]
            }
        },
        "GymEnvironment.test": {
            "name": "test",
            "location": 177,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_episodes": [
                    "int"
                ],
                "load_state_dicts": [
                    "bool"
                ],
                "render": [
                    "bool"
                ]
            }
        }
    },
    "rlib-master/rlib/environments/parallel_env.py": {
        "CloudpickleWrapper.__init__": {
            "name": "__init__",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env_fn": []
            }
        },
        "CloudpickleWrapper.__getstate__": {
            "name": "__getstate__",
            "location": 21,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "CloudpickleWrapper.__setstate__": {
            "name": "__setstate__",
            "location": 25,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "ob": []
            }
        },
        "VectorizedEnv.__init__": {
            "name": "__init__",
            "location": 33,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_envs": [],
                "observation_space": [],
                "action_space": []
            }
        },
        "VectorizedEnv.reset": {
            "name": "reset",
            "location": 39,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "VectorizedEnv.step_async": {
            "name": "step_async",
            "location": 48,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "actions": []
            }
        },
        "VectorizedEnv.step_wait": {
            "name": "step_wait",
            "location": 56,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "VectorizedEnv.close": {
            "name": "close",
            "location": 68,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "VectorizedEnv.step": {
            "name": "step",
            "location": 72,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": [],
                "actions": []
            }
        },
        "VectorizedEnv.render": {
            "name": "render",
            "location": 79,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "mode": []
            }
        },
        "VectorizedEnv.unwrapped": {
            "name": "unwrapped",
            "location": 84,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ParallelEnv.__init__": {
            "name": "__init__",
            "location": 92,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": [],
                "env_name": [],
                "n": [],
                "seed": [],
                "spaces": []
            }
        },
        "ParallelEnv.step_async": {
            "name": "step_async",
            "location": 128,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "actions": []
            }
        },
        "ParallelEnv.step_wait": {
            "name": "step_wait",
            "location": 133,
            "return": [
                "Tuple[(Any, Any, Any, Any)]"
            ],
            "arguments": {
                "self": []
            }
        },
        "ParallelEnv.reset": {
            "name": "reset",
            "location": 139,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "ParallelEnv.reset_task": {
            "name": "reset_task",
            "location": 144,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        },
        "ParallelEnv.close": {
            "name": "close",
            "location": 149,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "ParallelEnv.worker": {
            "name": "worker",
            "location": 162,
            "return": [
                "None"
            ],
            "arguments": {
                "remote": [],
                "parent_remote": [],
                "env_fn_wrapper": []
            }
        }
    },
    "rlib-master/rlib/environments/unity.py": {
        "UnityEnvironment.__init__": {
            "name": "__init__",
            "location": 9,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/environments/__init__.py": {},
    "rlib-master/rlib/shared/noise.py": {
        "OUNoise.__init__": {
            "name": "__init__",
            "location": 10,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "size": [],
                "seed": [],
                "mu": [
                    "float"
                ],
                "theta": [
                    "float"
                ],
                "sigma": [
                    "float"
                ]
            }
        },
        "OUNoise.reset": {
            "name": "reset",
            "location": 29,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "OUNoise.sample": {
            "name": "sample",
            "location": 33,
            "return": [
                "Any"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/shared/replay_buffer.py": {
        "ReplayBuffer.__init__": {
            "name": "__init__",
            "location": 11,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "buffer_size": [
                    "int"
                ],
                "batch_size": [
                    "int"
                ],
                "device": [
                    "str"
                ],
                "seed": [
                    "int"
                ]
            }
        },
        "ReplayBuffer.add": {
            "name": "add",
            "location": 29,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "action": [],
                "reward": [],
                "next_state": [],
                "done": []
            }
        },
        "ReplayBuffer.sample": {
            "name": "sample",
            "location": 42,
            "return": [
                "Tuple[(Any, Any, Any, Any, Any)]"
            ],
            "arguments": {
                "self": []
            }
        },
        "ReplayBuffer.__len__": {
            "name": "__len__",
            "location": 74,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/shared/utils.py": {
        "hard_update": {
            "name": "hard_update",
            "location": 93,
            "return": [
                "None"
            ],
            "arguments": {
                "local_model": [],
                "target_model": []
            }
        },
        "soft_update": {
            "name": "soft_update",
            "location": 106,
            "return": [
                "None"
            ],
            "arguments": {
                "local_model": [],
                "target_model": [],
                "tau": [
                    "float"
                ]
            }
        },
        "Logger.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ],
                "comment": [
                    "str"
                ],
                "verbosity": [
                    "str"
                ],
                "experiment_name": [
                    "str"
                ]
            }
        },
        "Logger.close": {
            "name": "close",
            "location": 39,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Logger.add_scalar": {
            "name": "add_scalar",
            "location": 43,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "name": [
                    "str"
                ],
                "data": [],
                "index": [
                    "int"
                ]
            }
        },
        "Logger.add_scalars": {
            "name": "add_scalars",
            "location": 47,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "name": [
                    "str"
                ],
                "data": [],
                "index": [
                    "int"
                ]
            }
        },
        "Logger.add_video": {
            "name": "add_video",
            "location": 51,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": []
            }
        },
        "GIFRecorder.__init__": {
            "name": "__init__",
            "location": 58,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ],
                "duration": [
                    "float"
                ],
                "experiment_name": [
                    "str"
                ]
            }
        },
        "GIFRecorder.save_gif": {
            "name": "save_gif",
            "location": 79,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "filename": [
                    "str"
                ],
                "frames": []
            }
        }
    },
    "rlib-master/rlib/shared/__init__.py": {},
    "rlib-master/test/__init__.py": {},
    "rlib-master/test/algorithms/ddpg_test.py": {
        "main": {
            "name": "main",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "seed": []
            }
        }
    },
    "rlib-master/test/algorithms/dqn_test.py": {
        "main": {
            "name": "main",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "seed": []
            }
        }
    },
    "rlib-master/test/algorithms/vpg_test.py": {
        "main": {
            "name": "main",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "seed": []
            }
        }
    },
    "rlib-master/test/algorithms/__init__.py": {},
    "rlib-master/test/environments/test_base.py": {
        "BaseEnvironmentTest.setUp": {
            "name": "setUp",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/test/environments/test_gym.py": {
        "GymEnvironmentTest.setUp": {
            "name": "setUp",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/test/environments/test_unity.py": {
        "UnityEnvironmentTest.setUp": {
            "name": "setUp",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/test/environments/__init__.py": {},
    "rlib-master/test/shared/test_noise.py": {
        "OUNoiseTest.setUp": {
            "name": "setUp",
            "location": 10,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "OUNoiseTest.test_reset": {
            "name": "test_reset",
            "location": 13,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "OUNoiseTest.test_sample": {
            "name": "test_sample",
            "location": 20,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/test/shared/test_replay_buffer.py": {
        "ReplayBufferTest.setUp": {
            "name": "setUp",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "ReplayBufferTest.populate_replay_buffer": {
            "name": "populate_replay_buffer",
            "location": 12,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "n": []
            }
        },
        "ReplayBufferTest.test_add": {
            "name": "test_add",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "ReplayBufferTest.test_sample": {
            "name": "test_sample",
            "location": 26,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/test/shared/test_units.py": {
        "UtilsTest.test_hard_update": {
            "name": "test_hard_update",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "UtilsTest.test_soft_update": {
            "name": "test_soft_update",
            "location": 10,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/test/shared/__init__.py": {}
}
{
    "words-exercise-master/wordcounter.py": {
        "_invert_counts": {
            "name": "_invert_counts",
            "location": 17,
            "return": [
                "Dict[(Any, list)]"
            ],
            "arguments": {
                "counts": []
            }
        },
        "top_words": {
            "name": "top_words",
            "location": 26,
            "return": [
                "List[Tuple[(Any, list)]]"
            ],
            "arguments": {
                "streams_or_paths": [],
                "encoding": [],
                "n": [],
                "ascii_only": [],
                "nodes": []
            }
        }
    },
    "words-exercise-master/test/test_counter.py": {
        "_count_words": {
            "name": "_count_words",
            "location": 20,
            "return": [
                "Dict[(str, int)]"
            ],
            "arguments": {
                "words_string": []
            }
        },
        "WordCounterTest.test_nonempty": {
            "name": "test_nonempty",
            "location": 28,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "WordCounterTest.test_empty": {
            "name": "test_empty",
            "location": 32,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "WordCounterTest.test_wordless": {
            "name": "test_wordless",
            "location": 36,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "words-exercise-master/test/test_tokenizer.py": {
        "_unicode_tokenizer": {
            "name": "_unicode_tokenizer",
            "location": 32,
            "return": [
                "word_tokenizer.WordTokenizer"
            ],
            "arguments": {
                "string": []
            }
        },
        "TokenizerTest.setUp": {
            "name": "setUp",
            "location": 19,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "TokenizerTest.test_ascii": {
            "name": "test_ascii",
            "location": 22,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "TokenizerTest.test_unicode": {
            "name": "test_unicode",
            "location": 27,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "EmptyTokenizerTest.test_empty": {
            "name": "test_empty",
            "location": 37,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "EmptyTokenizerTest.test_wordless": {
            "name": "test_wordless",
            "location": 41,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "words-exercise-master/test/__init__.py": {},
    "words-exercise-master/wordcounter/dispy_counter.py": {
        "_computation": {
            "name": "_computation",
            "location": 17,
            "return": [
                "Any"
            ],
            "arguments": {
                "path": [],
                "counter": []
            }
        },
        "_dispy_create_cluster": {
            "name": "_dispy_create_cluster",
            "location": 22,
            "return": [
                "Any"
            ],
            "arguments": {
                "status_cb": [],
                "nodes": []
            }
        },
        "dispy_count_words": {
            "name": "dispy_count_words",
            "location": 35,
            "return": [
                "Dict[(nothing, nothing)]"
            ],
            "arguments": {
                "paths": [],
                "counter": [],
                "nodes": []
            }
        },
        "dispy_count_words.status_cb": {
            "name": "status_cb",
            "location": 56,
            "return": [],
            "arguments": {
                "status": [],
                "_node": [],
                "_job": []
            }
        }
    },
    "words-exercise-master/wordcounter/word_counter.py": {
        "merge_counts": {
            "name": "merge_counts",
            "location": 10,
            "return": [
                "None"
            ],
            "arguments": {
                "totals": [],
                "new_counts": []
            }
        },
        "count_words": {
            "name": "count_words",
            "location": 59,
            "return": [
                "dict"
            ],
            "arguments": {
                "streams_or_paths": [],
                "counter": []
            }
        },
        "WordCounter.__init__": {
            "name": "__init__",
            "location": 19,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "encoding": [],
                "ascii_only": []
            }
        },
        "WordCounter._words": {
            "name": "_words",
            "location": 32,
            "return": [
                "word_tokenizer.WordTokenizer"
            ],
            "arguments": {
                "self": [],
                "stream": []
            }
        },
        "WordCounter.count_words": {
            "name": "count_words",
            "location": 38,
            "return": [
                "Dict[(str, int)]"
            ],
            "arguments": {
                "self": [],
                "stream_or_path": []
            }
        }
    },
    "words-exercise-master/wordcounter/word_tokenizer.py": {
        "is_ascii_alnum": {
            "name": "is_ascii_alnum",
            "location": 10,
            "return": [
                "bool"
            ],
            "arguments": {
                "s": []
            }
        },
        "WordTokenizer.__init__": {
            "name": "__init__",
            "location": 22,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "stream": [],
                "word_test": []
            }
        },
        "WordTokenizer._chars": {
            "name": "_chars",
            "location": 34,
            "return": [
                "Generator[(Any, Any, None)]"
            ],
            "arguments": {
                "self": []
            }
        },
        "WordTokenizer.__iter__": {
            "name": "__iter__",
            "location": 44,
            "return": [
                "Generator[(str, Any, None)]"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "words-exercise-master/wordcounter/__init__.py": {}
}
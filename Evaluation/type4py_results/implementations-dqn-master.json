{
    "implementations-dqn-master/train_eval.py": {
        "get_config": {
            "name": "get_config",
            "location": 74,
            "return": [],
            "arguments": {}
        },
        "train_eval": {
            "name": "train_eval",
            "location": 245,
            "return": [],
            "arguments": {
                "dqn_agent": [],
                "replay_buffer": [],
                "env": [],
                "eval_env": [],
                "device": [],
                "logger": [],
                "CONFIG": []
            }
        },
        "main": {
            "name": "main",
            "location": 416,
            "return": [],
            "arguments": {}
        }
    },
    "implementations-dqn-master/train_eval_atari.py": {
        "main": {
            "name": "main",
            "location": 67,
            "return": [
                ""
            ],
            "arguments": {}
        }
    },
    "implementations-dqn-master/dqn/agents.py": {
        "DQNAgent.__init__": {
            "name": "__init__",
            "location": 15,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "env": [
                    "gym.Env",
                    "str",
                    "Mapping[str, str]",
                    "dict",
                    "List[str]"
                ],
                "q_net": [
                    "Dict[str, str]",
                    "bool",
                    "dict",
                    "int",
                    "str",
                    "Sequence[str]"
                ],
                "optimizer": [
                    "gym.Env",
                    "str",
                    "Mapping[str, str]",
                    "dict",
                    "List[str]"
                ],
                "device": [
                    "gym.Env",
                    "str",
                    "Mapping[str, str]",
                    "dict",
                    "List[str]"
                ]
            }
        },
        "DQNAgent.select_action": {
            "name": "select_action",
            "location": 45,
            "return": [
                "Optional[int]",
                "List[str]",
                "type",
                "str",
                "Optional[Iterable[Any]]"
            ],
            "arguments": {
                "self": [],
                "obs": [
                    "Callable"
                ],
                "epsilon": [
                    "float",
                    "int"
                ]
            }
        },
        "DQNAgent.train": {
            "name": "train",
            "location": 71,
            "return": [
                "bytes",
                "int",
                "str",
                "numpy.ndarray",
                "torch.FloatTensor"
            ],
            "arguments": {
                "self": [],
                "experiences": [
                    "int",
                    "List[torch.Tensor]",
                    "str",
                    "float"
                ],
                "discount": [
                    "int",
                    "List[int]",
                    "torch.Tensor",
                    "bool",
                    "dict"
                ]
            }
        },
        "DQNAgent.update_target_q_net": {
            "name": "update_target_q_net",
            "location": 115,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "implementations-dqn-master/dqn/networks.py": {
        "QNetwork.__init__": {
            "name": "__init__",
            "location": 10,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "in_dim": [
                    "bool",
                    "int"
                ],
                "out_dim": [
                    "bool",
                    "int"
                ]
            }
        },
        "QNetwork.forward": {
            "name": "forward",
            "location": 38,
            "return": [
                "str",
                "Tuple[str]"
            ],
            "arguments": {
                "self": [],
                "x": [
                    "int",
                    "float",
                    "str",
                    "T"
                ]
            }
        },
        "AtariQNetwork.__init__": {
            "name": "__init__",
            "location": 56,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "in_dim": [
                    "bool",
                    "int"
                ],
                "out_dim": [
                    "bool",
                    "int"
                ]
            }
        },
        "AtariQNetwork.forward": {
            "name": "forward",
            "location": 88,
            "return": [
                "str"
            ],
            "arguments": {
                "self": [],
                "x": [
                    "torch.Tensor",
                    "float"
                ]
            }
        },
        "QNetwork.__init__.weights_init": {
            "name": "weights_init",
            "location": 31,
            "return": [
                ""
            ],
            "arguments": {
                "m": [
                    "str",
                    "bool",
                    "dict",
                    "List[Dict[str, Any]]",
                    "int"
                ]
            }
        },
        "AtariQNetwork.__init__.weights_init": {
            "name": "weights_init",
            "location": 80,
            "return": [
                ""
            ],
            "arguments": {
                "m": [
                    "torch.Tensor",
                    "Dict[str, Dict[str, int]]",
                    "int",
                    "bool"
                ]
            }
        }
    },
    "implementations-dqn-master/dqn/replays.py": {
        "NATUREDQN_ATARI_PREPROCESS_BATCH": {
            "name": "NATUREDQN_ATARI_PREPROCESS_BATCH",
            "location": 14,
            "return": [
                "str",
                "int",
                "List[str]",
                "list",
                "bool"
            ],
            "arguments": {
                "o": [
                    "float",
                    "numpy.ndarray",
                    "Sequence",
                    "list",
                    "numpy.array",
                    "int"
                ],
                "a": [
                    "float",
                    "numpy.ndarray",
                    "Sequence",
                    "list",
                    "numpy.array",
                    "int"
                ],
                "r": [
                    "float",
                    "numpy.ndarray",
                    "Sequence",
                    "list",
                    "numpy.array",
                    "int"
                ],
                "n": [
                    "float",
                    "numpy.ndarray",
                    "Sequence",
                    "list",
                    "numpy.array",
                    "int"
                ],
                "d": [
                    "float",
                    "numpy.ndarray",
                    "Sequence",
                    "list",
                    "numpy.array",
                    "int"
                ]
            }
        },
        "NORMALIZE_OBSERVATION": {
            "name": "NORMALIZE_OBSERVATION",
            "location": 22,
            "return": [
                "int",
                "bytearray",
                "str",
                "bytes"
            ],
            "arguments": {
                "obs_b": [
                    "int",
                    "float",
                    "str",
                    "List[float]",
                    "List[str]",
                    "torch.BoolTensor",
                    "bytes"
                ],
                "action_b": [
                    "int",
                    "float",
                    "str",
                    "List[float]",
                    "List[str]",
                    "torch.BoolTensor",
                    "bytes"
                ],
                "rew_b": [
                    "int",
                    "float",
                    "str",
                    "List[float]",
                    "List[str]",
                    "torch.BoolTensor",
                    "bytes"
                ],
                "next_obs_b": [
                    "int",
                    "float",
                    "str",
                    "List[float]",
                    "List[str]",
                    "torch.BoolTensor",
                    "bytes"
                ],
                "done_b": [
                    "int",
                    "float",
                    "str",
                    "List[float]",
                    "List[str]",
                    "torch.BoolTensor",
                    "bytes"
                ]
            }
        },
        "CLIP_REWARD": {
            "name": "CLIP_REWARD",
            "location": 30,
            "return": [
                "bytes",
                "torch.BoolTensor",
                "Union[bytes, bytearray]",
                "str"
            ],
            "arguments": {
                "obs_b": [
                    "int",
                    "str",
                    "bool",
                    "List[float]",
                    "List[str]",
                    "bytes"
                ],
                "action_b": [
                    "int",
                    "str",
                    "bool",
                    "List[float]",
                    "List[str]",
                    "bytes"
                ],
                "rew_b": [
                    "int",
                    "str",
                    "bool",
                    "List[float]",
                    "List[str]",
                    "bytes"
                ],
                "next_obs_b": [
                    "int",
                    "str",
                    "bool",
                    "List[float]",
                    "List[str]",
                    "bytes"
                ],
                "done_b": [
                    "int",
                    "str",
                    "bool",
                    "List[float]",
                    "List[str]",
                    "bytes"
                ]
            }
        },
        "FIXED_MAGNITUDE_REWARD": {
            "name": "FIXED_MAGNITUDE_REWARD",
            "location": 36,
            "return": [
                "bytes",
                "torch.BoolTensor",
                "Union[bytes, bytearray]",
                "str"
            ],
            "arguments": {
                "obs_b": [
                    "int",
                    "str",
                    "bool",
                    "List[float]",
                    "List[str]",
                    "bytes"
                ],
                "action_b": [
                    "int",
                    "str",
                    "bool",
                    "List[float]",
                    "List[str]",
                    "bytes"
                ],
                "rew_b": [
                    "int",
                    "str",
                    "bool",
                    "List[float]",
                    "List[str]",
                    "bytes"
                ],
                "next_obs_b": [
                    "int",
                    "str",
                    "bool",
                    "List[float]",
                    "List[str]",
                    "bytes"
                ],
                "done_b": [
                    "int",
                    "str",
                    "bool",
                    "List[float]",
                    "List[str]",
                    "bytes"
                ]
            }
        },
        "ReplayBuffer.__init__": {
            "name": "__init__",
            "location": 42,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "maxlen": [
                    "int",
                    "bool",
                    "float"
                ],
                "device": [
                    "int",
                    "bool",
                    "float"
                ],
                "preprocess_batch": [
                    "int",
                    "bool",
                    "float"
                ]
            }
        },
        "ReplayBuffer.__len__": {
            "name": "__len__",
            "location": 61,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "ReplayBuffer.append": {
            "name": "append",
            "location": 64,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "str",
                    "List[List[int]]"
                ]
            }
        },
        "ReplayBuffer.get_numpy_batch": {
            "name": "get_numpy_batch",
            "location": 76,
            "return": [
                "bytes",
                "List[dict]",
                "bytearray",
                "str",
                "float",
                "List[str]",
                "int"
            ],
            "arguments": {
                "self": [],
                "batch_size": [
                    "int",
                    "float",
                    "Optional[int]",
                    "numpy.ndarray",
                    "Tuple[int, int]",
                    "str"
                ]
            }
        },
        "ReplayBuffer.get_torch_batch": {
            "name": "get_torch_batch",
            "location": 118,
            "return": [
                "str",
                "int",
                "bytes",
                "Union[bytes, bytearray]"
            ],
            "arguments": {
                "self": [],
                "batch_size": [
                    "int",
                    "Collection[int]",
                    "List[str]",
                    "bool"
                ]
            }
        },
        "CircularReplayBuffer.__init__": {
            "name": "__init__",
            "location": 153,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "env": [
                    "gym.Env",
                    "str",
                    "Mapping[str, str]",
                    "dict",
                    "List[str]"
                ],
                "maxlen": [
                    "Dict[str, Any]",
                    "int",
                    "Optional[str]",
                    "Optional[Dict[str, Any]]",
                    "Type[\"SerializationDialect\"]"
                ],
                "device": [
                    "gym.Env",
                    "str",
                    "Mapping[str, str]",
                    "dict",
                    "List[str]"
                ],
                "preprocess_batch": [
                    "gym.Env",
                    "str",
                    "Mapping[str, str]",
                    "dict",
                    "List[str]"
                ]
            }
        },
        "CircularReplayBuffer.__len__": {
            "name": "__len__",
            "location": 197,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "CircularReplayBuffer.append": {
            "name": "append",
            "location": 200,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "transition": [
                    "int",
                    "list"
                ]
            }
        },
        "CircularReplayBuffer.get_numpy_batch": {
            "name": "get_numpy_batch",
            "location": 215,
            "return": [
                "bytes",
                "List[dict]",
                "bytearray",
                "str",
                "float",
                "List[str]",
                "int"
            ],
            "arguments": {
                "self": [],
                "batch_size": [
                    "int",
                    "str"
                ]
            }
        },
        "CircularReplayBuffer.get_torch_batch": {
            "name": "get_torch_batch",
            "location": 259,
            "return": [
                "str",
                "int",
                "bytes",
                "Union[bytes, bytearray]"
            ],
            "arguments": {
                "self": [],
                "batch_size": [
                    "int",
                    "Collection[int]",
                    "List[str]",
                    "bool"
                ]
            }
        }
    },
    "implementations-dqn-master/dqn/__init__.py": {},
    "implementations-dqn-master/environments/atari_preprocessing.py": {
        "AtariPreprocessing.__init__": {
            "name": "__init__",
            "location": 36,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "env": [
                    "Callable[[numpy.ndarray], numpy.ndarray]",
                    "str"
                ],
                "noop_max": [
                    "int",
                    "bool",
                    "str"
                ],
                "frame_skip": [
                    "int",
                    "bool",
                    "str"
                ],
                "screen_size": [
                    "int",
                    "float",
                    "Optional[int]"
                ],
                "terminal_on_life_loss": [
                    "int",
                    "bool",
                    "str"
                ],
                "grayscale_obs": [
                    "int",
                    "bool",
                    "str"
                ]
            }
        },
        "AtariPreprocessing.step": {
            "name": "step",
            "location": 82,
            "return": [
                "bool",
                "str"
            ],
            "arguments": {
                "self": [],
                "action": []
            }
        },
        "AtariPreprocessing.reset": {
            "name": "reset",
            "location": 109,
            "return": [
                "int",
                "str",
                "bool",
                "Optional[BaseException]",
                "Union[str, Tuple[str, ...]]"
            ],
            "arguments": {
                "self": []
            }
        },
        "AtariPreprocessing._get_obs": {
            "name": "_get_obs",
            "location": 135,
            "return": [
                "str",
                "bool"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "implementations-dqn-master/environments/atari_wrappers.py": {
        "make_atari": {
            "name": "make_atari",
            "location": 308,
            "return": [],
            "arguments": {
                "env_id": [],
                "max_episode_steps": []
            }
        },
        "wrap_deepmind": {
            "name": "wrap_deepmind",
            "location": 318,
            "return": [],
            "arguments": {
                "env": [],
                "episode_life": [],
                "clip_rewards": [],
                "frame_stack": [],
                "scale": []
            }
        },
        "TimeLimit.__init__": {
            "name": "__init__",
            "location": 23,
            "return": [],
            "arguments": {
                "self": [],
                "env": [],
                "max_episode_steps": []
            }
        },
        "TimeLimit.step": {
            "name": "step",
            "location": 28,
            "return": [],
            "arguments": {
                "self": [],
                "ac": []
            }
        },
        "TimeLimit.reset": {
            "name": "reset",
            "location": 36,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "NoopResetEnv.__init__": {
            "name": "__init__",
            "location": 42,
            "return": [],
            "arguments": {
                "self": [],
                "env": [],
                "noop_max": []
            }
        },
        "NoopResetEnv.reset": {
            "name": "reset",
            "location": 52,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "NoopResetEnv.step": {
            "name": "step",
            "location": 69,
            "return": [],
            "arguments": {
                "self": [],
                "ac": []
            }
        },
        "FireResetEnv.__init__": {
            "name": "__init__",
            "location": 74,
            "return": [],
            "arguments": {
                "self": [],
                "env": []
            }
        },
        "FireResetEnv.reset": {
            "name": "reset",
            "location": 80,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "FireResetEnv.step": {
            "name": "step",
            "location": 90,
            "return": [],
            "arguments": {
                "self": [],
                "ac": []
            }
        },
        "EpisodicLifeEnv.__init__": {
            "name": "__init__",
            "location": 95,
            "return": [],
            "arguments": {
                "self": [],
                "env": []
            }
        },
        "EpisodicLifeEnv.step": {
            "name": "step",
            "location": 103,
            "return": [],
            "arguments": {
                "self": [],
                "action": []
            }
        },
        "EpisodicLifeEnv.reset": {
            "name": "reset",
            "location": 117,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "MaxAndSkipEnv.__init__": {
            "name": "__init__",
            "location": 132,
            "return": [],
            "arguments": {
                "self": [],
                "env": [],
                "skip": []
            }
        },
        "MaxAndSkipEnv.step": {
            "name": "step",
            "location": 139,
            "return": [],
            "arguments": {
                "self": [],
                "action": []
            }
        },
        "MaxAndSkipEnv.reset": {
            "name": "reset",
            "location": 158,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ClipRewardEnv.__init__": {
            "name": "__init__",
            "location": 163,
            "return": [],
            "arguments": {
                "self": [],
                "env": []
            }
        },
        "ClipRewardEnv.reward": {
            "name": "reward",
            "location": 166,
            "return": [],
            "arguments": {
                "self": [],
                "reward": []
            }
        },
        "WarpFrame.__init__": {
            "name": "__init__",
            "location": 172,
            "return": [],
            "arguments": {
                "self": [],
                "env": [],
                "width": [],
                "height": [],
                "grayscale": [],
                "dict_space_key": []
            }
        },
        "WarpFrame.observation": {
            "name": "observation",
            "location": 202,
            "return": [],
            "arguments": {
                "self": [],
                "obs": []
            }
        },
        "FrameStack.__init__": {
            "name": "__init__",
            "location": 225,
            "return": [],
            "arguments": {
                "self": [],
                "env": [],
                "k": []
            }
        },
        "FrameStack.reset": {
            "name": "reset",
            "location": 243,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "FrameStack.step": {
            "name": "step",
            "location": 249,
            "return": [],
            "arguments": {
                "self": [],
                "action": []
            }
        },
        "FrameStack._get_ob": {
            "name": "_get_ob",
            "location": 254,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ScaledFloatFrame.__init__": {
            "name": "__init__",
            "location": 260,
            "return": [],
            "arguments": {
                "self": [],
                "env": []
            }
        },
        "ScaledFloatFrame.observation": {
            "name": "observation",
            "location": 266,
            "return": [],
            "arguments": {
                "self": [],
                "observation": []
            }
        },
        "LazyFrames.__init__": {
            "name": "__init__",
            "location": 273,
            "return": [],
            "arguments": {
                "self": [],
                "frames": []
            }
        },
        "LazyFrames._force": {
            "name": "_force",
            "location": 282,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "LazyFrames.__array__": {
            "name": "__array__",
            "location": 288,
            "return": [],
            "arguments": {
                "self": [],
                "dtype": []
            }
        },
        "LazyFrames.__len__": {
            "name": "__len__",
            "location": 294,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "LazyFrames.__getitem__": {
            "name": "__getitem__",
            "location": 297,
            "return": [],
            "arguments": {
                "self": [],
                "i": []
            }
        },
        "LazyFrames.count": {
            "name": "count",
            "location": 300,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "LazyFrames.frame": {
            "name": "frame",
            "location": 304,
            "return": [],
            "arguments": {
                "self": [],
                "i": []
            }
        }
    },
    "implementations-dqn-master/environments/frame_stack.py": {
        "FrameStack.__init__": {
            "name": "__init__",
            "location": 15,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "env": [
                    "str"
                ],
                "stack_size": [
                    "int",
                    "numpy.ndarray"
                ]
            }
        },
        "FrameStack.__getattr__": {
            "name": "__getattr__",
            "location": 27,
            "return": [
                "str",
                "Optional[str]",
                "Tuple[str]"
            ],
            "arguments": {
                "self": [],
                "name": [
                    "str"
                ]
            }
        },
        "FrameStack._generate_observation": {
            "name": "_generate_observation",
            "location": 31,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "FrameStack.reset": {
            "name": "reset",
            "location": 34,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "FrameStack.step": {
            "name": "step",
            "location": 40,
            "return": [
                "int",
                "str",
                "List[str]"
            ],
            "arguments": {
                "self": [],
                "action": [
                    "str",
                    "dict"
                ]
            }
        }
    },
    "implementations-dqn-master/environments/__init__.py": {},
    "implementations-dqn-master/tests/__init__.py": {}
}
{
    "torchvideo-master/conftest.py": {},
    "torchvideo-master/setup.py": {
        "UploadCommand.status": {
            "name": "status",
            "location": 60,
            "return": [],
            "arguments": {
                "s": []
            }
        },
        "UploadCommand.initialize_options": {
            "name": "initialize_options",
            "location": 64,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "UploadCommand.finalize_options": {
            "name": "finalize_options",
            "location": 67,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "UploadCommand.run": {
            "name": "run",
            "location": 70,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/docs/source/conf.py": {},
    "torchvideo-master/src/torchvideo/samplers.py": {
        "frame_idx_to_list": {
            "name": "frame_idx_to_list",
            "location": 313,
            "return": [],
            "arguments": {
                "frames_idx": []
            }
        },
        "compute_sample_length": {
            "name": "compute_sample_length",
            "location": 346,
            "return": [],
            "arguments": {
                "clip_length": [],
                "step_size": []
            }
        },
        "_slice_to_list": {
            "name": "_slice_to_list",
            "location": 362,
            "return": [],
            "arguments": {
                "slice_": []
            }
        },
        "_oversample": {
            "name": "_oversample",
            "location": 371,
            "return": [],
            "arguments": {
                "video_length": [],
                "sample_length": []
            }
        },
        "FrameSampler.sample": {
            "name": "sample",
            "location": 15,
            "return": [],
            "arguments": {
                "self": [],
                "video_length": []
            }
        },
        "FullVideoSampler.__init__": {
            "name": "__init__",
            "location": 35,
            "return": [],
            "arguments": {
                "self": [],
                "frame_step": []
            }
        },
        "FullVideoSampler.sample": {
            "name": "sample",
            "location": 38,
            "return": [],
            "arguments": {
                "self": [],
                "video_length": []
            }
        },
        "FullVideoSampler.__str__": {
            "name": "__str__",
            "location": 57,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "FullVideoSampler.__repr__": {
            "name": "__repr__",
            "location": 60,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "ClipSampler.__init__": {
            "name": "__init__",
            "location": 67,
            "return": [],
            "arguments": {
                "self": [],
                "clip_length": [],
                "frame_step": [],
                "test": []
            }
        },
        "ClipSampler.sample": {
            "name": "sample",
            "location": 80,
            "return": [],
            "arguments": {
                "self": [],
                "video_length": []
            }
        },
        "ClipSampler.__repr__": {
            "name": "__repr__",
            "location": 99,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TemporalSegmentSampler.__init__": {
            "name": "__init__",
            "location": 132,
            "return": [],
            "arguments": {
                "self": [],
                "segment_count": [],
                "snippet_length": []
            }
        },
        "TemporalSegmentSampler.sample": {
            "name": "sample",
            "location": 171,
            "return": [],
            "arguments": {
                "self": [],
                "video_length": []
            }
        },
        "TemporalSegmentSampler._sample": {
            "name": "_sample",
            "location": 204,
            "return": [],
            "arguments": {
                "self": [],
                "video_length": []
            }
        },
        "TemporalSegmentSampler._oversample_segments": {
            "name": "_oversample_segments",
            "location": 212,
            "return": [],
            "arguments": {
                "self": [],
                "video_length": []
            }
        },
        "TemporalSegmentSampler._oversample_snippet": {
            "name": "_oversample_snippet",
            "location": 234,
            "return": [],
            "arguments": {
                "self": [],
                "video_length": []
            }
        },
        "TemporalSegmentSampler._get_segment_offsets": {
            "name": "_get_segment_offsets",
            "location": 238,
            "return": [],
            "arguments": {
                "self": [],
                "segment_length": []
            }
        },
        "TemporalSegmentSampler.segment_video": {
            "name": "segment_video",
            "location": 246,
            "return": [],
            "arguments": {
                "self": [],
                "video_length": []
            }
        },
        "TemporalSegmentSampler.__str__": {
            "name": "__str__",
            "location": 262,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TemporalSegmentSampler.__repr__": {
            "name": "__repr__",
            "location": 265,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TemporalSegmentSampler._make_snippet_slice": {
            "name": "_make_snippet_slice",
            "location": 279,
            "return": [],
            "arguments": {
                "self": [],
                "start": []
            }
        },
        "LambdaSampler.__init__": {
            "name": "__init__",
            "location": 288,
            "return": [],
            "arguments": {
                "self": [],
                "sampler": []
            }
        },
        "LambdaSampler.sample": {
            "name": "sample",
            "location": 299,
            "return": [],
            "arguments": {
                "self": [],
                "video_length": []
            }
        },
        "LambdaSampler.__repr__": {
            "name": "__repr__",
            "location": 309,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/tools.py": {
        "show_video": {
            "name": "show_video",
            "location": 16,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "frames": [
                    "str",
                    "int",
                    "list"
                ],
                "fps": [
                    "str",
                    "int",
                    "list"
                ],
                "ndarray_format": [
                    "str",
                    "int",
                    "list"
                ]
            }
        },
        "convert_to_clip": {
            "name": "convert_to_clip",
            "location": 44,
            "return": [
                "Union[str, int, float]",
                "numpy.ndarray",
                "str",
                "torch.Tensor",
                "List[int]",
                "float",
                "Dict[str, numpy.ndarray]"
            ],
            "arguments": {
                "frames": [
                    "str",
                    "bool",
                    "Optional[List[str]]",
                    "List[str]"
                ],
                "fps": [
                    "str",
                    "Set[int]",
                    "Callable[[str, str], float]",
                    "bool"
                ],
                "ndarray_format": [
                    "str",
                    "bool",
                    "Optional[List[str]]",
                    "List[str]"
                ]
            }
        },
        "_to_list_of_np_frames": {
            "name": "_to_list_of_np_frames",
            "location": 70,
            "return": [
                "List[Dict]",
                "List[str]",
                "list",
                "List[int]",
                "dict",
                "bool"
            ],
            "arguments": {
                "frames": [
                    "str"
                ],
                "ndarray_format": [
                    "str",
                    "Optional[str]"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/__init__.py": {
        "get_video_backend": {
            "name": "get_video_backend",
            "location": 10,
            "return": [
                "str",
                "bool"
            ],
            "arguments": {}
        }
    },
    "torchvideo-master/src/torchvideo/__version__.py": {},
    "torchvideo-master/src/torchvideo/datasets/gulp_video_dataset.py": {
        "GulpVideoDataset.__init__": {
            "name": "__init__",
            "location": 30,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "root_path": [
                    "str",
                    "Optional[str]",
                    "Union[str, pathlib.Path]",
                    "pathlib.Path",
                    "TextIO",
                    "bool"
                ]
            }
        },
        "GulpVideoDataset.video_ids": {
            "name": "video_ids",
            "location": 86,
            "return": [
                "int",
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "GulpVideoDataset.__len__": {
            "name": "__len__",
            "location": 89,
            "return": [
                "str",
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "GulpVideoDataset.__getitem__": {
            "name": "__getitem__",
            "location": 92,
            "return": [
                "str",
                "bool",
                "List[Dict]",
                "int"
            ],
            "arguments": {
                "self": [],
                "index": [
                    "str"
                ]
            }
        },
        "GulpVideoDataset._label_examples": {
            "name": "_label_examples",
            "location": 134,
            "return": [
                "bool",
                "Optional[str]",
                "Dict[str, Union[str, int]]",
                "type"
            ],
            "arguments": {
                "video_ids": [
                    "str",
                    "dict",
                    "int",
                    "List[dict]",
                    "Optional[str]"
                ],
                "label_set": [
                    "Optional[str]",
                    "str",
                    "int",
                    "Optional[Dict[str, str]]"
                ]
            }
        },
        "GulpVideoDataset._get_video_ids": {
            "name": "_get_video_ids",
            "location": 141,
            "return": [
                "bool",
                "Set[str]",
                "str",
                "List[object]"
            ],
            "arguments": {
                "gulp_dir": [
                    "Optional[str]",
                    "str",
                    "Optional['Directory']",
                    "dict",
                    "Path"
                ],
                "filter_fn": [
                    "Optional[str]",
                    "str",
                    "Optional['Directory']",
                    "dict",
                    "Path"
                ]
            }
        },
        "GulpVideoDataset._get_label_set": {
            "name": "_get_label_set",
            "location": 153,
            "return": [
                "str",
                "Optional[str]"
            ],
            "arguments": {
                "gulp_dir": [
                    "Optional[str]",
                    "Optional[TextIO]"
                ],
                "label_field": [
                    "Optional[str]",
                    "Optional[Iterable[str]]"
                ],
                "label_set": [
                    "Optional[str]",
                    "Optional[label_sets.LabelSet]"
                ]
            }
        },
        "GulpVideoDataset._load_frames": {
            "name": "_load_frames",
            "location": 162,
            "return": [
                "str",
                "bool"
            ],
            "arguments": {
                "self": [],
                "id_": [
                    "str",
                    "Optional[str]",
                    "Optional[int]",
                    "int",
                    "List[int]"
                ],
                "frame_idx": [
                    "str",
                    "Optional[str]",
                    "Optional[int]",
                    "int",
                    "List[int]"
                ]
            }
        },
        "GulpVideoDataset._get_frame_count": {
            "name": "_get_frame_count",
            "location": 166,
            "return": [
                "str",
                "Optional[str]",
                "int",
                "torch.nn.Module",
                "Dict[str, str]",
                "apistar.types.WSGIEnviron"
            ],
            "arguments": {
                "self": [],
                "id_": [
                    "str"
                ]
            }
        },
        "GulpVideoDataset.__init__.transform": {
            "name": "transform",
            "location": 65,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "frames": [
                    "int",
                    "Callable",
                    "str"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/helpers.py": {
        "invoke_transform": {
            "name": "invoke_transform",
            "location": 4,
            "return": [
                "str",
                "Dict[str, int]",
                "dict",
                "List[str]"
            ],
            "arguments": {
                "transform": [
                    "Dict[str, str]",
                    "str"
                ],
                "frames": [
                    "str"
                ],
                "label": [
                    "str"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/image_folder_video_dataset.py": {
        "ImageFolderVideoDataset.__init__": {
            "name": "__init__",
            "location": 35,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "root_path": [
                    "Union[str, pathlib.Path]",
                    "str",
                    "Optional[label_sets.LabelSet]",
                    "torchvideo.samplers.FrameSampler",
                    "lib.Path",
                    "path.Path",
                    "pathlib.Path"
                ],
                "filename_template": [
                    "str",
                    "dict",
                    "Dict[int, bool]"
                ],
                "filter": [
                    "Optional[str]",
                    "str",
                    "Optional[List[str]]",
                    "Optional['Directory']",
                    "Optional[TextIO]"
                ],
                "label_set": [
                    "torchvideo.samplers.FrameSampler",
                    "Optional[label_sets.LabelSet]",
                    "List[str]",
                    "pathlib.Path",
                    "str",
                    "Union[str, pathlib.Path]",
                    "path.Path"
                ],
                "sampler": [
                    "torchvideo.samplers.FrameSampler",
                    "List[str]",
                    "str",
                    "Optional[label_sets.LabelSet]",
                    "Union[str, pathlib.Path]",
                    "path.Path",
                    "pathlib.Path",
                    "Optional[pathlib.Path]"
                ],
                "transform": [
                    "str",
                    "torchvideo.samplers.FrameSampler",
                    "List[str]",
                    "Optional[label_sets.LabelSet]",
                    "pathlib.Path",
                    "Union[str, pathlib.Path]",
                    "Optional[str]"
                ],
                "frame_counter": [
                    "str",
                    "Optional[Sequence[str]]",
                    "int",
                    "pathlib.Path",
                    "Optional[str]"
                ]
            }
        },
        "ImageFolderVideoDataset.video_ids": {
            "name": "video_ids",
            "location": 78,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "ImageFolderVideoDataset.__len__": {
            "name": "__len__",
            "location": 81,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "ImageFolderVideoDataset.__getitem__": {
            "name": "__getitem__",
            "location": 84,
            "return": [
                "str",
                "torch.FloatTensor",
                "dict",
                "int"
            ],
            "arguments": {
                "self": [],
                "index": [
                    "float",
                    "str",
                    "List['cirq.Qid']",
                    "T",
                    "torch.autograd.Variable",
                    "Awaitable"
                ]
            }
        },
        "ImageFolderVideoDataset._measure_video_lengths": {
            "name": "_measure_video_lengths",
            "location": 103,
            "return": [
                "str",
                "bool",
                "Tuple[int, int]",
                "Union[List[str], str]",
                "List[str]"
            ],
            "arguments": {
                "video_dirs": [
                    "str",
                    "pathlib.Path",
                    "List[str]"
                ],
                "frame_counter": [
                    "Optional[Callable[[pathlib.Path], int]]",
                    "bool",
                    "Any",
                    "Optional[Any]",
                    "Union[str, pathlib.Path, None]"
                ]
            }
        },
        "ImageFolderVideoDataset._label_examples": {
            "name": "_label_examples",
            "location": 112,
            "return": [
                "dict",
                "Dict[str, Any]",
                "str",
                "Dict[str, str]",
                "int"
            ],
            "arguments": {
                "video_dirs": [
                    "str"
                ],
                "label_set": [
                    "Optional[label_sets.LabelSet]",
                    "Optional[str]",
                    "str",
                    "torch.optim.Optimizer",
                    "list"
                ]
            }
        },
        "ImageFolderVideoDataset._load_frames": {
            "name": "_load_frames",
            "location": 118,
            "return": [
                "str",
                "bool"
            ],
            "arguments": {
                "self": [],
                "frames_idx": [
                    "int",
                    "bool",
                    "str",
                    "List[float]",
                    "bytes",
                    "Optional[str]"
                ],
                "video_folder": [
                    "str",
                    "int"
                ]
            }
        },
        "ImageFolderVideoDataset._load_image": {
            "name": "_load_image",
            "location": 130,
            "return": [
                "str",
                "Callable"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "pathlib.Path",
                    "str",
                    "cerulean.Path",
                    "Union[str, pathlib.Path]"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/types.py": {},
    "torchvideo-master/src/torchvideo/datasets/video_dataset.py": {
        "VideoDataset.__init__": {
            "name": "__init__",
            "location": 16,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "root_path": [
                    "pathlib.Path",
                    "str",
                    "Union[str, pathlib.Path]"
                ],
                "label_set": [
                    "Dict[str, str]",
                    "dict",
                    "List[str]",
                    "int",
                    "str"
                ],
                "sampler": [
                    "Optional[str]",
                    "Sequence[pathlib.Path]",
                    "int",
                    "str",
                    "pathlib.Path",
                    "Sequence[str]"
                ],
                "transform": [
                    "Optional[str]",
                    "Sequence[pathlib.Path]",
                    "int",
                    "str",
                    "pathlib.Path",
                    "Sequence[str]"
                ]
            }
        },
        "VideoDataset.video_ids": {
            "name": "video_ids",
            "location": 42,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "VideoDataset.__getitem__": {
            "name": "__getitem__",
            "location": 45,
            "return": [
                "typing.Union[torch.Tensor, typing.Tuple[torch.Tensor, types.Label]]"
            ],
            "arguments": {
                "self": [],
                "index": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        },
        "VideoDataset.__len__": {
            "name": "__len__",
            "location": 61,
            "return": [
                "builtins.int"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/video_folder_dataset.py": {
        "VideoFolderDataset.__init__": {
            "name": "__init__",
            "location": 27,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "root_path": [
                    "torchvideo.samplers.FrameSampler",
                    "Union[str, pathlib.Path]",
                    "Optional[label_sets.LabelSet]",
                    "pathlib.Path",
                    "Optional[str]",
                    "Union[pathlib.Path, str]"
                ],
                "filter": [
                    "pathlib.Path",
                    "str",
                    "path.Path",
                    "List[str]",
                    "Optional[str]"
                ],
                "label_set": [
                    "torchvideo.samplers.FrameSampler",
                    "Optional[label_sets.LabelSet]",
                    "pathlib.Path",
                    "Union[str, pathlib.Path]",
                    "Optional[str]",
                    "Union[pathlib.Path, str]"
                ],
                "sampler": [
                    "torchvideo.samplers.FrameSampler",
                    "pathlib.Path",
                    "Optional[label_sets.LabelSet]",
                    "Union[str, pathlib.Path]",
                    "Optional[str]",
                    "Union[pathlib.Path, str]",
                    "str"
                ],
                "transform": [
                    "Optional[str]",
                    "pathlib.Path",
                    "Callable[[str], str]",
                    "bool"
                ],
                "frame_counter": [
                    "bool",
                    "pathlib.Path",
                    "str",
                    "Dict[str, Any]"
                ]
            }
        },
        "VideoFolderDataset.video_ids": {
            "name": "video_ids",
            "location": 63,
            "return": [
                "str",
                "pathlib.Path"
            ],
            "arguments": {
                "self": []
            }
        },
        "VideoFolderDataset.__getitem__": {
            "name": "__getitem__",
            "location": 68,
            "return": [
                "str",
                "dict",
                "List[str]"
            ],
            "arguments": {
                "self": [],
                "index": [
                    "str",
                    "bytes",
                    "Tuple[str, str]"
                ]
            }
        },
        "VideoFolderDataset.__len__": {
            "name": "__len__",
            "location": 85,
            "return": [
                "str",
                "List[int]",
                "types.StrPath",
                "int"
            ],
            "arguments": {
                "self": []
            }
        },
        "VideoFolderDataset._measure_video_lengths": {
            "name": "_measure_video_lengths",
            "location": 89,
            "return": [
                "bool",
                "str",
                "Optional[Callable[[pathlib.Path], int]]"
            ],
            "arguments": {
                "video_paths": [
                    "str",
                    "pathlib.Path"
                ],
                "frame_counter": [
                    "bool",
                    "Optional[str]",
                    "str",
                    "Optional[int]",
                    "int",
                    "Optional[bool]"
                ]
            }
        },
        "VideoFolderDataset._label_examples": {
            "name": "_label_examples",
            "location": 95,
            "return": [
                "Optional[dict]",
                "bool",
                "str"
            ],
            "arguments": {
                "video_paths": [
                    "str",
                    "pathlib.Path",
                    "Optional[IO[str]]"
                ],
                "label_set": [
                    "Optional[label_sets.LabelSet]",
                    "Optional[str]",
                    "pathlib.Path",
                    "Optional[pathlib.Path]"
                ]
            }
        },
        "VideoFolderDataset._get_video_paths": {
            "name": "_get_video_paths",
            "location": 102,
            "return": [
                "list",
                "List[str]",
                "str",
                "List[Tuple[str, str, str]]",
                "Set[str]",
                "Tuple[str, str, str, str, str, str, str, str, str]"
            ],
            "arguments": {
                "root_path": [
                    "str",
                    "Optional[str]",
                    "pathlib.Path",
                    "Optional[label_sets.LabelSet]",
                    "Optional['Directory']"
                ],
                "filter": [
                    "str",
                    "Optional[str]",
                    "pathlib.Path",
                    "Optional[label_sets.LabelSet]",
                    "Optional['Directory']"
                ]
            }
        },
        "VideoFolderDataset._load_frames": {
            "name": "_load_frames",
            "location": 112,
            "return": [
                "str",
                "Optional[str]",
                "List[str]"
            ],
            "arguments": {
                "frame_idx": [
                    "Union[slice, List[slice], List[int]]",
                    "pathlib.Path",
                    "str",
                    "Union[str, pathlib.Path]",
                    "List[pypi2nix.path.Path]",
                    "bool",
                    "List[str]"
                ],
                "video_file": [
                    "Union[slice, List[slice], List[int]]",
                    "pathlib.Path",
                    "str",
                    "Union[str, pathlib.Path]",
                    "List[pypi2nix.path.Path]",
                    "bool",
                    "List[str]"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/__init__.py": {},
    "torchvideo-master/src/torchvideo/datasets/label_sets/csv_label_set.py": {
        "CsvLabelSet.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "df": [
                    "str",
                    "bool",
                    "List[int]",
                    "int",
                    "Optional[Dict]"
                ],
                "col": [
                    "str",
                    "Callable",
                    "tuple"
                ]
            }
        },
        "CsvLabelSet.__getitem__": {
            "name": "__getitem__",
            "location": 32,
            "return": [
                "str",
                "Optional[str]",
                "dict",
                "List[str]",
                "int",
                "Optional[List[str]]"
            ],
            "arguments": {
                "self": [],
                "video_name": [
                    "str",
                    "Optional[str]"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/label_sets/dummy_label_set.py": {
        "DummyLabelSet.__init__": {
            "name": "__init__",
            "location": 7,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "label": [
                    "str",
                    "bool",
                    "List[List[Any]]",
                    "Optional[str]"
                ]
            }
        },
        "DummyLabelSet.__getitem__": {
            "name": "__getitem__",
            "location": 14,
            "return": [
                "str",
                "bool",
                "Iterable[str]",
                "List[List[str]]"
            ],
            "arguments": {
                "self": [],
                "video_name": [
                    "Optional[str]",
                    "str",
                    "List[str]",
                    "Iterable[float]",
                    "Any",
                    "Optional[Callable]",
                    "int"
                ]
            }
        },
        "DummyLabelSet.__repr__": {
            "name": "__repr__",
            "location": 17,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/label_sets/gulp_label_set.py": {
        "GulpLabelSet.__init__": {
            "name": "__init__",
            "location": 13,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "merged_meta_dict": [
                    "dict",
                    "Tuple['cirq.Qid']",
                    "List[Dict[str, Any]]",
                    "list"
                ],
                "label_field": [
                    "bool",
                    "Dict[str, str]",
                    "Optional[Union[\"IPUtilityFunction\", \"UtilityDistribution\"]]",
                    "int"
                ]
            }
        },
        "GulpLabelSet.__getitem__": {
            "name": "__getitem__",
            "location": 17,
            "return": [
                "dict",
                "str"
            ],
            "arguments": {
                "self": [],
                "video_name": [
                    "str",
                    "bool",
                    "type"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/label_sets/label_set.py": {
        "LabelSet.__getitem__": {
            "name": "__getitem__",
            "location": 12,
            "return": [
                "types.Label"
            ],
            "arguments": {
                "self": [],
                "video_name": [
                    "Optional[str]",
                    "str",
                    "List[str]",
                    "Iterable[float]",
                    "Any",
                    "Optional[Callable]",
                    "int"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/label_sets/lambda_label_set.py": {
        "LambdaLabelSet.__init__": {
            "name": "__init__",
            "location": 9,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "labeller_fn": [
                    "int",
                    "bool",
                    "float"
                ]
            }
        },
        "LambdaLabelSet.__getitem__": {
            "name": "__getitem__",
            "location": 16,
            "return": [
                "str",
                "int"
            ],
            "arguments": {
                "self": [],
                "video_name": [
                    "str"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/datasets/label_sets/__init__.py": {},
    "torchvideo-master/src/torchvideo/internal/readers.py": {
        "lintel_loader": {
            "name": "lintel_loader",
            "location": 30,
            "return": [
                "List[str]",
                "Iterator[str]",
                "Sequence['cirq.Qid']",
                "List[int]",
                "Mapping[str, Any]",
                "Iterable[int]"
            ],
            "arguments": {
                "file": [
                    "str",
                    "pathlib.Path",
                    "List[str]",
                    "norfs.fs.base.Path",
                    "bool"
                ],
                "frames_idx": [
                    "pathlib.Path",
                    "IO[str]",
                    "str"
                ]
            }
        },
        "default_loader": {
            "name": "default_loader",
            "location": 58,
            "return": [
                "str",
                "Callable",
                "pathlib.Path",
                "Optional[str]",
                "TextIO",
                "BinaryIO"
            ],
            "arguments": {
                "file": [
                    "str",
                    "IO[str]",
                    "Optional[str]"
                ],
                "frames_idx": [
                    "str",
                    "IO[str]",
                    "Optional[str]"
                ]
            }
        },
        "_get_videofile_frame_count": {
            "name": "_get_videofile_frame_count",
            "location": 71,
            "return": [
                "str",
                "int"
            ],
            "arguments": {
                "video_file_path": [
                    "str",
                    "pathlib.Path"
                ]
            }
        },
        "_is_video_file": {
            "name": "_is_video_file",
            "location": 92,
            "return": [
                "bool",
                "List[pathlib.Path]"
            ],
            "arguments": {
                "path": [
                    "str",
                    "Optional[str]",
                    "int"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/internal/utils.py": {
        "_is_int": {
            "name": "_is_int",
            "location": 1,
            "return": [
                "Dict[str, int]"
            ],
            "arguments": {
                "maybe_int": [
                    "str",
                    "list",
                    "float"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/internal/__init__.py": {},
    "torchvideo-master/src/torchvideo/scripts/dataloader_benchmark.py": {
        "benchmark_dataloader": {
            "name": "benchmark_dataloader",
            "location": 56,
            "return": [
                "None"
            ],
            "arguments": {
                "loader": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ],
                "max_iterations": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ],
                "profile": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ],
                "profile_callgrind": [
                    "str",
                    "Optional[IO[bytes]]",
                    "List[str]"
                ]
            }
        },
        "main": {
            "name": "main",
            "location": 99,
            "return": [
                "None"
            ],
            "arguments": {
                "args": []
            }
        },
        "make_dataset": {
            "name": "make_dataset",
            "location": 121,
            "return": [
                "bool",
                "Iterable[str]",
                "dict",
                "raiden.utils.TokenAmount"
            ],
            "arguments": {
                "args": [],
                "sampler": [
                    "float",
                    "Optional[\"Outcome\"]",
                    "Optional[bytes]"
                ],
                "transform": [
                    "Optional[\"Outcome\"]",
                    "bool",
                    "Optional[bytes]"
                ]
            }
        },
        "make_sampler": {
            "name": "make_sampler",
            "location": 155,
            "return": [
                "trezor.utils.Writer",
                "Callable",
                "pathlib.Path",
                "utils.Node",
                "torch.Tensor",
                "Optional[torch.Tensor]",
                "Dict[str, int]"
            ],
            "arguments": {
                "args": []
            }
        },
        "benchmark_dataloader.run_dataloader": {
            "name": "run_dataloader",
            "location": 64,
            "return": [
                ""
            ],
            "arguments": {}
        }
    },
    "torchvideo-master/src/torchvideo/transforms/__init__.py": {},
    "torchvideo-master/src/torchvideo/transforms/functional/normalize.py": {
        "normalize": {
            "name": "normalize",
            "location": 6,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "tensor": [
                    "int",
                    "Optional[bool]",
                    "torch.Tensor",
                    "bool",
                    "Union[int, float]"
                ],
                "mean": [
                    "Sequence",
                    "int",
                    "Sequence[T]",
                    "Dict[int, str]"
                ],
                "std": [
                    "Sequence",
                    "int",
                    "Set[str]",
                    "List[List[int]]"
                ],
                "channel_dim": [
                    "int",
                    "torch.Tensor"
                ],
                "inplace": [
                    "bool",
                    "int"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/functional/time_to_channel.py": {
        "time_to_channel": {
            "name": "time_to_channel",
            "location": 4,
            "return": [
                "bool",
                "Optional[str]",
                "Iterable[Any]"
            ],
            "arguments": {
                "tensor": [
                    "int",
                    "list",
                    "str",
                    "Sequence[T]",
                    "Sequence[int]",
                    "bytes"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/functional/__init__.py": {},
    "torchvideo-master/src/torchvideo/transforms/transforms/center_crop_video.py": {
        "CenterCropVideo.__init__": {
            "name": "__init__",
            "location": 19,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "size": [
                    "int",
                    "bytes"
                ]
            }
        },
        "CenterCropVideo._gen_params": {
            "name": "_gen_params",
            "location": 23,
            "return": [
                "Optional[str]",
                "str",
                "Optional[int]"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        },
        "CenterCropVideo.__repr__": {
            "name": "__repr__",
            "location": 26,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "CenterCropVideo._transform": {
            "name": "_transform",
            "location": 29,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ],
                "params": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/collect_frames.py": {
        "CollectFrames._gen_params": {
            "name": "_gen_params",
            "location": 15,
            "return": [
                "Optional[str]",
                "str",
                "Optional[int]"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        },
        "CollectFrames._transform": {
            "name": "_transform",
            "location": 18,
            "return": [
                "List[Dict]",
                "List[str]",
                "List[int]",
                "str",
                "List[List[Any]]"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "Callable",
                    "str"
                ],
                "params": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        },
        "CollectFrames.__repr__": {
            "name": "__repr__",
            "location": 21,
            "return": [
                "str",
                "int"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/compose.py": {
        "_supports_target": {
            "name": "_supports_target",
            "location": 52,
            "return": [
                "Dict[str, Any]"
            ],
            "arguments": {
                "transform": [
                    "int",
                    "Callable",
                    "str"
                ]
            }
        },
        "_requires_target": {
            "name": "_requires_target",
            "location": 58,
            "return": [
                "bool"
            ],
            "arguments": {
                "transform": [
                    "int",
                    "Callable",
                    "str"
                ]
            }
        },
        "Compose.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "transforms": [
                    "float",
                    "str",
                    "int",
                    "bool",
                    "dict"
                ]
            }
        },
        "Compose.__call__": {
            "name": "__call__",
            "location": 24,
            "return": [
                "Callable",
                "int",
                "float"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "float",
                    "List[int]"
                ],
                "target": [
                    "List[int]"
                ]
            }
        },
        "Compose._check_transforms_dont_require_target": {
            "name": "_check_transforms_dont_require_target",
            "location": 38,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "Compose.__repr__": {
            "name": "__repr__",
            "location": 46,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/identity_transform.py": {
        "IdentityTransform._transform": {
            "name": "_transform",
            "location": 12,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ],
                "params": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        },
        "IdentityTransform.__repr__": {
            "name": "__repr__",
            "location": 15,
            "return": [
                "str",
                "int"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/internal.py": {
        "canonicalize_size": {
            "name": "canonicalize_size",
            "location": 7,
            "return": [
                "str",
                "tuple",
                "int"
            ],
            "arguments": {
                "size": [
                    "int",
                    "Tuple[int, int]"
                ]
            }
        },
        "to_iter": {
            "name": "to_iter",
            "location": 28,
            "return": [
                "set"
            ],
            "arguments": {
                "seq": [
                    "str"
                ]
            }
        },
        "peek_iter": {
            "name": "peek_iter",
            "location": 37,
            "return": [
                "int",
                "Iterable[str]",
                "float"
            ],
            "arguments": {
                "iterator": [
                    "int",
                    "Iterable[str]",
                    "float"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/multiscale_crop_video.py": {
        "MultiScaleCropVideo._gen_params": {
            "name": "_gen_params",
            "location": 43,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "float",
                    "list",
                    "Deque",
                    "Callable[..., bool]",
                    "int"
                ]
            }
        },
        "MultiScaleCropVideo._transform": {
            "name": "_transform",
            "location": 63,
            "return": [
                "types.PILVideoI"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ],
                "params": [
                    "int",
                    "Callable",
                    "str"
                ]
            }
        },
        "MultiScaleCropVideo.__init__": {
            "name": "__init__",
            "location": 79,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "size": [
                    "int",
                    "Union[Tuple[int, int], int]",
                    "Tuple[int, int, int]"
                ],
                "scales": [
                    "int",
                    "bytes"
                ],
                "max_distortion": [
                    "int",
                    "Optional[int]"
                ],
                "fixed_crops": [
                    "int",
                    "bytes"
                ],
                "more_fixed_crops": [
                    "int",
                    "bytes"
                ]
            }
        },
        "MultiScaleCropVideo.__repr__": {
            "name": "__repr__",
            "location": 96,
            "return": [
                "Type",
                "list",
                "int",
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "MultiScaleCropVideo.get_params": {
            "name": "get_params",
            "location": 110,
            "return": [
                "str",
                "bool"
            ],
            "arguments": {
                "cls": [
                    "int",
                    "PIL.Image.Image",
                    "bool",
                    "Iterable[int]"
                ],
                "frame": [
                    "PIL.Image.Image",
                    "int",
                    "Iterable[int]",
                    "List[str]",
                    "float",
                    "bool"
                ],
                "output_shape": [
                    "int",
                    "str",
                    "bool"
                ],
                "scales": [
                    "bytes",
                    "str",
                    "dict",
                    "bool",
                    "int"
                ],
                "max_distortion": [
                    "int",
                    "PIL.Image.Image",
                    "Iterable[int]"
                ],
                "fixed_crops": [
                    "bool",
                    "Type",
                    "T",
                    "str"
                ],
                "more_fixed_crops": [
                    "str",
                    "bool",
                    "Dict[str, Any]"
                ]
            }
        },
        "MultiScaleCropVideo._sample_crop_shape": {
            "name": "_sample_crop_shape",
            "location": 136,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "cls": [
                    "int",
                    "bool",
                    "List[float]",
                    "MutableSet[types.signals.SignalHandlerRefT]"
                ],
                "crop_sizes": [
                    "int",
                    "float",
                    "Optional[int]",
                    "bool"
                ],
                "max_distortion": [
                    "int"
                ],
                "output_shape": [
                    "types.ImageShape",
                    "int",
                    "Tuple[int, int]"
                ]
            }
        },
        "MultiScaleCropVideo._sample_random_offset": {
            "name": "_sample_random_offset",
            "location": 156,
            "return": [
                "int",
                "List[str]",
                "bool"
            ],
            "arguments": {
                "input_shape": [
                    "int",
                    "Tuple[float, float]",
                    "str"
                ],
                "crop_shape": [
                    "int",
                    "Tuple[float, float]",
                    "str"
                ]
            }
        },
        "MultiScaleCropVideo._sample_fixed_offset": {
            "name": "_sample_fixed_offset",
            "location": 162,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "cls": [
                    "types.ImageShape",
                    "Sequence[T]",
                    "int"
                ],
                "input_shape": [
                    "types.ImageShape",
                    "Sequence[T]",
                    "int"
                ],
                "crop_shape": [
                    "types.ImageShape",
                    "Sequence[T]",
                    "int"
                ],
                "more_fixed_crops": [
                    "types.ImageShape",
                    "Sequence[T]",
                    "int"
                ]
            }
        },
        "MultiScaleCropVideo._fixed_crop_offsets": {
            "name": "_fixed_crop_offsets",
            "location": 171,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "image_shape": [
                    "Tuple[int, int, int]",
                    "PIL.Image.Image"
                ],
                "crop_shape": [
                    "Tuple[int, int, int]",
                    "PIL.Image.Image"
                ],
                "more_fixed_crops": [
                    "PIL.Image.Image",
                    "str",
                    "PIL.Image",
                    "int",
                    "Tuple[int, int, int]"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/ndarray_to_pil_video.py": {
        "NDArrayToPILVideo.__init__": {
            "name": "__init__",
            "location": 13,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "format": [
                    "str",
                    "Optional[Exception]",
                    "dict"
                ]
            }
        },
        "NDArrayToPILVideo._transform": {
            "name": "_transform",
            "location": 26,
            "return": [
                "types.PILVideoI"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "Callable",
                    "str"
                ],
                "params": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        },
        "NDArrayToPILVideo._gen_params": {
            "name": "_gen_params",
            "location": 32,
            "return": [
                "Optional[str]",
                "str",
                "Optional[int]"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        },
        "NDArrayToPILVideo.__repr__": {
            "name": "__repr__",
            "location": 35,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/normalize_video.py": {
        "NormalizeVideo.__init__": {
            "name": "__init__",
            "location": 30,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "mean": [
                    "int",
                    "str"
                ],
                "std": [
                    "str",
                    "bool",
                    "int"
                ],
                "channel_dim": [
                    "int",
                    "torch.Tensor"
                ],
                "inplace": [
                    "int",
                    "str"
                ]
            }
        },
        "NormalizeVideo._gen_params": {
            "name": "_gen_params",
            "location": 46,
            "return": [
                "Optional[str]",
                "str",
                "torch.Tensor",
                "Optional[int]"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        },
        "NormalizeVideo.__repr__": {
            "name": "__repr__",
            "location": 49,
            "return": [
                "str",
                "float",
                "Type",
                "Dict[str, Any]",
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "NormalizeVideo._transform": {
            "name": "_transform",
            "location": 57,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "str"
                ],
                "params": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        },
        "NormalizeVideo._broadcast_to_seq": {
            "name": "_broadcast_to_seq",
            "location": 66,
            "return": [
                "int",
                "Optional[int]"
            ],
            "arguments": {
                "x": [
                    "int",
                    "bool",
                    "float"
                ],
                "channel_count": [
                    "int",
                    "Tuple[bytes, bytes]",
                    "str"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/pil_video_to_tensor.py": {
        "PILVideoToTensor.__init__": {
            "name": "__init__",
            "location": 15,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "rescale": [
                    "int",
                    "bool",
                    "apistar.types.RouteConfig",
                    "float"
                ],
                "ordering": [
                    "int",
                    "str",
                    "Optional[int]"
                ]
            }
        },
        "PILVideoToTensor._gen_params": {
            "name": "_gen_params",
            "location": 34,
            "return": [
                "Optional[str]",
                "str",
                "torch.Tensor",
                "Optional[int]"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        },
        "PILVideoToTensor._transform": {
            "name": "_transform",
            "location": 37,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "Collection[int]",
                    "Set[str]",
                    "List[T]",
                    "Deque",
                    "bool"
                ],
                "params": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        },
        "PILVideoToTensor.__repr__": {
            "name": "__repr__",
            "location": 53,
            "return": [
                "str",
                "float",
                "Type",
                "Dict[str, Any]",
                "bool"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/random_crop_video.py": {
        "RandomCropVideo.__init__": {
            "name": "__init__",
            "location": 43,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "size": [
                    "int",
                    "float",
                    "Union[Tuple[int, int], int]",
                    "starfish.core.types.Number"
                ],
                "padding": [
                    "float",
                    "int",
                    "bool",
                    "bytes",
                    "str"
                ],
                "pad_if_needed": [
                    "float",
                    "int",
                    "bool",
                    "bytes",
                    "str"
                ],
                "fill": [
                    "float",
                    "int",
                    "bool",
                    "bytes",
                    "str"
                ],
                "padding_mode": [
                    "int",
                    "str",
                    "Optional[int]",
                    "float"
                ]
            }
        },
        "RandomCropVideo._gen_params": {
            "name": "_gen_params",
            "location": 58,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "Callable",
                    "str"
                ]
            }
        },
        "RandomCropVideo._transform": {
            "name": "_transform",
            "location": 65,
            "return": [
                "types.PILVideoI"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ],
                "params": [
                    "int",
                    "Callable",
                    "str"
                ]
            }
        },
        "RandomCropVideo._maybe_pad": {
            "name": "_maybe_pad",
            "location": 71,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "self": [],
                "frame": [
                    "int",
                    "tuple",
                    "float"
                ]
            }
        },
        "RandomCropVideo.__repr__": {
            "name": "__repr__",
            "location": 88,
            "return": [
                "Type",
                "int",
                "Dict[str, Any]"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/random_horizontal_flip_video.py": {
        "RandomHorizontalFlipVideo.__init__": {
            "name": "__init__",
            "location": 19,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "p": [
                    "int",
                    "bool",
                    "apistar.types.RouteConfig",
                    "float"
                ]
            }
        },
        "RandomHorizontalFlipVideo._gen_params": {
            "name": "_gen_params",
            "location": 22,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        },
        "RandomHorizontalFlipVideo._transform": {
            "name": "_transform",
            "location": 28,
            "return": [
                "typing.Iterator[PIL.Image.Image]"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ],
                "params": [
                    "int",
                    "Callable",
                    "str"
                ]
            }
        },
        "RandomHorizontalFlipVideo.__repr__": {
            "name": "__repr__",
            "location": 36,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/random_resized_crop_video.py": {
        "RandomResizedCropVideo._gen_params": {
            "name": "_gen_params",
            "location": 29,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "types.PILVideo",
                    "int",
                    "str",
                    "Callable"
                ]
            }
        },
        "RandomResizedCropVideo._transform": {
            "name": "_transform",
            "location": 36,
            "return": [
                "types.PILVideo.I"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ],
                "params": [
                    "bool",
                    "str",
                    "float",
                    "int",
                    "Sequence[int]"
                ]
            }
        },
        "RandomResizedCropVideo.__init__": {
            "name": "__init__",
            "location": 43,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "size": [
                    "int",
                    "Union[Tuple[int, int], int]",
                    "Tuple[int, int, int]"
                ],
                "scale": [
                    "int",
                    "bytes"
                ],
                "ratio": [
                    "int",
                    "bytes"
                ],
                "interpolation": [
                    "int",
                    "bytes"
                ]
            }
        },
        "RandomResizedCropVideo.__repr__": {
            "name": "__repr__",
            "location": 55,
            "return": [
                "Type",
                "list",
                "int",
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "RandomResizedCropVideo._transform_frame": {
            "name": "_transform_frame",
            "location": 66,
            "return": [
                "str",
                "Optional[str]",
                "float"
            ],
            "arguments": {
                "self": [],
                "frame": [
                    "int",
                    "PIL.Image.Image",
                    "bool"
                ],
                "i": [
                    "int",
                    "PIL.Image.Image",
                    "bool"
                ],
                "j": [
                    "int",
                    "PIL.Image.Image",
                    "bool"
                ],
                "h": [
                    "int",
                    "PIL.Image.Image",
                    "bool"
                ],
                "w": [
                    "int",
                    "PIL.Image.Image",
                    "bool"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/resize_video.py": {
        "ResizeVideo.__init__": {
            "name": "__init__",
            "location": 24,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "size": [
                    "int",
                    "bytes"
                ],
                "interpolation": [
                    "int",
                    "bytes"
                ]
            }
        },
        "ResizeVideo.__repr__": {
            "name": "__repr__",
            "location": 30,
            "return": [
                "str",
                "dict",
                "Dict[str, Any]"
            ],
            "arguments": {
                "self": []
            }
        },
        "ResizeVideo._transform": {
            "name": "_transform",
            "location": 36,
            "return": [
                "types.PILVideoI"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ],
                "params": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/time_apply.py": {
        "TimeApply.__init__": {
            "name": "__init__",
            "location": 21,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "img_transform": [
                    "int",
                    "bool",
                    "apistar.types.RouteConfig",
                    "float"
                ]
            }
        },
        "TimeApply._transform": {
            "name": "_transform",
            "location": 28,
            "return": [
                "types.PILVideoI"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ],
                "params": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/time_to_channel.py": {
        "TimeToChannel._gen_params": {
            "name": "_gen_params",
            "location": 12,
            "return": [
                "Optional[str]",
                "str",
                "torch.Tensor",
                "Optional[int]"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        },
        "TimeToChannel._transform": {
            "name": "_transform",
            "location": 15,
            "return": [
                "str",
                "dict"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "Callable",
                    "str"
                ],
                "params": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        },
        "TimeToChannel.__repr__": {
            "name": "__repr__",
            "location": 18,
            "return": [
                "str",
                "int"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/transform.py": {
        "FramesAndParams.__init__": {
            "name": "__init__",
            "location": 13,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "bool",
                    "apistar.types.RouteConfig",
                    "float"
                ],
                "params": [
                    "int",
                    "bool",
                    "apistar.types.RouteConfig",
                    "float"
                ]
            }
        },
        "Transform.__call__": {
            "name": "__call__",
            "location": 19,
            "return": [
                "starlette.types.Receive",
                "Callable",
                "starlette.types.Send",
                "int",
                "float"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "starlette.types.Receive",
                    "Callable",
                    "starlette.types.Send",
                    "int",
                    "float"
                ],
                "target": [
                    "starlette.types.Receive",
                    "Callable",
                    "starlette.types.Send",
                    "int",
                    "float"
                ]
            }
        },
        "Transform._gen_params": {
            "name": "_gen_params",
            "location": 40,
            "return": [
                "typing.Union[types.ParamsType, FramesAndParams[types.InputFramesType, types.ParamsType]]"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        },
        "Transform._transform": {
            "name": "_transform",
            "location": 46,
            "return": [
                "types.OutputFramesType"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ],
                "params": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        },
        "StatelessTransform._gen_params": {
            "name": "_gen_params",
            "location": 53,
            "return": [
                "Optional[str]",
                "str",
                "Optional[int]"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        }
    },
    "torchvideo-master/src/torchvideo/transforms/transforms/types.py": {},
    "torchvideo-master/src/torchvideo/transforms/transforms/__init__.py": {},
    "torchvideo-master/tests/__init__.py": {
        "TorchRandomState.getstate": {
            "name": "getstate",
            "location": 9,
            "return": [
                "List[str]",
                "str",
                "dict",
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "TorchRandomState.setstate": {
            "name": "setstate",
            "location": 12,
            "return": [
                "str",
                "numpy.ndarray",
                "List[str]"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "numpy.ndarray",
                    "List[List[str]]",
                    "Sequence[Sequence[str]]",
                    "Sequence[Tuple[str, int]]",
                    "torch.Tensor",
                    "numpy.array"
                ]
            }
        },
        "TorchRandomState.seed": {
            "name": "seed",
            "location": 15,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "seed": [
                    "int",
                    "Callable",
                    "str"
                ]
            }
        }
    },
    "torchvideo-master/tests/assertions/seq.py": {
        "assert_ordered": {
            "name": "assert_ordered",
            "location": 4,
            "return": [
                "Iterator"
            ],
            "arguments": {
                "seq": [
                    "int",
                    "Callable",
                    "str"
                ]
            }
        },
        "assert_elems_lt": {
            "name": "assert_elems_lt",
            "location": 18,
            "return": [
                ""
            ],
            "arguments": {
                "seq": [
                    "int",
                    "float",
                    "bool"
                ],
                "upper_bound": [
                    "int",
                    "float",
                    "bool"
                ]
            }
        },
        "assert_elems_gte": {
            "name": "assert_elems_gte",
            "location": 22,
            "return": [
                ""
            ],
            "arguments": {
                "seq": [
                    "bool",
                    "Dict[int, Tuple[int, int]]"
                ],
                "lower_bound": [
                    "bool",
                    "Dict[int, Tuple[int, int]]"
                ]
            }
        }
    },
    "torchvideo-master/tests/assertions/__init__.py": {},
    "torchvideo-master/tests/functional/test_readers.py": {
        "TestLintelReader.test_reading_sequential_contiguous_frames": {
            "name": "test_reading_sequential_contiguous_frames",
            "location": 10,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestLintelReader.test_reading_last_frame": {
            "name": "test_reading_last_frame",
            "location": 15,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestLintelReader.test_reading_frames_out_of_order": {
            "name": "test_reading_frames_out_of_order",
            "location": 20,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestLintelReader.test_reading_frames_beyond_length_of_video": {
            "name": "test_reading_frames_beyond_length_of_video",
            "location": 25,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestLintelReader.load_frames": {
            "name": "load_frames",
            "location": 30,
            "return": [
                "List[str]",
                "List[dict]"
            ],
            "arguments": {
                "self": [],
                "frame_idx": [
                    "str",
                    "bool"
                ]
            }
        },
        "TestLintelReader.check_frames": {
            "name": "check_frames",
            "location": 33,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "str",
                    "int",
                    "List[List[int]]"
                ],
                "expected_frame_count": [
                    "str",
                    "int",
                    "List[List[int]]"
                ]
            }
        }
    },
    "torchvideo-master/tests/functional/__init__.py": {},
    "torchvideo-master/tests/functional/datasets/test_gulp_video_dataset.py": {
        "gulp_path": {
            "name": "gulp_path",
            "location": 20,
            "return": [
                "bool",
                "str"
            ],
            "arguments": {}
        },
        "gulp_dataset": {
            "name": "gulp_dataset",
            "location": 25,
            "return": [
                "str"
            ],
            "arguments": {
                "gulp_path": [
                    "pathlib.Path",
                    "str",
                    "Union[str, pathlib.Path]"
                ]
            }
        },
        "TestGulpVideoDataset.test_dataset_length": {
            "name": "test_dataset_length",
            "location": 34,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "gulp_dataset": [
                    "tests.basilisp.helpers.CompileFn",
                    "str",
                    "tests.async_mock.Mock",
                    "float"
                ]
            }
        },
        "TestGulpVideoDataset.test_video_id": {
            "name": "test_video_id",
            "location": 37,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "gulp_dataset": []
            }
        },
        "TestGulpVideoDataset.test_video_range": {
            "name": "test_video_range",
            "location": 40,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "gulp_dataset": []
            }
        },
        "TestGulpVideoDataset.test_loads_all_frames_by_default": {
            "name": "test_loads_all_frames_by_default",
            "location": 46,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "gulp_dataset": [
                    "tests.async_mock.Mock",
                    "tests.basilisp.helpers.CompileFn",
                    "str"
                ]
            }
        },
        "TestGulpVideoDataset.test_loading_by_slice": {
            "name": "test_loading_by_slice",
            "location": 54,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "gulp_dataset": [
                    "tests.basilisp.helpers.CompileFn",
                    "str",
                    "tests.async_mock.Mock",
                    "float"
                ]
            }
        },
        "TestGulpVideoDataset.test_loading_by_list_of_slices": {
            "name": "test_loading_by_list_of_slices",
            "location": 64,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "gulp_dataset": [
                    "pathlib.Path",
                    "tests.basilisp.helpers.CompileFn"
                ]
            }
        },
        "TestGulpVideoDataset.test_loading_by_list_of_int": {
            "name": "test_loading_by_list_of_int",
            "location": 76,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "gulp_dataset": [
                    "pathlib.Path",
                    "tests.basilisp.helpers.CompileFn"
                ]
            }
        },
        "TestGulpVideoDataset.test_filtering_videos": {
            "name": "test_filtering_videos",
            "location": 87,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "gulp_path": [
                    "pathlib.Path",
                    "path.Path",
                    "str",
                    "Optional[Callable[[Any], None]]"
                ]
            }
        },
        "TestGulpVideoDataset.test_transforms_are_passed_uint8_ndarray_video": {
            "name": "test_transforms_are_passed_uint8_ndarray_video",
            "location": 98,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "gulp_path": [
                    "pathlib.Path",
                    "str"
                ]
            }
        },
        "TestGulpVideoDataset.test_transform_is_called": {
            "name": "test_transform_is_called",
            "location": 107,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "gulp_path": [
                    "pathlib.Path",
                    "str"
                ]
            }
        },
        "TestGulpVideoDataset.test_transform_is_passed_target_if_it_supports_it": {
            "name": "test_transform_is_passed_target_if_it_supports_it",
            "location": 116,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "gulp_path": [
                    "Callable",
                    "pathlib.Path",
                    "pypi2nix.path.Path"
                ]
            }
        },
        "TestGulpVideoDataset.test_labels_are_accessible": {
            "name": "test_labels_are_accessible",
            "location": 127,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "gulp_dataset": []
            }
        },
        "TestGulpVideoDataset.test_video_ids": {
            "name": "test_video_ids",
            "location": 131,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "gulp_dataset": [
                    "int",
                    "List[Dict[str, Any]]",
                    "str"
                ]
            }
        },
        "TestGulpVideoDataset.test_creating_gulp_video_dataset_from_gulp_directory": {
            "name": "test_creating_gulp_video_dataset_from_gulp_directory",
            "location": 137,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "gulp_path": [
                    "pathlib.Path",
                    "Dict[str, cerulean.Path]"
                ]
            }
        },
        "TestGulpVideoDataset.test_dataset_throws_error_if_root_path_is_different_from_gulp_dir_path": {
            "name": "test_dataset_throws_error_if_root_path_is_different_from_gulp_dir_path",
            "location": 146,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "gulp_path": [
                    "pathlib.Path",
                    "Dict[str, cerulean.Path]"
                ]
            }
        },
        "TestGulpVideoDataset.test_filtering_videos.filter": {
            "name": "filter",
            "location": 90,
            "return": [
                "bool",
                "int",
                "\"ID\""
            ],
            "arguments": {
                "video_id": [
                    "str",
                    "int"
                ]
            }
        }
    },
    "torchvideo-master/tests/functional/datasets/test_image_folder_video_dataset.py": {
        "image_folder": {
            "name": "image_folder",
            "location": 11,
            "return": [
                "str",
                "bool",
                "bytes"
            ],
            "arguments": {}
        },
        "image_folder_video_dataset": {
            "name": "image_folder_video_dataset",
            "location": 16,
            "return": [
                "str",
                "int"
            ],
            "arguments": {
                "image_folder": [
                    "str",
                    "Union[pathlib.Path, str]",
                    "Sequence[Sequence[T]]",
                    "List[int]"
                ]
            }
        },
        "TestImageFolderVideoDataset.test_length": {
            "name": "test_length",
            "location": 25,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "image_folder_video_dataset": [
                    "bytes",
                    "str",
                    "int",
                    "Type[T]"
                ]
            }
        },
        "TestImageFolderVideoDataset.test_video_range": {
            "name": "test_video_range",
            "location": 29,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "image_folder_video_dataset": [
                    "bytes",
                    "str",
                    "int",
                    "Type[T]"
                ]
            }
        },
        "TestImageFolderVideoDataset.test_loads_all_frames_by_default": {
            "name": "test_loads_all_frames_by_default",
            "location": 35,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "image_folder_video_dataset": [
                    "bytes",
                    "str",
                    "int",
                    "Type[T]"
                ]
            }
        },
        "TestImageFolderVideoDataset.test_loading_by_slice": {
            "name": "test_loading_by_slice",
            "location": 41,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "image_folder_video_dataset": [
                    "bytes",
                    "str",
                    "int",
                    "Type[T]"
                ]
            }
        },
        "TestImageFolderVideoDataset.test_loading_by_list_of_slice": {
            "name": "test_loading_by_list_of_slice",
            "location": 50,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "image_folder_video_dataset": [
                    "int",
                    "Tuple[int, int]",
                    "Optional[str]"
                ]
            }
        },
        "TestImageFolderVideoDataset.test_loading_by_list_of_ints": {
            "name": "test_loading_by_list_of_ints",
            "location": 61,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "image_folder_video_dataset": [
                    "int",
                    "Tuple[int, int]",
                    "Optional[str]"
                ]
            }
        },
        "TestImageFolderVideoDataset.test_using_custom_frame_counter": {
            "name": "test_using_custom_frame_counter",
            "location": 70,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "image_folder": [
                    "str"
                ]
            }
        }
    },
    "torchvideo-master/tests/functional/datasets/test_video_folder_dataset.py": {
        "video_folder_dir": {
            "name": "video_folder_dir",
            "location": 9,
            "return": [
                "bool",
                "str",
                "dict"
            ],
            "arguments": {}
        },
        "video_folder_dataset": {
            "name": "video_folder_dataset",
            "location": 14,
            "return": [
                "str",
                "Optional[int]",
                "Callable"
            ],
            "arguments": {
                "video_folder_dir": [
                    "str",
                    "Optional[str]"
                ]
            }
        },
        "TestVideoFolderDataset.test_dataset_length": {
            "name": "test_dataset_length",
            "location": 23,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video_folder_dataset": [
                    "str",
                    "float"
                ]
            }
        },
        "TestVideoFolderDataset.test_video_range": {
            "name": "test_video_range",
            "location": 26,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video_folder_dataset": []
            }
        },
        "TestVideoFolderDataset.test_loads_all_frames_by_default": {
            "name": "test_loads_all_frames_by_default",
            "location": 32,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video_folder_dataset": [
                    "str"
                ]
            }
        },
        "TestVideoFolderDataset.test_loading_by_slice": {
            "name": "test_loading_by_slice",
            "location": 40,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video_folder_dataset": [
                    "str",
                    "float"
                ]
            }
        },
        "TestVideoFolderDataset.test_loading_by_list_of_slices": {
            "name": "test_loading_by_list_of_slices",
            "location": 50,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video_folder_dataset": [
                    "bool"
                ]
            }
        },
        "TestVideoFolderDataset.test_loading_by_list_of_int": {
            "name": "test_loading_by_list_of_int",
            "location": 63,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video_folder_dataset": []
            }
        },
        "TestVideoFolderDataset.test_using_custom_frame_counter": {
            "name": "test_using_custom_frame_counter",
            "location": 74,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video_folder_dir": [
                    "str",
                    "Optional[str]"
                ]
            }
        }
    },
    "torchvideo-master/tests/functional/datasets/__init__.py": {},
    "torchvideo-master/tests/unit/mock_transforms.py": {
        "_has_at_least_one_param": {
            "name": "_has_at_least_one_param",
            "location": 10,
            "return": [
                "List[Dict]",
                "List[str]",
                "list",
                "Dict[str, str]",
                "str",
                "List[List[Any]]",
                "bool"
            ],
            "arguments": {
                "fn": [
                    "int",
                    "Callable",
                    "str"
                ]
            }
        },
        "MockTransform.__init__": {
            "name": "__init__",
            "location": 16,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "return_value": [
                    "str",
                    "int",
                    "Dict[str, Any]"
                ],
                "name": [
                    "str",
                    "Dict[str, Any]",
                    "Optional[str]"
                ]
            }
        },
        "MockTransform.assert_called_once_with": {
            "name": "assert_called_once_with",
            "location": 21,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "MockTransform.__repr__": {
            "name": "__repr__",
            "location": 30,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "MockTransform._get_frames_return_value": {
            "name": "_get_frames_return_value",
            "location": 36,
            "return": [
                "bool",
                "Callable"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "float",
                    "str",
                    "int"
                ]
            }
        },
        "MockTransformWithTarget.__init__": {
            "name": "__init__",
            "location": 46,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "frames_return_value": [
                    "int",
                    "bool",
                    "Optional[List[Any]]",
                    "Optional[bool]",
                    "str",
                    "Optional[str]",
                    "Optional[Sequence[Any]]",
                    "Dict[str, Any]"
                ],
                "target_return_value": [
                    "float",
                    "str"
                ]
            }
        },
        "MockTransformWithTarget._get_target_return_value": {
            "name": "_get_target_return_value",
            "location": 52,
            "return": [
                "tuple",
                "int",
                "float",
                "Type"
            ],
            "arguments": {
                "self": [],
                "target": [
                    "list",
                    "str",
                    "Callable[[KT, VT], bool]"
                ]
            }
        },
        "MockFramesOnlyTransform.__call__": {
            "name": "__call__",
            "location": 61,
            "return": [
                "Callable",
                "Optional[Iterable[Any]]",
                "int",
                "float",
                "str"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "str",
                    "bool",
                    "Iterable[int]"
                ]
            }
        },
        "MockFramesAndOptionalTargetTransform.__call__": {
            "name": "__call__",
            "location": 67,
            "return": [
                "Optional[int]",
                "Optional[Iterable[Any]]",
                "List[str]",
                "bool",
                "Optional[List[Callable]]"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "str",
                    "T"
                ],
                "target": [
                    "str",
                    "int",
                    "float",
                    "Union[str, bool, None]"
                ]
            }
        },
        "MockFramesAndRequiredTargetTransform.__init__": {
            "name": "__init__",
            "location": 79,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "frames_return_value": [
                    "Optional[bool]",
                    "Optional[Any]"
                ],
                "target_return_value": [
                    "str",
                    "bool"
                ],
                "name": [
                    "Optional[bool]",
                    "Optional[Any]"
                ]
            }
        },
        "MockFramesAndRequiredTargetTransform.__call__": {
            "name": "__call__",
            "location": 85,
            "return": [
                "Optional[int]",
                "Optional[Iterable[Any]]",
                "List[str]",
                "bool",
                "Optional[List[Callable]]"
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "str",
                    "T"
                ],
                "target": [
                    "str",
                    "T"
                ]
            }
        }
    },
    "torchvideo-master/tests/unit/strategies.py": {
        "numpy_video": {
            "name": "numpy_video",
            "location": 11,
            "return": [
                "str",
                "List[Dict[str, Any]]"
            ],
            "arguments": {
                "draw": [
                    "int",
                    "Tuple[int, int]",
                    "list"
                ],
                "min_length": [
                    "Tuple[int, int]",
                    "int",
                    "list"
                ],
                "max_length": [
                    "Tuple[int, int]",
                    "int",
                    "list"
                ],
                "min_width": [
                    "Tuple[int, int]",
                    "int",
                    "list"
                ],
                "max_width": [
                    "Tuple[int, int]",
                    "int",
                    "list"
                ],
                "min_height": [
                    "Tuple[int, int]",
                    "int",
                    "list"
                ],
                "max_height": [
                    "Tuple[int, int]",
                    "int",
                    "list"
                ],
                "mode": [
                    "Optional[List]",
                    "Optional[int]",
                    "Tuple[numpy.dtype]",
                    "int",
                    "Optional[Tuple[float, float]]",
                    "Optional[Union[float, Any]]",
                    "bool",
                    "Optional[Callable[[str], bool]]"
                ]
            }
        },
        "pil_video": {
            "name": "pil_video",
            "location": 36,
            "return": [
                "Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]",
                "tuple",
                "Optional[int]"
            ],
            "arguments": {
                "draw": [
                    "int",
                    "Tuple[int, int]",
                    "list"
                ],
                "min_length": [
                    "int",
                    "Tuple[int, int]",
                    "list"
                ],
                "max_length": [
                    "int",
                    "Tuple[int, int]",
                    "list"
                ],
                "min_width": [
                    "int",
                    "Tuple[int, int]",
                    "list"
                ],
                "max_width": [
                    "int",
                    "Tuple[int, int]",
                    "list"
                ],
                "min_height": [
                    "int",
                    "Tuple[int, int]",
                    "list"
                ],
                "max_height": [
                    "int",
                    "Tuple[int, int]",
                    "list"
                ],
                "mode": [
                    "int",
                    "Tuple[int, int]",
                    "list"
                ]
            }
        },
        "tensor_video": {
            "name": "tensor_video",
            "location": 63,
            "return": [
                "Union[str, List[str]]",
                "List[str]",
                "Dict[str, Any]",
                "numpy.ndarray",
                "bool",
                "Dict[str, dict]",
                "str"
            ],
            "arguments": {
                "draw": [
                    "int",
                    "Tuple[int, int]",
                    "Optional[int]",
                    "list"
                ],
                "min_length": [
                    "int",
                    "Tuple[int, int]",
                    "Optional[int]",
                    "list"
                ],
                "max_length": [
                    "int",
                    "Tuple[int, int]",
                    "Optional[int]",
                    "list"
                ],
                "min_width": [
                    "int",
                    "Tuple[int, int]",
                    "Optional[int]",
                    "list"
                ],
                "max_width": [
                    "int",
                    "Tuple[int, int]",
                    "Optional[int]",
                    "list"
                ],
                "min_height": [
                    "int",
                    "Tuple[int, int]",
                    "Optional[int]",
                    "list"
                ],
                "max_height": [
                    "int",
                    "Tuple[int, int]",
                    "Optional[int]",
                    "list"
                ],
                "mode": [
                    "int",
                    "Tuple[int, int]",
                    "Optional[int]",
                    "list"
                ]
            }
        },
        "video_shape": {
            "name": "video_shape",
            "location": 98,
            "return": [
                "str",
                "List[float]",
                "bool",
                "int"
            ],
            "arguments": {
                "draw": [
                    "int",
                    "str"
                ],
                "min_length": [
                    "str",
                    "int",
                    "float"
                ],
                "max_length": [
                    "str",
                    "int",
                    "float"
                ],
                "min_height": [
                    "str",
                    "int",
                    "float"
                ],
                "max_height": [
                    "str",
                    "int",
                    "float"
                ],
                "min_width": [
                    "int",
                    "Tuple[float, float]"
                ],
                "max_width": [
                    "int",
                    "Tuple[float, float]"
                ]
            }
        }
    },
    "torchvideo-master/tests/unit/test_internal.py": {
        "test_compute_sample_length": {
            "name": "test_compute_sample_length",
            "location": 26,
            "return": [
                ""
            ],
            "arguments": {
                "clip_length": [
                    "int"
                ],
                "step_size": [
                    "int"
                ],
                "expected_sample_size": [
                    "int",
                    "Optional[Set[str]]",
                    "List[Dict[str, str]]",
                    "Optional[float]"
                ]
            }
        }
    },
    "torchvideo-master/tests/unit/test_readers.py": {
        "loadvid_frame_nums_mock": {
            "name": "loadvid_frame_nums_mock",
            "location": 12,
            "return": [
                ""
            ],
            "arguments": {
                "monkeypatch": [
                    "Optional[str]",
                    "Dict[str, Any]",
                    "str"
                ]
            }
        },
        "loadvid_frame_nums_mock.side_effect": {
            "name": "side_effect",
            "location": 13,
            "return": [
                "str",
                "List[int]",
                "bytes"
            ],
            "arguments": {
                "binary_data": [
                    "bool",
                    "str"
                ],
                "frame_nums": [
                    "list",
                    "List[Dict]",
                    "int",
                    "List[int]",
                    "numpy.ndarray",
                    "List[Dict[str, Any]]"
                ]
            }
        },
        "TestLintelReaderUnit.test_loading_sequential_contiguous_frames": {
            "name": "test_loading_sequential_contiguous_frames",
            "location": 26,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "loadvid_frame_nums_mock": [
                    "List[str]"
                ]
            }
        },
        "TestLintelReaderUnit.test_loading_duplicate_frames": {
            "name": "test_loading_duplicate_frames",
            "location": 35,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "loadvid_frame_nums_mock": [
                    "List[str]"
                ]
            }
        },
        "TestLintelReaderUnit.test_loading_unorderd_frames": {
            "name": "test_loading_unorderd_frames",
            "location": 45,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "loadvid_frame_nums_mock": [
                    "List[str]"
                ]
            }
        },
        "TestLintelReaderUnit.assert_loadvid_correctly_called": {
            "name": "assert_loadvid_correctly_called",
            "location": 55,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "loadvid_frame_nums_mock": [
                    "dict",
                    "Optional[tuple]",
                    "List[str]",
                    "bool",
                    "Dict[str, Any]",
                    "Callable"
                ],
                "f": [
                    "str",
                    "Optional[List[str]]",
                    "Optional[str]",
                    "list"
                ],
                "frame_nums": [
                    "bool",
                    "str",
                    "bytes",
                    "Callable",
                    "int",
                    "numpy.ndarray",
                    "io.StringIO"
                ],
                "frames": [
                    "bool",
                    "str",
                    "bytes",
                    "Callable",
                    "int",
                    "numpy.ndarray",
                    "io.StringIO"
                ],
                "expected_load_idx": [
                    "float",
                    "List[int]",
                    "Optional[Dict[int, int]]"
                ]
            }
        }
    },
    "torchvideo-master/tests/unit/__init__.py": {},
    "torchvideo-master/tests/unit/datasets/conftest.py": {
        "mock_frame_count": {
            "name": "mock_frame_count",
            "location": 8,
            "return": [
                ""
            ],
            "arguments": {
                "monkeypatch": [
                    "str",
                    "bool",
                    "dict",
                    "Mapping[str, Any]"
                ]
            }
        },
        "dataset_dir": {
            "name": "dataset_dir",
            "location": 20,
            "return": [
                "str",
                "List[int]"
            ],
            "arguments": {
                "fs": [
                    "str",
                    "bool"
                ]
            }
        },
        "mock_frame_count.get_videofile_frame_count": {
            "name": "get_videofile_frame_count",
            "location": 9,
            "return": [
                "str",
                "bool"
            ],
            "arguments": {
                "path": [
                    "str",
                    "bool"
                ]
            }
        }
    },
    "torchvideo-master/tests/unit/datasets/test_image_folder_video_dataset.py": {
        "TestImageFolderVideoDatasetUnit.test_all_videos_folders_are_present_in_video_dirs_by_default": {
            "name": "test_all_videos_folders_are_present_in_video_dirs_by_default",
            "location": 14,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "dataset_dir": [
                    "str",
                    "pathlib.Path",
                    "List[str]",
                    "bool"
                ]
            }
        },
        "TestImageFolderVideoDatasetUnit.test_filtering_video_folders": {
            "name": "test_filtering_video_folders",
            "location": 22,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "dataset_dir": [
                    "str"
                ]
            }
        },
        "TestImageFolderVideoDatasetUnit.test_labels_are_accessible": {
            "name": "test_labels_are_accessible",
            "location": 37,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "dataset_dir": [
                    "str",
                    "cerulean.Path",
                    "pathlib.Path",
                    "Dict[str, pathlib.Path]",
                    "Optional[str]"
                ]
            }
        },
        "TestImageFolderVideoDatasetUnit.test_transform_is_applied": {
            "name": "test_transform_is_applied",
            "location": 49,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "dataset_dir": [
                    "pathlib.Path",
                    "pypi2nix.path.Path",
                    "pathlib.PosixPath",
                    "str"
                ]
            }
        },
        "TestImageFolderVideoDatasetUnit.test_transform_is_passed_target_if_it_supports_it": {
            "name": "test_transform_is_passed_target_if_it_supports_it",
            "location": 61,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "dataset_dir": [
                    "pathlib.Path",
                    "pypi2nix.path.Path",
                    "str",
                    "pathlib.PosixPath",
                    "path.Path"
                ]
            }
        },
        "TestImageFolderVideoDatasetUnit.test_video_ids": {
            "name": "test_video_ids",
            "location": 76,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "dataset_dir": [
                    "str",
                    "pathlib.Path",
                    "bool",
                    "Optional[str]"
                ]
            }
        },
        "TestImageFolderVideoDatasetUnit.make_video_dirs": {
            "name": "make_video_dirs",
            "location": 89,
            "return": [
                ""
            ],
            "arguments": {
                "dataset_dir": [
                    "str",
                    "bool"
                ],
                "video_count": [
                    "bool",
                    "Optional[str]",
                    "str",
                    "Dict[str, Any]"
                ],
                "frame_count": [
                    "bool",
                    "Optional[str]",
                    "str",
                    "Dict[str, Any]"
                ]
            }
        },
        "TestImageFolderVideoDatasetUnit.test_filtering_video_folders.filter": {
            "name": "filter",
            "location": 25,
            "return": [
                "str",
                "pathlib.Path"
            ],
            "arguments": {
                "video_path": [
                    "pathlib.Path",
                    "str",
                    "List[str]"
                ]
            }
        }
    },
    "torchvideo-master/tests/unit/datasets/test_video_folder_dataset.py": {
        "TestVideoFolderDatasetUnit.test_all_videos_are_present_in_video_paths_by_default": {
            "name": "test_all_videos_are_present_in_video_paths_by_default",
            "location": 18,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "dataset_dir": [],
                "fs": [
                    "str"
                ],
                "mock_frame_count": []
            }
        },
        "TestVideoFolderDatasetUnit.test_filtering_video_files": {
            "name": "test_filtering_video_files",
            "location": 28,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "dataset_dir": [
                    "str",
                    "Dict[str, Sequence[str]]"
                ],
                "fs": [],
                "mock_frame_count": []
            }
        },
        "TestVideoFolderDatasetUnit.test_labels_are_accessible": {
            "name": "test_labels_are_accessible",
            "location": 41,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "dataset_dir": [
                    "str"
                ],
                "fs": [
                    "str"
                ],
                "mock_frame_count": [
                    "Dict[str, Sequence[str]]"
                ]
            }
        },
        "TestVideoFolderDatasetUnit.test_transform_is_applied": {
            "name": "test_transform_is_applied",
            "location": 52,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "dataset_dir": [
                    "Callable",
                    "bool"
                ],
                "fs": [
                    "Optional[str]",
                    "str"
                ],
                "monkeypatch": [
                    "str",
                    "bool"
                ]
            }
        },
        "TestVideoFolderDatasetUnit.test_transform_is_passed_target_if_it_supports_it": {
            "name": "test_transform_is_passed_target_if_it_supports_it",
            "location": 73,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "dataset_dir": [
                    "Callable"
                ],
                "fs": [
                    "Optional[str]",
                    "str"
                ],
                "monkeypatch": [
                    "Callable"
                ]
            }
        },
        "TestVideoFolderDatasetUnit.test_video_ids": {
            "name": "test_video_ids",
            "location": 93,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "dataset_dir": [
                    "Callable",
                    "bool"
                ],
                "fs": [
                    "Optional[str]",
                    "str"
                ]
            }
        },
        "TestVideoFolderDatasetUnit.make_video_files": {
            "name": "make_video_files",
            "location": 106,
            "return": [
                ""
            ],
            "arguments": {
                "dataset_dir": [
                    "bool",
                    "str"
                ],
                "fs": [
                    "str"
                ],
                "video_count": [
                    "bool",
                    "dict"
                ]
            }
        },
        "TestVideoFolderDatasetUnit.test_filtering_video_files.filter": {
            "name": "filter",
            "location": 31,
            "return": [
                "str",
                "int",
                "bool"
            ],
            "arguments": {
                "path": [
                    "str"
                ]
            }
        },
        "TestVideoFolderDatasetUnit.test_transform_is_applied._load_mock_frames": {
            "name": "_load_mock_frames",
            "location": 53,
            "return": [
                "str",
                "int",
                "float"
            ],
            "arguments": {
                "self": [],
                "frames_idx": [
                    "List[str]",
                    "List[Tuple[int, int]]",
                    "Callable[[str], str]",
                    "str",
                    "BinaryIO"
                ],
                "video_file": [
                    "List[Dict[str, Any]]",
                    "List[str]"
                ]
            }
        }
    },
    "torchvideo-master/tests/unit/datasets/__init__.py": {},
    "torchvideo-master/tests/unit/label_sets/test_csv_label_set.py": {
        "TestCsvLabelSet.test_returns_label_field_for_dataframe": {
            "name": "test_returns_label_field_for_dataframe",
            "location": 7,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestCsvLabelSet.test_returns_element_from_series": {
            "name": "test_returns_element_from_series",
            "location": 16,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/label_sets/test_dummy_label_set.py": {
        "TestDummyLabelSet.test_return_label_for_any_video_name": {
            "name": "test_return_label_for_any_video_name",
            "location": 8,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video_name": [
                    "str",
                    "Sequence[str]"
                ]
            }
        },
        "TestDummyLabelSet.test_repr": {
            "name": "test_repr",
            "location": 14,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/label_sets/test_gulp_label_set.py": {
        "TestGulpLabelSet.test_defaults_to_label_field": {
            "name": "test_defaults_to_label_field",
            "location": 12,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestGulpLabelSet.test_custom_label_field": {
            "name": "test_custom_label_field",
            "location": 17,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/label_sets/__init__.py": {},
    "torchvideo-master/tests/unit/samplers/assertions.py": {
        "assert_valid_frame_index": {
            "name": "assert_valid_frame_index",
            "location": 6,
            "return": [
                ""
            ],
            "arguments": {
                "frame_idx": [
                    "List[int]",
                    "int",
                    "str",
                    "float"
                ],
                "expected_frame_count": [
                    "int",
                    "str",
                    "List[List[int]]",
                    "Optional[str]",
                    "float"
                ],
                "video_length": [
                    "int",
                    "str",
                    "bool",
                    "Optional[str]"
                ]
            }
        },
        "assert_valid_snippet_index": {
            "name": "assert_valid_snippet_index",
            "location": 15,
            "return": [
                ""
            ],
            "arguments": {
                "snippet_idx": [
                    "int",
                    "List[int]",
                    "List[str]",
                    "bool"
                ],
                "expected_snippet_length": [
                    "int",
                    "List[int]",
                    "bool",
                    "str"
                ],
                "expected_segment_count": [
                    "int",
                    "List[int]",
                    "bool",
                    "str"
                ],
                "video_length": [
                    "int",
                    "Tuple[int, int]",
                    "Union[float, int]",
                    "List[str]",
                    "str",
                    "Tuple[float, float]"
                ]
            }
        }
    },
    "torchvideo-master/tests/unit/samplers/test_clip_sampler.py": {
        "TestClipSampler.test_clip_is_subsampled_from_video_when_video_is_longer_than_clip": {
            "name": "test_clip_is_subsampled_from_video_when_video_is_longer_than_clip",
            "location": 9,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "data": [
                    "str"
                ]
            }
        },
        "TestClipSampler.test_clip_is_oversampled_when_video_is_shorter_than_clip_length": {
            "name": "test_clip_is_oversampled_when_video_is_shorter_than_clip_length",
            "location": 20,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "data": [
                    "str"
                ]
            }
        },
        "TestClipSampler.test_clip_sampler_samples_central_clip_in_test_mode": {
            "name": "test_clip_sampler_samples_central_clip_in_test_mode",
            "location": 31,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestClipSampler.test_clip_sampler_is_deterministic_in_test_mode": {
            "name": "test_clip_sampler_is_deterministic_in_test_mode",
            "location": 37,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "data": [
                    "bytes",
                    "str"
                ]
            }
        },
        "TestClipSampler.test_repr": {
            "name": "test_repr",
            "location": 48,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/samplers/test_full_video_sampler.py": {
        "TestFullVideoSampler.test_full_video_sampler": {
            "name": "test_full_video_sampler",
            "location": 8,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "length": [
                    "str",
                    "bool",
                    "float"
                ]
            }
        },
        "TestFullVideoSampler.test_full_video_sampler_repr": {
            "name": "test_full_video_sampler_repr",
            "location": 17,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestFullVideoSampler.test_full_video_sampler_str": {
            "name": "test_full_video_sampler_str",
            "location": 20,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/samplers/test_lambda_sampler.py": {
        "TestLambdaSampler.test_throws_error_if_user_provided_sampling_fn_returns_invalid_idx": {
            "name": "test_throws_error_if_user_provided_sampling_fn_returns_invalid_idx",
            "location": 7,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestLambdaSampler.test_repr": {
            "name": "test_repr",
            "location": 13,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestLambdaSampler.test_repr.MySampler.__call__": {
            "name": "__call__",
            "location": 15,
            "return": [
                "Callable",
                "int",
                "float"
            ],
            "arguments": {
                "self": [],
                "video_length": [
                    "Callable",
                    "int",
                    "float"
                ]
            }
        },
        "TestLambdaSampler.test_repr.MySampler.__repr__": {
            "name": "__repr__",
            "location": 18,
            "return": [
                "str",
                "int"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/samplers/test_samplers.py": {
        "full_video_sampler": {
            "name": "full_video_sampler",
            "location": 17,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {}
        },
        "temporal_segment_sampler": {
            "name": "temporal_segment_sampler",
            "location": 21,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {}
        },
        "clip_sampler": {
            "name": "clip_sampler",
            "location": 27,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {}
        },
        "frame_sampler": {
            "name": "frame_sampler",
            "location": 33,
            "return": [
                "int",
                "list"
            ],
            "arguments": {
                "request": [
                    "Callable"
                ]
            }
        },
        "TestFrameSampler.test_frame_sampler_raises_error_0_or_negative_frame_count": {
            "name": "test_frame_sampler_raises_error_0_or_negative_frame_count",
            "location": 43,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "frame_sampler": [],
                "frame_count": []
            }
        },
        "TestFrameSampler.test_frame_sampler_generates_sequential_idx": {
            "name": "test_frame_sampler_generates_sequential_idx",
            "location": 50,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "frame_sampler": [
                    "int",
                    "str"
                ],
                "frame_count": [
                    "float",
                    "str"
                ]
            }
        }
    },
    "torchvideo-master/tests/unit/samplers/test_temporal_segment_sampler.py": {
        "TestTemporalSegmentSampler.test_raises_value_error_when_sampling_from_a_video_of_0_frames": {
            "name": "test_raises_value_error_when_sampling_from_a_video_of_0_frames",
            "location": 14,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestTemporalSegmentSampler.test_oversampling_within_a_segment": {
            "name": "test_oversampling_within_a_segment",
            "location": 20,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "test_mode": [
                    "bool"
                ]
            }
        },
        "TestTemporalSegmentSampler.test_oversampling_segments_train": {
            "name": "test_oversampling_segments_train",
            "location": 36,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestTemporalSegmentSampler.test_oversampling_segments_test": {
            "name": "test_oversampling_segments_test",
            "location": 52,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestTemporalSegmentSampler.test_sampling_when_snippets_are_longer_than_segments": {
            "name": "test_sampling_when_snippets_are_longer_than_segments",
            "location": 73,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video_length": [
                    "numpy.ndarray",
                    "List[numpy.ndarray]",
                    "int",
                    "bool"
                ],
                "segment_count": [
                    "numpy.ndarray",
                    "List[numpy.ndarray]",
                    "int",
                    "bool"
                ],
                "snippet_length": [
                    "numpy.ndarray",
                    "List[numpy.ndarray]",
                    "int",
                    "bool"
                ],
                "expected_idx": [
                    "int"
                ]
            }
        },
        "TestTemporalSegmentSampler.test_sampling_snippets_same_length_as_segments": {
            "name": "test_sampling_snippets_same_length_as_segments",
            "location": 84,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video_length": [
                    "List[numpy.ndarray]",
                    "int",
                    "numpy.ndarray",
                    "Iterable[Any]",
                    "float"
                ],
                "segment_count": [
                    "List[numpy.ndarray]",
                    "int",
                    "numpy.ndarray",
                    "Iterable[Any]",
                    "float"
                ],
                "snippet_length": [
                    "List[numpy.ndarray]",
                    "int",
                    "numpy.ndarray",
                    "Iterable[Any]",
                    "float"
                ],
                "expected_idx": []
            }
        },
        "TestTemporalSegmentSampler.test_sampling_in_test_mode_centres_snippets_in_segments": {
            "name": "test_sampling_in_test_mode_centres_snippets_in_segments",
            "location": 103,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video_length": [
                    "bool",
                    "float"
                ],
                "segment_count": [
                    "bool",
                    "float"
                ],
                "snippet_length": [
                    "bool",
                    "float"
                ],
                "expected_idx": [
                    "int"
                ]
            }
        },
        "TestTemporalSegmentSampler.test_sampling_is_random": {
            "name": "test_sampling_is_random",
            "location": 111,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestTemporalSegmentSampler.test_fuzz_sampler_training": {
            "name": "test_fuzz_sampler_training",
            "location": 126,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "data": [
                    "List[List[Any]]",
                    "List[Dict[str, Any]]",
                    "bool"
                ]
            }
        },
        "TestTemporalSegmentSampler.test_fuzz_sampler_test": {
            "name": "test_fuzz_sampler_test",
            "location": 136,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "data": [
                    "List[List[Any]]",
                    "numpy.ndarray",
                    "dict",
                    "numpy.array"
                ]
            }
        },
        "TestTemporalSegmentSampler.test_repr": {
            "name": "test_repr",
            "location": 145,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestTemporalSegmentSampler.test_str": {
            "name": "test_str",
            "location": 151,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestTemporalSegmentSampler.test_segment_length_should_be_greater_than_0": {
            "name": "test_segment_length_should_be_greater_than_0",
            "location": 157,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestTemporalSegmentSampler.test_segment_count_should_be_greater_than_0": {
            "name": "test_segment_count_should_be_greater_than_0",
            "location": 161,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestTemporalSegmentSampler.sample": {
            "name": "sample",
            "location": 165,
            "return": [
                "int",
                "List[str]"
            ],
            "arguments": {
                "self": [],
                "video_length": [
                    "numpy.array",
                    "bool",
                    "List[bytes]"
                ],
                "segment_count": [
                    "List[int]",
                    "Optional[numpy.array]",
                    "str",
                    "int",
                    "bool"
                ],
                "snippet_length": [
                    "List[int]",
                    "Optional[numpy.array]",
                    "str",
                    "int",
                    "bool"
                ],
                "test": [
                    "List[int]",
                    "Optional[numpy.array]",
                    "str",
                    "int",
                    "bool"
                ]
            }
        },
        "TestTemporalSegmentSampler.draw_sampler_parameters": {
            "name": "draw_sampler_parameters",
            "location": 171,
            "return": [
                "int",
                "Optional[str]",
                "str"
            ],
            "arguments": {
                "data": [
                    "bytes",
                    "Dict[str, Any]",
                    "str",
                    "dict"
                ]
            }
        }
    },
    "torchvideo-master/tests/unit/samplers/__init__.py": {},
    "torchvideo-master/tests/unit/tools/test_show_video.py": {
        "TestShowVideo.test_raises_error_if_moviepy_not_available": {
            "name": "test_raises_error_if_moviepy_not_available",
            "location": 20,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestShowVideo.test_uses_ipython_display_if_ipython_is_available": {
            "name": "test_uses_ipython_display_if_ipython_is_available",
            "location": 48,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "monkeypatch": [
                    "Dict[str, Any]"
                ]
            }
        },
        "TestShowVideo.test_fallsback_on_pygame_display": {
            "name": "test_fallsback_on_pygame_display",
            "location": 61,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "monkeypatch": [
                    "Dict[str, Any]"
                ]
            }
        }
    },
    "torchvideo-master/tests/unit/tools/test_to_list_of_np_frames.py": {
        "TestToListOfNpFrames.test_from_ndarray_cthw": {
            "name": "test_from_ndarray_cthw",
            "location": 12,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestToListOfNpFrames.test_from_ndarray_thwc": {
            "name": "test_from_ndarray_thwc",
            "location": 26,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestToListOfNpFrames.test_from_tensor_with_range_0_1": {
            "name": "test_from_tensor_with_range_0_1",
            "location": 37,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestToListOfNpFrames.test_from_list_of_pil_images": {
            "name": "test_from_list_of_pil_images",
            "location": 57,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestToListOfNpFrames.test_raises_error_on_ndarray_formats_other_than_cthw_or_thwc": {
            "name": "test_raises_error_on_ndarray_formats_other_than_cthw_or_thwc",
            "location": 73,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestToListOfNpFrames.test_raises_error_on_unknown_format": {
            "name": "test_raises_error_on_unknown_format",
            "location": 82,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/tools/__init__.py": {},
    "torchvideo-master/tests/unit/transforms/assertions.py": {
        "assert_preserves_label": {
            "name": "assert_preserves_label",
            "location": 1,
            "return": [
                ""
            ],
            "arguments": {
                "transform": [
                    "str",
                    "tuple",
                    "Dict[str, Any]",
                    "bytes",
                    "int"
                ],
                "video": [
                    "str",
                    "tuple",
                    "Dict[str, Any]",
                    "bytes",
                    "int"
                ]
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_center_crop_video.py": {
        "TestCenterCropVideo.test_repr": {
            "name": "test_repr",
            "location": 11,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestCenterCropVideo.test_crop": {
            "name": "test_crop",
            "location": 15,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video": [
                    "int",
                    "str",
                    "List[int]"
                ]
            }
        },
        "TestCenterCropVideo.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 22,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_collect_frames.py": {
        "TestCollectFrames.test_repr": {
            "name": "test_repr",
            "location": 9,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestCollectFrames.test_collect_frames_make_list_from_iterator": {
            "name": "test_collect_frames_make_list_from_iterator",
            "location": 13,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video": []
            }
        },
        "TestCollectFrames.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 17,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_compose.py": {
        "TestCompose.test_calls_frames_only_transforms_sequentially": {
            "name": "test_calls_frames_only_transforms_sequentially",
            "location": 16,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestCompose.test_passes_target_to_supporting_transforms": {
            "name": "test_passes_target_to_supporting_transforms",
            "location": 30,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestCompose.test_raises_error_if_target_is_not_passed_when_a_transform_requires_target": {
            "name": "test_raises_error_if_target_is_not_passed_when_a_transform_requires_target",
            "location": 49,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestCompose.test_single_level_repr": {
            "name": "test_single_level_repr",
            "location": 61,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestCompose.test_nested_repr": {
            "name": "test_nested_repr",
            "location": 65,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestCompose.gen_transforms": {
            "name": "gen_transforms",
            "location": 73,
            "return": [
                "List[int]",
                "Dict[str, int]",
                "List[dict]"
            ],
            "arguments": {
                "self": [],
                "count": [
                    "int",
                    "Callable",
                    "str"
                ]
            }
        },
        "TestCompose.make_result_class": {
            "name": "make_result_class",
            "location": 83,
            "return": [],
            "arguments": {
                "self": [],
                "result_class_name": [
                    "str"
                ]
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_identity_transform.py": {
        "TestIdentityTransform.test_identity_transform_preserves_frames": {
            "name": "test_identity_transform_preserves_frames",
            "location": 8,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestIdentityTransform.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 15,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestIdentityTransform.test_repr": {
            "name": "test_repr",
            "location": 20,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_imports.py": {
        "TestTransformImports.test_importing_center_crop": {
            "name": "test_importing_center_crop",
            "location": 2,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_collect_frames": {
            "name": "test_importing_collect_frames",
            "location": 5,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_compose": {
            "name": "test_importing_compose",
            "location": 8,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_multiscale_crop_video": {
            "name": "test_importing_multiscale_crop_video",
            "location": 11,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_ndarray_to_pil_video": {
            "name": "test_importing_ndarray_to_pil_video",
            "location": 14,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_normalize_video": {
            "name": "test_importing_normalize_video",
            "location": 17,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_pil_video_to_tensor": {
            "name": "test_importing_pil_video_to_tensor",
            "location": 20,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_random_crop_video": {
            "name": "test_importing_random_crop_video",
            "location": 23,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_random_horizontal_flip_video": {
            "name": "test_importing_random_horizontal_flip_video",
            "location": 26,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_resize_video": {
            "name": "test_importing_resize_video",
            "location": 29,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_time_apply": {
            "name": "test_importing_time_apply",
            "location": 32,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_time_to_channel": {
            "name": "test_importing_time_to_channel",
            "location": 35,
            "return": [],
            "arguments": {
                "self": []
            }
        },
        "TestTransformImports.test_importing_random_resized_crop_video": {
            "name": "test_importing_random_resized_crop_video",
            "location": 38,
            "return": [],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_multiscale_crop_video.py": {
        "TestMultiScaleCropVideo.test_transform_always_yields_crops_of_the_correct_size": {
            "name": "test_transform_always_yields_crops_of_the_correct_size",
            "location": 13,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "data": [
                    "bytes",
                    "str"
                ]
            }
        },
        "TestMultiScaleCropVideo.test_repr": {
            "name": "test_repr",
            "location": 54,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestMultiScaleCropVideo.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 72,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_ndarray_to_pil_video.py": {
        "TestNDArrayToPILVideo.test_repr": {
            "name": "test_repr",
            "location": 15,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestNDArrayToPILVideo.test_converts_thwc_to_PIL_video": {
            "name": "test_converts_thwc_to_PIL_video",
            "location": 19,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "shape": [
                    "int"
                ]
            }
        },
        "TestNDArrayToPILVideo.test_converts_cthw_to_PIL_video": {
            "name": "test_converts_cthw_to_PIL_video",
            "location": 32,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "shape": [
                    "int"
                ]
            }
        },
        "TestNDArrayToPILVideo.test_only_thwc_and_cthw_are_valid_formats": {
            "name": "test_only_thwc_and_cthw_are_valid_formats",
            "location": 44,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestNDArrayToPILVideo.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 56,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestNDArrayToPILVideo.make_uint8_ndarray": {
            "name": "make_uint8_ndarray",
            "location": 63,
            "return": [
                "int"
            ],
            "arguments": {
                "shape": [
                    "int",
                    "numpy.ndarray"
                ]
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_normalize_video.py": {
        "TestNormalizeVideo.test_repr": {
            "name": "test_repr",
            "location": 16,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestNormalizeVideo.test_scalar_statistics_smoke": {
            "name": "test_scalar_statistics_smoke",
            "location": 23,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video": [
                    "str",
                    "float"
                ]
            }
        },
        "TestNormalizeVideo.test_vector_statistics_smoke": {
            "name": "test_vector_statistics_smoke",
            "location": 27,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video": [
                    "str",
                    "float"
                ]
            }
        },
        "TestNormalizeVideo.test_raises_value_error_on_0_std": {
            "name": "test_raises_value_error_on_0_std",
            "location": 32,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestNormalizeVideo.test_raises_value_error_on_0_element_in_std_vector": {
            "name": "test_raises_value_error_on_0_element_in_std_vector",
            "location": 36,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestNormalizeVideo.test_raises_value_error_when_length_of_std_and_mean_dont_match": {
            "name": "test_raises_value_error_when_length_of_std_and_mean_dont_match",
            "location": 40,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestNormalizeVideo.test_raises_value_error_when_length_of_mean_is_not_equal_to_channel_count": {
            "name": "test_raises_value_error_when_length_of_mean_is_not_equal_to_channel_count",
            "location": 44,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestNormalizeVideo.test_transform_inplace": {
            "name": "test_transform_inplace",
            "location": 50,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestNormalizeVideo.test_transform_not_inplace": {
            "name": "test_transform_not_inplace",
            "location": 57,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestNormalizeVideo.test_distribution_is_normal_after_transform": {
            "name": "test_distribution_is_normal_after_transform",
            "location": 66,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "ndim": [
                    "bool"
                ],
                "data": [
                    "bool"
                ]
            }
        },
        "TestNormalizeVideo.test_preserves_channel_count": {
            "name": "test_preserves_channel_count",
            "location": 112,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "data": [
                    "str",
                    "bytes",
                    "List[str]",
                    "T",
                    "dict"
                ]
            }
        },
        "TestNormalizeVideo.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 126,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestNormalizeVideo.test_distribution_is_normal_after_transform.samples_from_standard_normal": {
            "name": "samples_from_standard_normal",
            "location": 70,
            "return": [
                "str",
                "Dict[str, int]",
                "int",
                "dict"
            ],
            "arguments": {
                "tensor": [
                    "torch.Tensor",
                    "Any",
                    "str",
                    "bool",
                    "float",
                    "dict"
                ],
                "significance": [
                    "float",
                    "str",
                    "dict"
                ]
            }
        },
        "TestNormalizeVideo.test_distribution_is_normal_after_transform.get_stats": {
            "name": "get_stats",
            "location": 97,
            "return": [
                "str",
                "bool"
            ],
            "arguments": {
                "video": [
                    "torch.Tensor",
                    "int",
                    "float",
                    "List[Set[int]]"
                ],
                "channel_dim": [
                    "Callable"
                ],
                "channel_count": [
                    "int",
                    "str",
                    "float"
                ]
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_pil_video_to_tensor.py": {
        "TestPILVideoToTensor.test_repr": {
            "name": "test_repr",
            "location": 14,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestPILVideoToTensor.test_transform": {
            "name": "test_transform",
            "location": 21,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video": [
                    "numpy.ndarray",
                    "float",
                    "List[numpy.ndarray]"
                ]
            }
        },
        "TestPILVideoToTensor.test_rescales_between_0_and_1": {
            "name": "test_rescales_between_0_and_1",
            "location": 31,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestPILVideoToTensor.test_disabled_rescale": {
            "name": "test_disabled_rescale",
            "location": 41,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestPILVideoToTensor.test_raises_exception_if_ordering_isnt_tchw_or_cthw": {
            "name": "test_raises_exception_if_ordering_isnt_tchw_or_cthw",
            "location": 51,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestPILVideoToTensor.test_mapping_to_tchw_ordering": {
            "name": "test_mapping_to_tchw_ordering",
            "location": 62,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestPILVideoToTensor.test_mapping_to_cthw_ordering": {
            "name": "test_mapping_to_cthw_ordering",
            "location": 77,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestPILVideoToTensor.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 92,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_random_crop_video.py": {
        "TestRandomCropVideo.test_repr": {
            "name": "test_repr",
            "location": 11,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestRandomCropVideo.test_crop_yields_image_of_specified_size": {
            "name": "test_crop_yields_image_of_specified_size",
            "location": 19,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video": [
                    "int",
                    "str"
                ],
                "pad_if_needed": [
                    "int"
                ]
            }
        },
        "TestRandomCropVideo.test_crop_with_user_provided_padding": {
            "name": "test_crop_with_user_provided_padding",
            "location": 31,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video": [
                    "int",
                    "str"
                ],
                "fill": [
                    "random.Random",
                    "int"
                ]
            }
        },
        "TestRandomCropVideo.test_crop_with_different_padding_modes": {
            "name": "test_crop_with_different_padding_modes",
            "location": 44,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video": [
                    "List[int]",
                    "int",
                    "float",
                    "str"
                ],
                "padding_mode": [
                    "int",
                    "str",
                    "Optional[int]"
                ]
            }
        },
        "TestRandomCropVideo.test_propagates_label_unchanges": {
            "name": "test_propagates_label_unchanges",
            "location": 53,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_random_horizontal_flip_video.py": {
        "TestRandomHorizontalFlipVideo.test_repr": {
            "name": "test_repr",
            "location": 10,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestRandomHorizontalFlipVideo.test_always_flip": {
            "name": "test_always_flip",
            "location": 16,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video": []
            }
        },
        "TestRandomHorizontalFlipVideo.test_never_flip": {
            "name": "test_never_flip",
            "location": 26,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video": []
            }
        },
        "TestRandomHorizontalFlipVideo.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 35,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_resize_video.py": {
        "TestResizeVideo.test_resizes_to_given_size": {
            "name": "test_resizes_to_given_size",
            "location": 11,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video": [
                    "int",
                    "List[Dict[str, Any]]",
                    "List[dict]"
                ],
                "interpolation": [
                    "int"
                ],
                "data": [
                    "bytes",
                    "List[List[int]]"
                ]
            }
        },
        "TestResizeVideo.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 24,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_time_apply.py": {
        "TestTimeApply.test_applies_given_transform_for_each_frame": {
            "name": "test_applies_given_transform_for_each_frame",
            "location": 12,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "unittesmock.Mock"
                ]
            }
        },
        "TestTimeApply.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 23,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/test_time_to_channel.py": {
        "prod": {
            "name": "prod",
            "location": 10,
            "return": [
                "bool",
                "torch.Tensor",
                "List[Dict[str, Any]]",
                "List[int]",
                "str"
            ],
            "arguments": {
                "seq": [
                    "str",
                    "bool",
                    "int"
                ]
            }
        },
        "TestTimeToChannel.test_repr": {
            "name": "test_repr",
            "location": 22,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestTimeToChannel.test_reshaping": {
            "name": "test_reshaping",
            "location": 25,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        },
        "TestTimeToChannel.test_raises_value_error_if_tensor_is_not_4d": {
            "name": "test_raises_value_error_if_tensor_is_not_4d",
            "location": 33,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "ndim": [
                    "List[Dict[str, Any]]",
                    "int"
                ]
            }
        },
        "TestTimeToChannel.test_element_count_is_preserved": {
            "name": "test_element_count_is_preserved",
            "location": 38,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "int",
                    "bool",
                    "str"
                ]
            }
        },
        "TestTimeToChannel.test_first_dim_is_always_larger": {
            "name": "test_first_dim_is_always_larger",
            "location": 47,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "frames": [
                    "bool"
                ]
            }
        },
        "TestTimeToChannel.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 52,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/tset_random_resized_crop_video.py": {
        "TestRandomResizedCropVideo.test_resulting_video_are_specified_size": {
            "name": "test_resulting_video_are_specified_size",
            "location": 11,
            "return": [
                ""
            ],
            "arguments": {
                "self": [],
                "video": [
                    "int",
                    "List[Dict[str, Any]]",
                    "List[dict]"
                ],
                "interpolation": [
                    "int"
                ],
                "data": [
                    "bytes",
                    "List[List[int]]"
                ]
            }
        },
        "TestRandomResizedCropVideo.test_propagates_label_unchanged": {
            "name": "test_propagates_label_unchanged",
            "location": 25,
            "return": [
                ""
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "torchvideo-master/tests/unit/transforms/__init__.py": {}
}
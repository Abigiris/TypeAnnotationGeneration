{
    "Multi-Agent-DRL-master/src/agent.py": {
        "Agent.__init__": {
            "name": "__init__",
            "location": 16,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "config": [
                    "list[str]",
                    "str",
                    "bool",
                    "Dict[str, str]",
                    "List[str]",
                    "Dict[str, Any]",
                    "int",
                    "dict"
                ],
                "ckpt_path": [
                    "str",
                    "None",
                    "dict",
                    "Iterable[str]",
                    "dict[, ]"
                ]
            }
        },
        "Agent.learn": {
            "name": "learn",
            "location": 31,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent.remember": {
            "name": "remember",
            "location": 34,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "bool",
                    "Optional[float]",
                    "float",
                    "Iterable[Any]",
                    "None",
                    "Iterable[float]",
                    "typing.Iterable[typing.Any]",
                    "int",
                    "typing.Iterable[float]",
                    "Hashable",
                    "typing.Hashable"
                ],
                "action": [
                    "bool",
                    "Optional[float]",
                    "float",
                    "Iterable[Any]",
                    "None",
                    "Iterable[float]",
                    "typing.Iterable[typing.Any]",
                    "int",
                    "typing.Iterable[float]",
                    "Hashable",
                    "typing.Hashable"
                ],
                "reward": [
                    "bool",
                    "Optional[float]",
                    "float",
                    "Iterable[Any]",
                    "None",
                    "Iterable[float]",
                    "typing.Iterable[typing.Any]",
                    "int",
                    "typing.Iterable[float]",
                    "Hashable",
                    "typing.Hashable"
                ],
                "next_state": [
                    "bool",
                    "Optional[float]",
                    "float",
                    "Iterable[Any]",
                    "None",
                    "Iterable[float]",
                    "typing.Iterable[typing.Any]",
                    "int",
                    "typing.Iterable[float]",
                    "Hashable",
                    "typing.Hashable"
                ]
            }
        },
        "Agent.act": {
            "name": "act",
            "location": 37,
            "return": [
                "int",
                "Callable",
                "dict[str, list[str]]",
                "str",
                "dict[, ]"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "bool",
                    "str",
                    "dict",
                    "dict[, ]"
                ],
                "epsilon": [
                    "int",
                    "str",
                    "numpy.array",
                    "List[List[Any]]",
                    "List[List[str]]",
                    "Dict[str, float]"
                ]
            }
        },
        "Agent.close": {
            "name": "close",
            "location": 55,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "save_model_path": [
                    "str",
                    "None"
                ]
            }
        }
    },
    "Multi-Agent-DRL-master/src/cpr_environment.py": {
        "CPREnvironment.__init__": {
            "name": "__init__",
            "location": 10,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "conf": [
                    "int",
                    "bool",
                    "float"
                ]
            }
        },
        "CPREnvironment.growth": {
            "name": "growth",
            "location": 21,
            "return": [
                "str",
                "int",
                "float"
            ],
            "arguments": {
                "self": [],
                "N": [
                    "int"
                ]
            }
        },
        "CPREnvironment.harvest": {
            "name": "harvest",
            "location": 24,
            "return": [
                "float",
                "str",
                "Callable",
                "Optional[int]"
            ],
            "arguments": {
                "self": [],
                "x": [
                    "bool",
                    "float",
                    "int",
                    "list[list[]]",
                    "List[list]"
                ],
                "N": [
                    "bool",
                    "float",
                    "int",
                    "List[list]"
                ]
            }
        },
        "CPREnvironment.reward": {
            "name": "reward",
            "location": 28,
            "return": [
                "list"
            ],
            "arguments": {
                "self": [],
                "delta_n": [
                    "int",
                    "typing.Iterable[T]",
                    "bool",
                    "Iterable[T]"
                ],
                "pis": [
                    "int",
                    "typing.Iterable[T]",
                    "bool",
                    "Iterable[T]"
                ]
            }
        },
        "CPREnvironment.step": {
            "name": "step",
            "location": 37,
            "return": [
                "Tuple[(List[list], Any, bool)]"
            ],
            "arguments": {
                "self": [],
                "xs": [
                    "list",
                    "list[]"
                ]
            }
        },
        "CPREnvironment.reset": {
            "name": "reset",
            "location": 55,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "CPREnvironment.reward.step_func": {
            "name": "step_func",
            "location": 29,
            "return": [
                "str",
                "int"
            ],
            "arguments": {
                "x": [
                    "str",
                    "bool",
                    "Sequence",
                    "Dict[str, Any]",
                    "T"
                ]
            }
        }
    },
    "Multi-Agent-DRL-master/src/helper.py": {
        "save_result": {
            "name": "save_result",
            "location": 4,
            "return": [
                "None"
            ],
            "arguments": {
                "result_dict": [
                    "str",
                    "dict",
                    "Dict[int, str]",
                    "Exception",
                    "Mapping[int, str]"
                ],
                "save_path": [
                    "str"
                ]
            }
        }
    },
    "Multi-Agent-DRL-master/src/main.py": {
        "main": {
            "name": "main",
            "location": 14,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "Multi-Agent-DRL-master/src/step_counter.py": {
        "StepCounter.__init__": {
            "name": "__init__",
            "location": 2,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "StepCounter.reset": {
            "name": "reset",
            "location": 5,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "StepCounter.start": {
            "name": "start",
            "location": 8,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "Multi-Agent-DRL-master/src/model/base_model.py": {
        "BaseModel.__init__": {
            "name": "__init__",
            "location": 6,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "model_id": [
                    "str",
                    "int"
                ],
                "config": [
                    "str",
                    "bool",
                    "Optional[Iterable[str]]",
                    "Mapping[str, Any]",
                    "Dict[str, Any]"
                ],
                "ckpt_path": [
                    "str",
                    "bool",
                    "Dict[str, str]",
                    "dict[str, str]"
                ]
            }
        },
        "BaseModel._build_graph": {
            "name": "_build_graph",
            "location": 44,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "BaseModel.fit": {
            "name": "fit",
            "location": 51,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "BaseModel.predict": {
            "name": "predict",
            "location": 58,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "str"
                ],
                "epsilon": [
                    "str"
                ]
            }
        },
        "BaseModel.save_transition": {
            "name": "save_transition",
            "location": 62,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "Callable",
                    "typing.Callable[, ]"
                ],
                "action": [
                    "int",
                    "Callable",
                    "typing.Callable[, ]"
                ],
                "reward": [
                    "int",
                    "Callable",
                    "typing.Callable[, ]"
                ],
                "next_state": [
                    "int",
                    "Callable",
                    "typing.Callable[, ]"
                ]
            }
        },
        "BaseModel.save_model": {
            "name": "save_model",
            "location": 65,
            "return": [
                "str",
                "Tuple[str, str]"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "BaseModel.close": {
            "name": "close",
            "location": 71,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "Multi-Agent-DRL-master/src/model/ddpg.py": {
        "DDPGModel.__init__": {
            "name": "__init__",
            "location": 19,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "aid": [],
                "config": [],
                "ckpt_path": []
            }
        },
        "DDPGModel._build_graph": {
            "name": "_build_graph",
            "location": 36,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGModel.__build_actor_nn": {
            "name": "__build_actor_nn",
            "location": 119,
            "return": [],
            "arguments": {
                "self": [],
                "state": [],
                "scope": [],
                "phase": [],
                "trainable": [
                    "bool"
                ]
            }
        },
        "DDPGModel.__build_critic": {
            "name": "__build_critic",
            "location": 166,
            "return": [],
            "arguments": {
                "state": [],
                "action": [],
                "scope": [],
                "phase": [],
                "trainable": [
                    "bool"
                ]
            }
        },
        "DDPGModel.save_transition": {
            "name": "save_transition",
            "location": 205,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [],
                "action": [],
                "reward": [],
                "state_next": []
            }
        },
        "DDPGModel.get_sample_batch": {
            "name": "get_sample_batch",
            "location": 211,
            "return": [
                "Tuple[(Any, Any, Any, Any)]"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGModel.fit": {
            "name": "fit",
            "location": 228,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGModel.predict": {
            "name": "predict",
            "location": 244,
            "return": [],
            "arguments": {
                "self": [],
                "state": [],
                "epsilon": []
            }
        }
    },
    "Multi-Agent-DRL-master/src/model/dqn.py": {
        "DQNModel.__init__": {
            "name": "__init__",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "aid": [
                    "str",
                    "float",
                    "Optional[str]",
                    "None"
                ],
                "config": [
                    "Dict[str, Any]",
                    "str",
                    "dict[str, typing.Any]",
                    "Optional[Dict[str, Any]]",
                    "None"
                ],
                "ckpt_path": [
                    "str",
                    "float",
                    "Optional[str]",
                    "None"
                ]
            }
        },
        "DQNModel._build_graph": {
            "name": "_build_graph",
            "location": 27,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQNModel.fit": {
            "name": "fit",
            "location": 164,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQNModel.save_transition": {
            "name": "save_transition",
            "location": 198,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "float",
                    "numpy.array",
                    "list[str]",
                    "None",
                    "List[str]",
                    "Optional[float]"
                ],
                "action": [
                    "float",
                    "numpy.array",
                    "list[str]",
                    "None",
                    "List[str]",
                    "Optional[float]"
                ],
                "reward": [
                    "float",
                    "numpy.array",
                    "list[str]",
                    "None",
                    "List[str]",
                    "Optional[float]"
                ],
                "state_next": [
                    "float",
                    "numpy.array",
                    "list[str]",
                    "None",
                    "List[str]",
                    "Optional[float]"
                ]
            }
        },
        "DQNModel.update_q": {
            "name": "update_q",
            "location": 207,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQNModel.predict": {
            "name": "predict",
            "location": 213,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "str",
                    "List[str]",
                    "list[str]"
                ],
                "epsilon": [
                    "float",
                    "list[list[int]]",
                    "int",
                    "List[List[int]]",
                    "list[int]",
                    "numpy.ndarray",
                    "List[int]"
                ]
            }
        }
    },
    "Multi-Agent-DRL-master/src/model/drqn_agent.py": {
        "DRQNAgent.__init__": {
            "name": "__init__",
            "location": 22,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "name": [
                    "str",
                    "tensorflow.Tensor"
                ],
                "opt": [
                    "str",
                    "Optional[str]",
                    "None"
                ],
                "learning_mode": [
                    "bool",
                    "str",
                    "tensorflow.Tensor"
                ]
            }
        },
        "DRQNAgent._build_model": {
            "name": "_build_model",
            "location": 29,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DRQNAgent.update_q": {
            "name": "update_q",
            "location": 114,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DRQNAgent.learn": {
            "name": "learn",
            "location": 120,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "global_step": [
                    "int",
                    "str",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        },
        "DRQNAgent.choose_action": {
            "name": "choose_action",
            "location": 148,
            "return": [
                "int",
                "bool"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "str"
                ]
            }
        },
        "DRQNAgent.save_transition": {
            "name": "save_transition",
            "location": 158,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "step": [
                    "int",
                    "Sequence[Any]",
                    "typing.Sequence[typing.Any]"
                ],
                "state": [
                    "bool",
                    "int"
                ],
                "action": [
                    "bool",
                    "int"
                ],
                "reward": [
                    "bool",
                    "int"
                ],
                "done": [
                    "bool",
                    "str",
                    "Dict[str, int]",
                    "dict[str, int]"
                ]
            }
        }
    },
    "Multi-Agent-DRL-master/src/model/model_factory.py": {
        "ModelFactory.__init__": {
            "name": "__init__",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "uid": [
                    "str",
                    "dict",
                    "bytes",
                    "dict[, ]",
                    "Union[Dict, List]",
                    "list[]",
                    "Dict[int, Dict[int, Any]]",
                    "dict[int, dict[int, typing.Any]]"
                ],
                "config": [
                    "Dict[str, Any]",
                    "str",
                    "dict[str, typing.Any]",
                    "bool",
                    "Dict[str, str]",
                    "dict[str, str]",
                    "Optional[str]",
                    "None"
                ],
                "ckpt_path": [
                    "str"
                ]
            }
        },
        "ModelFactory.get_model": {
            "name": "get_model",
            "location": 12,
            "return": [
                "model.base_model.BaseModel"
            ],
            "arguments": {
                "self": [],
                "model_type": [
                    "str"
                ]
            }
        }
    },
    "Multi-Agent-DRL-master/src/model/rdpg_agent.py": {
        "RDPGAgent.__init__": {
            "name": "__init__",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "name": [],
                "opt": [],
                "learning_mode": [
                    "bool"
                ]
            }
        },
        "RDPGAgent._build_model": {
            "name": "_build_model",
            "location": 26,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "RDPGAgent.__build_actor_nn": {
            "name": "__build_actor_nn",
            "location": 63,
            "return": [],
            "arguments": {
                "self": [],
                "state": [],
                "scope": [],
                "trainable": [
                    "bool"
                ]
            }
        },
        "RDPGAgent.__build_critic": {
            "name": "__build_critic",
            "location": 99,
            "return": [],
            "arguments": {
                "self": [],
                "state": [],
                "action": [],
                "scope": [],
                "trainable": [
                    "bool"
                ]
            }
        },
        "RDPGAgent.save_transition": {
            "name": "save_transition",
            "location": 131,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "states": [],
                "actions": [],
                "rewards": []
            }
        },
        "RDPGAgent.get_sample_batch": {
            "name": "get_sample_batch",
            "location": 140,
            "return": [
                "Tuple[(Any, Any, Any, Any)]"
            ],
            "arguments": {
                "self": []
            }
        },
        "RDPGAgent.learn": {
            "name": "learn",
            "location": 149,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "global_step": []
            }
        },
        "RDPGAgent.choose_action": {
            "name": "choose_action",
            "location": 163,
            "return": [],
            "arguments": {
                "self": [],
                "state": [],
                "action_upper_bound": []
            }
        }
    },
    "Multi-Agent-DRL-master/src/model/__init__.py": {}
}
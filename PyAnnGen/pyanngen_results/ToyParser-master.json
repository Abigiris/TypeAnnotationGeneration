{
    "ToyParser-master/minicompiler.py": {
        "cli": {
            "name": "cli",
            "location": 8,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "scanner": {
            "name": "scanner",
            "location": 14,
            "return": [
                "None"
            ],
            "arguments": {
                "input_string": [
                    "str"
                ]
            }
        },
        "parser": {
            "name": "parser",
            "location": 24,
            "return": [
                "None"
            ],
            "arguments": {
                "input_string": [
                    "str",
                    "Optional[str]",
                    "None"
                ]
            }
        }
    },
    "ToyParser-master/test_lexer.py": {
        "assert_tokenize": {
            "name": "assert_tokenize",
            "location": 6,
            "return": [
                "None"
            ],
            "arguments": {
                "token_list": [
                    "str",
                    "List[lexer.Token]",
                    "List[str]",
                    "List[Tuple[str,str]]",
                    "List[tuple[Union[str,str]]]"
                ],
                "input_string": [
                    "str",
                    "List[lexer.Token]",
                    "List[str]",
                    "List[Tuple[str,str]]",
                    "List[tuple[Union[str,str]]]"
                ]
            }
        },
        "test_sum": {
            "name": "test_sum",
            "location": 10,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_long_token": {
            "name": "test_long_token",
            "location": 32,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_invalid_variable": {
            "name": "test_invalid_variable",
            "location": 54,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_invalid_number": {
            "name": "test_invalid_number",
            "location": 60,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_nested_expression": {
            "name": "test_nested_expression",
            "location": 66,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_incomplete_variable": {
            "name": "test_incomplete_variable",
            "location": 100,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_expression_with_variables": {
            "name": "test_expression_with_variables",
            "location": 106,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_white_spaces": {
            "name": "test_white_spaces",
            "location": 128,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_no_floating_point_numbers": {
            "name": "test_no_floating_point_numbers",
            "location": 138,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_no_white_spaces_expression": {
            "name": "test_no_white_spaces_expression",
            "location": 144,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "ToyParser-master/test_parser.py": {
        "test_basic_expression": {
            "name": "test_basic_expression",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_nested_expression": {
            "name": "test_nested_expression",
            "location": 28,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_incomplete_expression": {
            "name": "test_incomplete_expression",
            "location": 61,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_bad_expression": {
            "name": "test_bad_expression",
            "location": 80,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "test_consume_all": {
            "name": "test_consume_all",
            "location": 102,
            "return": [
                "None"
            ],
            "arguments": {}
        }
    },
    "ToyParser-master/lexer/exceptions.py": {
        "InvalidTokenException.__init__": {
            "name": "__init__",
            "location": 2,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "token": [
                    "str",
                    "bool"
                ]
            }
        }
    },
    "ToyParser-master/lexer/lexer.py": {
        "convert_character": {
            "name": "convert_character",
            "location": 64,
            "return": [
                "str",
                "Set[int]",
                "List[str]",
                "Dict",
                "int",
                "bytes"
            ],
            "arguments": {
                "s": [
                    "str",
                    "Set[int]",
                    "Dict"
                ]
            }
        },
        "token_or_exception": {
            "name": "token_or_exception",
            "location": 74,
            "return": [
                "Token"
            ],
            "arguments": {
                "state": [
                    "str",
                    "bytes",
                    "List[List[str]]",
                    "List[str]",
                    "List[list[str]]"
                ],
                "token": [
                    "str",
                    "bytes"
                ]
            }
        },
        "tokenize_helper": {
            "name": "tokenize_helper",
            "location": 80,
            "return": [
                "Generator[(Token, Any, None)]"
            ],
            "arguments": {
                "automata": [
                    "str",
                    "bool",
                    "Mapping[str,Any]",
                    "Mapping"
                ],
                "text": [
                    "str",
                    "bool"
                ]
            }
        },
        "Token.__str__": {
            "name": "__str__",
            "location": 33,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "ToyParser-master/lexer/utils.py": {
        "is_digit": {
            "name": "is_digit",
            "location": 4,
            "return": [
                "bool"
            ],
            "arguments": {
                "s": [
                    "str"
                ]
            }
        },
        "is_operator": {
            "name": "is_operator",
            "location": 12,
            "return": [
                "bool"
            ],
            "arguments": {
                "s": [
                    "str"
                ]
            }
        },
        "is_letter": {
            "name": "is_letter",
            "location": 19,
            "return": [
                "bool"
            ],
            "arguments": {
                "s": [
                    "str",
                    "Set[int]",
                    "bytes",
                    "bool",
                    "float",
                    "Optional[str]",
                    "None"
                ]
            }
        }
    },
    "ToyParser-master/lexer/__init__.py": {},
    "ToyParser-master/parser/exceptions.py": {
        "IncorrectTokenException.__init__": {
            "name": "__init__",
            "location": 10,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "token": [
                    "Iterable[str]",
                    "Callable",
                    "lexer.Token",
                    "bytes",
                    "tokens.Token"
                ]
            }
        }
    },
    "ToyParser-master/parser/parser.py": {
        "consume_token": {
            "name": "consume_token",
            "location": 11,
            "return": [
                "None"
            ],
            "arguments": {
                "token_type": [
                    "str",
                    "Optional[str]",
                    "None"
                ],
                "token_list": [
                    "str",
                    "bytes"
                ]
            }
        },
        "parse_expression": {
            "name": "parse_expression",
            "location": 26,
            "return": [
                "None"
            ],
            "arguments": {
                "token_list": [
                    "str",
                    "Dict",
                    "Iterable[T]"
                ]
            }
        },
        "parse_full_expression": {
            "name": "parse_full_expression",
            "location": 36,
            "return": [
                "None"
            ],
            "arguments": {
                "token_list": [
                    "List[T]",
                    "Atom",
                    "List[D]",
                    "List[DictDataLoader]"
                ]
            }
        },
        "parse": {
            "name": "parse",
            "location": 47,
            "return": [
                "None"
            ],
            "arguments": {
                "token_list": [
                    "str",
                    "bool",
                    "list",
                    "Sequence[T]"
                ]
            }
        }
    },
    "ToyParser-master/parser/__init__.py": {}
}
{
    "nlp-toolkit-master/setup.py": {},
    "nlp-toolkit-master/nlp_toolkit/__init__.py": {},
    "nlp-toolkit-master/nlp_toolkit/tools/farasa.py": {
        "Farasa.__new__": {
            "name": "__new__",
            "location": 49,
            "return": [
                "Farasa"
            ],
            "arguments": {
                "cls": [
                    "Type[_TFarasa]"
                ],
                "singelton": [
                    "bool"
                ]
            }
        },
        "Farasa.__init__": {
            "name": "__init__",
            "location": 61,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "singelton": [
                    "bool"
                ]
            }
        },
        "Farasa.tag_pos": {
            "name": "tag_pos",
            "location": 87,
            "return": [
                "list[tuple[]]",
                "dict",
                "str",
                "Dict[str, Any]"
            ],
            "arguments": {
                "self": [],
                "text": [
                    "str"
                ]
            }
        },
        "Farasa.merge_iffix": {
            "name": "merge_iffix",
            "location": 107,
            "return": [
                "_T0"
            ],
            "arguments": {
                "self": [],
                "tags": [
                    "_T0"
                ]
            }
        },
        "Farasa.filter_pos": {
            "name": "filter_pos",
            "location": 125,
            "return": [
                "str",
                "Dict[str, int]",
                "bool",
                "Generator",
                "float"
            ],
            "arguments": {
                "self": [],
                "text": [
                    "str",
                    "bool",
                    "Type[BaseException]",
                    "typing.Type",
                    "Sequence[str]",
                    "typing.Sequence[str]"
                ],
                "parts_of_speech_to_keep": [
                    "str",
                    "int",
                    "bool"
                ]
            }
        },
        "Farasa.lemmetize": {
            "name": "lemmetize",
            "location": 149,
            "return": [
                "str",
                "int",
                "Generator"
            ],
            "arguments": {
                "self": [],
                "text": [
                    "str"
                ]
            }
        },
        "Farasa.segment": {
            "name": "segment",
            "location": 160,
            "return": [
                "cmk.utils.type_defs.ServiceName",
                "cmk.utils.type_defs.HostName",
                "bool",
                "logging.LogRecord"
            ],
            "arguments": {
                "self": [],
                "text": [
                    "str"
                ]
            }
        },
        "Farasa._get_named_entities": {
            "name": "_get_named_entities",
            "location": 173,
            "return": [
                "str",
                "Optional[str]",
                "Callable[[], Any]",
                "List[str]",
                "Dict[str, str]"
            ],
            "arguments": {
                "self": [],
                "text": [
                    "str"
                ],
                "lemmatize": [
                    "bool",
                    "str"
                ]
            }
        },
        "Farasa.get_named_entities": {
            "name": "get_named_entities",
            "location": 216,
            "return": [
                "List[Tuple[(str, str)]]"
            ],
            "arguments": {
                "self": [],
                "text": [
                    "str"
                ],
                "lemmatize": [
                    "bool"
                ]
            }
        },
        "Farasa.diacritize": {
            "name": "diacritize",
            "location": 228,
            "return": [
                "str"
            ],
            "arguments": {
                "self": [],
                "text": [
                    "str"
                ],
                "keep_original_diacritics": [
                    "str",
                    "bool"
                ]
            }
        },
        "Farasa.__launch_java_gateway": {
            "name": "__launch_java_gateway",
            "location": 239,
            "return": [
                "JavaGateway",
                "recidiviz.utils.regions.Region",
                "str",
                "int",
                "cmk.utils.type_defs.HostName"
            ],
            "arguments": {
                "cls": [
                    "List[str]",
                    "bool",
                    "list[str]",
                    "Type[object]",
                    "typing.Type"
                ]
            }
        }
    },
    "nlp-toolkit-master/nlp_toolkit/tools/similarity.py": {
        "WMDSimilarityClustering.__init__": {
            "name": "__init__",
            "location": 29,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "stop_words": [
                    "Set[str]"
                ],
                "word_embeddings": [
                    "nlp_toolkit.tools.word_embedding.WordEmbedding"
                ]
            }
        },
        "WMDSimilarityClustering.preprocess_document": {
            "name": "preprocess_document",
            "location": 39,
            "return": [
                "str"
            ],
            "arguments": {
                "self": [],
                "document": [
                    "str"
                ]
            }
        },
        "WMDSimilarityClustering.preprocess_documents": {
            "name": "preprocess_documents",
            "location": 52,
            "return": [
                "Generator[(str, None, None)]"
            ],
            "arguments": {
                "self": [],
                "documents": [
                    "Sequence[str]"
                ]
            }
        },
        "WMDSimilarityClustering.tokenize": {
            "name": "tokenize",
            "location": 70,
            "return": [
                "List[str]"
            ],
            "arguments": {
                "self": [],
                "document": [
                    "str"
                ]
            }
        },
        "WMDSimilarityClustering.fit": {
            "name": "fit",
            "location": 81,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "documents": [
                    "Sequence[str]"
                ],
                "preprocess": [
                    "bool"
                ]
            }
        }
    },
    "nlp-toolkit-master/nlp_toolkit/tools/summarization.py": {
        "summarize": {
            "name": "summarize",
            "location": 16,
            "return": [
                "str"
            ],
            "arguments": {
                "text": [
                    "str"
                ],
                "ratio": [
                    "str"
                ]
            }
        },
        "extract_keywords": {
            "name": "extract_keywords",
            "location": 35,
            "return": [
                "List[str]"
            ],
            "arguments": {
                "text": [
                    "str"
                ],
                "pos_filter": [
                    "List[str]"
                ],
                "top_n": [
                    "int"
                ]
            }
        },
        "extract_entities": {
            "name": "extract_entities",
            "location": 52,
            "return": [
                "List[Tuple[(str, str)]]"
            ],
            "arguments": {
                "text": [
                    "str"
                ]
            }
        }
    },
    "nlp-toolkit-master/nlp_toolkit/tools/topic_model.py": {
        "load_topic_model": {
            "name": "load_topic_model",
            "location": 29,
            "return": [
                "GPy.models.GPRegression",
                "allennlp.models.model.Model"
            ],
            "arguments": {
                "model_id": [
                    "str",
                    "int"
                ]
            }
        },
        "infer_topic": {
            "name": "infer_topic",
            "location": 49,
            "return": [
                "str",
                "float",
                "Dict[str, Dict[str, int]]",
                "bool"
            ],
            "arguments": {
                "model_id": [
                    "int"
                ],
                "document": [
                    "str"
                ]
            }
        },
        "TopicModel.__init__": {
            "name": "__init__",
            "location": 61,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "pos_to_use": [
                    "List[str]"
                ],
                "stop_words": [
                    "Union[(str, List[str], Set[str])]"
                ],
                "min_df": [
                    "float"
                ],
                "max_df": [
                    "float"
                ],
                "num_workers": [
                    "int"
                ]
            }
        },
        "TopicModel._init_pool": {
            "name": "_init_pool",
            "location": 107,
            "return": [
                "None"
            ],
            "arguments": {}
        },
        "TopicModel.preprocess_document": {
            "name": "preprocess_document",
            "location": 116,
            "return": [
                "str"
            ],
            "arguments": {
                "self": [],
                "document": [
                    "str"
                ]
            }
        },
        "TopicModel._unit_of_work": {
            "name": "_unit_of_work",
            "location": 129,
            "return": [
                "str"
            ],
            "arguments": {
                "self": [],
                "pos_to_use": [
                    "List[str]"
                ],
                "document": [
                    "str"
                ]
            }
        },
        "TopicModel.preprocess_documents": {
            "name": "preprocess_documents",
            "location": 143,
            "return": [
                "Generator[(str, None, None)]"
            ],
            "arguments": {
                "self": [],
                "documents": [
                    "Sequence[str]"
                ]
            }
        },
        "TopicModel.tokenize": {
            "name": "tokenize",
            "location": 173,
            "return": [
                "List[str]"
            ],
            "arguments": {
                "self": [],
                "document": [
                    "str"
                ]
            }
        },
        "TopicModel.create_trigrams": {
            "name": "create_trigrams",
            "location": 184,
            "return": [
                "List[str]"
            ],
            "arguments": {
                "self": [],
                "tokens": [
                    "List[str]"
                ]
            }
        },
        "TopicModel.build_vocab": {
            "name": "build_vocab",
            "location": 196,
            "return": [
                "Tuple[(List[List[str]], dict)]"
            ],
            "arguments": {
                "self": [],
                "documents_tokens": [
                    "List[List[str]]"
                ]
            }
        },
        "TopicModel.fit": {
            "name": "fit",
            "location": 235,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "documents": [
                    "Sequence[str]"
                ],
                "preprocess": [
                    "bool"
                ],
                "passes": [
                    "int"
                ],
                "random_state": [
                    "int"
                ],
                "num_topics": [
                    "int"
                ],
                "chunksize": [
                    "int"
                ]
            }
        },
        "TopicModel.predict": {
            "name": "predict",
            "location": 268,
            "return": [
                "int",
                "Set[cmk.utils.type_defs.HostName]",
                "bytes",
                "dict",
                "Optional[float]",
                "str"
            ],
            "arguments": {
                "self": [],
                "document": [
                    "bool",
                    "Optional[str]",
                    "str",
                    "int",
                    "None",
                    "Tuple[int, int]",
                    "tuple[typing.Union[int,int]]"
                ],
                "topics_map": [
                    "Tuple[float, float, float, float]",
                    "float",
                    "tuple[typing.Union[float,float,float,float]]",
                    "bytes",
                    "Optional[List[Any]]",
                    "list[typing.Any]",
                    "None"
                ],
                "num_topics": [
                    "bool",
                    "typing.Callable[, ]",
                    "str",
                    "int",
                    "list[str]",
                    "Callable",
                    "List[str]"
                ]
            }
        },
        "TopicModel.load": {
            "name": "load",
            "location": 301,
            "return": [
                "TopicModel"
            ],
            "arguments": {
                "path": [
                    "str"
                ]
            }
        },
        "TopicModel.save": {
            "name": "save",
            "location": 309,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        }
    },
    "nlp-toolkit-master/nlp_toolkit/tools/utils.py": {
        "remove_extra_spaces": {
            "name": "remove_extra_spaces",
            "location": 46,
            "return": [
                "str"
            ],
            "arguments": {
                "text": [
                    "str"
                ]
            }
        },
        "_preprocess_arabic_text": {
            "name": "_preprocess_arabic_text",
            "location": 58,
            "return": [
                "str"
            ],
            "arguments": {
                "text": [],
                "remove_non_arabic": [
                    "bool"
                ],
                "remove_punctuation": [
                    "bool"
                ],
                "remove_numbers": [
                    "bool"
                ],
                "remove_emails_urls_html": [
                    "bool"
                ],
                "remove_hashtags_mentions": [
                    "bool"
                ]
            }
        },
        "preprorcess_arabic_text": {
            "name": "preprorcess_arabic_text",
            "location": 128,
            "return": [],
            "arguments": {}
        },
        "setup_logger": {
            "name": "setup_logger",
            "location": 145,
            "return": [
                "logging.Logger"
            ],
            "arguments": {
                "name": [
                    "str"
                ],
                "level": []
            }
        },
        "load_stop_words": {
            "name": "load_stop_words",
            "location": 171,
            "return": [
                "List[str]"
            ],
            "arguments": {
                "filename": [
                    "str"
                ]
            }
        },
        "preprorcess_arabic_text.wrapper": {
            "name": "wrapper",
            "location": 131,
            "return": [],
            "arguments": {
                "wrapped": [],
                "instance": [],
                "args": [],
                "kwargs": []
            }
        }
    },
    "nlp-toolkit-master/nlp_toolkit/tools/word_embedding.py": {
        "WordEmbedding.__init__": {
            "name": "__init__",
            "location": 13,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ]
            }
        },
        "WordEmbedding.get_word_vector": {
            "name": "get_word_vector",
            "location": 21,
            "return": [
                "Optional[numpy.ndarray]"
            ],
            "arguments": {
                "self": [],
                "word": [
                    "str"
                ]
            }
        },
        "WordEmbedding.create_ngrams": {
            "name": "create_ngrams",
            "location": 29,
            "return": [
                "Generator[(str, None, None)]"
            ],
            "arguments": {
                "self": [],
                "tokens": [
                    "List[str]"
                ],
                "nrange": [
                    "Tuple[(int, int)]"
                ]
            }
        },
        "WordEmbedding.create_valid_trigrams": {
            "name": "create_valid_trigrams",
            "location": 40,
            "return": [
                "Generator[(str, None, None)]"
            ],
            "arguments": {
                "self": [],
                "text": [
                    "str"
                ]
            }
        },
        "WordEmbedding.encode_document": {
            "name": "encode_document",
            "location": 62,
            "return": [
                "Generator[(numpy.ndarray, None, None)]"
            ],
            "arguments": {
                "self": [],
                "text": [
                    "str"
                ]
            }
        },
        "WordEmbedding.get_distance": {
            "name": "get_distance",
            "location": 72,
            "return": [
                "float"
            ],
            "arguments": {
                "self": [],
                "document1": [
                    "List[str]"
                ],
                "document2": [
                    "List[str]"
                ]
            }
        }
    },
    "nlp-toolkit-master/nlp_toolkit/tools/__init__.py": {}
}
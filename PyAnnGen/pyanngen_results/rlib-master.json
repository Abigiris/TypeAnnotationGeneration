{
    "rlib-master/setup.py": {},
    "rlib-master/docs/conf.py": {},
    "rlib-master/rlib/__init__.py": {},
    "rlib-master/rlib/algorithms/base.py": {
        "Agent.__init__": {
            "name": "__init__",
            "location": 16,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent.origin": {
            "name": "origin",
            "location": 28,
            "return": [
                "",
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent.description": {
            "name": "description",
            "location": 32,
            "return": [
                "",
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent.reset": {
            "name": "reset",
            "location": 35,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent.act": {
            "name": "act",
            "location": 40,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "bool",
                    "Set[str]",
                    "set[str]",
                    "Optional[str]",
                    "str",
                    "Dict[str, object]",
                    "None",
                    "Optional[IO[bytes]]",
                    "dict[str, object]",
                    "typing.IO"
                ],
                "add_noise": [
                    "bool",
                    "Set[str]",
                    "Optional[str]",
                    "Dict[str, object]",
                    "Optional[IO[bytes]]"
                ],
                "logger": [
                    "bool",
                    "None",
                    "Set[str]",
                    "Optional[str]",
                    "set[str]",
                    "Dict[str, object]",
                    "str",
                    "Optional[IO[bytes]]",
                    "dict[str, object]",
                    "typing.IO"
                ]
            }
        },
        "Agent.step": {
            "name": "step",
            "location": 44,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "bool",
                    "List[Callable]",
                    "list[typing.Callable[, ]]"
                ],
                "action": [
                    "bool",
                    "List[Callable]",
                    "list[typing.Callable[, ]]"
                ],
                "reward": [
                    "bool",
                    "List[Callable]",
                    "list[typing.Callable[, ]]"
                ],
                "next_state": [
                    "bool",
                    "List[Callable]",
                    "list[typing.Callable[, ]]"
                ],
                "done": [
                    "bool",
                    "List[Callable]",
                    "list[typing.Callable[, ]]"
                ],
                "logger": [
                    "bool",
                    "None",
                    "List[Callable]",
                    "list[typing.Callable[, ]]"
                ]
            }
        },
        "Agent.learn": {
            "name": "learn",
            "location": 48,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "experiences": [
                    "Iterable[str]",
                    "int",
                    "typing.Iterable[str]",
                    "str",
                    "Callable[[str], None]",
                    "typing.Callable[str, None]"
                ],
                "logger": [
                    "Iterable[str]",
                    "None",
                    "int",
                    "str",
                    "typing.Iterable[str]",
                    "Callable[[str], None]",
                    "typing.Callable[str, None]"
                ]
            }
        },
        "Agent.update": {
            "name": "update",
            "location": 52,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "rewards": [
                    "int",
                    "str",
                    "None",
                    "Optional[bool]",
                    "bool"
                ],
                "logger": [
                    "int",
                    "None",
                    "str",
                    "Optional[bool]",
                    "bool"
                ]
            }
        },
        "Agent.get_hyperparameters": {
            "name": "get_hyperparameters",
            "location": 56,
            "return": [
                "dict"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent._set_hyperparameters": {
            "name": "_set_hyperparameters",
            "location": 64,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "new_hyperparameters": [
                    "dict[str, set[str]]",
                    "dict[, ]",
                    "Dict[str, Set[str]]",
                    "Dict[str, Any]",
                    "Iterable[T]",
                    "dict",
                    "Sequence"
                ]
            }
        },
        "Agent.save_state_dicts": {
            "name": "save_state_dicts",
            "location": 74,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Agent.load_state_dicts": {
            "name": "load_state_dicts",
            "location": 85,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/algorithms/__init__.py": {},
    "rlib-master/rlib/algorithms/a2c/agent.py": {
        "A2CAgent.__init__": {
            "name": "__init__",
            "location": 15,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/algorithms/a2c/__init__.py": {},
    "rlib-master/rlib/algorithms/a3c/agent.py": {
        "A3CAgent.__init__": {
            "name": "__init__",
            "location": 15,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/algorithms/a3c/__init__.py": {},
    "rlib-master/rlib/algorithms/ddpg/agent.py": {
        "DDPGAgent.__init__": {
            "name": "__init__",
            "location": 30,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_size": [
                    "int"
                ],
                "action_size": [
                    "int"
                ],
                "num_agents": [
                    "int"
                ],
                "actor_local": [
                    "None"
                ],
                "actor_target": [
                    "None"
                ],
                "actor_optimizer": [
                    "None"
                ],
                "critic_local": [
                    "None"
                ],
                "critic_target": [
                    "None"
                ],
                "critic_optimizer": [
                    "None"
                ],
                "new_hyperparameters": [
                    "None"
                ],
                "seed": [
                    "int"
                ],
                "device": [
                    "str"
                ],
                "model_output_dir": [
                    "str"
                ],
                "enable_logger": [
                    "bool"
                ],
                "logger_path": [
                    "str"
                ],
                "logger_comment": [
                    "str"
                ],
                "opt_soft_update": [
                    "bool"
                ]
            }
        },
        "DDPGAgent.__str__": {
            "name": "__str__",
            "location": 115,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGAgent.origin": {
            "name": "origin",
            "location": 132,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGAgent.description": {
            "name": "description",
            "location": 140,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGAgent.step": {
            "name": "step",
            "location": 155,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "states": [],
                "actions": [],
                "rewards": [],
                "next_states": [],
                "dones": [],
                "logger": [
                    "None"
                ]
            }
        },
        "DDPGAgent.act": {
            "name": "act",
            "location": 180,
            "return": [],
            "arguments": {
                "self": [],
                "state": [],
                "add_noise": [
                    "bool"
                ],
                "logger": [
                    "None"
                ]
            }
        },
        "DDPGAgent.learn": {
            "name": "learn",
            "location": 221,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "experiences": [],
                "logger": [
                    "None"
                ]
            }
        }
    },
    "rlib-master/rlib/algorithms/ddpg/model.py": {
        "hidden_init": {
            "name": "hidden_init",
            "location": 8,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "layer": [
                    "bool",
                    "str",
                    "list[str]",
                    "List[str]",
                    "torch.Tensor"
                ]
            }
        },
        "Actor.__init__": {
            "name": "__init__",
            "location": 17,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_size": [
                    "int"
                ],
                "action_size": [
                    "int"
                ],
                "seed": [
                    "int"
                ],
                "fc1_units": [
                    "int"
                ],
                "fc2_units": [
                    "int"
                ]
            }
        },
        "Actor.reset_parameters": {
            "name": "reset_parameters",
            "location": 40,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Actor.forward": {
            "name": "forward",
            "location": 47,
            "return": [
                "str",
                "Optional[str]",
                "int"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "list[int]",
                    "List[int]",
                    "dict[str, str]",
                    "Dict[str, str]",
                    "typing.Callable[..., None]",
                    "torch.Tensor",
                    "Callable[..., None]"
                ]
            }
        },
        "Critic.__init__": {
            "name": "__init__",
            "location": 64,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_size": [
                    "int"
                ],
                "action_size": [
                    "int"
                ],
                "seed": [
                    "int"
                ],
                "fcs1_units": [
                    "int"
                ],
                "fc2_units": [
                    "int"
                ]
            }
        },
        "Critic.reset_parameters": {
            "name": "reset_parameters",
            "location": 86,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Critic.forward": {
            "name": "forward",
            "location": 91,
            "return": [
                "str",
                "Tuple[str]"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "list[int]",
                    "List[int]",
                    "dict[str, str]",
                    "Dict[str, str]",
                    "typing.Callable[..., None]",
                    "torch.Tensor",
                    "Callable[..., None]"
                ],
                "action": []
            }
        }
    },
    "rlib-master/rlib/algorithms/ddpg/__init__.py": {},
    "rlib-master/rlib/algorithms/dqn/agent.py": {
        "DQNAgent.__init__": {
            "name": "__init__",
            "location": 34,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_size": [
                    "int"
                ],
                "action_size": [
                    "int"
                ],
                "qnetwork_local": [
                    "int",
                    "float",
                    "None",
                    "Union[float, List[float]]",
                    "list[float]"
                ],
                "qnetwork_target": [
                    "int",
                    "None",
                    "bool"
                ],
                "optimizer": [
                    "str",
                    "None",
                    "Optional[int]",
                    "int"
                ],
                "new_hyperparameters": [
                    "str",
                    "None",
                    "Set[Tuple[int, int]]",
                    "int",
                    "set[tuple[typing.Union[int,int]]]",
                    "Optional[int]",
                    "bool",
                    "dict[, ]",
                    "dict"
                ],
                "seed": [
                    "int"
                ],
                "device": [
                    "str"
                ],
                "model_output_dir": [
                    "str"
                ],
                "opt_soft_update": [
                    "bool"
                ],
                "opt_ddqn": [
                    "bool"
                ]
            }
        },
        "DQNAgent.__str__": {
            "name": "__str__",
            "location": 109,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQNAgent.origin": {
            "name": "origin",
            "location": 122,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQNAgent.description": {
            "name": "description",
            "location": 130,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "DQNAgent.step": {
            "name": "step",
            "location": 145,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "float",
                    "int",
                    "list[]",
                    "numpy.array",
                    "list"
                ],
                "action": [
                    "float",
                    "int",
                    "list[]",
                    "numpy.array",
                    "list"
                ],
                "reward": [
                    "float",
                    "int",
                    "list[]",
                    "numpy.array",
                    "list"
                ],
                "next_state": [
                    "float",
                    "int",
                    "list[]",
                    "numpy.array",
                    "list"
                ],
                "done": [
                    "float",
                    "int",
                    "list[]",
                    "numpy.array",
                    "list"
                ],
                "logger": [
                    "bool",
                    "None",
                    "str",
                    "float",
                    "int"
                ]
            }
        },
        "DQNAgent.act": {
            "name": "act",
            "location": 165,
            "return": [
                "str",
                "numpy.ndarray",
                "float"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "torch.Tensor",
                    "tuple[typing.Union[int,int]]",
                    "numpy.array",
                    "Tuple[int, int]"
                ],
                "eps": [
                    "float",
                    "int",
                    "dict",
                    "numpy.ndarray",
                    "torch.Tensor"
                ],
                "add_noise": [
                    "bool",
                    "torch.Tensor",
                    "int"
                ],
                "logger": [
                    "None",
                    "bool",
                    "torch.Tensor",
                    "int"
                ]
            }
        },
        "DQNAgent.learn": {
            "name": "learn",
            "location": 189,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "experiences": [
                    "list[]",
                    "list",
                    "tuple[torch.Tensor]",
                    "Tuple[torch.Tensor]",
                    "typing.Callable[, ]",
                    "Callable",
                    "raiden.utils.Locksroot"
                ],
                "logger": [
                    "bool",
                    "str",
                    "None"
                ]
            }
        }
    },
    "rlib-master/rlib/algorithms/dqn/model.py": {
        "QNetwork.__init__": {
            "name": "__init__",
            "location": 9,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_size": [
                    "int"
                ],
                "action_size": [
                    "int"
                ],
                "hidden_layer_input_size": [
                    "int"
                ],
                "hidden_layer_output_size": [
                    "int"
                ],
                "seed": [
                    "int"
                ],
                "softmax_output": [
                    "bool"
                ]
            }
        },
        "QNetwork.forward": {
            "name": "forward",
            "location": 35,
            "return": [
                "str",
                "list[]",
                "int",
                "float",
                "list[typing.Type]"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "list[int]",
                    "List[int]",
                    "dict[str, str]",
                    "Dict[str, str]",
                    "typing.Callable[..., None]",
                    "torch.Tensor",
                    "Callable[..., None]"
                ]
            }
        }
    },
    "rlib-master/rlib/algorithms/dqn/__init__.py": {},
    "rlib-master/rlib/algorithms/maddpg/agent.py": {
        "MADDPGAgent.__init__": {
            "name": "__init__",
            "location": 33,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": [],
                "state_size": [],
                "action_size": [],
                "num_agents": [],
                "agents": [
                    "None"
                ],
                "new_hyperparameters": [
                    "None"
                ],
                "seed": [
                    "int"
                ],
                "device": [
                    "typing.Text"
                ],
                "model_output_dir": [
                    "None"
                ],
                "enable_logger": [
                    "bool"
                ],
                "logger_path": [
                    "None"
                ],
                "logger_comment": [
                    "None"
                ],
                "opt_soft_update": [
                    "bool"
                ]
            }
        },
        "MADDPGAgent.reset": {
            "name": "reset",
            "location": 82,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "MADDPGAgent.act": {
            "name": "act",
            "location": 87,
            "return": [
                "np.ndarray"
            ],
            "arguments": {
                "self": [],
                "observations": [],
                "add_noise": [
                    "bool"
                ],
                "logger": [
                    "None"
                ]
            }
        },
        "MADDPGAgent.step": {
            "name": "step",
            "location": 96,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "observations": [],
                "actions": [],
                "rewards": [],
                "next_observations": [],
                "dones": [],
                "logger": [
                    "None"
                ]
            }
        },
        "MADDPGAgent.learn": {
            "name": "learn",
            "location": 112,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "experiences": [],
                "agent_number": [],
                "logger": [
                    "None"
                ]
            }
        },
        "MADDPGAgent._get_agent_number": {
            "name": "_get_agent_number",
            "location": 142,
            "return": [],
            "arguments": {
                "self": [],
                "i": []
            }
        },
        "DDPGAgent.__init__": {
            "name": "__init__",
            "location": 150,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_size": [],
                "action_size": [],
                "agent_id": [],
                "handler": [],
                "actor_local": [
                    "None"
                ],
                "actor_target": [
                    "None"
                ],
                "actor_optimizer": [
                    "None"
                ],
                "critic_local": [
                    "None"
                ],
                "critic_target": [
                    "None"
                ],
                "critic_optimizer": [
                    "None"
                ],
                "seed": [
                    "int"
                ],
                "device": [
                    "typing.Text"
                ]
            }
        },
        "DDPGAgent.__str__": {
            "name": "__str__",
            "location": 194,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "DDPGAgent.act": {
            "name": "act",
            "location": 208,
            "return": [],
            "arguments": {
                "self": [],
                "state": [],
                "add_noise": [
                    "bool"
                ],
                "logger": [
                    "None"
                ]
            }
        },
        "DDPGAgent.learn": {
            "name": "learn",
            "location": 223,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "experiences": [],
                "next_actions": [],
                "actions_pred": [],
                "logger": [
                    "None"
                ]
            }
        },
        "DDPGAgent._decay_noise_amplification": {
            "name": "_decay_noise_amplification",
            "location": 273,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/algorithms/maddpg/model.py": {
        "hidden_init": {
            "name": "hidden_init",
            "location": 8,
            "return": [
                "Tuple[(Any, Any)]"
            ],
            "arguments": {
                "layer": [
                    "bool",
                    "str",
                    "list[str]",
                    "List[str]",
                    "torch.Tensor"
                ]
            }
        },
        "Actor.__init__": {
            "name": "__init__",
            "location": 17,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_size": [
                    "int"
                ],
                "action_size": [
                    "str",
                    "int",
                    "List[int]",
                    "list[int]"
                ],
                "seed": [
                    "str",
                    "int",
                    "List[int]",
                    "list[int]"
                ],
                "fc1_units": [
                    "int"
                ],
                "fc2_units": [
                    "int",
                    "str",
                    "List[int]"
                ]
            }
        },
        "Actor.reset_parameters": {
            "name": "reset_parameters",
            "location": 34,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Actor.forward": {
            "name": "forward",
            "location": 39,
            "return": [
                "str",
                "Optional[str]",
                "int"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "list[int]",
                    "List[int]",
                    "dict[str, str]",
                    "Dict[str, str]",
                    "typing.Callable[..., None]",
                    "torch.Tensor",
                    "Callable[..., None]"
                ]
            }
        },
        "Critic.__init__": {
            "name": "__init__",
            "location": 49,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_size": [
                    "int",
                    "List[float]",
                    "list[float]",
                    "List[str]",
                    "list[str]",
                    "List[int]",
                    "list[int]"
                ],
                "action_size": [
                    "int",
                    "List[float]",
                    "list[float]",
                    "List[str]",
                    "list[str]",
                    "List[int]",
                    "list[int]"
                ],
                "seed": [
                    "str",
                    "int",
                    "List[int]",
                    "list[int]"
                ],
                "fcs1_units": [
                    "int",
                    "List[float]",
                    "List[str]",
                    "List[int]"
                ],
                "fc2_units": [
                    "int",
                    "str",
                    "List[int]"
                ]
            }
        },
        "Critic.reset_parameters": {
            "name": "reset_parameters",
            "location": 66,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Critic.forward": {
            "name": "forward",
            "location": 71,
            "return": [
                "str",
                "Tuple[str]"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "str",
                    "bool",
                    "torch.Tensor",
                    "numpy.ndarray",
                    "numpy.array",
                    "int"
                ],
                "action": [
                    "str",
                    "bool",
                    "torch.Tensor",
                    "numpy.ndarray",
                    "numpy.array",
                    "int"
                ]
            }
        }
    },
    "rlib-master/rlib/algorithms/maddpg/__init__.py": {},
    "rlib-master/rlib/algorithms/ppo/agent.py": {
        "PPOAgent.__init__": {
            "name": "__init__",
            "location": 27,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": [],
                "state_size": [
                    "int",
                    "str",
                    "None",
                    "bool",
                    "Optional[int]"
                ],
                "action_size": [
                    "int",
                    "str",
                    "None",
                    "bool",
                    "Optional[int]"
                ],
                "policy": [
                    "int",
                    "None",
                    "str",
                    "bool",
                    "Optional[int]"
                ],
                "optimizer": [
                    "str",
                    "None",
                    "bool",
                    "Optional[Dict]",
                    "dict[, ]",
                    "list",
                    "list[]",
                    "int",
                    "Optional[bool]"
                ],
                "new_hyperparameters": [
                    "bool",
                    "None",
                    "str",
                    "int"
                ],
                "seed": [
                    "int",
                    "str",
                    "Union[int, str]"
                ],
                "device": [
                    "typing.Text",
                    "int",
                    "Optional[int]",
                    "Optional[str]",
                    "bool"
                ],
                "model_output_dir": [
                    "str",
                    "None",
                    "bytes",
                    "Optional[str]"
                ],
                "enable_logger": [
                    "bool",
                    "str",
                    "int"
                ],
                "logger_path": [
                    "bool",
                    "None",
                    "str",
                    "int"
                ],
                "logger_comment": [
                    "bool",
                    "None",
                    "str",
                    "int"
                ]
            }
        },
        "PPOAgent.reset": {
            "name": "reset",
            "location": 78,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "PPOAgent.step": {
            "name": "step",
            "location": 81,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "bool",
                    "List[Callable]",
                    "list[typing.Callable[, ]]"
                ],
                "action": [
                    "bool",
                    "List[Callable]",
                    "list[typing.Callable[, ]]"
                ],
                "reward": [
                    "bool",
                    "List[Callable]",
                    "list[typing.Callable[, ]]"
                ],
                "next_state": [
                    "bool",
                    "List[Callable]",
                    "list[typing.Callable[, ]]"
                ],
                "done": [
                    "bool",
                    "List[Callable]",
                    "list[typing.Callable[, ]]"
                ],
                "logger": [
                    "bool",
                    "None",
                    "List[Callable]",
                    "list[typing.Callable[, ]]"
                ]
            }
        },
        "PPOAgent.act": {
            "name": "act",
            "location": 85,
            "return": [
                "list",
                "List[T]",
                "List[float]",
                "int"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "numpy.ndarray",
                    "float",
                    "str",
                    "None",
                    "Optional[torch.device]"
                ],
                "add_noise": [
                    "bool",
                    "Set[str]",
                    "Optional[str]",
                    "Dict[str, object]",
                    "Optional[IO[bytes]]",
                    "graphql.execution.base.ResolveInfo"
                ],
                "logger": [
                    "bool",
                    "None",
                    "Set[str]",
                    "Optional[str]",
                    "set[str]",
                    "Dict[str, object]",
                    "str",
                    "Optional[IO[bytes]]",
                    "dict[str, object]",
                    "graphql.execution.base.ResolveInfo",
                    "typing.IO"
                ]
            }
        },
        "PPOAgent.update": {
            "name": "update",
            "location": 94,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "rewards": [
                    "int",
                    "list",
                    "List[str]",
                    "List[int]",
                    "List[Tuple[int, int]]",
                    "str"
                ],
                "logger": [
                    "int",
                    "None",
                    "bool",
                    "str",
                    "dict",
                    "dict[, ]"
                ]
            }
        },
        "PPOAgent.clipped_surrogate": {
            "name": "clipped_surrogate",
            "location": 117,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "policy": [
                    "typing.Sequence[str]",
                    "Sequence[str]",
                    "dict[, ]",
                    "torch.Tensor",
                    "dict"
                ],
                "old_probs": [],
                "states": [
                    "typing.Sequence[str]",
                    "Sequence[str]",
                    "dict[, ]",
                    "torch.Tensor",
                    "dict"
                ],
                "actions": [
                    "Optional[Any]",
                    "typing.Any",
                    "Dict[str, torch.Tensor]",
                    "None",
                    "Callable",
                    "dict[str, torch.Tensor]",
                    "typing.Callable[, ]"
                ],
                "rewards": [
                    "Optional[Tuple[torch.Tensor, torch.Tensor]]",
                    "List[int]",
                    "torch.Tensor",
                    "bytes"
                ],
                "discount": [
                    "float",
                    "Optional[Tuple[torch.Tensor, torch.Tensor]]",
                    "List[int]",
                    "torch.Tensor",
                    "bytes"
                ],
                "epsilon": [
                    "float",
                    "Sequence[str]",
                    "torch.Tensor",
                    "dict"
                ],
                "beta": [
                    "float",
                    "Sequence[str]",
                    "torch.Tensor",
                    "dict"
                ]
            }
        }
    },
    "rlib-master/rlib/algorithms/ppo/model.py": {
        "Policy.__init__": {
            "name": "__init__",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "s_size": [
                    "int",
                    "Optional[int]",
                    "List[float]",
                    "float",
                    "torch.BoolTensor",
                    "str",
                    "allennlp.nn.beam_search.BeamSearch"
                ],
                "h_size": [
                    "int",
                    "Optional[int]",
                    "Union[Tuple[int, int], int]",
                    "torch.BoolTensor",
                    "float"
                ],
                "a_size": [
                    "int",
                    "Optional[int]",
                    "float"
                ]
            }
        },
        "Policy.forward": {
            "name": "forward",
            "location": 12,
            "return": [
                "str"
            ],
            "arguments": {
                "self": [],
                "x": [
                    "torch.Tensor"
                ]
            }
        }
    },
    "rlib-master/rlib/algorithms/ppo/__init__.py": {},
    "rlib-master/rlib/algorithms/sac/agent.py": {
        "SACAgent.__init__": {
            "name": "__init__",
            "location": 15,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/algorithms/sac/__init__.py": {},
    "rlib-master/rlib/algorithms/td3/agent.py": {
        "TD3Agent.__init__": {
            "name": "__init__",
            "location": 15,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/algorithms/td3/__init__.py": {},
    "rlib-master/rlib/algorithms/trpo/agent.py": {
        "TRPOAgent.__init__": {
            "name": "__init__",
            "location": 15,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/algorithms/trpo/__init__.py": {},
    "rlib-master/rlib/algorithms/vpg/agent.py": {
        "VPGAgent.__init__": {
            "name": "__init__",
            "location": 24,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state_size": [
                    "int"
                ],
                "action_size": [
                    "int"
                ],
                "policy": [
                    "int",
                    "None",
                    "str",
                    "bool",
                    "Optional[int]"
                ],
                "optimizer": [
                    "str",
                    "None",
                    "bool",
                    "Optional[Dict]",
                    "dict[, ]",
                    "list",
                    "list[]",
                    "int",
                    "Optional[bool]"
                ],
                "new_hyperparameters": [
                    "bool",
                    "None",
                    "bytes",
                    "Optional[bool]"
                ],
                "seed": [
                    "int"
                ],
                "device": [
                    "str"
                ],
                "model_output_dir": [
                    "str",
                    "None",
                    "bytes",
                    "Optional[str]"
                ],
                "enable_logger": [
                    "bool"
                ],
                "logger_path": [
                    "str"
                ],
                "logger_comment": [
                    "str"
                ]
            }
        },
        "VPGAgent.__str__": {
            "name": "__str__",
            "location": 88,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "VPGAgent.origin": {
            "name": "origin",
            "location": 99,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "VPGAgent.description": {
            "name": "description",
            "location": 107,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "VPGAgent.reset": {
            "name": "reset",
            "location": 121,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "VPGAgent.step": {
            "name": "step",
            "location": 125,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "bool",
                    "List[Callable]",
                    "list[typing.Callable[, ]]"
                ],
                "action": [
                    "bool",
                    "List[Callable]",
                    "list[typing.Callable[, ]]"
                ],
                "reward": [
                    "bool",
                    "List[Callable]",
                    "list[typing.Callable[, ]]"
                ],
                "next_state": [
                    "bool",
                    "List[Callable]",
                    "list[typing.Callable[, ]]"
                ],
                "done": [
                    "bool",
                    "List[Callable]",
                    "list[typing.Callable[, ]]"
                ],
                "logger": [
                    "bool",
                    "None",
                    "List[Callable]",
                    "list[typing.Callable[, ]]"
                ]
            }
        },
        "VPGAgent.act": {
            "name": "act",
            "location": 129,
            "return": [
                "list",
                "List[T]",
                "List[float]",
                "int"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "numpy.ndarray",
                    "float",
                    "str",
                    "None",
                    "Optional[torch.device]"
                ],
                "add_noise": [
                    "bool",
                    "Set[str]",
                    "Optional[str]",
                    "Dict[str, object]",
                    "Optional[IO[bytes]]",
                    "graphql.execution.base.ResolveInfo"
                ],
                "logger": [
                    "bool",
                    "None",
                    "Set[str]",
                    "Optional[str]",
                    "set[str]",
                    "Dict[str, object]",
                    "str",
                    "Optional[IO[bytes]]",
                    "dict[str, object]",
                    "graphql.execution.base.ResolveInfo",
                    "typing.IO"
                ]
            }
        },
        "VPGAgent.update": {
            "name": "update",
            "location": 148,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "rewards": [
                    "int",
                    "list",
                    "List[str]",
                    "List[int]",
                    "List[Tuple[int, int]]",
                    "str"
                ],
                "logger": [
                    "int",
                    "None",
                    "bool",
                    "str",
                    "dict",
                    "dict[, ]"
                ]
            }
        }
    },
    "rlib-master/rlib/algorithms/vpg/model.py": {
        "Policy.__init__": {
            "name": "__init__",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "s_size": [
                    "int",
                    "Optional[int]",
                    "List[float]",
                    "float",
                    "torch.BoolTensor",
                    "str",
                    "allennlp.nn.beam_search.BeamSearch"
                ],
                "h_size": [
                    "int",
                    "Optional[int]",
                    "Union[Tuple[int, int], int]",
                    "torch.BoolTensor",
                    "float"
                ],
                "a_size": [
                    "int",
                    "Optional[int]",
                    "float"
                ]
            }
        },
        "Policy.forward": {
            "name": "forward",
            "location": 12,
            "return": [
                "str"
            ],
            "arguments": {
                "self": [],
                "x": [
                    "torch.Tensor"
                ]
            }
        }
    },
    "rlib-master/rlib/algorithms/vpg/__init__.py": {},
    "rlib-master/rlib/environments/base.py": {
        "BaseEnvironment.act": {
            "name": "act",
            "location": 6,
            "return": [
                "list[]",
                "int",
                "dict[str, int]",
                "Callable",
                "str"
            ],
            "arguments": {
                "self": [],
                "observations": [
                    "str",
                    "int",
                    "typing.Callable[, ]",
                    "Callable",
                    "Callable[[str], None]"
                ],
                "add_noise": [
                    "bool",
                    "str",
                    "Callable",
                    "int",
                    "Callable[[str], None]"
                ],
                "logger": [
                    "str",
                    "None",
                    "int",
                    "Callable",
                    "typing.Callable[, ]",
                    "Callable[[str], None]"
                ]
            }
        },
        "BaseEnvironment.plot_scores": {
            "name": "plot_scores",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "scores": [
                    "Dict[str, Set[str]]",
                    "List[str]",
                    "\"Counter\""
                ],
                "env_solved_score": [
                    "Dict[str, str]",
                    "None",
                    "bool",
                    "Iterable[str]",
                    "dict[str, str]"
                ]
            }
        },
        "BaseEnvironment.get_max_score_per_episode": {
            "name": "get_max_score_per_episode",
            "location": 43,
            "return": [
                "str",
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "BaseEnvironment.get_rolling_score_averages": {
            "name": "get_rolling_score_averages",
            "location": 47,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "window": [
                    "bool",
                    "dict[int, dict[, ]]",
                    "Dict[int, dict]",
                    "typing.Sequence[dict[str, typing.Any]]",
                    "Sequence[Dict[str, Any]]",
                    "int"
                ]
            }
        },
        "BaseEnvironment.get_current_average_score": {
            "name": "get_current_average_score",
            "location": 59,
            "return": [
                "str",
                "bool"
            ],
            "arguments": {
                "self": [],
                "window": [
                    "float",
                    "int",
                    "str",
                    "Optional[str]",
                    "type",
                    "Optional[float]"
                ]
            }
        }
    },
    "rlib-master/rlib/environments/gym.py": {
        "GymEnvironment.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env": [
                    "bool",
                    "str",
                    "dict[str, typing.Any]",
                    "Dict[str, Any]",
                    "int",
                    "tuple[typing.Type]",
                    "Tuple[Type]"
                ],
                "algorithm": [
                    "str",
                    "gym.Env",
                    "typing.Mapping",
                    "dict[, ]",
                    "Mapping[str, str]",
                    "list[str]",
                    "dict",
                    "List[str]"
                ],
                "seed": [
                    "int"
                ],
                "logger": [
                    "rlib.shared.utils.Logger"
                ],
                "gifs_recorder": [
                    "rlib.shared.utils.GIFRecorder"
                ]
            }
        },
        "GymEnvironment.__str__": {
            "name": "__str__",
            "location": 47,
            "return": [
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "GymEnvironment.start_env": {
            "name": "start_env",
            "location": 59,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "GymEnvironment.close_env": {
            "name": "close_env",
            "location": 64,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "GymEnvironment.is_observation_box": {
            "name": "is_observation_box",
            "location": 68,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "GymEnvironment.is_observation_discrete": {
            "name": "is_observation_discrete",
            "location": 71,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "GymEnvironment.is_action_box": {
            "name": "is_action_box",
            "location": 74,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "GymEnvironment.is_action_discrete": {
            "name": "is_action_discrete",
            "location": 77,
            "return": [
                "bool"
            ],
            "arguments": {
                "self": []
            }
        },
        "GymEnvironment.normalize_observation": {
            "name": "normalize_observation",
            "location": 80,
            "return": [
                "_T0"
            ],
            "arguments": {
                "self": [],
                "obs": [
                    "_T0"
                ]
            }
        },
        "GymEnvironment.train": {
            "name": "train",
            "location": 90,
            "return": [
                "List[float]"
            ],
            "arguments": {
                "self": [],
                "num_episodes": [
                    "int"
                ],
                "max_t": [
                    "int"
                ],
                "add_noise": [
                    "bool"
                ],
                "scores_window_size": [
                    "int"
                ],
                "save_every": [
                    "int"
                ]
            }
        },
        "GymEnvironment.test": {
            "name": "test",
            "location": 177,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_episodes": [
                    "int"
                ],
                "load_state_dicts": [
                    "bool"
                ],
                "render": [
                    "bool"
                ]
            }
        }
    },
    "rlib-master/rlib/environments/parallel_env.py": {
        "CloudpickleWrapper.__init__": {
            "name": "__init__",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "env_fn": [
                    "List[str]",
                    "list[str]",
                    "dict",
                    "dict[, ]"
                ]
            }
        },
        "CloudpickleWrapper.__getstate__": {
            "name": "__getstate__",
            "location": 21,
            "return": [
                "slice",
                "Iterable[Any]",
                "str",
                "bool",
                "List[str]"
            ],
            "arguments": {
                "self": []
            }
        },
        "CloudpickleWrapper.__setstate__": {
            "name": "__setstate__",
            "location": 25,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "ob": [
                    "Dict[str, Any]",
                    "dict[str, typing.Any]",
                    "dict",
                    "dict[, ]",
                    "List[dict]",
                    "list[dict[, ]]"
                ]
            }
        },
        "VectorizedEnv.__init__": {
            "name": "__init__",
            "location": 33,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "num_envs": [
                    "int",
                    "Optional[int]",
                    "None"
                ],
                "observation_space": [
                    "int",
                    "float",
                    "Union[str, float]",
                    "str"
                ],
                "action_space": [
                    "int",
                    "float",
                    "Union[str, float]",
                    "str"
                ]
            }
        },
        "VectorizedEnv.reset": {
            "name": "reset",
            "location": 39,
            "return": [
                "",
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "VectorizedEnv.step_async": {
            "name": "step_async",
            "location": 48,
            "return": [
                "",
                "None"
            ],
            "arguments": {
                "self": [],
                "actions": [
                    "int",
                    "str",
                    "typing.Iterable[C]",
                    "Iterable['Context']",
                    "dict",
                    "bool"
                ]
            }
        },
        "VectorizedEnv.step_wait": {
            "name": "step_wait",
            "location": 56,
            "return": [
                "",
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "VectorizedEnv.close": {
            "name": "close",
            "location": 68,
            "return": [
                "",
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "VectorizedEnv.step": {
            "name": "step",
            "location": 72,
            "return": [
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "self": [],
                "actions": [
                    "str",
                    "OrderedDict",
                    "typing.OrderedDict",
                    "DefaultDict[int, List[Any]]",
                    "typing.DefaultDict"
                ]
            }
        },
        "VectorizedEnv.render": {
            "name": "render",
            "location": 79,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "mode": [
                    "typing.Text",
                    "str",
                    "bool",
                    "Callable"
                ]
            }
        },
        "VectorizedEnv.unwrapped": {
            "name": "unwrapped",
            "location": 84,
            "return": [
                "VectorizedEnv",
                "int",
                "Callable",
                "str"
            ],
            "arguments": {
                "self": []
            }
        },
        "ParallelEnv.__init__": {
            "name": "__init__",
            "location": 92,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": [],
                "env_name": [
                    "str",
                    "int",
                    "Optional[str]",
                    "None"
                ],
                "n": [
                    "int",
                    "str",
                    "Optional[str]"
                ],
                "seed": [
                    "None",
                    "Optional[str]",
                    "bool",
                    "str",
                    "typing.Type",
                    "Type",
                    "int",
                    "Optional[int]"
                ],
                "spaces": [
                    "str",
                    "None",
                    "bool",
                    "Optional[str]"
                ]
            }
        },
        "ParallelEnv.step_async": {
            "name": "step_async",
            "location": 128,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "actions": [
                    "int",
                    "str",
                    "Callable",
                    "typing.Callable[, ]"
                ]
            }
        },
        "ParallelEnv.step_wait": {
            "name": "step_wait",
            "location": 133,
            "return": [
                "Tuple[(Any, Any, Any, Any)]"
            ],
            "arguments": {
                "self": []
            }
        },
        "ParallelEnv.reset": {
            "name": "reset",
            "location": 139,
            "return": [
                "str",
                "int",
                "tuple",
                "List[str]",
                "list",
                "Union[List[str], str]",
                "float"
            ],
            "arguments": {
                "self": []
            }
        },
        "ParallelEnv.reset_task": {
            "name": "reset_task",
            "location": 144,
            "return": [
                "bool",
                "float",
                "Tuple[float]",
                "List[int]",
                "Tuple[int]",
                "List[List[Any]]"
            ],
            "arguments": {
                "self": []
            }
        },
        "ParallelEnv.close": {
            "name": "close",
            "location": 149,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "ParallelEnv.worker": {
            "name": "worker",
            "location": 162,
            "return": [
                "None"
            ],
            "arguments": {
                "remote": [
                    "str",
                    "Optional[str]",
                    "bool",
                    "AbstractSet"
                ],
                "parent_remote": [
                    "bool",
                    "float",
                    "Dict[str, int]",
                    "Optional[List[str]]"
                ],
                "env_fn_wrapper": [
                    "bool"
                ]
            }
        }
    },
    "rlib-master/rlib/environments/unity.py": {
        "UnityEnvironment.__init__": {
            "name": "__init__",
            "location": 9,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/environments/__init__.py": {},
    "rlib-master/rlib/shared/noise.py": {
        "OUNoise.__init__": {
            "name": "__init__",
            "location": 10,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "size": [
                    "int",
                    "bytes"
                ],
                "seed": [
                    "int"
                ],
                "mu": [
                    "float"
                ],
                "theta": [
                    "float"
                ],
                "sigma": [
                    "float"
                ]
            }
        },
        "OUNoise.reset": {
            "name": "reset",
            "location": 29,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "OUNoise.sample": {
            "name": "sample",
            "location": 33,
            "return": [
                "Callable",
                "List[str]",
                "dict",
                "int"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/shared/replay_buffer.py": {
        "ReplayBuffer.__init__": {
            "name": "__init__",
            "location": 11,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "buffer_size": [
                    "int"
                ],
                "batch_size": [
                    "int"
                ],
                "device": [
                    "str"
                ],
                "seed": [
                    "int"
                ]
            }
        },
        "ReplayBuffer.add": {
            "name": "add",
            "location": 29,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "state": [
                    "int",
                    "float",
                    "torch.LongTensor",
                    "numpy.ndarray",
                    "torch.Tensor",
                    "bool"
                ],
                "action": [
                    "int",
                    "float",
                    "torch.LongTensor",
                    "numpy.ndarray",
                    "torch.Tensor",
                    "bool"
                ],
                "reward": [
                    "int",
                    "float",
                    "torch.LongTensor",
                    "numpy.ndarray",
                    "torch.Tensor",
                    "bool"
                ],
                "next_state": [
                    "int",
                    "float",
                    "torch.LongTensor",
                    "numpy.ndarray",
                    "torch.Tensor",
                    "bool"
                ],
                "done": [
                    "int",
                    "float",
                    "torch.LongTensor",
                    "numpy.ndarray",
                    "torch.Tensor",
                    "bool"
                ]
            }
        },
        "ReplayBuffer.sample": {
            "name": "sample",
            "location": 42,
            "return": [
                "Tuple[(Any, Any, Any, Any, Any)]"
            ],
            "arguments": {
                "self": []
            }
        },
        "ReplayBuffer.__len__": {
            "name": "__len__",
            "location": 74,
            "return": [
                "int"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/rlib/shared/utils.py": {
        "hard_update": {
            "name": "hard_update",
            "location": 93,
            "return": [
                "None"
            ],
            "arguments": {
                "local_model": [],
                "target_model": []
            }
        },
        "soft_update": {
            "name": "soft_update",
            "location": 106,
            "return": [
                "None"
            ],
            "arguments": {
                "local_model": [],
                "target_model": [],
                "tau": [
                    "float"
                ]
            }
        },
        "Logger.__init__": {
            "name": "__init__",
            "location": 14,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ],
                "comment": [
                    "str"
                ],
                "verbosity": [
                    "str"
                ],
                "experiment_name": [
                    "str"
                ]
            }
        },
        "Logger.close": {
            "name": "close",
            "location": 39,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "Logger.add_scalar": {
            "name": "add_scalar",
            "location": 43,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "name": [
                    "str"
                ],
                "data": [],
                "index": [
                    "int"
                ]
            }
        },
        "Logger.add_scalars": {
            "name": "add_scalars",
            "location": 47,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "name": [
                    "str"
                ],
                "data": [],
                "index": [
                    "int"
                ]
            }
        },
        "Logger.add_video": {
            "name": "add_video",
            "location": 51,
            "return": [
                "NoReturn"
            ],
            "arguments": {
                "self": []
            }
        },
        "GIFRecorder.__init__": {
            "name": "__init__",
            "location": 58,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "path": [
                    "str"
                ],
                "duration": [
                    "float"
                ],
                "experiment_name": [
                    "str"
                ]
            }
        },
        "GIFRecorder.save_gif": {
            "name": "save_gif",
            "location": 79,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "filename": [
                    "str"
                ],
                "frames": []
            }
        }
    },
    "rlib-master/rlib/shared/__init__.py": {},
    "rlib-master/test/__init__.py": {},
    "rlib-master/test/algorithms/ddpg_test.py": {
        "main": {
            "name": "main",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "seed": [
                    "int",
                    "bool"
                ]
            }
        }
    },
    "rlib-master/test/algorithms/dqn_test.py": {
        "main": {
            "name": "main",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "seed": [
                    "int",
                    "List[float]",
                    "str"
                ]
            }
        }
    },
    "rlib-master/test/algorithms/vpg_test.py": {
        "main": {
            "name": "main",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "seed": [
                    "int",
                    "List[float]",
                    "str"
                ]
            }
        }
    },
    "rlib-master/test/algorithms/__init__.py": {},
    "rlib-master/test/environments/test_base.py": {
        "BaseEnvironmentTest.setUp": {
            "name": "setUp",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/test/environments/test_gym.py": {
        "GymEnvironmentTest.setUp": {
            "name": "setUp",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/test/environments/test_unity.py": {
        "UnityEnvironmentTest.setUp": {
            "name": "setUp",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/test/environments/__init__.py": {},
    "rlib-master/test/shared/test_noise.py": {
        "OUNoiseTest.setUp": {
            "name": "setUp",
            "location": 10,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "OUNoiseTest.test_reset": {
            "name": "test_reset",
            "location": 13,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "OUNoiseTest.test_sample": {
            "name": "test_sample",
            "location": 20,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/test/shared/test_replay_buffer.py": {
        "ReplayBufferTest.setUp": {
            "name": "setUp",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "ReplayBufferTest.populate_replay_buffer": {
            "name": "populate_replay_buffer",
            "location": 12,
            "return": [
                "None"
            ],
            "arguments": {
                "self": [],
                "n": [
                    "int"
                ]
            }
        },
        "ReplayBufferTest.test_add": {
            "name": "test_add",
            "location": 18,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "ReplayBufferTest.test_sample": {
            "name": "test_sample",
            "location": 26,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/test/shared/test_units.py": {
        "UtilsTest.test_hard_update": {
            "name": "test_hard_update",
            "location": 7,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        },
        "UtilsTest.test_soft_update": {
            "name": "test_soft_update",
            "location": 10,
            "return": [
                "None"
            ],
            "arguments": {
                "self": []
            }
        }
    },
    "rlib-master/test/shared/__init__.py": {}
}